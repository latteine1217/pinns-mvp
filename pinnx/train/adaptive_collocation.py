"""
è‡ªé©æ‡‰æ®˜å·®é»ï¼ˆCollocation Pointsï¼‰æ¡æ¨£å™¨

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. é€±æœŸæ€§æ®˜å·®é»é‡é¸/å¢è£œï¼ˆé¿å…éæ“¬åˆå›ºå®šé»é›†ï¼‰
2. æ®˜å·® SVD â†’ QR-pivot é¸é»ï¼ˆå°ˆæ³¨é«˜æ®˜å·®/é«˜ä¸ç¢ºå®šå€åŸŸï¼‰
3. å¢é‡æ›¿æ›ç­–ç•¥ï¼ˆä¿ç•™æ­·å²é»é¿å…ç½é›£æ€§éºå¿˜ï¼‰
4. ç©ºé–“ç´„æŸï¼ˆæœ€å°é»é–“è·é˜²èšé›†ï¼‰
5. æ§“æ¡¿åˆ†æ•¸è©•ä¼°ï¼ˆç§»é™¤ä½å½±éŸ¿åŠ›é»ï¼‰

ç†è«–ä¾æ“šï¼š
- Adaptive Residual Sampling (Wang et al., 2022)
- R-PINN: Residual-based Adaptive Sampling (Wu & Karniadakis, 2020)
- Greedy Selection via Leverage Scores (Drineas et al., 2012)

åƒè€ƒæ–‡ç»ï¼š
- Understanding and Mitigating Gradient Flow Pathologies in PINNs (Wang et al., 2021)
- When and Why PINNs Fail: A Survey (Krishnapriyan et al., 2021)
"""

import numpy as np
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Optional, Union, Callable
from scipy.linalg import qr, svd
from scipy.spatial.distance import pdist, squareform
import logging

logger = logging.getLogger(__name__)


class AdaptiveCollocationSampler:
    """
    è‡ªé©æ‡‰æ®˜å·®é»æ¡æ¨£å™¨
    
    å¯¦ç¾é€±æœŸæ€§æ®˜å·®é»é‡é¸ï¼ŒåŸºæ–¼æ®˜å·®åˆ†ä½ˆå’Œ QR-pivot ç­–ç•¥ã€‚
    """
    
    def __init__(self, config: Dict):
        """
        Args:
            config: é…ç½®å­—å…¸ï¼ˆå°æ‡‰ YAML ä¸­çš„ adaptive_collocation å€å¡Šï¼‰
        """
        self.config = config
        self.enabled = config.get('enabled', True)
        
        # è§¸ç™¼æ¢ä»¶
        trigger_cfg = config.get('trigger', {})
        self.trigger_method = trigger_cfg.get('method', 'epoch_interval')
        self.epoch_interval = trigger_cfg.get('epoch_interval', 1000)
        self.stagnation_window = trigger_cfg.get('stagnation_window', 500)
        self.stagnation_threshold = trigger_cfg.get('stagnation_threshold', 0.01)
        self.residual_percentile = trigger_cfg.get('residual_percentile', 95)
        self.residual_threshold = trigger_cfg.get('residual_threshold', 0.1)
        
        # é‡é¸ç­–ç•¥
        self.resampling_strategy = config.get('resampling_strategy', 'incremental_replace')
        
        # å¢é‡æ›¿æ›åƒæ•¸
        incr_cfg = config.get('incremental_replace', {})
        self.keep_ratio = incr_cfg.get('keep_ratio', 0.7)
        self.replace_ratio = incr_cfg.get('replace_ratio', 0.3)
        self.removal_criterion = incr_cfg.get('removal_criterion', 'leverage_score')
        self.leverage_threshold = incr_cfg.get('leverage_threshold', 0.1)
        
        # æ®˜å·® QR é…ç½®
        residual_qr_cfg = config.get('residual_qr', {})
        self.residual_qr_enabled = residual_qr_cfg.get('enabled', True)
        self.candidate_pool_size = residual_qr_cfg.get('candidate_pool_size', 16384)
        self.candidate_sampling = residual_qr_cfg.get('candidate_sampling', 'latin_hypercube')
        
        # å¿«ç…§é…ç½®
        snapshot_cfg = residual_qr_cfg.get('snapshot_config', {})
        self.n_snapshots = snapshot_cfg.get('n_snapshots', 20)
        self.snapshot_method = snapshot_cfg.get('snapshot_method', 'batch')
        
        # SVD é…ç½®
        svd_cfg = residual_qr_cfg.get('svd', {})
        self.energy_threshold = svd_cfg.get('energy_threshold', 0.99)
        self.max_rank = svd_cfg.get('max_rank', 50)
        self.svd_centering = svd_cfg.get('centering', True)
        
        # QR é…ç½®
        qr_cfg = residual_qr_cfg.get('qr', {})
        self.qr_column_pivoting = qr_cfg.get('column_pivoting', True)
        self.qr_tolerance = qr_cfg.get('tolerance', 1e-10)
        
        # ç©ºé–“ç´„æŸ
        spatial_cfg = residual_qr_cfg.get('spatial_constraints', {})
        self.spatial_constraints_enabled = spatial_cfg.get('enabled', True)
        self.min_distance = spatial_cfg.get('min_distance', 0.02)
        self.max_distance = spatial_cfg.get('max_distance', None)
        
        # å…§éƒ¨ç‹€æ…‹
        self.loss_history = []
        self.residual_snapshots = []
        self.candidate_pool = None
        self.last_trigger_epoch = 0
        
    def should_trigger(self, 
                      epoch: int, 
                      current_loss: float,
                      residuals: Optional[torch.Tensor] = None) -> bool:
        """
        æª¢æŸ¥æ˜¯å¦æ‡‰è©²è§¸ç™¼æ®˜å·®é»é‡é¸
        
        Args:
            epoch: ç•¶å‰ epoch
            current_loss: ç•¶å‰æå¤±å€¼
            residuals: ç•¶å‰æ®˜å·®å¼µé‡ [N_pde,] ï¼ˆå¯é¸ï¼‰
            
        Returns:
            æ˜¯å¦è§¸ç™¼é‡é¸
        """
        if not self.enabled:
            return False
        
        # è¨˜éŒ„æå¤±æ­·å²
        self.loss_history.append(current_loss)
        
        # æ–¹æ³• 1: å›ºå®šé–“éš”è§¸ç™¼
        if self.trigger_method in ['epoch_interval', 'hybrid']:
            if epoch > 0 and epoch % self.epoch_interval == 0:
                logger.info(f"è§¸ç™¼æ¢ä»¶: epoch é–“éš” ({epoch} % {self.epoch_interval} == 0)")
                self.last_trigger_epoch = epoch
                return True
        
        # æ–¹æ³• 2: æå¤±åœæ»¯è§¸ç™¼
        if self.trigger_method in ['loss_stagnation', 'hybrid']:
            if len(self.loss_history) >= self.stagnation_window:
                recent_losses = self.loss_history[-self.stagnation_window:]
                improvement = (max(recent_losses) - min(recent_losses)) / (max(recent_losses) + 1e-16)
                
                if improvement < self.stagnation_threshold:
                    logger.info(f"è§¸ç™¼æ¢ä»¶: æå¤±åœæ»¯ (æ”¹å–„={improvement:.4f} < {self.stagnation_threshold})")
                    self.last_trigger_epoch = epoch
                    return True
        
        # æ–¹æ³• 3: æ®˜å·®é–¾å€¼è§¸ç™¼
        if residuals is not None:
            residual_np = residuals.detach().cpu().numpy()
            percentile_value = np.percentile(np.abs(residual_np), self.residual_percentile)
            
            if percentile_value > self.residual_threshold:
                logger.info(f"è§¸ç™¼æ¢ä»¶: æ®˜å·®é–¾å€¼ ({self.residual_percentile}% = {percentile_value:.4f} > {self.residual_threshold})")
                self.last_trigger_epoch = epoch
                return True
        
        return False
    
    def resample_collocation_points(self,
                                   current_points: torch.Tensor,
                                   domain_bounds: Dict[str, Tuple[float, float]],
                                   residual_fn: Callable,
                                   n_keep: Optional[int] = None,
                                   device: str = 'cpu') -> Tuple[torch.Tensor, Dict]:
        """
        é‡é¸æ®˜å·®é»ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        
        Args:
            current_points: ç•¶å‰æ®˜å·®é» [N_old, dim]
            domain_bounds: åŸŸé‚Šç•Œ {'x': (xmin, xmax), 'y': (ymin, ymax), ...}
            residual_fn: æ®˜å·®è¨ˆç®—å‡½æ•¸ points -> residuals [N, n_equations]
            n_keep: ä¿ç•™é»æ•¸ï¼ˆNone = è‡ªå‹•è¨ˆç®—ï¼‰
            device: è¨ˆç®—è¨­å‚™
            
        Returns:
            (new_points, metrics)
            - new_points: æ–°æ®˜å·®é» [N_new, dim]
            - metrics: çµ±è¨ˆæŒ‡æ¨™å­—å…¸
        """
        N_old = current_points.shape[0]
        dim = current_points.shape[1]
        
        # è¨ˆç®—ä¿ç•™å’Œæ›¿æ›æ•¸é‡
        if n_keep is None:
            n_keep = int(N_old * self.keep_ratio)
        n_replace = N_old - n_keep
        
        logger.info(f"æ®˜å·®é»é‡é¸: ä¿ç•™ {n_keep}/{N_old} é»ï¼Œæ›¿æ› {n_replace} é»")
        
        # ========================================
        # Step 1: é¸æ“‡è¦ä¿ç•™çš„é»
        # ========================================
        if self.removal_criterion == 'leverage_score':
            # åŸºæ–¼æ§“æ¡¿åˆ†æ•¸é¸æ“‡ä¿ç•™é»
            keep_indices = self._select_by_leverage_score(
                current_points, residual_fn, n_keep, device)
        elif self.removal_criterion == 'low_residual':
            # ä¿ç•™ä½æ®˜å·®é»ï¼ˆå·²æ”¶æ–‚å€åŸŸï¼‰
            with torch.no_grad():
                residuals = residual_fn(current_points.to(device))
                residual_norms = torch.norm(residuals, dim=-1).cpu()
            keep_indices = torch.argsort(residual_norms)[:n_keep]
        elif self.removal_criterion == 'random':
            # éš¨æ©Ÿä¿ç•™
            keep_indices = torch.randperm(N_old)[:n_keep]
        else:
            # é»˜èªï¼šéš¨æ©Ÿä¿ç•™
            keep_indices = torch.randperm(N_old)[:n_keep]
        
        kept_points = current_points[keep_indices]
        
        # ========================================
        # Step 2: ç”Ÿæˆå€™é¸æ± 
        # ========================================
        if self.candidate_pool is None or self.candidate_pool.shape[0] < self.candidate_pool_size:
            self.candidate_pool = self._generate_candidate_pool(
                domain_bounds, self.candidate_pool_size, dim)
        
        # ========================================
        # Step 3: æ®˜å·® SVD â†’ QR é¸é»
        # ========================================
        if self.residual_qr_enabled:
            new_indices, qr_metrics = self._residual_qr_selection(
                self.candidate_pool, residual_fn, n_replace, device)
            new_points = self.candidate_pool[new_indices]
        else:
            # å›é€€ï¼šéš¨æ©Ÿé¸æ“‡
            random_indices = np.random.choice(
                self.candidate_pool.shape[0], n_replace, replace=False)
            new_points = self.candidate_pool[random_indices]
            qr_metrics = {}
        
        # ========================================
        # Step 4: æ‡‰ç”¨ç©ºé–“ç´„æŸ
        # ========================================
        if self.spatial_constraints_enabled:
            new_points = self._apply_spatial_constraints(
                kept_points, new_points, self.min_distance)
        
        # ========================================
        # Step 5: åˆä½µä¿ç•™é»å’Œæ–°é»
        # ========================================
        final_points = torch.cat([kept_points, new_points], dim=0)
        
        # ========================================
        # Step 6: çµ±è¨ˆæŒ‡æ¨™
        # ========================================
        metrics = {
            'n_kept': n_keep,
            'n_replaced': len(new_points),
            'n_final': len(final_points),
            'keep_ratio': n_keep / N_old,
            **qr_metrics
        }
        
        logger.info(f"é‡é¸å®Œæˆ: {N_old} â†’ {len(final_points)} é» "
                   f"(ä¿ç•™={n_keep}, æ–°å¢={len(new_points)})")
        
        return final_points, metrics
    
    def _select_by_leverage_score(self,
                                 points: torch.Tensor,
                                 residual_fn: Callable,
                                 n_select: int,
                                 device: str) -> torch.Tensor:
        """
        åŸºæ–¼æ§“æ¡¿åˆ†æ•¸é¸æ“‡é»
        
        æ§“æ¡¿åˆ†æ•¸ = å°è§’ç·š H_{ii}ï¼Œå…¶ä¸­ H = X(X^T X)^{-1}X^T æ˜¯å¸½å­çŸ©é™£ã€‚
        é«˜æ§“æ¡¿åˆ†æ•¸ = é«˜å½±éŸ¿åŠ›é»ï¼Œæ‡‰å„ªå…ˆä¿ç•™ã€‚
        
        Args:
            points: å€™é¸é» [N, dim]
            residual_fn: æ®˜å·®å‡½æ•¸
            n_select: é¸æ“‡æ•¸é‡
            device: è¨ˆç®—è¨­å‚™
            
        Returns:
            selected_indices: é¸ä¸­çš„ç´¢å¼• [n_select,]
        """
        try:
            with torch.no_grad():
                # è¨ˆç®—æ®˜å·®é›…å¯æ¯”çŸ©é™£ï¼ˆè¿‘ä¼¼ï¼‰
                points_var = points.to(device).requires_grad_(True)
                residuals = residual_fn(points_var)  # [N, n_eqs]
                
                # æ§‹å»ºç‰¹å¾µçŸ©é™£ï¼ˆä½¿ç”¨é»åæ¨™ + æ®˜å·®ï¼‰
                X = torch.cat([points_var, residuals.detach()], dim=1)  # [N, dim + n_eqs]
                X = X.cpu().numpy()
                
                # è¨ˆç®—æ§“æ¡¿åˆ†æ•¸ï¼ˆå¸½å­çŸ©é™£å°è§’ç·šï¼‰
                # ä½¿ç”¨ QR åˆ†è§£è¨ˆç®—ï¼ˆæ•¸å€¼ç©©å®šï¼‰
                Q, R = np.linalg.qr(X)
                leverage_scores = np.sum(Q**2, axis=1)  # [N,]
                
                # é¸æ“‡é«˜æ§“æ¡¿åˆ†æ•¸é»
                selected_indices = torch.from_numpy(
                    np.argsort(leverage_scores)[-n_select:][::-1]
                )
                
                logger.debug(f"æ§“æ¡¿åˆ†æ•¸ç¯„åœ: [{leverage_scores.min():.4f}, {leverage_scores.max():.4f}]")
                
        except Exception as e:
            logger.warning(f"æ§“æ¡¿åˆ†æ•¸è¨ˆç®—å¤±æ•—: {e}ï¼Œå›é€€åˆ°éš¨æ©Ÿé¸æ“‡")
            selected_indices = torch.randperm(points.shape[0])[:n_select]
        
        return selected_indices
    
    def _generate_candidate_pool(self,
                                domain_bounds: Dict[str, Tuple[float, float]],
                                pool_size: int,
                                dim: int) -> torch.Tensor:
        """
        ç”Ÿæˆå€™é¸é»æ± 
        
        Args:
            domain_bounds: åŸŸé‚Šç•Œ
            pool_size: æ± å¤§å°
            dim: ç©ºé–“ç¶­åº¦
            
        Returns:
            candidate_pool: å€™é¸é» [pool_size, dim]
        """
        if self.candidate_sampling == 'latin_hypercube':
            # æ‹‰ä¸è¶…ç«‹æ–¹æ¡æ¨£ï¼ˆLHSï¼‰
            from scipy.stats import qmc
            sampler = qmc.LatinHypercube(d=dim)
            samples = sampler.random(n=pool_size)  # [0, 1]^dim
            
            # ç¸®æ”¾åˆ°åŸŸé‚Šç•Œ
            bounds_list = list(domain_bounds.values())
            for i, (lb, ub) in enumerate(bounds_list):
                samples[:, i] = lb + samples[:, i] * (ub - lb)
            
            candidate_pool = torch.from_numpy(samples).float()
            
        elif self.candidate_sampling == 'uniform':
            # å‡å‹»éš¨æ©Ÿæ¡æ¨£
            bounds_list = list(domain_bounds.values())
            samples = np.random.uniform(
                low=[b[0] for b in bounds_list],
                high=[b[1] for b in bounds_list],
                size=(pool_size, dim)
            )
            candidate_pool = torch.from_numpy(samples).float()
            
        elif self.candidate_sampling == 'stratified':
            # åˆ†å±¤æ¡æ¨£ï¼ˆç¶²æ ¼ + æ“¾å‹•ï¼‰
            n_per_dim = int(np.ceil(pool_size ** (1/dim)))
            grids = [np.linspace(b[0], b[1], n_per_dim) 
                    for b in domain_bounds.values()]
            mesh = np.meshgrid(*grids, indexing='ij')
            grid_points = np.stack([m.flatten() for m in mesh], axis=1)
            
            # éš¨æ©Ÿæ“¾å‹•
            cell_size = [(b[1] - b[0]) / n_per_dim for b in domain_bounds.values()]
            perturbation = np.random.uniform(
                low=[-cs/2 for cs in cell_size],
                high=[cs/2 for cs in cell_size],
                size=grid_points.shape
            )
            samples = grid_points + perturbation
            
            # éš¨æ©Ÿé¸æ“‡ pool_size å€‹é»
            if len(samples) > pool_size:
                indices = np.random.choice(len(samples), pool_size, replace=False)
                samples = samples[indices]
            
            candidate_pool = torch.from_numpy(samples).float()
            
        else:
            raise ValueError(f"æœªçŸ¥çš„å€™é¸æ¡æ¨£æ–¹æ³•: {self.candidate_sampling}")
        
        logger.info(f"ç”Ÿæˆå€™é¸æ± : {pool_size} é»ï¼Œæ–¹æ³•={self.candidate_sampling}")
        return candidate_pool
    
    def _residual_qr_selection(self,
                              candidate_pool: torch.Tensor,
                              residual_fn: Callable,
                              n_select: int,
                              device: str) -> Tuple[np.ndarray, Dict]:
        """
        æ®˜å·® SVD â†’ QR é¸é»
        
        æµç¨‹ï¼š
        1. åœ¨å€™é¸æ± ä¸Šè¨ˆç®—æ®˜å·®å¿«ç…§çŸ©é™£ R [M, n_snapshots Ã— n_eqs]
        2. SVD åˆ†è§£: R = U Î£ V^Tï¼Œä¿ç•™å‰ r å€‹æ¨¡æ…‹
        3. åœ¨ä¸»æ¨¡æ…‹ç©ºé–“ U_r [M, r] ä¸ŠåŸ·è¡Œ QR-pivot é¸ K å€‹é»
        
        Args:
            candidate_pool: å€™é¸é»æ±  [M, dim]
            residual_fn: æ®˜å·®è¨ˆç®—å‡½æ•¸
            n_select: é¸æ“‡é»æ•¸ K
            device: è¨ˆç®—è¨­å‚™
            
        Returns:
            (selected_indices, metrics)
        """
        M = candidate_pool.shape[0]
        
        # ========================================
        # Step 1: æ”¶é›†æ®˜å·®å¿«ç…§
        # ========================================
        residual_matrix = []
        
        with torch.no_grad():
            if self.snapshot_method == 'batch':
                # åˆ†æ‰¹è¨ˆç®—æ®˜å·®ï¼ˆä¸åŒéš¨æ©Ÿæ‰¹æ¬¡æ¨¡æ“¬å¿«ç…§ï¼‰
                batch_size = M // self.n_snapshots
                
                for i in range(self.n_snapshots):
                    # éš¨æ©Ÿæ‰“äº‚å€™é¸æ± ï¼ˆæ¨¡æ“¬ä¸åŒæ‰¹æ¬¡ï¼‰
                    perm = torch.randperm(M)
                    batch_indices = perm[:batch_size]
                    batch_points = candidate_pool[batch_indices].to(device)
                    
                    residuals = residual_fn(batch_points)  # [batch_size, n_eqs]
                    residual_matrix.append(residuals.cpu().numpy())
                
                # æ‹¼æ¥æˆçŸ©é™£ [M_total, n_eqs]
                residual_matrix = np.concatenate(residual_matrix, axis=0)
                
            else:
                # å…¨å€™é¸æ± è¨ˆç®—ï¼ˆå…§å­˜å…è¨±çš„æƒ…æ³ä¸‹ï¼‰
                all_residuals = residual_fn(candidate_pool.to(device))  # [M, n_eqs]
                residual_matrix = all_residuals.cpu().numpy()
        
        # ========================================
        # Step 2: SVD åˆ†è§£
        # ========================================
        if self.svd_centering:
            residual_mean = residual_matrix.mean(axis=0, keepdims=True)
            residual_matrix_centered = residual_matrix - residual_mean
        else:
            residual_matrix_centered = residual_matrix
        
        try:
            U, s, Vt = svd(residual_matrix_centered, full_matrices=False)
            
            # ç¢ºå®šç§©ï¼ˆåŸºæ–¼èƒ½é‡é–¾å€¼ï¼‰
            total_energy = np.sum(s**2)
            cumulative_energy = np.cumsum(s**2) / total_energy
            rank = min(
                np.argmax(cumulative_energy >= self.energy_threshold) + 1,
                self.max_rank,
                len(s)
            )
            
            logger.info(f"SVD åˆ†è§£: ç§©={rank}/{len(s)}, "
                       f"èƒ½é‡ä¿ç•™={cumulative_energy[rank-1]:.4f}")
            
            # æå–ä¸»æ¨¡æ…‹
            U_r = U[:, :rank]  # [M_batch, rank]
            
            # é‡æ–°æ˜ å°„åˆ°å®Œæ•´å€™é¸æ± ç´¢å¼•
            # ï¼ˆå¦‚æœä½¿ç”¨æ‰¹æ¬¡æ¡æ¨£ï¼Œéœ€è¦é‡å»ºå®Œæ•´ U çŸ©é™£ï¼‰
            if self.snapshot_method == 'batch':
                # ç°¡åŒ–è™•ç†ï¼šåœ¨æ‰¹æ¬¡é»ä¸Šåš QRï¼Œç„¶å¾Œæ˜ å°„å›åŸç´¢å¼•
                # é€™è£¡å‡è¨­æ‰¹æ¬¡é»å·²è¶³å¤ ä»£è¡¨å€™é¸æ± åˆ†ä½ˆ
                pass
            
        except np.linalg.LinAlgError as e:
            logger.error(f"SVD å¤±æ•—: {e}ï¼Œå›é€€åˆ°éš¨æ©Ÿé¸æ“‡")
            random_indices = np.random.choice(M, n_select, replace=False)
            return random_indices, {'svd_failed': True}
        
        # ========================================
        # Step 3: QR-Pivot é¸é»
        # ========================================
        try:
            if self.qr_column_pivoting:
                # å° U_r^T åš QR åˆ†è§£ï¼ˆé¸æ“‡è¡Œ = å€™é¸æ± ä¸­çš„é»ï¼‰
                qr_result = qr(U_r.T, mode='economic', pivoting=True)  # type: ignore
                # scipy.linalg.qr with pivoting=True returns (Q, R, P)
                piv = qr_result[2]  # type: ignore
                selected_indices = np.array(piv[:n_select])
            else:
                # æ¨™æº– QRï¼ˆç„¡ä¸»å…ƒï¼‰
                qr_result = qr(U_r.T, mode='economic', pivoting=False)  # type: ignore
                R = qr_result[1]  # type: ignore
                # ä½¿ç”¨å°è§’å…ƒç´ å¤§å°æ’åº
                diag_importance = np.abs(np.diag(R))
                selected_indices = np.argsort(diag_importance)[-n_select:][::-1]
            
            # ç¢ºä¿ç´¢å¼•æœ‰æ•ˆ
            selected_indices = selected_indices[selected_indices < M]
            selected_indices = selected_indices[:n_select]
            
            logger.info(f"QR-Pivot é¸é»: {len(selected_indices)}/{n_select} é»")
            
        except Exception as e:
            logger.error(f"QR åˆ†è§£å¤±æ•—: {e}ï¼Œå›é€€åˆ°éš¨æ©Ÿé¸æ“‡")
            selected_indices = np.random.choice(M, n_select, replace=False)
            return selected_indices, {'qr_failed': True}
        
        # ========================================
        # Step 4: çµ±è¨ˆæŒ‡æ¨™
        # ========================================
        metrics = {
            'svd_rank': rank,
            'svd_energy_ratio': float(cumulative_energy[rank-1]),
            'n_snapshots': self.n_snapshots,
            'candidate_pool_size': M,
        }
        
        return selected_indices, metrics
    
    def _apply_spatial_constraints(self,
                                  existing_points: torch.Tensor,
                                  new_points: torch.Tensor,
                                  min_distance: float) -> torch.Tensor:
        """
        æ‡‰ç”¨ç©ºé–“ç´„æŸï¼ˆæœ€å°é»é–“è·ï¼‰
        
        Args:
            existing_points: å·²æœ‰é» [N_exist, dim]
            new_points: æ–°å€™é¸é» [N_new, dim]
            min_distance: æœ€å°é»é–“è·
            
        Returns:
            filtered_new_points: éæ¿¾å¾Œçš„æ–°é»
        """
        if min_distance <= 0:
            return new_points
        
        all_points = torch.cat([existing_points, new_points], dim=0)
        n_exist = existing_points.shape[0]
        
        # è¨ˆç®—è·é›¢çŸ©é™£ï¼ˆæ–°é» vs æ‰€æœ‰é»ï¼‰
        all_points_np = all_points.numpy()
        dist_matrix = squareform(pdist(all_points_np))
        
        # æ–°é»èˆ‡å·²æœ‰é»çš„è·é›¢
        new_to_all_dist = dist_matrix[n_exist:, :n_exist]
        
        # éæ¿¾ï¼šä¿ç•™èˆ‡æ‰€æœ‰å·²æœ‰é»è·é›¢ >= min_distance çš„æ–°é»
        valid_mask = np.all(new_to_all_dist >= min_distance, axis=1)
        
        filtered_new_points = new_points[valid_mask]
        
        n_filtered = len(new_points) - len(filtered_new_points)
        if n_filtered > 0:
            logger.warning(f"ç©ºé–“ç´„æŸéæ¿¾: ç§»é™¤ {n_filtered}/{len(new_points)} å€‹éè¿‘é» "
                          f"(min_dist={min_distance:.4f})")
        
        return filtered_new_points
    
    def collect_residual_snapshot(self,
                                 points: torch.Tensor,
                                 residuals: torch.Tensor):
        """
        æ”¶é›†æ®˜å·®å¿«ç…§ï¼ˆç”¨æ–¼å¾ŒçºŒ SVD åˆ†æï¼‰
        
        Args:
            points: æ®˜å·®é» [N, dim]
            residuals: æ®˜å·®å€¼ [N, n_eqs]
        """
        snapshot = {
            'points': points.detach().cpu(),
            'residuals': residuals.detach().cpu()
        }
        
        self.residual_snapshots.append(snapshot)
        
        # é™åˆ¶å¿«ç…§æ•¸é‡ï¼ˆé¿å…å…§å­˜çˆ†ç‚¸ï¼‰
        max_snapshots = self.n_snapshots * 2
        if len(self.residual_snapshots) > max_snapshots:
            self.residual_snapshots = self.residual_snapshots[-max_snapshots:]
    
    def get_statistics(self) -> Dict:
        """ç²å–æ¡æ¨£å™¨çµ±è¨ˆä¿¡æ¯"""
        return {
            'enabled': self.enabled,
            'trigger_method': self.trigger_method,
            'resampling_strategy': self.resampling_strategy,
            'n_snapshots_collected': len(self.residual_snapshots),
            'last_trigger_epoch': self.last_trigger_epoch,
            'loss_history_length': len(self.loss_history),
        }


def create_adaptive_collocation_sampler(config: Dict) -> AdaptiveCollocationSampler:
    """
    å‰µå»ºè‡ªé©æ‡‰æ®˜å·®é»æ¡æ¨£å™¨çš„ä¾¿æ·å‡½æ•¸
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        æ¡æ¨£å™¨å¯¦ä¾‹
    """
    return AdaptiveCollocationSampler(config)


if __name__ == "__main__":
    # å–®å…ƒæ¸¬è©¦
    print("ğŸ§ª æ¸¬è©¦è‡ªé©æ‡‰æ®˜å·®é»æ¡æ¨£å™¨...")
    
    # æ¨¡æ“¬é…ç½®
    config = {
        'enabled': True,
        'trigger': {
            'method': 'epoch_interval',
            'epoch_interval': 1000,
        },
        'resampling_strategy': 'incremental_replace',
        'incremental_replace': {
            'keep_ratio': 0.7,
            'replace_ratio': 0.3,
            'removal_criterion': 'leverage_score',
        },
        'residual_qr': {
            'enabled': True,
            'candidate_pool_size': 1000,
            'candidate_sampling': 'latin_hypercube',
            'snapshot_config': {'n_snapshots': 10},
            'svd': {'energy_threshold': 0.99, 'max_rank': 20},
            'qr': {'column_pivoting': True},
            'spatial_constraints': {'enabled': True, 'min_distance': 0.02}
        }
    }
    
    sampler = AdaptiveCollocationSampler(config)
    
    # æ¸¬è©¦è§¸ç™¼æ¢ä»¶
    print("\næ¸¬è©¦è§¸ç™¼æ¢ä»¶...")
    for epoch in range(0, 3000, 500):
        triggered = sampler.should_trigger(epoch, current_loss=0.1 * np.exp(-epoch/1000))
        if triggered:
            print(f"  âœ… Epoch {epoch}: è§¸ç™¼é‡é¸")
    
    # æ¸¬è©¦å€™é¸æ± ç”Ÿæˆ
    print("\næ¸¬è©¦å€™é¸æ± ç”Ÿæˆ...")
    domain_bounds = {'x': (0.0, 1.0), 'y': (0.0, 1.0)}
    candidate_pool = sampler._generate_candidate_pool(domain_bounds, pool_size=500, dim=2)
    print(f"  å€™é¸æ± å¤§å°: {candidate_pool.shape}")
    print(f"  ç¯„åœ: x âˆˆ [{candidate_pool[:, 0].min():.3f}, {candidate_pool[:, 0].max():.3f}], "
          f"y âˆˆ [{candidate_pool[:, 1].min():.3f}, {candidate_pool[:, 1].max():.3f}]")
    
    # æ¸¬è©¦é‡é¸ï¼ˆæ¨¡æ“¬æ®˜å·®å‡½æ•¸ï¼‰
    print("\næ¸¬è©¦æ®˜å·®é»é‡é¸...")
    current_points = torch.rand(100, 2)  # 100 å€‹ç•¶å‰é»
    
    def mock_residual_fn(points):
        """æ¨¡æ“¬æ®˜å·®å‡½æ•¸ï¼ˆPDE æ®˜å·® + BC æ®˜å·®ï¼‰"""
        N = points.shape[0]
        # 3 å€‹ PDE + 2 å€‹ BC
        residuals = torch.randn(N, 5) * 0.1
        return residuals
    
    new_points, metrics = sampler.resample_collocation_points(
        current_points=current_points,
        domain_bounds=domain_bounds,
        residual_fn=mock_residual_fn,
        device='cpu'
    )
    
    print(f"  é‡é¸çµæœ:")
    print(f"    åŸé»æ•¸: {current_points.shape[0]}")
    print(f"    æ–°é»æ•¸: {new_points.shape[0]}")
    print(f"    ä¿ç•™é»æ•¸: {metrics['n_kept']}")
    print(f"    æ›¿æ›é»æ•¸: {metrics['n_replaced']}")
    print(f"    SVD ç§©: {metrics.get('svd_rank', 'N/A')}")
    
    # æ¸¬è©¦ç©ºé–“ç´„æŸ
    print("\næ¸¬è©¦ç©ºé–“ç´„æŸ...")
    existing = torch.tensor([[0.5, 0.5]])
    new = torch.tensor([[0.51, 0.51], [0.2, 0.2], [0.8, 0.8]])
    filtered = sampler._apply_spatial_constraints(existing, new, min_distance=0.05)
    print(f"  éæ¿¾å‰: {len(new)} é»")
    print(f"  éæ¿¾å¾Œ: {len(filtered)} é» (min_dist=0.05)")
    
    print("\nâœ… è‡ªé©æ‡‰æ®˜å·®é»æ¡æ¨£å™¨æ¸¬è©¦å®Œæˆï¼")
