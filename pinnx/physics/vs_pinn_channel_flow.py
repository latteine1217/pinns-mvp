"""
VS-PINN Channel Flow ç‰©ç†æ¨¡å—
=============================

å®ç°åŸºäºå„å‘å¼‚æ€§å˜æ•°ç¼©æ”¾çš„ Navier-Stokes æ–¹ç¨‹æ±‚è§£å™¨ï¼Œä¸“ç”¨äº JHTDB Channel Flow Re_Ï„=1000ã€‚

æ ¸å¿ƒåŠŸèƒ½:
1. å„å‘å¼‚æ€§ç¼©æ”¾åæ ‡å˜æ¢: (X, Y, Z) = (N_xÂ·x, N_yÂ·y, N_zÂ·z)
2. é“¾å¼æ³•åˆ™æ¢¯åº¦è®¡ç®—: âˆ‚u/âˆ‚x = N_x Â· âˆ‚v/âˆ‚X
3. Laplacian å˜æ¢: âˆ‡Â²u = N_xÂ² âˆ‚Â²v/âˆ‚XÂ² + N_yÂ² âˆ‚Â²v/âˆ‚YÂ² + N_zÂ² âˆ‚Â²v/âˆ‚ZÂ²
4. Channel Flow ä¸“ç”¨å‹é™é¡¹: dP/dx = 0.0025
5. å‘¨æœŸæ€§è¾¹ç•Œçº¦æŸ
6. Loss æƒé‡ç¼©æ”¾è¡¥å¿

ç†è®ºä¾æ®:
- arXiv:2308.08468 (VS-PINN åŸå§‹è®ºæ–‡)
- JHTDB Channel Flow Re_Ï„=1000 æ•°æ®è§„æ ¼

ä½œè€…: PINNs-MVP å›¢é˜Ÿ
æ—¥æœŸ: 2025-10-09
"""

import torch
import torch.nn as nn
import torch.autograd as autograd
from typing import Tuple, Dict, Optional, Any
import numpy as np

from .ns_3d_temporal import compute_derivatives_3d_temporal


def compute_gradient_3d(
    field: torch.Tensor,
    coords: torch.Tensor,
    component: int
) -> torch.Tensor:
    """
    è¨ˆç®— 3D ç©©æ…‹å ´çš„åå°æ•¸ï¼ˆå–®ä¸€åˆ†é‡ï¼‰
    
    Args:
        field: æ¨™é‡å ´ [batch, 1]ï¼ˆéœ€è¦åœ¨è¨ˆç®—åœ–ä¸­ï¼‰
        coords: 3D åæ¨™ [batch, 3]ï¼ˆéœ€è¦ requires_grad=Trueï¼‰
        component: å¾®åˆ†åˆ†é‡ (0=x, 1=y, 2=z)
        
    Returns:
        åå°æ•¸ [batch, 1]ï¼ˆä¿ç•™è¨ˆç®—åœ–ï¼‰
        
    Note:
        æ­¤å‡½æ•¸ä¿è­‰ä¿ç•™è¨ˆç®—åœ–ï¼Œé©ç”¨æ–¼éœ€è¦é«˜éšå°æ•¸çš„ PINNs è¨“ç·´ã€‚
        ä½¿ç”¨ create_graph=True ç¢ºä¿è¿”å›çš„æ¢¯åº¦å¼µé‡å¯ä»¥é€²ä¸€æ­¥å¾®åˆ†ã€‚
    """
    # é—œéµï¼šcreate_graph=True ç¢ºä¿è¿”å›çš„æ¢¯åº¦æœ¬èº«ä¹Ÿåœ¨è¨ˆç®—åœ–ä¸­
    grad_outputs = torch.ones_like(field)
    grads = autograd.grad(
        outputs=field,
        inputs=coords,
        grad_outputs=grad_outputs,
        create_graph=True,  # ä¿ç•™è¨ˆç®—åœ–ä»¥æ”¯æŒé«˜éšå°æ•¸
        retain_graph=True,  # ä¿ç•™åœ–ä»¥æ”¯æŒå¤šæ¬¡æ¢¯åº¦è¨ˆç®—
        only_inputs=True,
        allow_unused=False  # ç¢ºä¿æ‰€æœ‰è¼¸å…¥éƒ½è¢«ä½¿ç”¨
    )[0]
    
    # æå–æŒ‡å®šåˆ†é‡ï¼ˆåˆ‡ç‰‡æ“ä½œä¿ç•™è¨ˆç®—åœ–ï¼‰
    return grads[:, component:component+1]


class VSPINNChannelFlow(nn.Module):
    """
    VS-PINN Channel Flow æ±‚è§£å™¨
    
    å®ç°å„å‘å¼‚æ€§ç¼©æ”¾çš„ NS æ–¹ç¨‹ï¼Œé’ˆå¯¹é€šé“æµç‰¹æ€§ä¼˜åŒ–ï¼š
    - å£æ³•å‘ (y) æœ€åˆšæ€§ï¼Œä½¿ç”¨æœ€å¤§ç¼©æ”¾å› å­ N_y = 8-16
    - æµå‘ (x) å’Œå±•å‘ (z) ä½¿ç”¨è¾ƒå°ç¼©æ”¾å› å­ N_x = N_z = 1-4
    - å‹é™é¡¹é©±åŠ¨æµåŠ¨: dP/dx = 0.0025
    - å‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶: x, z æ–¹å‘
    
    Args:
        scaling_factors: ç¼©æ”¾å› å­å­—å…¸ {'N_x': float, 'N_y': float, 'N_z': float}
        physics_params: ç‰©ç†å‚æ•°å­—å…¸ {'nu': float, 'dP_dx': float, 'rho': float}
        domain_bounds: åŸŸè¾¹ç•Œ {'x': (x_min, x_max), 'y': (y_min, y_max), 'z': (z_min, z_max)}
    """
    
    def __init__(
        self, 
        scaling_factors: Optional[Dict[str, float]] = None,
        physics_params: Optional[Dict[str, float]] = None,
        domain_bounds: Optional[Dict[str, Tuple[float, float]]] = None,
        loss_config: Optional[Dict[str, Any]] = None,  # ğŸ”´ æ–°å¢ï¼šæ¥æ”¶æå¤±é…ç½®
    ):
        super().__init__()
        
        # === é»˜è®¤é…ç½®ï¼ˆåŸºäº VS-PINN è®ºæ–‡ä¸ JHTDB Channel Flowï¼‰ ===
        default_scaling = {'N_x': 2.0, 'N_y': 12.0, 'N_z': 2.0}
        default_physics = {
            'nu': 5e-5,        # åŠ¨åŠ›é»åº¦ Î½ = U_Ï„ Â· h / Re_Ï„ = 1.0 Â· 1.0 / 1000 = 1e-3 (JHTDBå®é™…å€¼çº¦ 5e-5)
            'dP_dx': 0.0025,   # å‹é™æ¢¯åº¦ï¼ˆé©±åŠ¨æµåŠ¨ï¼‰
            'rho': 1.0,        # å¯†åº¦ï¼ˆæ ‡å‡†åŒ–ï¼‰
        }
        default_bounds = {
            'x': (0.0, 8.0 * np.pi),  # æµå‘å‘¨æœŸåŸŸ [0, 8Ï€]
            'y': (-1.0, 1.0),          # å£æ³•å‘ [-1, 1]
            'z': (0.0, 3.0 * np.pi),  # å±•å‘å‘¨æœŸåŸŸ [0, 3Ï€]
        }
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        self.scaling_factors = {**default_scaling, **(scaling_factors or {})}
        self.physics_params = {**default_physics, **(physics_params or {})}
        self.domain_bounds = {**default_bounds, **(domain_bounds or {})}
        
        # æ³¨å†Œç¼©æ”¾å› å­ä¸ºç¼“å†²åŒºï¼ˆä¸å‚ä¸æ¢¯åº¦è®¡ç®—ï¼‰
        for key, value in self.scaling_factors.items():
            self.register_buffer(key, torch.tensor(float(value)))
        
        # æ³¨å†Œç‰©ç†å‚æ•°
        for key, value in self.physics_params.items():
            self.register_buffer(key, torch.tensor(float(value)))
        
        # è®¡ç®—å¹¶ç¼“å­˜æœ€å¤§ç¼©æ”¾å› å­ï¼ˆç”¨äº loss æƒé‡è¡¥å¿ï¼‰
        N_max_value = max(self.scaling_factors.values())
        self.register_buffer('N_max', torch.tensor(float(N_max_value)))
        self.register_buffer('N_max_sq', torch.tensor(float(N_max_value ** 2)))
        
        # === æå¤±æ­¸ä¸€åŒ–åƒæ•¸ ===
        self.loss_normalizers: Dict[str, float] = {}  # å­˜å„²æ¯å€‹æå¤±é …çš„åƒè€ƒå€¼
        self.normalize_losses = True  # æå¤±æ­¸ä¸€åŒ–é–‹é—œï¼ˆå¯é€šéé…ç½®æ§åˆ¶ï¼‰
        # ğŸ”´ ä¿®æ­£ï¼šå¾é…ç½®è®€å– warmup_epochsï¼Œé»˜èª 5
        self.warmup_epochs = (loss_config or {}).get('warmup_epochs', 5)
        self.normalizer_momentum = 0.9  # æ»‘å‹•å¹³å‡å‹•é‡ï¼ˆå¹³æ»‘æ›´æ–°ï¼‰
        
        # éªŒè¯é…ç½®
        self._verify_configuration()
        
        print(f"âœ… VS-PINN Channel Flow åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç¼©æ”¾å› å­: N_x={self.N_x:.1f}, N_y={self.N_y:.1f}, N_z={self.N_z:.1f}")  # type: ignore[attr-defined]
        print(f"   ç‰©ç†å‚æ•°: Î½={self.nu:.2e}, dP/dx={self.dP_dx:.4f}, Ï={self.rho:.1f}")  # type: ignore[attr-defined]
        print(f"   Loss è¡¥å¿å› å­: 1/N_maxÂ² = 1/{self.N_max_sq:.2f}")  # type: ignore[attr-defined]
        print(f"   æå¤±æ­¸ä¸€åŒ–: {'å•Ÿç”¨' if self.normalize_losses else 'ç¦ç”¨'} (warmup={self.warmup_epochs} epochs)")
    
    def _verify_configuration(self):
        """éªŒè¯é…ç½®çš„ç‰©ç†åˆç†æ€§"""
        # 1. ç¼©æ”¾å› å­åº”æ»¡è¶³: N_y > N_x, N_z ï¼ˆå£æ³•å‘æœ€åˆšæ€§ï¼‰
        if not (self.scaling_factors['N_y'] >= self.scaling_factors['N_x'] and 
                self.scaling_factors['N_y'] >= self.scaling_factors['N_z']):
            print(f"âš ï¸  è­¦å‘Š: å£æ³•å‘ç¼©æ”¾å› å­ N_y={self.scaling_factors['N_y']} åº”å¤§äº N_x, N_z")
        
        # 2. Reynolds æ•°ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆç§»é™¤ä¸æ­£ç¡®çš„éªŒè¯é€»è¾‘ï¼‰
        # æ³¨é‡Šï¼šåŸéªŒè¯é€»è¾‘ Re_Ï„ = 1/Î½ ä¸æ­£ç¡®
        # æ­£ç¡®å…¬å¼ï¼šRe_Ï„ = U_Ï„ Â· h / Î½ï¼Œå…¶ä¸­ U_Ï„ å’Œ h éœ€ä»æµåœºè®¡ç®—æˆ–é…ç½®è·å–
        # å½“å‰é…ç½®ï¼ˆÎ½=5e-5, dP/dx=0.0025ï¼‰ä¸ JHTDB Re_Ï„=1000 ç‰©ç†ä¸Šè‡ªæ´½ï¼Œæ— éœ€é¢å¤–éªŒè¯
        
        # 3. å‹é™é¡¹åº”ä¸ºæ­£å€¼ï¼ˆæ¨åŠ¨æµåŠ¨ï¼‰
        if self.dP_dx <= 0:  # type: ignore[operator]
            raise ValueError(f"å‹é™é¡¹ dP/dx={self.dP_dx} å¿…é¡»ä¸ºæ­£å€¼")
    
    def scale_coordinates(self, coords: torch.Tensor) -> torch.Tensor:
        """
        åæ ‡ç¼©æ”¾å˜æ¢: (x, y, z) â†’ (X, Y, Z) = (N_xÂ·x, N_yÂ·y, N_zÂ·z)
        
        Args:
            coords: [batch, 3] = [x, y, z] ç‰©ç†åæ ‡
            
        Returns:
            scaled_coords: [batch, 3] = [X, Y, Z] ç¼©æ”¾åæ ‡
        """
        x, y, z = coords[:, 0:1], coords[:, 1:2], coords[:, 2:3]
        
        X = self.N_x * x  # type: ignore[operator]
        Y = self.N_y * y  # type: ignore[operator]
        Z = self.N_z * z  # type: ignore[operator]
        
        return torch.cat([X, Y, Z], dim=1)
    
    def inverse_scale_coordinates(self, scaled_coords: torch.Tensor) -> torch.Tensor:
        """
        åæ ‡é€†ç¼©æ”¾: (X, Y, Z) â†’ (x, y, z)
        
        Args:
            scaled_coords: [batch, 3] = [X, Y, Z]
            
        Returns:
            coords: [batch, 3] = [x, y, z]
        """
        X, Y, Z = scaled_coords[:, 0:1], scaled_coords[:, 1:2], scaled_coords[:, 2:3]
        
        x = X / self.N_x  # type: ignore[operator]
        y = Y / self.N_y  # type: ignore[operator]
        z = Z / self.N_z  # type: ignore[operator]
        
        return torch.cat([x, y, z], dim=1)
    
    def compute_gradients(
        self, 
        field: torch.Tensor, 
        coords: torch.Tensor, 
        order: int = 1,
        scaled_coords: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        è¨ˆç®—ç‰©ç†å ´å°ç‰©ç†åº§æ¨™çš„æ¢¯åº¦ï¼Œæ”¯æ´ VS-PINN çš„è®Šæ•¸å°ºåº¦åŒ–ã€‚
        
        Args:
            field: æ¨™é‡å ´ [batch, 1]ï¼ˆå¦‚ u, v, w, pï¼‰
            coords: åŸå§‹ç‰©ç†åæ¨™ [batch, 3] = [x, y, z]
            order: å¾®åˆ†éšæ•¸ (1 æˆ– 2)
            scaled_coords: è‹¥æä¾›ï¼Œè¦–ç‚ºæ¨¡å‹è¼¸å…¥çš„ç¸®æ”¾åº§æ¨™ (X, Y, Z)ï¼Œ
                           å°‡è‡ªå‹•å¥—ç”¨éˆå¼æ³•å‰‡å›æ¨è‡³ç‰©ç†åº§æ¨™ã€‚
            
        Returns:
            æ¢¯åº¦å­—å…¸ï¼š
                order=1 â†’ {'x': âˆ‚f/âˆ‚x, 'y': âˆ‚f/âˆ‚y, 'z': âˆ‚f/âˆ‚z}
                order=2 â†’ {'xx': âˆ‚Â²f/âˆ‚xÂ², ...}
        """
        base_coords = scaled_coords if scaled_coords is not None else coords
        
        if order == 1:
            grad_x_base = compute_gradient_3d(field, base_coords, component=0)
            grad_y_base = compute_gradient_3d(field, base_coords, component=1)
            grad_z_base = compute_gradient_3d(field, base_coords, component=2)
            
            if scaled_coords is not None:
                grad_x = grad_x_base * self.N_x  # type: ignore[operator]
                grad_y = grad_y_base * self.N_y  # type: ignore[operator]
                grad_z = grad_z_base * self.N_z  # type: ignore[operator]
            else:
                grad_x, grad_y, grad_z = grad_x_base, grad_y_base, grad_z_base
            
            return {'x': grad_x, 'y': grad_y, 'z': grad_z}
        
        if order == 2:
            grad_x_base = compute_gradient_3d(field, base_coords, component=0)
            grad_y_base = compute_gradient_3d(field, base_coords, component=1)
            grad_z_base = compute_gradient_3d(field, base_coords, component=2)
            
            grad_xx_base = compute_gradient_3d(grad_x_base, base_coords, component=0)
            grad_yy_base = compute_gradient_3d(grad_y_base, base_coords, component=1)
            grad_zz_base = compute_gradient_3d(grad_z_base, base_coords, component=2)
            
            if scaled_coords is not None:
                grad_xx = grad_xx_base * (self.N_x ** 2)  # type: ignore[operator]
                grad_yy = grad_yy_base * (self.N_y ** 2)  # type: ignore[operator]
                grad_zz = grad_zz_base * (self.N_z ** 2)  # type: ignore[operator]
            else:
                grad_xx, grad_yy, grad_zz = grad_xx_base, grad_yy_base, grad_zz_base
            
            return {'xx': grad_xx, 'yy': grad_yy, 'zz': grad_zz}
        
        raise ValueError(f"ä¸æ”¯æŒçš„å¾®åˆ†éšæ•¸: {order}")
    
    def compute_laplacian(
        self, 
        field: torch.Tensor, 
        coords: torch.Tensor,
        scaled_coords: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        è®¡ç®— Laplacian: âˆ‡Â²f = âˆ‚Â²f/âˆ‚xÂ² + âˆ‚Â²f/âˆ‚yÂ² + âˆ‚Â²f/âˆ‚zÂ²
        
        Args:
            field: æ ‡é‡åœº [batch, 1]
            coords: åŸå§‹ç‰©ç†åæ ‡ [batch, 3]ï¼ˆéœ€è¦ requires_grad=Trueï¼‰
            
        Returns:
            laplacian: [batch, 1]
        """
        second_derivs = self.compute_gradients(field, coords, order=2, scaled_coords=scaled_coords)
        laplacian = second_derivs['xx'] + second_derivs['yy'] + second_derivs['zz']
        
        return laplacian
    
    def compute_momentum_residuals(
        self, 
        coords: torch.Tensor, 
        predictions: torch.Tensor,
        scaled_coords: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®— 3D ä¸å¯å‹ç¼© NS æ–¹ç¨‹çš„åŠ¨é‡æ®‹å·®ï¼ˆç¨³æ€ç‰ˆæœ¬ï¼‰
        
        æ–¹ç¨‹ï¼ˆå«å‹é™é¡¹ï¼‰:
            uâˆ‚u/âˆ‚x + vâˆ‚u/âˆ‚y + wâˆ‚u/âˆ‚z = -âˆ‚p/âˆ‚x + Î½âˆ‡Â²u + dP/dx  # x æ–¹å‘æœ‰é©±åŠ¨å‹é™
            uâˆ‚v/âˆ‚x + vâˆ‚v/âˆ‚y + wâˆ‚v/âˆ‚z = -âˆ‚p/âˆ‚y + Î½âˆ‡Â²v
            uâˆ‚w/âˆ‚x + vâˆ‚w/âˆ‚y + wâˆ‚w/âˆ‚z = -âˆ‚p/âˆ‚z + Î½âˆ‡Â²w
        
        Args:
            coords: [batch, 3] = [x, y, z] ç‰©ç†åæ ‡
            predictions: [batch, 4] = [u, v, w, p] é¢„æµ‹å€¼ï¼ˆæ¨¡å‹è¼¸å‡ºï¼Œè‡ªå‹•è¿½è¹¤æ¢¯åº¦ï¼‰
            scaled_coords: æ¨¡å‹è¼¸å…¥ä½¿ç”¨çš„ç¸®æ”¾åº§æ¨™ (X, Y, Z)ï¼Œè‹¥ç‚º None å‰‡è¦–ç‚ºæœªç¸®æ”¾
            
        Returns:
            æ®‹å·®å­—å…¸ {'momentum_x', 'momentum_y', 'momentum_z'}
        """
        if scaled_coords is None:
            scaled_coords = self.scale_coordinates(coords)
        
        u = predictions[:, 0:1]
        v = predictions[:, 1:2]
        w = predictions[:, 2:3]
        p = predictions[:, 3:4]
        
        # === è®¡ç®—ä¸€é˜¶å¯¼æ•°ï¼ˆå¯¹æµé¡¹ + å‹åŠ›é¡¹ï¼‰ ===
        u_grads = self.compute_gradients(u, coords, order=1, scaled_coords=scaled_coords)
        v_grads = self.compute_gradients(v, coords, order=1, scaled_coords=scaled_coords)
        w_grads = self.compute_gradients(w, coords, order=1, scaled_coords=scaled_coords)
        p_grads = self.compute_gradients(p, coords, order=1, scaled_coords=scaled_coords)
        
        # å¯¹æµé¡¹
        conv_u = u * u_grads['x'] + v * u_grads['y'] + w * u_grads['z']
        conv_v = u * v_grads['x'] + v * v_grads['y'] + w * v_grads['z']
        conv_w = u * w_grads['x'] + v * w_grads['y'] + w * w_grads['z']
        
        # å‹åŠ›æ¢¯åº¦é¡¹
        pressure_x = p_grads['x'] / self.rho  # type: ignore[operator]
        pressure_y = p_grads['y'] / self.rho  # type: ignore[operator]
        pressure_z = p_grads['z'] / self.rho  # type: ignore[operator]
        
        # === è®¡ç®—äºŒé˜¶å¯¼æ•°ï¼ˆé»æ€§é¡¹ï¼‰ ===
        laplacian_u = self.compute_laplacian(u, coords, scaled_coords=scaled_coords)
        laplacian_v = self.compute_laplacian(v, coords, scaled_coords=scaled_coords)
        laplacian_w = self.compute_laplacian(w, coords, scaled_coords=scaled_coords)
        
        viscous_u = self.nu * laplacian_u  # type: ignore[operator]
        viscous_v = self.nu * laplacian_v  # type: ignore[operator]
        viscous_w = self.nu * laplacian_w  # type: ignore[operator]
        
        # === ç»„è£…æ®‹å·® ===
        # x æ–¹å‘åŠ¨é‡æ–¹ç¨‹ï¼ˆå«å‹é™é©±åŠ¨é¡¹ï¼‰
        residual_x = conv_u + pressure_x - viscous_u - self.dP_dx  # type: ignore[operator]
        
        # y æ–¹å‘åŠ¨é‡æ–¹ç¨‹
        residual_y = conv_v + pressure_y - viscous_v
        
        # z æ–¹å‘åŠ¨é‡æ–¹ç¨‹
        residual_z = conv_w + pressure_z - viscous_w
        
        return {
            'momentum_x': residual_x,
            'momentum_y': residual_y,
            'momentum_z': residual_z,
        }
    
    def compute_continuity_residual(
        self, 
        coords: torch.Tensor, 
        predictions: torch.Tensor,
        scaled_coords: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        è®¡ç®—è¿ç»­æ–¹ç¨‹æ®‹å·®ï¼ˆä¸å¯å‹ç¼©æ¡ä»¶ï¼‰
        
        æ–¹ç¨‹:
            âˆ‚u/âˆ‚x + âˆ‚v/âˆ‚y + âˆ‚w/âˆ‚z = 0
        
        Args:
            coords: [batch, 3] = [x, y, z] ç‰©ç†åº§æ¨™
            predictions: [batch, 4] = [u, v, w, p]ï¼ˆæ¨¡å‹è¼¸å‡ºï¼Œè‡ªå‹•è¿½è¹¤æ¢¯åº¦ï¼‰
            scaled_coords: æ¨¡å‹è¼¸å…¥ä½¿ç”¨çš„ç¸®æ”¾åº§æ¨™ (X, Y, Z)ï¼Œè‹¥ç‚º None å‰‡è¦–ç‚ºæœªç¸®æ”¾
            
        Returns:
            continuity_residual: [batch, 1]
        """
        if scaled_coords is None:
            scaled_coords = self.scale_coordinates(coords)
        
        u = predictions[:, 0:1]
        v = predictions[:, 1:2]
        w = predictions[:, 2:3]
        
        # è®¡ç®—æ•£åº¦
        u_grads = self.compute_gradients(u, coords, order=1, scaled_coords=scaled_coords)
        v_grads = self.compute_gradients(v, coords, order=1, scaled_coords=scaled_coords)
        w_grads = self.compute_gradients(w, coords, order=1, scaled_coords=scaled_coords)
        
        divergence = u_grads['x'] + v_grads['y'] + w_grads['z']
        
        return divergence
    
    def compute_periodic_loss(
        self, 
        coords: torch.Tensor, 
        predictions: torch.Tensor
    ) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å‘¨æœŸæ€§è¾¹ç•Œçº¦æŸæŸå¤±
        
        å¯¹äº x å’Œ z æ–¹å‘çš„å‘¨æœŸè¾¹ç•Œ:
            u(x_min, y, z) = u(x_max, y, z)
            v(x_min, y, z) = v(x_max, y, z)
            w(x_min, y, z) = w(x_max, y, z)
            p(x_min, y, z) = p(x_max, y, z)
        
        Args:
            coords: [batch, 3] = [x, y, z]
            predictions: [batch, 4] = [u, v, w, p]
            
        Returns:
            å‘¨æœŸæ€§æŸå¤±å­—å…¸ {'periodic_x', 'periodic_z'}
        """
        # æå–è¾¹ç•Œåæ ‡ï¼ˆéœ€è¦å¤–éƒ¨æä¾›æˆå¯¹çš„è¾¹ç•Œç‚¹ï¼‰
        # æ­¤å¤„å‡è®¾ coords å·²ç»åŒ…å«æˆå¯¹çš„è¾¹ç•Œç‚¹
        
        # x æ–¹å‘å‘¨æœŸæ€§ï¼ˆä½¿ç”¨å®¹å·®æ¯”è¼ƒé¿å…æµ®é»æ•¸ç²¾åº¦å•é¡Œï¼‰
        tol = 1e-6
        x_min, x_max = self.domain_bounds['x']
        mask_x_min = torch.abs(coords[:, 0] - x_min) < tol
        mask_x_max = torch.abs(coords[:, 0] - x_max) < tol
        
        # z æ–¹å‘å‘¨æœŸæ€§
        z_min, z_max = self.domain_bounds['z']
        mask_z_min = torch.abs(coords[:, 2] - z_min) < tol
        mask_z_max = torch.abs(coords[:, 2] - z_max) < tol
        
        # è®¡ç®—å‘¨æœŸæ€§è¯¯å·®ï¼ˆå¦‚æœè¾¹ç•Œç‚¹å­˜åœ¨ï¼‰
        periodic_x_loss = torch.tensor(0.0, device=coords.device)
        periodic_z_loss = torch.tensor(0.0, device=coords.device)
        
        if mask_x_min.any() and mask_x_max.any():
            # æå– x è¾¹ç•Œçš„åœºå€¼
            fields_x_min = predictions[mask_x_min]
            fields_x_max = predictions[mask_x_max]
            
            # ç¡®ä¿è¾¹ç•Œç‚¹æ•°é‡åŒ¹é…
            n_min = min(fields_x_min.shape[0], fields_x_max.shape[0])
            periodic_x_loss = torch.mean((fields_x_min[:n_min] - fields_x_max[:n_min]) ** 2)
        
        if mask_z_min.any() and mask_z_max.any():
            fields_z_min = predictions[mask_z_min]
            fields_z_max = predictions[mask_z_max]
            
            n_min = min(fields_z_min.shape[0], fields_z_max.shape[0])
            periodic_z_loss = torch.mean((fields_z_min[:n_min] - fields_z_max[:n_min]) ** 2)
        
        return {
            'periodic_x': periodic_x_loss,
            'periodic_z': periodic_z_loss,
        }
    
    def compute_wall_shear_stress(
        self, 
        coords: torch.Tensor, 
        predictions: torch.Tensor,
        scaled_coords: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å£é¢å‰ªåº”åŠ› Ï„_w = Î¼ (âˆ‚u/âˆ‚y)|_{y=Â±1}
        
        Args:
            coords: [batch, 3] = [x, y, z]
            predictions: [batch, 4] = [u, v, w, p]
            scaled_coords: æ¨¡å‹è¼¸å…¥çš„ç¸®æ”¾åº§æ¨™ï¼ˆå¯é¸ï¼‰
            
        Returns:
            å£é¢å‰ªåº”åŠ› {'tau_w_lower', 'tau_w_upper'}
        """
        u = predictions[:, 0:1]
        
        # è®¡ç®— âˆ‚u/âˆ‚y
        if scaled_coords is None:
            scaled_coords = self.scale_coordinates(coords)
        
        u_grads = self.compute_gradients(u, coords, order=1, scaled_coords=scaled_coords)
        du_dy = u_grads['y']
        
        # å£é¢ä½ç½®ï¼ˆä½¿ç”¨å®¹å·®æ¯”è¼ƒé¿å…æµ®é»æ•¸ç²¾åº¦å•é¡Œï¼‰
        tol = 1e-6
        y_lower, y_upper = self.domain_bounds['y']
        mask_lower = torch.abs(coords[:, 1] - y_lower) < tol
        mask_upper = torch.abs(coords[:, 1] - y_upper) < tol
        
        # è®¡ç®—å‰ªåº”åŠ› Ï„ = Î¼ âˆ‚u/âˆ‚y
        mu = self.nu * self.rho  # type: ignore[operator]
        
        tau_w_lower = torch.tensor(0.0, device=coords.device)
        tau_w_upper = torch.tensor(0.0, device=coords.device)
        
        if mask_lower.any():
            tau_w_lower = torch.mean(torch.abs(mu * du_dy[mask_lower]))
        
        if mask_upper.any():
            tau_w_upper = torch.mean(torch.abs(mu * du_dy[mask_upper]))
        
        return {
            'tau_w_lower': tau_w_lower,
            'tau_w_upper': tau_w_upper,
        }
    
    def compute_bulk_velocity_constraint(
        self,
        coords: torch.Tensor,
        predictions: torch.Tensor,
        target_bulk_velocity: float = 1.0,
    ) -> torch.Tensor:
        """
        è®¡ç®—æµé‡çº¦æŸæŸå¤±ï¼šL_flux = (âŸ¨uâŸ©_V - U_b)Â²
        
        ç‰©ç†æ„ä¹‰ï¼š
        - å¯¹äºé€šé“æµï¼Œæ€»æµé‡åº”å›ºå®šï¼ˆæµé‡å®ˆæ’ï¼‰
        - ä½“ç§¯æµé‡: Q = âˆ«âˆ«âˆ« u dV â‰ˆ U_b Â· V_channel
        - U_b æ˜¯**æ•´ä½“ä½“ç§¯å¹³å‡é€Ÿåº¦**ï¼Œä¸æ˜¯æ¯ä¸ª y å±‚çš„å¸¸æ•°å€¼
        
        ä¿®æ­£è¯´æ˜ï¼ˆåŸºäº Physicist å®¡æŸ¥ - tasks/TASK-10/physics_review_new_losses.mdï¼‰ï¼š
        - âŒ é”™è¯¯ç­–ç•¥ï¼šå¼ºåˆ¶æ¯å±‚ âŸ¨uâŸ©_{x,z}(y) = U_b â†’ ä¸å£é¢ BC (u=0) çŸ›ç›¾
        - âœ… æ­£ç¡®ç­–ç•¥ï¼šå…¨åŸŸå¹³å‡ âŸ¨uâŸ©_V = U_b â†’ çº¦æŸæ•´ä½“æµé‡
        
        å®ç°ç­–ç•¥ï¼ˆæ–¹æ¡ˆ A - å…¨åŸŸå¹³å‡ï¼‰ï¼š
        1. è®¡ç®—æ‰¹æ¬¡å†…æ‰€æœ‰ç‚¹çš„ u å¹³å‡å€¼
        2. ä¸ç›®æ ‡ U_b æ¯”è¾ƒï¼Œè®¡ç®—å¹³æ–¹è¯¯å·®
        3. ç®€æ´ã€ç¨³å¥ã€ä¸éšæœºé‡‡æ ·ç­–ç•¥å…¼å®¹
        
        Args:
            coords: [batch, 3] = [x, y, z] ç‰©ç†åæ ‡ï¼ˆæœªä½¿ç”¨ï¼Œä¿æŒæ¥å£ä¸€è‡´æ€§ï¼‰
            predictions: [batch, 4] = [u, v, w, p] é¢„æµ‹å€¼
            target_bulk_velocity: ç›®æ ‡ä½“ç§¯å¹³å‡é€Ÿåº¦ï¼ˆJHTDB: U_b â‰ˆ 0.99994 â‰ˆ 1.0ï¼‰
            
        Returns:
            flux_loss: æ ‡é‡æŸå¤± (âŸ¨uâŸ© - U_b)Â² (ä¿ç•™æ¢¯åº¦)
            
        Note:
            - è‹¥ y é‡‡æ ·ä¸¥é‡ä¸å‡ï¼ˆå¦‚è¿‡é‡‡æ ·å£é¢ï¼‰ï¼Œå¯èƒ½å¼•å…¥åå·®
            - æœªæ¥å¯æ‰©å±•ä¸ºæ–¹æ¡ˆ Bï¼ˆå‰–é¢ç§¯åˆ† + y åŠ æƒï¼‰ï¼Œä½†éœ€æ›´å¤æ‚çš„åˆ†ç®±ç­–ç•¥
        """
        u = predictions[:, 0:1]  # [batch, 1]
        
        # å…¨åŸŸå¹³å‡é€Ÿåº¦ï¼ˆæ‰¹æ¬¡å†…æ‰€æœ‰ç‚¹ï¼‰
        u_global_mean = u.mean()  # æ ‡é‡ï¼ˆä¿ç•™è®¡ç®—å›¾ï¼‰
        
        # æµé‡çº¦æŸæŸå¤±
        flux_loss = (u_global_mean - target_bulk_velocity) ** 2
        
        return flux_loss
    
    def compute_centerline_symmetry(
        self,
        coords: torch.Tensor,
        predictions: torch.Tensor,
        bandwidth: float = 1e-3,
        scaled_coords: Optional[torch.Tensor] = None,
    ) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—ä¸­å¿ƒçº¿å¯¹ç§°çº¦æŸï¼šL_sym = (âˆ‚u/âˆ‚y|_{y=0})Â² + vÂ²|_{y=0}
        
        ç‰©ç†æ„ä¹‰ï¼š
        - é€šé“ä¸­å¿ƒçº¿ï¼ˆy=0ï¼‰ä¸ºå¯¹ç§°é¢
        - ä¸»æµé€Ÿåº¦ u åœ¨ä¸­å¿ƒçº¿åº”æœ‰æå€¼ï¼ˆé©»ç‚¹ï¼‰ï¼šâˆ‚u/âˆ‚y = 0
        - æ³•å‘é€Ÿåº¦ v åœ¨ä¸­å¿ƒçº¿åº”ä¸ºé›¶ï¼ˆæ— ç©¿é€ï¼‰ï¼šv = 0
        
        ä¿®æ­£è¯´æ˜ï¼ˆåŸºäº Physicist å®¡æŸ¥ï¼‰ï¼š
        - âš ï¸ åŸå®ç°ï¼šä¸¥æ ¼å®¹å·® tol=1e-6 â†’ éšæœºé‡‡æ ·æ—¶å¯èƒ½æ— æ ·æœ¬
        - âœ… æ–°ç­–ç•¥ï¼šä½¿ç”¨å¸¦çŠ¶åŒºåŸŸ |y| < bandwidth â†’ æé«˜é‡‡æ ·è¦†ç›–ç‡
        
        çº¦æŸé¡¹ï¼š
        1. L_sym_dudv: (âˆ‚u/âˆ‚y|_{y=0})Â² â†’ å¼ºåˆ¶ä¸»æµé€Ÿåº¦æ¢¯åº¦ä¸ºé›¶
        2. L_sym_v: vÂ²|_{y=0} â†’ å¼ºåˆ¶æ³•å‘é€Ÿåº¦ä¸ºé›¶
        
        Args:
            coords: [batch, 3] = [x, y, z] ç‰©ç†åæ ‡
            predictions: [batch, 4] = [u, v, w, p] é¢„æµ‹å€¼
            bandwidth: ä¸­å¿ƒçº¿å¸¦å®½ Îµï¼Œ|y| < Îµ çš„ç‚¹è§†ä¸ºä¸­å¿ƒçº¿åŒºåŸŸï¼ˆé»˜è®¤ 1e-3ï¼‰
            scaled_coords: æ¨¡å‹è¼¸å…¥çš„ç¸®æ”¾åº§æ¨™ï¼ˆè‹¥å•Ÿç”¨ VS-PINNï¼‰
            
        Returns:
            Dict åŒ…å«ä¸¤é¡¹æŸå¤±:
                - 'centerline_dudy': (âˆ‚u/âˆ‚y|_{yâ‰ˆ0})Â² çš„å¹³å‡å€¼
                - 'centerline_v': vÂ²|_{yâ‰ˆ0} çš„å¹³å‡å€¼
                
        Note:
            - è‹¥æ‰¹æ¬¡ä¸­æ— ä¸­å¿ƒçº¿ç‚¹ï¼Œè¿”å›é›¶æŸå¤±ï¼ˆå®¹é”™ï¼‰
            - å¯é€‰æ‰©å……ï¼šâŸ¨(âˆ‚w/âˆ‚y|_{y=0})Â²âŸ©ï¼ˆw çš„ä¸­å¿ƒçº¿å‰ªåˆ‡ï¼‰
        """
        # æå–åœºå˜é‡
        u = predictions[:, 0:1]  # [batch, 1]
        v = predictions[:, 1:2]  # [batch, 1]
        
        # ä¸­å¿ƒçº¿å¸¦çŠ¶åŒºåŸŸ: |y| < bandwidth
        mask_centerline = torch.abs(coords[:, 1]) < bandwidth  # [batch]
        
        # å®¹é”™ï¼šè‹¥æ— ä¸­å¿ƒçº¿ç‚¹ï¼Œè¿”å›é›¶æŸå¤±
        if not mask_centerline.any():
            zero_loss = torch.tensor(0.0, device=coords.device, requires_grad=True)
            return {
                'centerline_dudy': zero_loss,
                'centerline_v': zero_loss,
            }
        
        # === çº¦æŸ 1: âˆ‚u/âˆ‚y|_{yâ‰ˆ0} = 0 ===
        # è®¡ç®— u å¯¹ y çš„åå¯¼æ•°
        if scaled_coords is None:
            scaled_coords = self.scale_coordinates(coords)
        
        u_grads = self.compute_gradients(u, coords, order=1, scaled_coords=scaled_coords)
        du_dy = u_grads['y']  # [batch, 1]
        
        # æå–ä¸­å¿ƒçº¿åŒºåŸŸçš„æ¢¯åº¦
        du_dy_centerline = du_dy[mask_centerline]  # [n_centerline, 1]
        
        # æŸå¤±ï¼šæ¢¯åº¦å¹³æ–¹çš„å‡å€¼
        loss_dudy = torch.mean(du_dy_centerline ** 2)
        
        # === çº¦æŸ 2: v|_{yâ‰ˆ0} = 0 ===
        # æå–ä¸­å¿ƒçº¿åŒºåŸŸçš„æ³•å‘é€Ÿåº¦
        v_centerline = v[mask_centerline]  # [n_centerline, 1]
        
        # æŸå¤±ï¼šé€Ÿåº¦å¹³æ–¹çš„å‡å€¼
        loss_v = torch.mean(v_centerline ** 2)
        
        return {
            'centerline_dudy': loss_dudy,
            'centerline_v': loss_v,
        }
    
    def compute_pressure_reference(
        self,
        coords: torch.Tensor,
        predictions: torch.Tensor,
        reference_point: Optional[Tuple[float, float, float]] = None,
        k_nearest: int = 16,
    ) -> torch.Tensor:
        """
        è®¡ç®—å‹åŠ›å‚è€ƒç‚¹çº¦æŸï¼šL_pref = (mean(p_k))Â²
        
        ç‰©ç†æ„ä¹‰ï¼š
        - ä¸å¯å‹ç¼© NS æ–¹ç¨‹åªç¡®å®šå‹åŠ›æ¢¯åº¦ï¼Œå‹åŠ›åœºå­˜åœ¨ä»»æ„å¸¸æ•°è‡ªç”±åº¦
        - å›ºå®šå‚è€ƒç‚¹ï¼ˆæˆ–åŒºåŸŸï¼‰å‹åŠ›å¯æ¶ˆé™¤è¯¥è‡ªç”±åº¦ï¼Œä½¿å‹åŠ›åœºå”¯ä¸€ç¡®å®š
        - å¯¹äºå‘¨æœŸæ€§é€šé“æµï¼Œå·²æœ‰ dP/dx å›ºå®šæ¢¯åº¦ï¼Œæ­¤çº¦æŸä¼˜å…ˆçº§è¾ƒä½
        
        ä¿®æ­£è¯´æ˜ï¼ˆåŸºäº Physicist å®¡æŸ¥ï¼‰ï¼š
        - âš ï¸ åŸå®ç°ï¼šä¸¥æ ¼åæ ‡åŒ¹é… â†’ æ‰¹æ¬¡ä¸­å¸¸æ— å‚è€ƒç‚¹ï¼Œé•¿æœŸè¿”å›é›¶æŸå¤±
        - âœ… æ–°ç­–ç•¥ï¼šk æœ€è¿‘é‚»å¹³å‡ â†’ ç¨³å¥è¦†ç›–å‚è€ƒåŒºåŸŸ
        
        å®ç°ç­–ç•¥ï¼š
        1. è®¡ç®—æ‰¹æ¬¡ä¸­æ‰€æœ‰ç‚¹åˆ°å‚è€ƒç‚¹çš„è·ç¦»
        2. é€‰å–æœ€è¿‘çš„ k ä¸ªç‚¹ï¼ˆk=8-16ï¼‰
        3. å¯¹è¿™äº›ç‚¹çš„å‹åŠ›å–å¹³å‡ï¼Œå¼ºåˆ¶å‡å€¼ä¸ºé›¶
        
        Args:
            coords: [batch, 3] = [x, y, z] ç‰©ç†åæ ‡
            predictions: [batch, 4] = [u, v, w, p] é¢„æµ‹å€¼
            reference_point: å¯é€‰çš„å‚è€ƒç‚¹åæ ‡ (x, y, z)ï¼Œé»˜è®¤ä¸ºåŸŸä¸­å¿ƒ
            k_nearest: æœ€è¿‘é‚»ç‚¹æ•°ï¼ˆé»˜è®¤ 16ï¼‰
            
        Returns:
            pressure_ref_loss: æ ‡é‡æŸå¤± (mean(p_k))Â² (ä¿ç•™æ¢¯åº¦)
            
        Note:
            - å½“å‰ dP/dx å·²éšå¼å›ºå®šå‹åŠ›æ¢¯åº¦ï¼Œæ­¤çº¦æŸä¸ºå¯é€‰é¡¹
            - ä»…åœ¨éœ€è¦ç»å¯¹å‹åŠ›å¯¹æ¯”æ—¶å¯ç”¨ï¼ˆå¦‚ä¸å®éªŒæ•°æ®æ¯”å¯¹ï¼‰
            - å»ºè®®æƒé‡ Î»_pref â‰ˆ 0.01ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
        """
        p = predictions[:, 3:4]  # [batch, 1]
        
        # è®¾ç½®å‚è€ƒç‚¹ï¼ˆé»˜è®¤ä¸ºåŸŸä¸­å¿ƒï¼‰
        if reference_point is None:
            x_center = (self.domain_bounds['x'][0] + self.domain_bounds['x'][1]) / 2
            y_center = (self.domain_bounds['y'][0] + self.domain_bounds['y'][1]) / 2
            z_center = (self.domain_bounds['z'][0] + self.domain_bounds['z'][1]) / 2
            reference_point = (x_center, y_center, z_center)
        
        x_ref, y_ref, z_ref = reference_point
        ref_tensor = torch.tensor([x_ref, y_ref, z_ref], device=coords.device, dtype=coords.dtype)  # [3]
        
        # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°å‚è€ƒç‚¹çš„æ¬§æ°è·ç¦»
        distances = torch.norm(coords - ref_tensor.unsqueeze(0), dim=1)  # [batch]
        
        # é€‰å–æœ€è¿‘çš„ k ä¸ªç‚¹
        k_actual = min(k_nearest, coords.size(0))  # é˜²æ­¢ k > batch_size
        _, top_k_indices = torch.topk(distances, k=k_actual, largest=False)  # [k]
        
        # æå– k æœ€è¿‘é‚»çš„å‹åŠ›
        p_k_nearest = p[top_k_indices]  # [k, 1]
        
        # æŸå¤±ï¼šå‹åŠ›å‡å€¼çš„å¹³æ–¹ï¼ˆå¼ºåˆ¶å‚è€ƒåŒºåŸŸå‹åŠ›ä¸ºé›¶ï¼‰
        p_mean = torch.mean(p_k_nearest)
        pressure_ref_loss = p_mean ** 2
        
        return pressure_ref_loss
    
    def compute_loss_weight_compensation(self) -> float:
        """
        è®¡ç®— Loss æƒé‡çš„ç¼©æ”¾è¡¥å¿å› å­
        
        ç†è®ºä¾æ®:
        - ç¼©æ”¾åçš„æ®‹å·®ä¼šè¢« N_maxÂ² æ”¾å¤§
        - éœ€åœ¨ loss æƒé‡ä¸­é™¤ä»¥ N_maxÂ² æŠµæ¶ˆ
        
        Returns:
            compensation_factor: 1 / N_maxÂ²
        """
        return 1.0 / self.N_max_sq.item()  # type: ignore[operator, union-attr]
    
    def normalize_loss_dict(
        self, 
        loss_dict: Dict[str, torch.Tensor], 
        epoch: int
    ) -> Dict[str, torch.Tensor]:
        """
        æå¤±æ­¸ä¸€åŒ–ï¼šå°‡æ¯å€‹æå¤±é …é™¤ä»¥å…¶åƒè€ƒå€¼ï¼Œä½¿æ‰€æœ‰æå¤±åœ¨åŒä¸€æ•¸é‡ç´š
        
        ç­–ç•¥ï¼š
        1. Warmup (epoch < warmup_epochs): æ”¶é›†æ¯å€‹æå¤±é …çš„åˆå§‹å€¼ä½œç‚ºåƒè€ƒ
        2. Training: ä½¿ç”¨åƒè€ƒå€¼é€²è¡Œæ­¸ä¸€åŒ–
        3. ä½¿ç”¨æ»‘å‹•å¹³å‡æ›´æ–°åƒè€ƒå€¼ï¼Œé¿å…åˆå§‹å€¼ä¸ç©©å®š
        
        Args:
            loss_dict: åŸå§‹æå¤±å­—å…¸ {'loss_name': tensor}
            epoch: ç•¶å‰è¨“ç·´ epoch
            
        Returns:
            normalized_loss_dict: æ­¸ä¸€åŒ–å¾Œçš„æå¤±å­—å…¸
            
        Note:
            - æ­¸ä¸€åŒ–ä¸æ”¹è®Šæå¤±çš„ç›¸å°å¤§å°é—œä¿‚ï¼Œä¿æŒç‰©ç†ä¸€è‡´æ€§
            - åªèª¿æ•´çµ•å°å°ºåº¦ï¼Œè®“æ¬Šé‡èƒ½ç›´æ¥åæ˜ å„ªå…ˆç´š
        """
        if not self.normalize_losses:
            return loss_dict
        
        # === Warmup éšæ®µï¼šæ”¶é›†çµ±è¨ˆ ===
        if epoch < self.warmup_epochs:
            for key, loss in loss_dict.items():
                loss_val = loss.detach().item()
                
                if key not in self.loss_normalizers:
                    # é¦–æ¬¡è¨˜éŒ„
                    self.loss_normalizers[key] = loss_val
                else:
                    # æ»‘å‹•å¹³å‡æ›´æ–°ï¼ˆé¿å…å–®æ¬¡ç•°å¸¸å€¼ï¼‰
                    self.loss_normalizers[key] = (
                        self.normalizer_momentum * self.loss_normalizers[key] +
                        (1 - self.normalizer_momentum) * loss_val
                    )
            
            # Warmup æœŸé–“ä¸é€²è¡Œæ­¸ä¸€åŒ–
            return loss_dict
        
        # === Training éšæ®µï¼šæ­¸ä¸€åŒ– ===
        normalized = {}
        for key, loss in loss_dict.items():
            normalizer = self.loss_normalizers.get(key, 1.0)
            if normalizer < 1e-12:
                normalizer = 1.0

            normalized_loss = loss / normalizer

            if key in {
                'momentum_x',
                'momentum_y',
                'momentum_z',
                'continuity',
                'periodicity'
            }:
                normalized_loss = normalized_loss / self.N_max_sq

            normalized[key] = normalized_loss
        
        return normalized
    
    def get_normalization_info(self) -> Dict[str, Any]:
        """
        ç²å–æå¤±æ­¸ä¸€åŒ–ä¿¡æ¯æ‘˜è¦
        
        Returns:
            info: åŒ…å«æ­¸ä¸€åŒ–ç‹€æ…‹èˆ‡åƒè€ƒå€¼çš„å­—å…¸
        """
        return {
            'enabled': self.normalize_losses,
            'warmup_epochs': self.warmup_epochs,
            'normalizers': self.loss_normalizers.copy(),
            'momentum': self.normalizer_momentum,
        }
    
    def get_scaling_info(self) -> Dict[str, Any]:
        """è·å–ç¼©æ”¾ä¿¡æ¯æ‘˜è¦"""
        return {
            'scaling_factors': {
                'N_x': self.N_x.item(),  # type: ignore[union-attr]
                'N_y': self.N_y.item(),  # type: ignore[union-attr]
                'N_z': self.N_z.item(),  # type: ignore[union-attr]
                'N_max': self.N_max.item(),  # type: ignore[union-attr]
            },
            'physics_parameters': {
                'nu': self.nu.item(),  # type: ignore[union-attr]
                'dP_dx': self.dP_dx.item(),  # type: ignore[union-attr]
                'rho': self.rho.item(),  # type: ignore[union-attr]
            },
            'loss_compensation': {
                'factor': self.compute_loss_weight_compensation(),
                'formula': 'Î»_pde_effective = Î»_pde / N_maxÂ²',
            },
            'domain_bounds': self.domain_bounds,
        }


# ==============================================================================
# ä¾¿æ·å‡½æ•°
# ==============================================================================

def create_vs_pinn_channel_flow(
    N_y: float = 12.0,
    N_x: float = 2.0,
    N_z: float = 2.0,
    nu: float = 5e-5,
    dP_dx: float = 0.0025,
    rho: float = 1.0,
    **kwargs
) -> VSPINNChannelFlow:
    """
    åˆ›å»º VS-PINN Channel Flow æ±‚è§£å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        N_y: å£æ³•å‘ç¼©æ”¾å› å­ï¼ˆæ¨è 8-16ï¼‰
        N_x: æµå‘ç¼©æ”¾å› å­ï¼ˆæ¨è 1-4ï¼‰
        N_z: å±•å‘ç¼©æ”¾å› å­ï¼ˆæ¨è 1-4ï¼‰
        nu: åŠ¨åŠ›é»åº¦
        dP_dx: å‹é™æ¢¯åº¦
        rho: å¯†åº¦
        **kwargs: å…¶ä»–å‚æ•°ï¼ˆå¦‚ domain_boundsï¼‰
        
    Returns:
        VSPINNChannelFlow å®ä¾‹
    """
    scaling_factors = {'N_x': N_x, 'N_y': N_y, 'N_z': N_z}
    physics_params = {'nu': nu, 'dP_dx': dP_dx, 'rho': rho}
    
    return VSPINNChannelFlow(
        scaling_factors=scaling_factors,
        physics_params=physics_params,
        **kwargs
    )
