"""
VS-PINN è®Šæ•¸å°ºåº¦åŒ–æ¨¡çµ„
====================

å¯¦ç¾Variable Scaling Physics-Informed Neural Networksçš„å°ºåº¦åŒ–åŠŸèƒ½ï¼š
1. å¯å­¸ç¿’çš„è¼¸å…¥/è¼¸å‡ºè®Šæ•¸å°ºåº¦åŒ–
2. æ¨™æº–åŒ–ã€æœ€å¤§æœ€å°å€¼æ¨™æº–åŒ–ç­‰å‚³çµ±æ–¹æ³•
3. å¾è³‡æ–™è‡ªå‹•æ¨æ–·å°ºåº¦åƒæ•¸
4. æ¢¯åº¦åæ¨™æº–åŒ– (ç”¨æ–¼ç‰©ç†å®šå¾‹è¨ˆç®—)
"""

import torch
import torch.nn as nn
from typing import Union, Tuple, Optional, Dict, Any
import numpy as np
from abc import ABC, abstractmethod

class BaseScaler(ABC, nn.Module):
    """å°ºåº¦åŒ–å™¨åŸºé¡"""
    
    def __init__(self):
        super().__init__()
    
    @abstractmethod
    def fit(self, data: torch.Tensor) -> 'BaseScaler':
        """æ ¹æ“šè³‡æ–™æ“¬åˆå°ºåº¦åƒæ•¸"""
        pass
    
    @abstractmethod
    def transform(self, data: torch.Tensor) -> torch.Tensor:
        """å°‡è³‡æ–™è½‰æ›åˆ°æ¨™æº–åŒ–ç©ºé–“"""
        pass
    
    @abstractmethod  
    def inverse_transform(self, data: torch.Tensor) -> torch.Tensor:
        """å°‡æ¨™æº–åŒ–è³‡æ–™è½‰æ›å›åŸå§‹ç©ºé–“"""
        pass
    
    def fit_transform(self, data: torch.Tensor) -> torch.Tensor:
        """æ“¬åˆä¸¦è½‰æ›è³‡æ–™"""
        return self.fit(data).transform(data)

class StandardScaler(BaseScaler):
    """
    æ¨™æº–åŒ–å°ºåº¦å™¨: x_norm = (x - Î¼) / Ïƒ
    ä½¿ç”¨å‡å€¼å’Œæ¨™æº–å·®é€²è¡Œæ¨™æº–åŒ–
    """
    
    def __init__(self, learnable: bool = False):
        super().__init__()
        self.learnable = learnable
        self.fitted = False
        
    def fit(self, data: torch.Tensor) -> 'StandardScaler':
        """
        æ ¹æ“šè³‡æ–™è¨ˆç®—å‡å€¼å’Œæ¨™æº–å·®
        
        Args:
            data: è¼¸å…¥è³‡æ–™ [batch_size, feature_dim]
        """
        with torch.no_grad():
            mean = torch.mean(data, dim=0, keepdim=True)
            std = torch.std(data, dim=0, keepdim=True)
            
            # é¿å…é™¤é›¶éŒ¯èª¤
            std = torch.where(std < 1e-8, torch.ones_like(std), std)
        
        # è¨»å†Šåƒæ•¸ (å¯å­¸ç¿’æˆ–å›ºå®š)
        self.register_parameter(
            'mean', 
            nn.Parameter(mean, requires_grad=self.learnable)
        )
        self.register_parameter(
            'std',
            nn.Parameter(std, requires_grad=self.learnable)  
        )
        
        self.fitted = True
        return self
    
    def transform(self, data: torch.Tensor) -> torch.Tensor:
        """æ¨™æº–åŒ–è½‰æ›"""
        if not self.fitted:
            raise RuntimeError("å°ºåº¦å™¨å°šæœªæ“¬åˆï¼Œè«‹å…ˆèª¿ç”¨ fit() æ–¹æ³•")
        
        return (data - self.mean) / self.std
    
    def inverse_transform(self, data: torch.Tensor) -> torch.Tensor:
        """é€†æ¨™æº–åŒ–è½‰æ›"""
        if not self.fitted:
            raise RuntimeError("å°ºåº¦å™¨å°šæœªæ“¬åˆï¼Œè«‹å…ˆèª¿ç”¨ fit() æ–¹æ³•")
        
        return data * self.std + self.mean

class MinMaxScaler(BaseScaler):
    """
    æœ€å¤§æœ€å°å€¼å°ºåº¦å™¨: x_norm = (x - min) / (max - min)
    å°‡è³‡æ–™ç¸®æ”¾åˆ° [0, 1] ç¯„åœ
    """
    
    def __init__(self, feature_range: Tuple[float, float] = (0.0, 1.0), 
                 learnable: bool = False):
        super().__init__()
        self.feature_range = feature_range
        self.learnable = learnable  
        self.fitted = False
        
    def fit(self, data: torch.Tensor) -> 'MinMaxScaler':
        """æ ¹æ“šè³‡æ–™è¨ˆç®—æœ€å¤§æœ€å°å€¼"""
        with torch.no_grad():
            data_min = torch.min(data, dim=0, keepdim=True)[0]
            data_max = torch.max(data, dim=0, keepdim=True)[0]
            
            # é¿å…é™¤é›¶éŒ¯èª¤
            data_range = data_max - data_min
            data_range = torch.where(
                data_range < 1e-8, 
                torch.ones_like(data_range), 
                data_range
            )
        
        self.register_parameter(
            'data_min',
            nn.Parameter(data_min, requires_grad=self.learnable)
        )
        self.register_parameter(
            'data_range', 
            nn.Parameter(data_range, requires_grad=self.learnable)
        )
        
        self.fitted = True
        return self
        
    def transform(self, data: torch.Tensor) -> torch.Tensor:
        """æœ€å¤§æœ€å°å€¼æ¨™æº–åŒ–"""
        if not self.fitted:
            raise RuntimeError("å°ºåº¦å™¨å°šæœªæ“¬åˆ")
            
        # æ¨™æº–åŒ–åˆ° [0, 1]
        normalized = (data - self.data_min) / self.data_range
        
        # ç¸®æ”¾åˆ°æŒ‡å®šç¯„åœ
        scale = self.feature_range[1] - self.feature_range[0]
        return normalized * scale + self.feature_range[0]
    
    def inverse_transform(self, data: torch.Tensor) -> torch.Tensor:
        """é€†æœ€å¤§æœ€å°å€¼æ¨™æº–åŒ–"""
        if not self.fitted:
            raise RuntimeError("å°ºåº¦å™¨å°šæœªæ“¬åˆ")
            
        # å¾æŒ‡å®šç¯„åœç¸®æ”¾å› [0, 1]
        scale = self.feature_range[1] - self.feature_range[0]
        normalized = (data - self.feature_range[0]) / scale
        
        # é€†æ¨™æº–åŒ–åˆ°åŸå§‹ç¯„åœ
        return normalized * self.data_range + self.data_min

class VSScaler(BaseScaler):
    """
    VS-PINN è®Šæ•¸å°ºåº¦å™¨
    å¯å­¸ç¿’çš„è¼¸å…¥è¼¸å‡ºå°ºåº¦åŒ–ï¼Œæ”¯æ´ç¨ç«‹çš„å‡å€¼å’Œæ–¹å·®å­¸ç¿’
    """
    
    def __init__(self, 
                 input_dim: int,
                 output_dim: int, 
                 learnable: bool = True,
                 init_method: str = "standard"):
        super().__init__()
        
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.learnable = learnable
        self.init_method = init_method
        self.fitted = False
        
        # åˆå§‹åŒ–å¯å­¸ç¿’åƒæ•¸
        self._initialize_parameters()
    
    def _initialize_parameters(self):
        """åˆå§‹åŒ–å°ºåº¦åƒæ•¸"""
        # è¼¸å…¥å°ºåº¦åƒæ•¸
        if self.init_method == "standard":
            input_mean = torch.zeros(1, self.input_dim)
            input_std = torch.ones(1, self.input_dim)
        elif self.init_method == "uniform":
            input_mean = torch.zeros(1, self.input_dim)
            input_std = torch.ones(1, self.input_dim)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„åˆå§‹åŒ–æ–¹æ³•: {self.init_method}")
        
        self.register_parameter(
            'input_mean',
            nn.Parameter(input_mean, requires_grad=self.learnable)
        )
        self.register_parameter(
            'input_std', 
            nn.Parameter(input_std, requires_grad=self.learnable)
        )
        
        # è¼¸å‡ºå°ºåº¦åƒæ•¸  
        output_mean = torch.zeros(1, self.output_dim)
        output_std = torch.ones(1, self.output_dim)
        
        self.register_parameter(
            'output_mean',
            nn.Parameter(output_mean, requires_grad=self.learnable)
        )
        self.register_parameter(
            'output_std',
            nn.Parameter(output_std, requires_grad=self.learnable)
        )
    
    def fit(self, input_data: torch.Tensor, 
            output_data: Optional[torch.Tensor] = None) -> 'VSScaler':
        """
        æ ¹æ“šè³‡æ–™æ“¬åˆå°ºåº¦åƒæ•¸
        
        Args:
            input_data: è¼¸å…¥è³‡æ–™ [batch_size, input_dim]
            output_data: è¼¸å‡ºè³‡æ–™ [batch_size, output_dim] (å¯é¸)
        """
        with torch.no_grad():
            # æ“¬åˆè¼¸å…¥å°ºåº¦
            input_mean = torch.mean(input_data, dim=0, keepdim=True)
            input_std = torch.std(input_data, dim=0, keepdim=True)
            input_std = torch.where(
                input_std < 1e-8, 
                torch.ones_like(input_std), 
                input_std
            )
            
            self.input_mean.data.copy_(input_mean)
            self.input_std.data.copy_(input_std)
            
            # æ“¬åˆè¼¸å‡ºå°ºåº¦ (å¦‚æœæä¾›è¼¸å‡ºè³‡æ–™)
            if output_data is not None:
                output_mean = torch.mean(output_data, dim=0, keepdim=True)
                output_std = torch.std(output_data, dim=0, keepdim=True) 
                output_std = torch.where(
                    output_std < 1e-8,
                    torch.ones_like(output_std),
                    output_std
                )
                
                self.output_mean.data.copy_(output_mean)
                self.output_std.data.copy_(output_std)
        
        self.fitted = True
        return self
    
    def transform_input(self, data: torch.Tensor) -> torch.Tensor:
        """æ¨™æº–åŒ–è¼¸å…¥è³‡æ–™"""
        return (data - self.input_mean) / self.input_std
    
    def transform_output(self, data: torch.Tensor) -> torch.Tensor:
        """æ¨™æº–åŒ–è¼¸å‡ºè³‡æ–™"""  
        return (data - self.output_mean) / self.output_std
    
    def inverse_transform_input(self, data: torch.Tensor) -> torch.Tensor:
        """é€†æ¨™æº–åŒ–è¼¸å…¥è³‡æ–™"""
        return data * self.input_std + self.input_mean
    
    def inverse_transform_output(self, data: torch.Tensor) -> torch.Tensor:
        """é€†æ¨™æº–åŒ–è¼¸å‡ºè³‡æ–™"""
        return data * self.output_std + self.output_mean
    
    # ç‚ºäº†å…¼å®¹BaseScalerä»‹é¢
    def transform(self, data: torch.Tensor) -> torch.Tensor:
        return self.transform_input(data)
    
    def inverse_transform(self, data: torch.Tensor) -> torch.Tensor:
        return self.inverse_transform_input(data)
    
    def get_scale_info(self) -> Dict[str, torch.Tensor]:
        """ç²å–ç•¶å‰å°ºåº¦åƒæ•¸è³‡è¨Š"""
        return {
            'input_mean': self.input_mean.data.clone(),
            'input_std': self.input_std.data.clone(),
            'output_mean': self.output_mean.data.clone(), 
            'output_std': self.output_std.data.clone()
        }

def create_scaler_from_data(input_data: torch.Tensor,
                          output_data: Optional[torch.Tensor] = None,
                          scaler_type: str = "standard",
                          learnable: bool = False,
                          **kwargs) -> BaseScaler:
    """
    æ ¹æ“šè³‡æ–™è‡ªå‹•å‰µå»ºä¸¦æ“¬åˆå°ºåº¦å™¨
    
    Args:
        input_data: è¼¸å…¥è³‡æ–™
        output_data: è¼¸å‡ºè³‡æ–™ (å¯é¸)
        scaler_type: å°ºåº¦å™¨é¡å‹ ("standard", "minmax", "vs")
        learnable: æ˜¯å¦å¯å­¸ç¿’
        **kwargs: é¡å¤–åƒæ•¸
        
    Returns:
        å·²æ“¬åˆçš„å°ºåº¦å™¨
    """
    if scaler_type == "standard":
        scaler = StandardScaler(learnable=learnable)
        scaler.fit(input_data)
        
    elif scaler_type == "minmax":
        feature_range = kwargs.get('feature_range', (0.0, 1.0))
        scaler = MinMaxScaler(feature_range=feature_range, learnable=learnable)
        scaler.fit(input_data)
        
    elif scaler_type == "vs":
        input_dim = input_data.shape[1]
        output_dim = output_data.shape[1] if output_data is not None else 1
        init_method = kwargs.get('init_method', "standard")
        
        scaler = VSScaler(
            input_dim=input_dim,
            output_dim=output_dim,
            learnable=learnable,
            init_method=init_method
        )
        scaler.fit(input_data, output_data)
        
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„å°ºåº¦å™¨é¡å‹: {scaler_type}")
    
    return scaler

def denormalize_gradients(gradients: torch.Tensor,
                         scaler: BaseScaler,
                         input_coords: torch.Tensor,
                         output_vars: torch.Tensor) -> torch.Tensor:
    """
    å°‡æ¨™æº–åŒ–ç©ºé–“çš„æ¢¯åº¦è½‰æ›å›ç‰©ç†ç©ºé–“
    ç”¨æ–¼ç‰©ç†å®šå¾‹è¨ˆç®—ä¸­çš„æ¢¯åº¦æ ¡æ­£
    
    Args:
        gradients: æ¨™æº–åŒ–ç©ºé–“çš„æ¢¯åº¦
        scaler: ä½¿ç”¨çš„å°ºåº¦å™¨
        input_coords: è¼¸å…¥åº§æ¨™
        output_vars: è¼¸å‡ºè®Šæ•¸
        
    Returns:
        ç‰©ç†ç©ºé–“çš„æ¢¯åº¦
    """
    if isinstance(scaler, VSScaler):
        # VS-PINN æ¢¯åº¦è®Šæ›
        # âˆ‚f_phys/âˆ‚x_phys = (âˆ‚f_norm/âˆ‚x_norm) * (Ïƒ_f/Ïƒ_x)
        input_scale = scaler.input_std
        output_scale = scaler.output_std
        
        scale_factor = output_scale / input_scale
        physical_gradients = gradients * scale_factor
        
    elif isinstance(scaler, StandardScaler):
        # æ¨™æº–å°ºåº¦å™¨æ¢¯åº¦è®Šæ›
        scale_factor = scaler.std  # åªè€ƒæ…®æ¨™æº–å·®ç¸®æ”¾
        physical_gradients = gradients / scale_factor
        
    elif isinstance(scaler, MinMaxScaler):
        # æœ€å¤§æœ€å°å€¼å°ºåº¦å™¨æ¢¯åº¦è®Šæ›
        scale_factor = scaler.data_range
        physical_gradients = gradients * scale_factor
        
    else:
        # å¦‚æœä¸æ˜¯å·²çŸ¥çš„å°ºåº¦å™¨ï¼Œè¿”å›åŸå§‹æ¢¯åº¦
        physical_gradients = gradients
    
    return physical_gradients

# é«˜ç´šå°ºåº¦åŒ–å·¥å…·
class AdaptiveScaler(VSScaler):
    """
    è‡ªé©æ‡‰å°ºåº¦å™¨
    åœ¨è¨“ç·´éç¨‹ä¸­å‹•æ…‹èª¿æ•´å°ºåº¦åƒæ•¸
    """
    
    def __init__(self, input_dim: int, output_dim: int, 
                 adaptation_rate: float = 0.01):
        super().__init__(input_dim, output_dim, learnable=True)
        self.adaptation_rate = adaptation_rate
        self.update_count = 0
    
    def adaptive_update(self, input_batch: torch.Tensor,
                       output_batch: torch.Tensor):
        """æ ¹æ“šç•¶å‰æ‰¹æ¬¡è‡ªé©æ‡‰æ›´æ–°å°ºåº¦åƒæ•¸"""
        with torch.no_grad():
            # è¨ˆç®—ç•¶å‰æ‰¹æ¬¡çµ±è¨ˆ
            batch_input_mean = torch.mean(input_batch, dim=0, keepdim=True)
            batch_input_std = torch.std(input_batch, dim=0, keepdim=True)
            
            batch_output_mean = torch.mean(output_batch, dim=0, keepdim=True)
            batch_output_std = torch.std(output_batch, dim=0, keepdim=True)
            
            # æŒ‡æ•¸ç§»å‹•å¹³å‡æ›´æ–°
            alpha = self.adaptation_rate
            
            self.input_mean.data = (1-alpha) * self.input_mean.data + alpha * batch_input_mean
            self.input_std.data = (1-alpha) * self.input_std.data + alpha * batch_input_std
            
            self.output_mean.data = (1-alpha) * self.output_mean.data + alpha * batch_output_mean
            self.output_std.data = (1-alpha) * self.output_std.data + alpha * batch_output_std
            
            self.update_count += 1

def analyze_scaling_sensitivity(model: nn.Module,
                              scaler: BaseScaler,
                              test_data: torch.Tensor,
                              scale_factors: np.ndarray = None) -> Dict[str, Any]:
    """
    åˆ†ææ¨¡å‹å°å°ºåº¦è®ŠåŒ–çš„æ•æ„Ÿæ€§
    ç”¨æ–¼å„ªåŒ–å°ºåº¦åƒæ•¸
    
    Args:
        model: ç¥ç¶“ç¶²è·¯æ¨¡å‹
        scaler: å°ºåº¦å™¨
        test_data: æ¸¬è©¦è³‡æ–™
        scale_factors: å°ºåº¦å› å­ç¯„åœ
        
    Returns:
        æ•æ„Ÿæ€§åˆ†æçµæœ
    """
    if scale_factors is None:
        scale_factors = np.logspace(-1, 1, 11)  # 0.1 åˆ° 10
    
    results = {
        'scale_factors': scale_factors,
        'losses': [],
        'gradients': []
    }
    
    original_state = scaler.state_dict()
    
    for factor in scale_factors:
        # ä¿®æ”¹å°ºåº¦åƒæ•¸
        if isinstance(scaler, VSScaler):
            scaler.input_std.data *= factor
            scaler.output_std.data *= factor
        
        # è©•ä¼°æ¨¡å‹æ€§èƒ½
        with torch.no_grad():
            scaled_input = scaler.transform_input(test_data)
            output = model(scaled_input)
            scaled_output = scaler.inverse_transform_output(output)
            
            # è¨ˆç®—æŸç¨®æå¤± (é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›æƒ…æ³å®šç¾©)
            loss = torch.mean(scaled_output**2)  # ç°¡å–®çš„L2æå¤±ç¤ºä¾‹
            results['losses'].append(loss.item())
        
        # æ¢å¾©åŸå§‹ç‹€æ…‹
        scaler.load_state_dict(original_state)
    
    return results


# ==============================================================================
# JHTDB Channel Flow å°ˆç”¨ç„¡é‡ç¶±åŒ–ç³»çµ±
# ==============================================================================

class NonDimensionalizer(nn.Module):
    """
    JHTDB Channel Flow Re=1000 å°ˆç”¨ç„¡é‡ç¶±åŒ–å™¨
    
    åŸºæ–¼ Buckingham Ï€ å®šç†å’Œ arXiv 2308.08468 æœ€ä½³å¯¦è¸è¨­è¨ˆ
    ç¢ºä¿ç‰©ç†ä¸€è‡´æ€§å’Œæ•¸å€¼ç©©å®šæ€§
    
    ç‰¹å¾µé‡:
    - L_char = 1.0 (åŠé€šé“é«˜åº¦)  
    - U_char = 1.0 (æ‘©æ“¦é€Ÿåº¦ u_Ï„)
    - t_char = 1.0 (h/u_Ï„)
    - P_char = 1.0 (Ïu_Ï„Â²)
    - Re_Ï„ = 1000 (æ‘©æ“¦é›·è«¾æ•¸)
    """
    
    def __init__(self, config: Optional[Dict[str, float]] = None):
        super().__init__()
        
        # JHTDB Channel Flow Re=1000 ç‰©ç†åƒæ•¸
        default_config = {
            'L_char': 1.0,         # åŠé€šé“é«˜åº¦
            'U_char': 1.0,         # æ‘©æ“¦é€Ÿåº¦ u_Ï„
            't_char': 1.0,         # L_char/U_char
            'P_char': 1.0,         # ÏU_charÂ²
            'nu': 1e-3,            # å‹•åŠ›é»åº¦ Î½ = U_char*L_char/Re_Ï„
            'Re_tau': 1000.0,      # æ‘©æ“¦é›·è«¾æ•¸
            'rho': 1.0,            # å¯†åº¦ (æ¨™æº–åŒ–ç‚º1)
        }
        
        if config is not None:
            default_config.update(config)
        
        self.config = default_config
        
        # è¨»å†Šç‰¹å¾µé‡ç‚ºç·©è¡å€ (ä¸åƒèˆ‡æ¢¯åº¦è¨ˆç®—)
        for key, value in default_config.items():
            self.register_buffer(key, torch.tensor(float(value)))
        
        # é©—è­‰ç‰©ç†ä¸€è‡´æ€§
        self._verify_physical_consistency()
        
        # çµ±è¨ˆé‡ç·©è¡å€ (å°‡åœ¨ fit æ–¹æ³•ä¸­å¡«å……)
        self.register_buffer('coord_stats_fitted', torch.tensor(False))
        self.register_buffer('field_stats_fitted', torch.tensor(False))
        
    def _verify_physical_consistency(self):
        """é©—è­‰ç‰©ç†åƒæ•¸çš„ä¸€è‡´æ€§"""
        # é›·è«¾æ•¸ä¸€è‡´æ€§æª¢æŸ¥: Re_Ï„ = U_char * L_char / Î½
        # ä½¿ç”¨ float64 ç²¾åº¦é€²è¡Œé—œéµè¨ˆç®—ä»¥é¿å…æ•¸å€¼èª¤å·®
        Re_computed = (self.U_char.double() * self.L_char.double() / self.nu.double()).float()
        
        # èª¿æ•´å®¹å·®ä»¥é©æ‡‰ float32 ç²¾åº¦é™åˆ¶ (æ ¹æ“šé¢¨éšªåˆ†æ #007)
        tolerance = 1e-4  # å¾ç†è«–ç›®æ¨™ 1e-12 èª¿æ•´ç‚ºå¯¦éš›å¯è¡Œçš„ 1e-4
        
        if abs(Re_computed - self.Re_tau) > tolerance:
            raise ValueError(
                f"é›·è«¾æ•¸ä¸ä¸€è‡´: é…ç½® Re_Ï„={self.Re_tau}, "
                f"è¨ˆç®—å€¼={Re_computed:.12f}, å·®ç•°={abs(Re_computed - self.Re_tau):.2e}, "
                f"å®¹å·®={tolerance:.2e}"
            )
        
        # ç‰¹å¾µæ™‚é–“ä¸€è‡´æ€§æª¢æŸ¥
        t_computed = self.L_char / self.U_char
        if abs(t_computed - self.t_char) > 1e-10:
            raise ValueError(f"ç‰¹å¾µæ™‚é–“ä¸ä¸€è‡´: t_char={self.t_char}, è¨ˆç®—å€¼={t_computed}")
        
        # ç‰¹å¾µå£“åŠ›ä¸€è‡´æ€§æª¢æŸ¥  
        P_computed = self.rho * self.U_char**2
        if abs(P_computed - self.P_char) > 1e-10:
            raise ValueError(f"ç‰¹å¾µå£“åŠ›ä¸ä¸€è‡´: P_char={self.P_char}, è¨ˆç®—å€¼={P_computed}")
        
        print(f"âœ… ç‰©ç†ä¸€è‡´æ€§é©—è­‰é€šé: Re_Ï„={self.Re_tau}, Î½={self.nu}")
    
    def fit_statistics(self, coords: torch.Tensor, fields: torch.Tensor, 
                      robust: bool = True) -> 'NonDimensionalizer':
        """
        æ ¹æ“š JHTDB æ•¸æ“šæ“¬åˆçµ±è¨ˆé‡
        
        Args:
            coords: åº§æ¨™ [N, 2] (x, y)
            fields: ç‰©ç†å ´ [N, 3] (u, v, p) 
            robust: æ˜¯å¦ä½¿ç”¨ç©©å¥çµ±è¨ˆä¼°è¨ˆ
        """
        with torch.no_grad():
            if robust:
                coord_stats = self._robust_statistics(coords)
                field_stats = self._robust_statistics(fields)
            else:
                coord_stats = self._standard_statistics(coords) 
                field_stats = self._standard_statistics(fields)
            
            # åº§æ¨™çµ±è¨ˆé‡
            self.register_buffer('x_mean', coord_stats['mean'][:1])
            self.register_buffer('x_std', coord_stats['std'][:1])
            self.register_buffer('y_mean', coord_stats['mean'][1:2])
            self.register_buffer('y_std', coord_stats['std'][1:2])
            
            # å ´è®Šæ•¸çµ±è¨ˆé‡ (u, v, p)
            self.register_buffer('u_mean', field_stats['mean'][:1])
            self.register_buffer('u_std', field_stats['std'][:1])
            self.register_buffer('v_mean', field_stats['mean'][1:2])
            self.register_buffer('v_std', field_stats['std'][1:2])
            self.register_buffer('p_mean', field_stats['mean'][2:3])
            self.register_buffer('p_std', field_stats['std'][2:3])
            
            # æ›´æ–°ç‹€æ…‹
            self.coord_stats_fitted = torch.tensor(True)
            self.field_stats_fitted = torch.tensor(True)
            
            # è¨˜éŒ„çµ±è¨ˆè³‡è¨Š
            print(f"ğŸ“Š çµ±è¨ˆé‡æ“¬åˆå®Œæˆ:")
            print(f"  åº§æ¨™ - x: Î¼={self.x_mean.item():.3f}, Ïƒ={self.x_std.item():.3f}")
            print(f"  åº§æ¨™ - y: Î¼={self.y_mean.item():.3f}, Ïƒ={self.y_std.item():.3f}")
            print(f"  é€Ÿåº¦ - u: Î¼={self.u_mean.item():.3f}, Ïƒ={self.u_std.item():.3f}")
            print(f"  é€Ÿåº¦ - v: Î¼={self.v_mean.item():.3f}, Ïƒ={self.v_std.item():.3f}")
            print(f"  å£“åŠ› - p: Î¼={self.p_mean.item():.3f}, Ïƒ={self.p_std.item():.3f}")
        
        return self
    
    def _robust_statistics(self, data: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ç©©å¥çµ±è¨ˆé‡ä¼°è¨ˆ (åŸºæ–¼åˆ†ä½æ•¸)"""
        q25, q50, q75 = torch.quantile(data, torch.tensor([0.25, 0.5, 0.75]), dim=0)
        iqr = q75 - q25
        
        # ç•°å¸¸å€¼æª¢æ¸¬å’Œéæ¿¾
        lower_bound = q25 - 1.5 * iqr
        upper_bound = q75 + 1.5 * iqr
        
        filtered_data = []
        for i in range(data.shape[1]):
            col_data = data[:, i]
            mask = (col_data >= lower_bound[i]) & (col_data <= upper_bound[i])
            filtered_col = col_data[mask]
            if len(filtered_col) < 0.5 * len(col_data):  # å¦‚æœéæ¿¾å¤ªå¤šï¼Œä½¿ç”¨åŸå§‹æ•¸æ“š
                filtered_col = col_data
            filtered_data.append(filtered_col)
        
        # è¨ˆç®—ç©©å¥çµ±è¨ˆé‡
        robust_mean = torch.stack([torch.median(col) for col in filtered_data])
        robust_std = iqr / 1.349  # é«˜æ–¯åˆ†ä½ˆä¸‹ IQRâ†’Ïƒ è½‰æ›
        
        # ç¢ºä¿ std > 0
        robust_std = torch.where(robust_std < 1e-8, torch.ones_like(robust_std), robust_std)
        
        return {'mean': robust_mean, 'std': robust_std}
    
    def _standard_statistics(self, data: torch.Tensor) -> Dict[str, torch.Tensor]:
        """æ¨™æº–çµ±è¨ˆé‡ä¼°è¨ˆ"""
        mean = torch.mean(data, dim=0)
        std = torch.std(data, dim=0)
        std = torch.where(std < 1e-8, torch.ones_like(std), std)
        
        return {'mean': mean, 'std': std}
    
    def scale_coordinates(self, coords: torch.Tensor) -> torch.Tensor:
        """
        åº§æ¨™ç„¡é‡ç¶±åŒ–: ä¿æŒç‰©ç†æ„ç¾©çš„åŒæ™‚æ¨™æº–åŒ–æ•¸å€¼ç¯„åœ
        
        Args:
            coords: [N, 2] (x, y) ç‰©ç†åº§æ¨™
            
        Returns:
            scaled_coords: [N, 2] ç„¡é‡ç¶±åŒ–åº§æ¨™
        """
        if not self.coord_stats_fitted:
            raise RuntimeError("åº§æ¨™çµ±è¨ˆé‡å°šæœªæ“¬åˆï¼Œè«‹å…ˆèª¿ç”¨ fit_statistics()")
        
        x, y = coords[:, 0:1], coords[:, 1:2]
        
        # æµå‘(x): åŸºæ–¼é€±æœŸé•·åº¦æ¨™æº–åŒ–åˆ° [-1, 1] 
        # JHTDB Channel Flow: x âˆˆ [0, 8Ï€] â†’ [-1, 1]
        x_scaled = 2 * (x / (8 * np.pi)) - 1
        
        # å£æ³•å‘(y): åŸºæ–¼çµ±è¨ˆé‡æ¨™æº–åŒ– (å·²åœ¨ [-1, 1])
        y_scaled = (y - self.y_mean) / self.y_std
        
        return torch.cat([x_scaled, y_scaled], dim=1)
    
    def scale_velocity(self, velocity: torch.Tensor) -> torch.Tensor:
        """
        é€Ÿåº¦å ´ç„¡é‡ç¶±åŒ–: åŸºæ–¼æ‘©æ“¦é€Ÿåº¦å’Œçµ±è¨ˆæ¨™æº–åŒ–
        
        Args:
            velocity: [N, 2] (u, v) ç‰©ç†é€Ÿåº¦
            
        Returns:
            scaled_velocity: [N, 2] ç„¡é‡ç¶±åŒ–é€Ÿåº¦
        """
        if not self.field_stats_fitted:
            raise RuntimeError("å ´çµ±è¨ˆé‡å°šæœªæ“¬åˆï¼Œè«‹å…ˆèª¿ç”¨ fit_statistics()")
        
        u, v = velocity[:, 0:1], velocity[:, 1:2]
        
        # çµ±è¨ˆæ¨™æº–åŒ– + é™åˆ¶ç¯„åœé¿å…æ¥µå€¼
        u_scaled = (u - self.u_mean) / self.u_std
        v_scaled = (v - self.v_mean) / self.v_std
        
        # é™åˆ¶åˆ°åˆç†ç¯„åœ (3Ïƒ åŸå‰‡)
        u_scaled = torch.clamp(u_scaled, -3.0, 3.0)
        v_scaled = torch.clamp(v_scaled, -3.0, 3.0)
        
        return torch.cat([u_scaled, v_scaled], dim=1)
    
    def scale_pressure(self, pressure: torch.Tensor) -> torch.Tensor:
        """
        å£“åŠ›å ´ç„¡é‡ç¶±åŒ–: åŸºæ–¼æ‘©æ“¦å£“åŠ›æ¨™æº–åŒ–
        
        Args:
            pressure: [N, 1] ç‰©ç†å£“åŠ›
            
        Returns:
            scaled_pressure: [N, 1] ç„¡é‡ç¶±åŒ–å£“åŠ›
        """
        if not self.field_stats_fitted:
            raise RuntimeError("å ´çµ±è¨ˆé‡å°šæœªæ“¬åˆï¼Œè«‹å…ˆèª¿ç”¨ fit_statistics()")
        
        # çµ±è¨ˆæ¨™æº–åŒ–
        p_scaled = (pressure - self.p_mean) / self.p_std
        
        # å£“åŠ›å…è¨±æ›´å¤§æ³¢å‹•ç¯„åœ
        p_scaled = torch.clamp(p_scaled, -4.0, 4.0)
        
        return p_scaled
    
    def inverse_scale_coordinates(self, coords_scaled: torch.Tensor) -> torch.Tensor:
        """åº§æ¨™åå‘ç¸®æ”¾"""
        x_scaled, y_scaled = coords_scaled[:, 0:1], coords_scaled[:, 1:2]
        
        # åå‘æµå‘ç¸®æ”¾: [-1, 1] â†’ [0, 8Ï€]
        x = (x_scaled + 1) * (8 * np.pi) / 2
        
        # åå‘å£æ³•å‘ç¸®æ”¾
        y = y_scaled * self.y_std + self.y_mean
        
        return torch.cat([x, y], dim=1)
    
    def inverse_scale_velocity(self, velocity_scaled: torch.Tensor) -> torch.Tensor:
        """é€Ÿåº¦å ´åå‘ç¸®æ”¾"""
        u_scaled, v_scaled = velocity_scaled[:, 0:1], velocity_scaled[:, 1:2]
        
        u = u_scaled * self.u_std + self.u_mean
        v = v_scaled * self.v_std + self.v_mean
        
        return torch.cat([u, v], dim=1)
    
    def inverse_scale_pressure(self, pressure_scaled: torch.Tensor) -> torch.Tensor:
        """å£“åŠ›å ´åå‘ç¸®æ”¾"""
        return pressure_scaled * self.p_std + self.p_mean
    
    def transform_gradients(self, gradients_scaled: torch.Tensor, 
                          variable_type: str, coord_type: str) -> torch.Tensor:
        """
        æ¢¯åº¦ç¸®æ”¾è®Šæ›: éˆå¼æ³•å‰‡æ‡‰ç”¨
        
        âˆ‚f_phys/âˆ‚x_phys = (âˆ‚f_scaled/âˆ‚x_scaled) Ã— (scale_f/scale_x)
        
        Args:
            gradients_scaled: ç¸®æ”¾ç©ºé–“æ¢¯åº¦
            variable_type: è®Šæ•¸é¡å‹ ('velocity', 'pressure')
            coord_type: åº§æ¨™é¡å‹ ('spatial_x', 'spatial_y', 'temporal')
            
        Returns:
            physical_gradients: ç‰©ç†ç©ºé–“æ¢¯åº¦
        """
        if variable_type == 'velocity' and coord_type == 'spatial_x':
            # âˆ‚u/âˆ‚x: é€Ÿåº¦å°æµå‘çš„æ¢¯åº¦
            scale_factor = self.u_std / (8 * np.pi / 2)  # u_scale / x_scale
            
        elif variable_type == 'velocity' and coord_type == 'spatial_y':
            # âˆ‚u/âˆ‚y: é€Ÿåº¦å°å£æ³•å‘çš„æ¢¯åº¦  
            scale_factor = self.u_std / self.y_std
            
        elif variable_type == 'pressure' and coord_type == 'spatial_x':
            # âˆ‚p/âˆ‚x: å£“åŠ›å°æµå‘çš„æ¢¯åº¦
            scale_factor = self.p_std / (8 * np.pi / 2)
            
        elif variable_type == 'pressure' and coord_type == 'spatial_y':
            # âˆ‚p/âˆ‚y: å£“åŠ›å°å£æ³•å‘çš„æ¢¯åº¦
            scale_factor = self.p_std / self.y_std
            
        elif variable_type == 'velocity' and coord_type == 'temporal':
            # âˆ‚u/âˆ‚t: é€Ÿåº¦å°æ™‚é–“çš„æ¢¯åº¦ (å¦‚éœ€æ™‚é–“ç›¸é—œæ€§)
            scale_factor = self.u_std / self.t_char
            
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¢¯åº¦è®Šæ›: {variable_type} vs {coord_type}")
        
        return gradients_scaled * scale_factor
    
    def compute_ns_scales(self) -> Dict[str, torch.Tensor]:
        """
        è¨ˆç®—ç„¡é‡ç¶±åŒ– NS æ–¹ç¨‹å„é …çš„ç›®æ¨™é‡ç´š
        
        ç¢ºä¿é‡ç´šå¹³è¡¡:
        - å°æµé …: uâˆ‚u/âˆ‚x ~ O(1)
        - å£“åŠ›é …: âˆ‚p/âˆ‚x ~ O(1)  
        - é»æ€§é …: Î½âˆ‡Â²u ~ O(1/Re_Ï„) ~ 1e-3
        - æ™‚é–“é …: âˆ‚u/âˆ‚t ~ O(1)
        """
        return {
            'convection_scale': torch.tensor(1.0),           # å°æµé …ç›®æ¨™é‡ç´š
            'pressure_scale': torch.tensor(1.0),             # å£“åŠ›é …ç›®æ¨™é‡ç´š
            'viscous_scale': torch.tensor(1.0 / self.Re_tau), # é»æ€§é … ~ 1e-3
            'temporal_scale': torch.tensor(1.0),             # æ™‚é–“é …ç›®æ¨™é‡ç´š
            'continuity_scale': torch.tensor(1.0),           # é€£çºŒæ–¹ç¨‹ç›®æ¨™é‡ç´š
        }
    
    def validate_scaling(self, coords: torch.Tensor, fields: torch.Tensor) -> Dict[str, bool]:
        """
        é©—è­‰ç¸®æ”¾çš„ç‰©ç†ä¸€è‡´æ€§
        
        Returns:
            é©—è­‰çµæœå­—å…¸
        """
        results = {}
        
        # 1. é›·è«¾æ•¸ä¸è®Šæ€§æª¢æŸ¥
        Re_original = self.U_char * self.L_char / self.nu
        Re_scaled = 1.0 * 1.0 / (self.nu / (self.U_char * self.L_char))
        reynolds_error = abs(Re_original - Re_scaled)
        results['reynolds_invariant'] = reynolds_error < 1e-12
        
        # 2. åº§æ¨™è®Šæ›å¯é€†æ€§
        coords_scaled = self.scale_coordinates(coords)
        coords_recovered = self.inverse_scale_coordinates(coords_scaled)
        coord_error = torch.max(torch.abs(coords - coords_recovered))
        results['coordinate_invertible'] = coord_error < 1e-6
        
        # 3. å ´è®Šæ•¸å¯é€†æ€§
        velocity = fields[:, :2]
        pressure = fields[:, 2:3]
        
        velocity_scaled = self.scale_velocity(velocity)
        velocity_recovered = self.inverse_scale_velocity(velocity_scaled)
        velocity_error = torch.max(torch.abs(velocity - velocity_recovered))
        results['velocity_invertible'] = velocity_error < 1e-6
        
        pressure_scaled = self.scale_pressure(pressure)
        pressure_recovered = self.inverse_scale_pressure(pressure_scaled)
        pressure_error = torch.max(torch.abs(pressure - pressure_recovered))
        results['pressure_invertible'] = pressure_error < 1e-6
        
        # 4. é‚Šç•Œæ¢ä»¶ä¿æŒæ€§
        zero_velocity = torch.zeros_like(velocity[:5])  # æ¸¬è©¦å‰5å€‹é»
        zero_scaled = self.scale_velocity(zero_velocity)
        results['boundary_preserved'] = torch.allclose(zero_scaled, torch.zeros_like(zero_scaled), atol=1e-8)
        
        return results
    
    def get_scaling_info(self) -> Dict[str, Any]:
        """ç²å–å®Œæ•´çš„ç¸®æ”¾è³‡è¨Šæ‘˜è¦"""
        return {
            'physical_parameters': {
                'L_char': self.L_char.item(),
                'U_char': self.U_char.item(), 
                't_char': self.t_char.item(),
                'P_char': self.P_char.item(),
                'nu': self.nu.item(),
                'Re_tau': self.Re_tau.item(),
            },
            'coordinate_statistics': {
                'x_mean': self.x_mean.item() if self.coord_stats_fitted else None,
                'x_std': self.x_std.item() if self.coord_stats_fitted else None,
                'y_mean': self.y_mean.item() if self.coord_stats_fitted else None,
                'y_std': self.y_std.item() if self.coord_stats_fitted else None,
            },
            'field_statistics': {
                'u_mean': self.u_mean.item() if self.field_stats_fitted else None,
                'u_std': self.u_std.item() if self.field_stats_fitted else None,
                'v_mean': self.v_mean.item() if self.field_stats_fitted else None,
                'v_std': self.v_std.item() if self.field_stats_fitted else None,
                'p_mean': self.p_mean.item() if self.field_stats_fitted else None,
                'p_std': self.p_std.item() if self.field_stats_fitted else None,
            },
            'fitted_status': {
                'coordinates': self.coord_stats_fitted.item(),
                'fields': self.field_stats_fitted.item(),
            }
        }