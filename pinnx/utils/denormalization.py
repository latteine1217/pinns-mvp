"""
è¼¸å‡ºåæ¨™æº–åŒ–å·¥å…·æ¨¡çµ„

æä¾›çµ±ä¸€çš„æ¨¡å‹è¼¸å‡ºåæ¨™æº–åŒ–åŠŸèƒ½ï¼Œç¢ºä¿è©•ä¼°æ™‚é æ¸¬å€¼èˆ‡çœŸå¯¦å€¼åœ¨ç›¸åŒé‡ç¶±ä¸‹æ¯”è¼ƒã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- æ”¯æŒå¤šç¨®æ¨™æº–åŒ–é¡å‹ï¼šfriction_velocity, channel_flow, manual_scaling
- å¾é…ç½®æ–‡ä»¶é‡å»ºç¸®æ”¾åƒæ•¸
- è™•ç† ManualScalingWrapper çš„åç¸®æ”¾é‚è¼¯
- è©³ç´°çš„æ—¥èªŒè¼¸å‡ºèˆ‡ç¯„åœé©—è­‰

ä½¿ç”¨æ–¹å¼ï¼š
    from pinnx.utils.denormalization import denormalize_output
    
    predictions = model(coords)  # å·²æ¨™æº–åŒ–çš„é æ¸¬
    predictions_physical = denormalize_output(predictions, config)
"""

from __future__ import annotations

import numpy as np
import torch
from typing import Dict, Optional, Tuple, Union
import logging

logger = logging.getLogger(__name__)


def denormalize_output(
    predictions: Union[np.ndarray, torch.Tensor],
    config: Dict,
    output_norm_type: Optional[str] = None,
    verbose: bool = True,
    true_ranges: Optional[Dict[str, Tuple[float, float]]] = None
) -> np.ndarray:
    """
    åæ¨™æº–åŒ–æ¨¡å‹è¼¸å‡ºåˆ°ç‰©ç†é‡ç¶±
    
    æ”¯æŒçš„æ¨™æº–åŒ–é¡å‹ï¼š
    1. "friction_velocity": åŸºæ–¼æ‘©æ“¦é€Ÿåº¦å°ºåº¦
       - u, v, w â†’ u, v, w * u_Ï„
       - p â†’ p * Ïu_Ï„Â²
    
    2. "manual_scaling": ManualScalingWrapper çš„åç¸®æ”¾
       - å¾ [-1, 1] åç¸®æ”¾åˆ°é…ç½®ä¸­çš„ output_ranges
    
    3. "post_scaling": å¾Œè™•ç†ç¸®æ”¾ï¼ˆè‡ªå‹•ç¯„åœæ˜ å°„ï¼‰
       - å¾æ¨¡å‹è¼¸å‡ºç¯„åœç·šæ€§æ˜ å°„åˆ°çœŸå¯¦æ•¸æ“šç¯„åœ
       - é©ç”¨æ–¼è¨“ç·´æ™‚æœªä½¿ç”¨ç¸®æ”¾çš„æƒ…æ³
    
    4. "none" / "identity": ä¸è™•ç†
    
    Args:
        predictions: æ¨¡å‹é æ¸¬ [N, out_dim]ï¼Œout_dim âˆˆ {3, 4, 5}
                    - 3D: (u, v, w) æˆ– (u, v, p)
                    - 4D: (u, v, w, p)
                    - 5D: (u, v, w, p, S) - å«æºé …
        config: è¨“ç·´é…ç½®å­—å…¸ï¼ˆéœ€åŒ…å« physics å’Œ model.scaling æ®µï¼‰
        output_norm_type: æ¨™æº–åŒ–é¡å‹ï¼ˆè‹¥ç‚º None å‰‡å¾ config è®€å–ï¼‰
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°æ—¥èªŒ
        true_ranges: çœŸå¯¦æ•¸æ“šç¯„åœ (ç”¨æ–¼ post_scaling)
                    ä¾‹å¦‚: {'u': (0.0, 17.37), 'v': (-1.31, 1.33), ...}
        
    Returns:
        åæ¨™æº–åŒ–å¾Œçš„é æ¸¬ [N, out_dim] (numpy array)
        
    Raises:
        ValueError: é…ç½®ç¼ºå¤±æˆ–ä¸æ”¯æŒçš„æ¨™æº–åŒ–é¡å‹
        
    Examples:
        >>> # Friction velocity æ¨™æº–åŒ–
        >>> config = {
        ...     'model': {'scaling': {'output_norm': 'friction_velocity'}},
        ...     'physics': {'rho': 1.0, 'channel_flow': {'u_tau': 1.0}}
        ... }
        >>> pred_normalized = np.array([[1.0, 0.1, 0.5, 0.01]])  # (u, v, w, p)
        >>> pred_physical = denormalize_output(pred_normalized, config)
        >>> # çµæœ: [[1.0, 0.1, 0.5, 0.01]] (u_tau=1.0 æ™‚ç„¡è®ŠåŒ–)
        
        >>> # å¾Œè™•ç†ç¸®æ”¾
        >>> true_ranges = {'u': (0, 17.4), 'v': (-1.3, 1.3), 'w': (-22, 21), 'p': (-226, 2.4)}
        >>> pred_scaled = denormalize_output(pred_normalized, config, 'post_scaling', 
        ...                                   true_ranges=true_ranges)
    """
    # è½‰æ›ç‚º numpy array (å¦‚æœæ˜¯ torch.Tensor)
    if isinstance(predictions, torch.Tensor):
        predictions = predictions.detach().cpu().numpy()
    
    predictions = np.array(predictions, dtype=np.float32)
    
    # ç¢ºå®šæ¨™æº–åŒ–é¡å‹
    if output_norm_type is None:
        if 'model' in config and 'scaling' in config['model']:
            output_norm_type = config['model']['scaling'].get('output_norm', 'none')
        else:
            output_norm_type = 'none'
    
    if verbose:
        logger.info(f"ğŸ”„ åæ¨™æº–åŒ–é¡å‹: {output_norm_type}")
        logger.info(f"ğŸ“Š è¼¸å…¥é æ¸¬ç¯„åœ: min={predictions.min():.4f}, max={predictions.max():.4f}")
    
    # ä¸éœ€è¦åæ¨™æº–åŒ–çš„æƒ…æ³
    if output_norm_type in ('none', 'identity', None):
        if verbose:
            logger.info("âœ… ç„¡éœ€åæ¨™æº–åŒ– (type=none)")
        return predictions
    
    # ===================================================================
    # é¡å‹ 1: Friction Velocity æ¨™æº–åŒ–
    # ===================================================================
    if output_norm_type == 'friction_velocity':
        return _denormalize_friction_velocity(predictions, config, verbose)
    
    # ===================================================================
    # é¡å‹ 2: Manual Scaling (å¾çµ±è¨ˆç¯„åœåç¸®æ”¾)
    # ===================================================================
    elif output_norm_type == 'manual_scaling':
        return _denormalize_manual_scaling(predictions, config, verbose)
    
    # ===================================================================
    # é¡å‹ 3: Post Scaling (å¾Œè™•ç†è‡ªå‹•ç¯„åœæ˜ å°„)
    # ===================================================================
    elif output_norm_type == 'post_scaling':
        if true_ranges is None:
            raise ValueError("post_scaling æ¨¡å¼éœ€è¦æä¾› true_ranges åƒæ•¸")
        return _denormalize_post_scaling(predictions, true_ranges, verbose)
    
    # ===================================================================
    # é¡å‹ 4: å­—å…¸æ ¼å¼ (ç›´æ¥æŒ‡å®šç¯„åœ)
    # ===================================================================
    elif isinstance(output_norm_type, dict):
        return _denormalize_from_dict(predictions, output_norm_type, verbose)
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ output_norm é¡å‹: {output_norm_type}")


def _denormalize_friction_velocity(
    predictions: np.ndarray,
    config: Dict,
    verbose: bool
) -> np.ndarray:
    """
    Friction velocity åæ¨™æº–åŒ–ï¼šu,v,w * u_Ï„; p * Ïu_Ï„Â²
    
    æ³¨æ„ï¼šå¯¦éš›ä¸Šè¨“ç·´æ™‚å¯èƒ½ä½¿ç”¨ ManualScalingWrapperï¼Œæ­¤å‡½æ•¸åƒ…è™•ç†
    é…ç½®ä¸­æ˜ç¢ºè²æ˜ä½¿ç”¨ friction_velocity æ¨™æº–åŒ–çš„æƒ…æ³ã€‚
    """
    # æå–ç‰©ç†åƒæ•¸
    if 'physics' not in config:
        raise ValueError("é…ç½®ç¼ºå°‘ 'physics' æ®µè½")
    
    physics = config['physics']
    
    # æ‘©æ“¦é€Ÿåº¦ u_Ï„
    if 'channel_flow' in physics and 'u_tau' in physics['channel_flow']:
        u_tau = physics['channel_flow']['u_tau']
    else:
        u_tau = 1.0  # é»˜èªå€¼
        if verbose:
            logger.warning(f"âš ï¸  æœªæ‰¾åˆ° u_tauï¼Œä½¿ç”¨é»˜èªå€¼ 1.0")
    
    # å¯†åº¦ Ï
    rho = physics.get('rho', 1.0)
    
    # è¨ˆç®—ç¸®æ”¾å› å­
    velocity_scale = u_tau
    pressure_scale = rho * u_tau ** 2
    
    if verbose:
        logger.info(f"ğŸ“ ç‰©ç†åƒæ•¸: u_Ï„={u_tau}, Ï={rho}")
        logger.info(f"ğŸ“ ç¸®æ”¾å› å­: vel_scale={velocity_scale}, p_scale={pressure_scale}")
    
    # æ‡‰ç”¨åç¸®æ”¾
    result = predictions.copy()
    out_dim = predictions.shape[-1]
    
    if out_dim == 3:
        # (u, v, p) æˆ– (u, v, w)
        # å‡è¨­å‰å…©å€‹æ˜¯é€Ÿåº¦ï¼Œæœ€å¾Œä¸€å€‹æ˜¯å£“åŠ›æˆ– w
        result[:, 0:2] *= velocity_scale  # u, v
        # ç¬¬ä¸‰å€‹è®Šé‡éœ€è¦æ ¹æ“šå¯¦éš›æƒ…æ³åˆ¤æ–·
        # é€™è£¡å‡è¨­æ˜¯ wï¼ˆ3D æƒ…æ³ï¼‰
        result[:, 2] *= velocity_scale  # w
        
    elif out_dim == 4:
        # (u, v, w, p)
        result[:, 0:3] *= velocity_scale  # u, v, w
        result[:, 3] *= pressure_scale    # p
        
    elif out_dim == 5:
        # (u, v, w, p, S)
        result[:, 0:3] *= velocity_scale  # u, v, w
        result[:, 3] *= pressure_scale    # p
        # æºé … S é€šå¸¸å·²ç¶“åœ¨ç‰©ç†é‡ç¶±ï¼Œä¸ç¸®æ”¾
        
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¼¸å‡ºç¶­åº¦: {out_dim} (é æœŸ 3, 4, æˆ– 5)")
    
    if verbose:
        logger.info(f"ğŸ“Š è¼¸å‡ºé æ¸¬ç¯„åœ: min={result.min():.4f}, max={result.max():.4f}")
        logger.info("âœ… Friction velocity åæ¨™æº–åŒ–å®Œæˆ")
    
    return result


def _denormalize_manual_scaling(
    predictions: np.ndarray,
    config: Dict,
    verbose: bool
) -> np.ndarray:
    """
    ManualScalingWrapper åæ¨™æº–åŒ–ï¼šå¾ [-1, 1] åç¸®æ”¾åˆ°ç‰©ç†ç¯„åœ
    
    åç¸®æ”¾å…¬å¼ï¼ˆèˆ‡ ManualScalingWrapper.forward ç¬¬ 67 è¡Œå°æ‡‰ï¼‰ï¼š
        y_physical = (y_scaled + 1) / 2 * (max - min) + min
    
    æ³¨æ„ï¼šManualScalingWrapper åœ¨è¨“ç·´æ™‚å·²ç¶“åŸ·è¡Œäº†åç¸®æ”¾ï¼ˆforward è¿”å›ç‰©ç†å€¼ï¼‰ï¼Œ
    æ‰€ä»¥è©•ä¼°æ™‚å¦‚æœä½¿ç”¨ç›¸åŒçš„ wrapperï¼Œè¼¸å‡ºå·²ç¶“æ˜¯ç‰©ç†é‡ã€‚
    
    æ­¤å‡½æ•¸ç”¨æ–¼ï¼šç›´æ¥å¾åŸºç¤æ¨¡å‹ï¼ˆæœªåŒ…è£ï¼‰ç²å–é æ¸¬æ™‚çš„åç¸®æ”¾ã€‚
    """
    if verbose:
        logger.warning("âš ï¸  manual_scaling æ¨¡å¼ï¼šéœ€è¦å¾é…ç½®é‡å»ºè¼¸å‡ºç¯„åœ")
    
    # å¾é…ç½®æå–è¼¸å‡ºç¯„åœ
    output_ranges = _extract_output_ranges(config, verbose)
    
    # å‡è¨­ç¶²è·¯è¼¸å‡ºåœ¨ [-1, 1]
    result = predictions.copy()
    
    # åç¸®æ”¾å…¬å¼: y = (y_scaled + 1) / 2 * (max - min) + min
    for i, (var_name, (min_val, max_val)) in enumerate(output_ranges.items()):
        if i >= result.shape[-1]:
            break
        result[:, i] = (result[:, i] + 1) / 2 * (max_val - min_val) + min_val
    
    if verbose:
        logger.info(f"ğŸ“Š è¼¸å‡ºé æ¸¬ç¯„åœ: min={result.min():.4f}, max={result.max():.4f}")
        logger.info("âœ… Manual scaling åæ¨™æº–åŒ–å®Œæˆ")
    
    return result


def _denormalize_post_scaling(
    predictions: np.ndarray,
    true_ranges: Dict[str, Tuple[float, float]],
    verbose: bool
) -> np.ndarray:
    """
    å¾Œè™•ç†ç¸®æ”¾ï¼šè‡ªå‹•å°‡æ¨¡å‹è¼¸å‡ºç¯„åœæ˜ å°„åˆ°çœŸå¯¦æ•¸æ“šç¯„åœ
    
    é©ç”¨å ´æ™¯ï¼š
    - è¨“ç·´æ™‚æœªä½¿ç”¨ä»»ä½•è¼¸å‡ºç¸®æ”¾ï¼ˆVS-PINN è·³é ManualScalingWrapperï¼‰
    - æ¨¡å‹è¼¸å‡ºåœ¨è¿‘ä¼¼ç‰©ç†é‡ç¶±ä½†æ•¸å€¼ç¯„åœéŒ¯èª¤
    - éœ€è¦å¾Œè™•ç†æ ¡æ­£åˆ°çœŸå¯¦ç‰©ç†å°ºåº¦
    
    ç¸®æ”¾å…¬å¼ï¼ˆç·šæ€§æ˜ å°„ï¼‰ï¼š
        y_scaled = (y_pred - pred_min) / (pred_max - pred_min) * (true_max - true_min) + true_min
    
    Args:
        predictions: æ¨¡å‹åŸå§‹é æ¸¬ [N, out_dim]
        true_ranges: çœŸå¯¦æ•¸æ“šç¯„åœï¼Œä¾‹å¦‚:
                    {'u': (0.0, 17.37), 'v': (-1.31, 1.33), 'w': (-22, 21), 'p': (-226, 2.4)}
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°æ—¥èªŒ
        
    Returns:
        ç¸®æ”¾å¾Œçš„é æ¸¬ [N, out_dim]
        
    Notes:
        - è‡ªå‹•å¾ predictions è¨ˆç®—ç•¶å‰ç¯„åœï¼ˆpred_min, pred_maxï¼‰
        - åŸ·è¡Œç·šæ€§æ˜ å°„åˆ° (true_min, true_max)
        - å‡è¨­æ¨¡å‹å·²å­¸åˆ°æµå ´ç›¸å°çµæ§‹ï¼Œåƒ…çµ•å°å°ºåº¦éŒ¯èª¤
    """
    if verbose:
        logger.info("ğŸ”§ åŸ·è¡Œå¾Œè™•ç†ç¸®æ”¾ (post_scaling)")
    
    result = predictions.copy()
    var_names = list(true_ranges.keys())
    
    # å°æ¯å€‹è®Šé‡åˆ†åˆ¥ç¸®æ”¾
    for i, var_name in enumerate(var_names):
        if i >= result.shape[-1]:
            break
        
        # ç•¶å‰è®Šé‡çš„é æ¸¬ç¯„åœ
        pred_min = result[:, i].min()
        pred_max = result[:, i].max()
        
        # çœŸå¯¦æ•¸æ“šç¯„åœ
        true_min, true_max = true_ranges[var_name]
        
        # ç·šæ€§æ˜ å°„å…¬å¼
        if pred_max - pred_min < 1e-8:
            # é¿å…é™¤ä»¥é›¶ï¼ˆé æ¸¬ç‚ºå¸¸æ•¸ï¼‰
            if verbose:
                logger.warning(f"âš ï¸  {var_name}: é æ¸¬ç‚ºå¸¸æ•¸ ({pred_min:.4f})ï¼Œè·³éç¸®æ”¾")
            continue
        
        result[:, i] = (result[:, i] - pred_min) / (pred_max - pred_min) * (true_max - true_min) + true_min
        
        if verbose:
            scaled_min = result[:, i].min()
            scaled_max = result[:, i].max()
            logger.info(f"  {var_name}: [{pred_min:.4f}, {pred_max:.4f}] â†’ [{scaled_min:.4f}, {scaled_max:.4f}] "
                       f"(çœŸå¯¦: [{true_min:.4f}, {true_max:.4f}])")
    
    if verbose:
        logger.info("âœ… å¾Œè™•ç†ç¸®æ”¾å®Œæˆ")
    
    return result


def _denormalize_from_dict(
    predictions: np.ndarray,
    output_ranges: Dict[str, Tuple[float, float]],
    verbose: bool
) -> np.ndarray:
    """
    å¾å­—å…¸æ ¼å¼çš„è¼¸å‡ºç¯„åœåæ¨™æº–åŒ–
    
    Args:
        output_ranges: ä¾‹å¦‚ {'u': (0, 20), 'v': (-1, 1), 'w': (-5, 5), 'p': (-100, 10)}
    """
    result = predictions.copy()
    
    # åç¸®æ”¾å…¬å¼: y = (y_scaled + 1) / 2 * (max - min) + min
    for i, (var_name, (min_val, max_val)) in enumerate(output_ranges.items()):
        if i >= result.shape[-1]:
            break
        result[:, i] = (result[:, i] + 1) / 2 * (max_val - min_val) + min_val
        
        if verbose:
            logger.info(f"  {var_name}: [{min_val}, {max_val}] -> "
                       f"[{result[:, i].min():.4f}, {result[:, i].max():.4f}]")
    
    if verbose:
        logger.info("âœ… å­—å…¸æ ¼å¼åæ¨™æº–åŒ–å®Œæˆ")
    
    return result


def _extract_output_ranges(
    config: Dict,
    verbose: bool
) -> Dict[str, Tuple[float, float]]:
    """
    å¾é…ç½®æå–è¼¸å‡ºç¯„åœï¼ˆç”¨æ–¼ ManualScalingWrapperï¼‰
    
    å„ªå…ˆç´šï¼š
    1. config['model']['scaling']['output_norm'] (dict æ ¼å¼)
    2. å¾çµ±è¨ˆä¿¡æ¯æ¨å°ï¼ˆå¦‚æœ‰ï¼‰
    3. ç¡¬ç·¨ç¢¼é»˜èªå€¼
    """
    output_ranges = {}
    
    # æª¢æŸ¥ scaling é…ç½®
    if 'model' in config and 'scaling' in config['model']:
        scaling_cfg = config['model']['scaling']
        output_norm_raw = scaling_cfg.get('output_norm')
        
        if isinstance(output_norm_raw, dict):
            # å­—å…¸æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨
            output_ranges = {
                'u': tuple(output_norm_raw.get('u', [0.0, 20.0])),
                'v': tuple(output_norm_raw.get('v', [-1.0, 1.0])),
                'w': tuple(output_norm_raw.get('w', [-5.0, 5.0])),
                'p': tuple(output_norm_raw.get('p', [-100.0, 10.0]))
            }
            if verbose:
                logger.info("âœ… å¾é…ç½®æ–‡ä»¶è®€å–è¼¸å‡ºç¯„åœ (dict æ ¼å¼)")
            return output_ranges
    
    # ç¡¬ç·¨ç¢¼é»˜èªå€¼ï¼ˆåŸºæ–¼ JHTDB Channel Re1000ï¼‰
    output_ranges = {
        'u': (0.0, 20.0),
        'v': (-1.0, 1.0),
        'w': (-5.0, 5.0),
        'p': (-100.0, 10.0)
    }
    
    if verbose:
        logger.warning("âš ï¸  ä½¿ç”¨ç¡¬ç·¨ç¢¼é»˜èªè¼¸å‡ºç¯„åœï¼ˆå¯èƒ½ä¸æº–ç¢ºï¼‰")
    
    return output_ranges


def verify_denormalization(
    predictions: np.ndarray,
    true_values: np.ndarray,
    var_names: Optional[list] = None,
    tolerance: float = 0.3
) -> bool:
    """
    é©—è­‰åæ¨™æº–åŒ–æ˜¯å¦æ­£ç¢ºï¼ˆé€šéç¯„åœåŒ¹é…ï¼‰
    
    Args:
        predictions: åæ¨™æº–åŒ–å¾Œçš„é æ¸¬
        true_values: çœŸå¯¦å€¼
        var_names: è®Šé‡åç¨±åˆ—è¡¨
        tolerance: ç¯„åœå®¹å·®ï¼ˆé æ¸¬ç¯„åœæ‡‰åœ¨çœŸå¯¦ç¯„åœçš„ Â±tolerance å…§ï¼‰
        
    Returns:
        é©—è­‰æ˜¯å¦é€šé
    """
    if var_names is None:
        var_names = ['u', 'v', 'w', 'p', 'S'][:predictions.shape[-1]]
    
    all_pass = True
    
    for i, var in enumerate(var_names):
        if i >= predictions.shape[-1]:
            break
        
        pred_min, pred_max = predictions[:, i].min(), predictions[:, i].max()
        true_min, true_max = true_values[:, i].min(), true_values[:, i].max()
        
        true_range = true_max - true_min
        
        # æª¢æŸ¥é æ¸¬ç¯„åœæ˜¯å¦åœ¨çœŸå¯¦ç¯„åœçš„å®¹å·®å…§
        min_ok = abs(pred_min - true_min) <= tolerance * true_range
        max_ok = abs(pred_max - true_max) <= tolerance * true_range
        
        status = "âœ…" if (min_ok and max_ok) else "âŒ"
        logger.info(f"{status} {var}: é æ¸¬[{pred_min:.2f}, {pred_max:.2f}] vs "
                   f"çœŸå¯¦[{true_min:.2f}, {true_max:.2f}]")
        
        if not (min_ok and max_ok):
            all_pass = False
    
    return all_pass


# ===================================================================
# ä¾¿æ·å‡½æ•¸
# ===================================================================

def create_denormalizer_from_config(config: Dict, verbose: bool = True):
    """
    å¾é…ç½®å‰µå»ºåæ¨™æº–åŒ–å‡½æ•¸ï¼ˆé–‰åŒ…ï¼‰
    
    Returns:
        denorm_fn: æ¥å— predictions ä¸¦è¿”å›åæ¨™æº–åŒ–çµæœçš„å‡½æ•¸
    """
    output_norm_type = None
    if 'model' in config and 'scaling' in config['model']:
        output_norm_type = config['model']['scaling'].get('output_norm', 'none')
    
    def denorm_fn(predictions):
        return denormalize_output(predictions, config, output_norm_type, verbose)
    
    return denorm_fn


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    import sys
    logging.basicConfig(level=logging.INFO, format='%(message)s')
    
    print("=" * 60)
    print("ğŸ“‹ åæ¨™æº–åŒ–å·¥å…·æ¸¬è©¦")
    print("=" * 60)
    
    # æ¸¬è©¦ 1: Friction velocity
    print("\n--- æ¸¬è©¦ 1: Friction Velocity åæ¨™æº–åŒ– ---")
    config_fv = {
        'model': {'scaling': {'output_norm': 'friction_velocity'}},
        'physics': {
            'rho': 1.0,
            'channel_flow': {'u_tau': 0.05}  # å¯¦éš› JHTDB çš„ u_tau
        }
    }
    
    pred_normalized = np.array([
        [1.0, 0.1, 0.5, 0.01],  # (u, v, w, p) æ¨™æº–åŒ–å¾Œ
        [1.2, -0.05, 0.3, -0.005]
    ])
    
    pred_physical = denormalize_output(pred_normalized, config_fv, verbose=True)
    print(f"\næ¨™æº–åŒ–é æ¸¬:\n{pred_normalized}")
    print(f"\nç‰©ç†é‡é æ¸¬:\n{pred_physical}")
    
    # é æœŸ: u,v,w * 0.05, p * (1.0 * 0.05^2) = p * 0.0025
    expected = pred_normalized.copy()
    expected[:, 0:3] *= 0.05  # u, v, w
    expected[:, 3] *= 0.0025  # p
    
    assert np.allclose(pred_physical, expected), "Friction velocity åæ¨™æº–åŒ–éŒ¯èª¤ï¼"
    print("âœ… æ¸¬è©¦ 1 é€šé")
    
    # æ¸¬è©¦ 2: None (ç„¡éœ€åæ¨™æº–åŒ–)
    print("\n--- æ¸¬è©¦ 2: None é¡å‹ (ç„¡éœ€åæ¨™æº–åŒ–) ---")
    config_none = {'model': {'scaling': {'output_norm': 'none'}}}
    
    pred_none = denormalize_output(pred_normalized, config_none, verbose=True)
    assert np.array_equal(pred_none, pred_normalized), "None é¡å‹æ‡‰è¿”å›åŸå§‹å€¼ï¼"
    print("âœ… æ¸¬è©¦ 2 é€šé")
    
    # æ¸¬è©¦ 3: ç¯„åœé©—è­‰
    print("\n--- æ¸¬è©¦ 3: ç¯„åœé©—è­‰ ---")
    true_values = np.array([
        [1.0, 0.1, 0.5, 0.02],
        [1.5, -0.03, 0.4, -0.003]
    ])
    
    is_valid = verify_denormalization(
        pred_physical, true_values, 
        var_names=['u', 'v', 'w', 'p'],
        tolerance=0.5  # å¯¬å®¹åº¦
    )
    
    if is_valid:
        print("âœ… æ¸¬è©¦ 3 é€šé")
    else:
        print("âš ï¸  æ¸¬è©¦ 3 éƒ¨åˆ†å¤±æ•—ï¼ˆä½†å¯èƒ½æ˜¯åˆç†çš„æ¨¡å‹èª¤å·®ï¼‰")
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
    print("=" * 60)
