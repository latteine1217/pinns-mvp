"""
é€šç”¨è¨“ç·´ç›£æ§ç³»çµ±

æä¾›è‡ªå‹•æª¢æ¸¬ã€æ—¥èªŒè§£æã€è¶¨å‹¢åˆ†æç­‰åŠŸèƒ½ï¼Œæ”¯æŒå¤šå¯¦é©—ä¸¦è¡Œç›£æ§ã€‚
"""

import re
import json
import subprocess
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import yaml


@dataclass
class ProcessInfo:
    """è¨“ç·´é€²ç¨‹è³‡è¨Š"""
    pid: int
    config_name: str
    config_path: str
    cpu_percent: float
    memory_mb: float
    start_time: Optional[datetime] = None


@dataclass
class EpochMetrics:
    """å–®å€‹ Epoch çš„æŒ‡æ¨™"""
    epoch: int
    total_epochs: int
    timestamp: datetime
    losses: Dict[str, float] = field(default_factory=dict)
    warnings: List[str] = field(default_factory=list)
    
    @property
    def progress_percent(self) -> float:
        """è¨“ç·´é€²åº¦ç™¾åˆ†æ¯”"""
        return (self.epoch / self.total_epochs) * 100 if self.total_epochs > 0 else 0.0


@dataclass
class TrainingStatus:
    """è¨“ç·´ç‹€æ…‹æ‘˜è¦"""
    config_name: str
    process_info: Optional[ProcessInfo]
    current_metrics: Optional[EpochMetrics]
    recent_metrics: List[EpochMetrics] = field(default_factory=list)
    log_file: Optional[Path] = None
    checkpoint_dir: Optional[Path] = None
    
    @property
    def is_active(self) -> bool:
        """æ˜¯å¦ç‚ºæ´»èºè¨“ç·´"""
        return self.process_info is not None
    
    @property
    def eta_seconds(self) -> Optional[float]:
        """é è¨ˆå‰©é¤˜æ™‚é–“ï¼ˆç§’ï¼‰"""
        if not self.current_metrics or len(self.recent_metrics) < 2:
            return None
        
        # è¨ˆç®—å¹³å‡ epoch æ™‚é–“
        time_diffs = []
        for i in range(1, len(self.recent_metrics)):
            dt = (self.recent_metrics[i].timestamp - 
                  self.recent_metrics[i-1].timestamp).total_seconds()
            time_diffs.append(dt)
        
        if not time_diffs:
            return None
        
        avg_epoch_time = sum(time_diffs) / len(time_diffs)
        remaining_epochs = (self.current_metrics.total_epochs - 
                           self.current_metrics.epoch)
        
        return avg_epoch_time * remaining_epochs


class ProcessDetector:
    """è¨“ç·´é€²ç¨‹è‡ªå‹•æª¢æ¸¬å™¨"""
    
    @staticmethod
    def detect_active_trainings() -> List[ProcessInfo]:
        """
        æª¢æ¸¬æ‰€æœ‰æ´»èºçš„è¨“ç·´é€²ç¨‹
        
        Returns:
            List[ProcessInfo]: æ´»èºè¨“ç·´é€²ç¨‹åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨ ps å‘½ä»¤æŸ¥æ‰¾ train.py é€²ç¨‹
            cmd = ["ps", "aux"]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            processes = []
            for line in result.stdout.split('\n'):
                if 'train.py' in line and '--cfg' in line and 'grep' not in line:
                    proc_info = ProcessDetector._parse_process_line(line)
                    if proc_info:
                        processes.append(proc_info)
            
            return processes
        
        except Exception as e:
            print(f"âš ï¸  æª¢æ¸¬é€²ç¨‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    @staticmethod
    def _parse_process_line(line: str) -> Optional[ProcessInfo]:
        """
        è§£æ ps å‘½ä»¤è¼¸å‡ºè¡Œ
        
        Args:
            line: ps å‘½ä»¤è¼¸å‡ºçš„ä¸€è¡Œ
        
        Returns:
            ProcessInfo æˆ– None
        """
        try:
            # è§£ææ ¼å¼: USER PID %CPU %MEM ... COMMAND
            parts = line.split()
            if len(parts) < 11:
                return None
            
            pid = int(parts[1])
            cpu_percent = float(parts[2])
            memory_mb = float(parts[3]) * 10  # ç²—ç•¥ä¼°ç®—
            
            # æå–é…ç½®æ–‡ä»¶è·¯å¾‘
            cfg_match = re.search(r'--cfg\s+(\S+)', line)
            if not cfg_match:
                return None
            
            config_path = cfg_match.group(1)
            config_name = Path(config_path).stem
            
            return ProcessInfo(
                pid=pid,
                config_name=config_name,
                config_path=config_path,
                cpu_percent=cpu_percent,
                memory_mb=memory_mb
            )
        
        except Exception as e:
            print(f"âš ï¸  è§£æé€²ç¨‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None


class LogParser:
    """è¨“ç·´æ—¥èªŒè§£æå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ—¥èªŒè§£æå™¨
        
        Args:
            config: ç›£æ§é…ç½®å­—å…¸
        """
        self.config = config
        self.epoch_pattern = re.compile(config['log_parsing']['epoch_pattern'])
        self.loss_patterns = [
            re.compile(pattern) 
            for pattern in config['log_parsing']['loss_patterns']
        ]
    
    def parse_log_file(self, log_path: Path, tail_lines: int = 100) -> List[EpochMetrics]:
        """
        è§£ææ—¥èªŒæ–‡ä»¶
        
        Args:
            log_path: æ—¥èªŒæ–‡ä»¶è·¯å¾‘
            tail_lines: åªè§£ææœ€å¾Œ N è¡Œ
        
        Returns:
            List[EpochMetrics]: è§£æå‡ºçš„ epoch æŒ‡æ¨™åˆ—è¡¨
        """
        if not log_path.exists():
            return []
        
        try:
            # è®€å–æœ€å¾Œ N è¡Œ
            with open(log_path, 'r') as f:
                lines = f.readlines()
            
            lines = lines[-tail_lines:] if len(lines) > tail_lines else lines
            
            metrics_list = []
            current_epoch = None
            current_losses = {}
            
            for line in lines:
                # æª¢æ¸¬ epoch è¡Œ
                epoch_match = self.epoch_pattern.search(line)
                if epoch_match:
                    # ä¿å­˜å‰ä¸€å€‹ epoch çš„æ•¸æ“š
                    if current_epoch is not None:
                        metrics_list.append(EpochMetrics(
                            epoch=current_epoch,
                            total_epochs=int(epoch_match.group(2)),
                            timestamp=datetime.now(),
                            losses=current_losses.copy()
                        ))
                    
                    # é–‹å§‹æ–° epoch
                    current_epoch = int(epoch_match.group(1))
                    current_losses = {}
                
                # è§£æ loss æŒ‡æ¨™
                if current_epoch is not None:
                    for pattern in self.loss_patterns:
                        for match in pattern.finditer(line):
                            key = match.group(1)
                            try:
                                value = float(match.group(2))
                                current_losses[key] = value
                            except ValueError:
                                pass
            
            # ä¿å­˜æœ€å¾Œä¸€å€‹ epoch
            if current_epoch is not None:
                metrics_list.append(EpochMetrics(
                    epoch=current_epoch,
                    total_epochs=current_epoch,  # æœƒè¢«æ›´æ–°
                    timestamp=datetime.now(),
                    losses=current_losses
                ))
            
            return metrics_list
        
        except Exception as e:
            print(f"âš ï¸  è§£ææ—¥èªŒæ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def detect_anomalies(self, metrics: EpochMetrics) -> List[str]:
        """
        æª¢æ¸¬ç•°å¸¸å€¼ï¼ˆNaN, Inf, æ¢¯åº¦çˆ†ç‚¸ç­‰ï¼‰
        
        Args:
            metrics: Epoch æŒ‡æ¨™
        
        Returns:
            List[str]: è­¦å‘Šè¨Šæ¯åˆ—è¡¨
        """
        warnings = []
        
        for key, value in metrics.losses.items():
            # æª¢æ¸¬ NaN/Inf
            if not isinstance(value, (int, float)):
                continue
            
            if value != value:  # NaN check
                warnings.append(f"âš ï¸  {key} = NaN")
            elif value == float('inf'):
                warnings.append(f"âš ï¸  {key} = +Inf")
            elif value == float('-inf'):
                warnings.append(f"âš ï¸  {key} = -Inf")
            
            # æª¢æ¸¬ç•°å¸¸å¤§çš„å€¼
            thresholds = self._get_thresholds(key)
            if thresholds:
                error_threshold = thresholds.get('error')
                warning_threshold = thresholds.get('warning')
                
                if error_threshold is not None and value > error_threshold:
                    warnings.append(f"ğŸ”¥ {key} = {value:.2e} (è¶…ééŒ¯èª¤é–¾å€¼)")
                elif warning_threshold is not None and value > warning_threshold:
                    warnings.append(f"âš ï¸  {key} = {value:.2e} (è¶…éè­¦å‘Šé–¾å€¼)")
        
        return warnings
    
    def _get_thresholds(self, metric_name: str) -> Optional[Dict[str, float]]:
        """å–å¾—æŒ‡æ¨™é–¾å€¼"""
        for category in ['primary', 'rans', 'constraints']:
            metrics = self.config['metrics'].get(category, [])
            for m in metrics:
                if m['name'] == metric_name:
                    return {
                        'warning': m.get('threshold_warning'),
                        'error': m.get('threshold_error')
                    }
        return None


class TrainingMonitor:
    """è¨“ç·´ç›£æ§å”èª¿å™¨"""
    
    def __init__(self, config_path: str = "configs/monitoring.yml"):
        """
        åˆå§‹åŒ–è¨“ç·´ç›£æ§å™¨
        
        Args:
            config_path: ç›£æ§é…ç½®æ–‡ä»¶è·¯å¾‘
        """
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.log_parser = LogParser(self.config)
        self.base_dir = Path.cwd()
    
    def _load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥ç›£æ§é…ç½®"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
        
        with open(self.config_path, 'r') as f:
            return yaml.safe_load(f)
    
    def get_all_training_status(self) -> List[TrainingStatus]:
        """
        å–å¾—æ‰€æœ‰è¨“ç·´ç‹€æ…‹
        
        Returns:
            List[TrainingStatus]: è¨“ç·´ç‹€æ…‹åˆ—è¡¨
        """
        # æª¢æ¸¬æ´»èºé€²ç¨‹
        active_processes = ProcessDetector.detect_active_trainings()
        
        status_list = []
        for proc in active_processes:
            status = self._build_training_status(proc)
            if status:
                status_list.append(status)
        
        return status_list
    
    def get_training_status(self, config_name: str) -> Optional[TrainingStatus]:
        """
        å–å¾—ç‰¹å®šè¨“ç·´çš„ç‹€æ…‹
        
        Args:
            config_name: é…ç½®åç¨±ï¼ˆä¸å« .yml å‰¯æª”åï¼‰
        
        Returns:
            TrainingStatus æˆ– None
        """
        # æª¢æ¸¬è©²è¨“ç·´æ˜¯å¦æ´»èº
        active_processes = ProcessDetector.detect_active_trainings()
        proc_info = None
        
        for proc in active_processes:
            if proc.config_name == config_name:
                proc_info = proc
                break
        
        # æ§‹å»ºç‹€æ…‹ï¼ˆå³ä½¿é€²ç¨‹ä¸æ´»èºï¼Œä¹Ÿå¯ä»¥è§£ææ—¥èªŒï¼‰
        return self._build_training_status(proc_info, config_name)
    
    def _build_training_status(
        self, 
        proc_info: Optional[ProcessInfo],
        config_name: Optional[str] = None
    ) -> Optional[TrainingStatus]:
        """
        æ§‹å»ºè¨“ç·´ç‹€æ…‹
        
        Args:
            proc_info: é€²ç¨‹è³‡è¨Šï¼ˆå¯ç‚º Noneï¼‰
            config_name: é…ç½®åç¨±ï¼ˆç•¶ proc_info ç‚º None æ™‚ä½¿ç”¨ï¼‰
        
        Returns:
            TrainingStatus æˆ– None
        """
        if proc_info:
            cfg_name = proc_info.config_name
        elif config_name:
            cfg_name = config_name
        else:
            return None
        
        # æŸ¥æ‰¾æ—¥èªŒæ–‡ä»¶
        log_dir = self.base_dir / self.config['paths']['log_base_dir'] / cfg_name
        log_file = log_dir / "training_stdout.log"
        
        if not log_file.exists():
            # æ—¥èªŒæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›åŸºæœ¬ç‹€æ…‹
            return TrainingStatus(
                config_name=cfg_name,
                process_info=proc_info,
                current_metrics=None,
                log_file=None
            )
        
        # è§£ææ—¥èªŒ
        metrics_list = self.log_parser.parse_log_file(log_file, tail_lines=200)
        
        if not metrics_list:
            return TrainingStatus(
                config_name=cfg_name,
                process_info=proc_info,
                current_metrics=None,
                log_file=log_file
            )
        
        # å–å¾—æœ€æ–°æŒ‡æ¨™
        current = metrics_list[-1]
        recent = metrics_list[-20:] if len(metrics_list) >= 20 else metrics_list
        
        # æª¢æ¸¬ç•°å¸¸
        current.warnings = self.log_parser.detect_anomalies(current)
        
        # æŸ¥æ‰¾æª¢æŸ¥é»ç›®éŒ„
        checkpoint_dir = (self.base_dir / 
                         self.config['paths']['checkpoint_base_dir'] / 
                         cfg_name)
        
        return TrainingStatus(
            config_name=cfg_name,
            process_info=proc_info,
            current_metrics=current,
            recent_metrics=recent,
            log_file=log_file,
            checkpoint_dir=checkpoint_dir if checkpoint_dir.exists() else None
        )
    
    def format_status_report(self, status: TrainingStatus) -> str:
        """
        æ ¼å¼åŒ–ç‹€æ…‹å ±å‘Š
        
        Args:
            status: è¨“ç·´ç‹€æ…‹
        
        Returns:
            str: æ ¼å¼åŒ–çš„å ±å‘Šæ–‡æœ¬
        """
        lines = []
        lines.append("=" * 80)
        lines.append(f"ğŸ“Š Training Status: {status.config_name}")
        lines.append("=" * 80)
        
        # é€²ç¨‹è³‡è¨Š
        if status.process_info:
            proc = status.process_info
            lines.append(f"ğŸŸ¢ Active Process:")
            lines.append(f"   PID: {proc.pid}")
            lines.append(f"   CPU: {proc.cpu_percent:.1f}%")
            lines.append(f"   Memory: {proc.memory_mb:.0f} MB")
        else:
            lines.append("ğŸ”´ No Active Process")
        
        lines.append("")
        
        # è¨“ç·´é€²åº¦
        if status.current_metrics:
            metrics = status.current_metrics
            lines.append(f"ğŸ“ˆ Progress:")
            lines.append(f"   Epoch: {metrics.epoch}/{metrics.total_epochs} "
                        f"({metrics.progress_percent:.1f}%)")
            
            # ETA
            if status.eta_seconds:
                eta_time = timedelta(seconds=int(status.eta_seconds))
                lines.append(f"   ETA: {eta_time}")
            
            lines.append("")
            
            # é—œéµæŒ‡æ¨™
            lines.append(f"ğŸ“‰ Key Metrics:")
            key_metrics = ['total_loss', 'data_loss', 'pde_loss', 
                          'wall_loss', 'mean_constraint']
            
            for key in key_metrics:
                if key in metrics.losses:
                    value = metrics.losses[key]
                    # è¨ˆç®—è¶¨å‹¢
                    trend = self._calculate_trend(status.recent_metrics, key)
                    trend_icon = "â†’" if trend == 0 else ("â†“" if trend < 0 else "â†‘")
                    
                    lines.append(f"   {key:20s}: {value:10.4f} {trend_icon}")
            
            # è­¦å‘Š
            if metrics.warnings:
                lines.append("")
                lines.append("âš ï¸  Warnings:")
                for warning in metrics.warnings:
                    lines.append(f"   {warning}")
        else:
            lines.append("âš ï¸  No metrics available")
        
        lines.append("=" * 80)
        return "\n".join(lines)
    
    def _calculate_trend(self, recent_metrics: List[EpochMetrics], key: str) -> int:
        """
        è¨ˆç®—æŒ‡æ¨™è¶¨å‹¢
        
        Args:
            recent_metrics: æœ€è¿‘çš„ epoch æŒ‡æ¨™
            key: æŒ‡æ¨™åç¨±
        
        Returns:
            int: -1 (ä¸‹é™), 0 (æŒå¹³), +1 (ä¸Šå‡)
        """
        if len(recent_metrics) < 2:
            return 0
        
        values = [m.losses[key] for m in recent_metrics if key in m.losses]
        if len(values) < 2:
            return 0
        
        # ç°¡å–®ç·šæ€§è¶¨å‹¢
        first_half = sum(values[:len(values)//2], 0.0) / (len(values)//2)
        second_half = sum(values[len(values)//2:], 0.0) / (len(values) - len(values)//2)
        
        ratio = (second_half - first_half) / (abs(first_half) + 1e-8)
        
        if ratio < -0.05:
            return -1
        elif ratio > 0.05:
            return 1
        else:
            return 0
