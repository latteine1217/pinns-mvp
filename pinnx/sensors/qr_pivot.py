"""
QR-pivot æ„Ÿæ¸¬é»é¸æ“‡ç®—æ³•

å¯¦ç¾åŸºæ–¼ QR åˆ†è§£çš„æœ€é©æ„Ÿæ¸¬é»é¸æ“‡ï¼Œé€™æ˜¯ç¨€ç–æ„Ÿæ¸¬èˆ‡é‡å»ºå•é¡Œçš„ç¶“å…¸æ–¹æ³•ã€‚
ç‰¹åˆ¥é©ç”¨æ–¼ PINNs é€†å•é¡Œä¸­çš„å°‘é‡è§€æ¸¬é»æœ€é©åŒ–é…ç½®ã€‚

æ ¸å¿ƒç®—æ³•ï¼š
1. QR-pivot: åŸºæ–¼ QR åˆ†è§£é¸ä¸»å…ƒçš„è²ªå¿ƒæœ€é©åŒ–
2. POD-based: çµåˆ POD æ¨¡æ…‹çš„æ„Ÿæ¸¬é»é…ç½®
3. Greedy: è²ªå¿ƒæœ€é©åŒ–ç­–ç•¥
4. Multi-objective: å¤šç›®æ¨™æœ€é©åŒ– (ç²¾åº¦ vs. ç©©å¥æ€§ vs. K)

åƒè€ƒæ–‡ç»ï¼š
- Sensor Selection via Convex Optimization (IEEE 2009)
- Sparsity-promoting optimal control for a class of distributed systems (SIAM 2012)
- Sparse sensor placement optimization for classification (SIAM 2016)
"""

import numpy as np
import torch
import torch.nn as nn
from typing import List, Dict, Tuple, Optional, Union, Callable, Any
from scipy.linalg import qr, svd
from scipy.optimize import differential_evolution, minimize
import logging
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


class BaseSensorSelector(ABC):
    """æ„Ÿæ¸¬é»é¸æ“‡å™¨åŸºé¡"""
    
    @abstractmethod
    def select_sensors(self, 
                      data_matrix: np.ndarray,
                      n_sensors: int,
                      **kwargs) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        é¸æ“‡æ„Ÿæ¸¬é»
        
        Args:
            data_matrix: è³‡æ–™çŸ©é™£ [n_samples, n_features] 
            n_sensors: æ„Ÿæ¸¬é»æ•¸é‡ K
            
        Returns:
            (selected_indices, metrics)
        """
        pass


class QRPivotSelector(BaseSensorSelector):
    """
    QR-pivot æ„Ÿæ¸¬é»é¸æ“‡å™¨
    
    ä½¿ç”¨ QR åˆ†è§£çš„é¸ä¸»å…ƒç­–ç•¥é¸æ“‡æœ€å…·ä»£è¡¨æ€§çš„æ„Ÿæ¸¬é»ã€‚
    é€™æ˜¯ç¶“å…¸çš„è²ªå¿ƒç®—æ³•ï¼Œè¨ˆç®—é«˜æ•ˆä¸”ç†è«–ä¿è­‰è‰¯å¥½ã€‚
    """
    
    def __init__(self, 
                 mode: str = 'column',
                 pivoting: bool = True,
                 regularization: float = 1e-12):
        """
        Args:
            mode: é¸æ“‡æ¨¡å¼ ('column' é¸åˆ—, 'row' é¸è¡Œ)
            pivoting: æ˜¯å¦ä½¿ç”¨é¸ä¸»å…ƒ
            regularization: æ­£å‰‡åŒ–é …é¿å…æ•¸å€¼ä¸ç©©å®š
        """
        self.mode = mode
        self.pivoting = pivoting
        self.regularization = regularization
    
    def select_sensors(self, 
                      data_matrix: np.ndarray,
                      n_sensors: int,
                      return_qr: bool = False) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        ä½¿ç”¨ QR-pivot é¸æ“‡æ„Ÿæ¸¬é»
        
        Args:
            data_matrix: è³‡æ–™çŸ©é™£ [n_samples, n_locations] (å¿«ç…§æ³•)
                        æˆ– [n_locations, n_modes] (POD æ¨¡æ…‹)
            n_sensors: æ„Ÿæ¸¬é»æ•¸é‡ K
            return_qr: æ˜¯å¦è¿”å› QR åˆ†è§£çµæœ
            
        Returns:
            (selected_indices, metrics)
        """
        # ç¢ºä¿æ•¸æ“šç‚º numpy æ•¸çµ„
        if isinstance(data_matrix, torch.Tensor):
            data_matrix = data_matrix.detach().cpu().numpy()
        
        X = data_matrix.copy()
        n_locations, n_features = X.shape
        
        # æ¨™æº–åŒ–è³‡æ–™ï¼ˆZ-Scoreï¼‰ä»¥æ”¹å–„æ•¸å€¼ç©©å®šæ€§
        # é¿å…ä¸åŒç‰¹å¾µçš„æ•¸å€¼å°ºåº¦å·®ç•°å°è‡´æ¢ä»¶æ•¸éé«˜
        X_mean = X.mean(axis=0, keepdims=True)
        X_std = X.std(axis=0, keepdims=True) + 1e-8  # é¿å…é™¤ä»¥é›¶
        X = (X - X_mean) / X_std
        
        # é™åˆ¶æ„Ÿæ¸¬é»æ•¸é‡ï¼ˆåªå—ç©ºé–“é»æ•¸é™åˆ¶ï¼Œä¸å—ç‰¹å¾µæ•¸é™åˆ¶ï¼‰
        n_sensors = min(n_sensors, n_locations)
        
        Q = None
        R = None
        try:
            if self.pivoting:
                # ä½¿ç”¨é¸ä¸»å…ƒ QR åˆ†è§£
                # X å½¢ç‹€ï¼š[n_locations, n_features]
                # ç›®æ¨™ï¼šé¸æ“‡ç©ºé–“é»ï¼ˆè¡Œï¼‰ï¼Œè€Œéç‰¹å¾µï¼ˆåˆ—ï¼‰
                # QR åˆ†è§£çš„ pivot é¸æ“‡çš„æ˜¯ã€Œåˆ—ã€ï¼ˆå°æ‡‰è½‰ç½®å¾Œçš„è¡Œï¼‰
                # å› æ­¤çµ±ä¸€å° X.T åš QR åˆ†è§£ï¼Œpivot å°æ‡‰ç©ºé–“é»ç´¢å¼•
                if self.mode == 'column':
                    # å° X^T åš QR åˆ†è§£é¸æ“‡åˆ— (å°æ‡‰åŸçŸ©é™£çš„è¡Œ/ç©ºé–“é»)
                    Q, R, piv = qr(X.T, mode='economic', pivoting=True)
                    selected_indices = piv[:n_sensors]
                else:
                    # mode='row': åŒæ¨£å° X.T åš QR åˆ†è§£é¸æ“‡ç©ºé–“é»
                    # è¨»ï¼šmode åƒæ•¸å·²æ£„ç”¨ï¼Œå»ºè­°çµ±ä¸€ä½¿ç”¨ 'column' è¡Œç‚º
                    Q, R, piv = qr(X.T, mode='economic', pivoting=True)
                    selected_indices = piv[:n_sensors]
            else:
                # æ¨™æº– QR åˆ†è§£
                Q, R = qr(X.T if self.mode == 'column' else X, mode='economic')
                # ä½¿ç”¨å°è§’å…ƒç´ å¤§å°é¸æ“‡
                diag_importance = np.abs(np.diag(R))
                selected_indices = np.argsort(diag_importance)[-n_sensors:][::-1]
        
        except np.linalg.LinAlgError as e:
            logger.warning(f"QR åˆ†è§£å¤±æ•—ï¼Œä½¿ç”¨ SVD å›é€€: {e}")
            # å›é€€åˆ° SVD æ–¹æ³•
            U, s, Vt = svd(X, full_matrices=False)
            # ä½¿ç”¨å¥‡ç•°å€¼æ¬Šé‡é¸æ“‡
            importance = np.sum(np.abs(Vt.T) * s, axis=1)
            selected_indices = np.argsort(importance)[-n_sensors:][::-1]
        
        # ç¢ºä¿ç´¢å¼•åœ¨æœ‰æ•ˆç¯„åœå…§
        selected_indices = selected_indices[selected_indices < n_locations]
        selected_indices = selected_indices[:n_sensors]
        
        # è¨ˆç®—å“è³ªæŒ‡æ¨™
        metrics = self._compute_metrics(X, selected_indices)
        
        result = (selected_indices, metrics)
        if return_qr:
            result = (*result, Q, R)
        
        return result
    
    def _compute_metrics(self, 
                        data_matrix: np.ndarray, 
                        selected_indices: np.ndarray) -> Dict[str, float]:
        """è¨ˆç®—æ„Ÿæ¸¬é»é…ç½®çš„å“è³ªæŒ‡æ¨™"""
        
        selected_data = data_matrix[selected_indices, :]
        
        # æ¢ä»¶æ•¸ï¼šä½¿ç”¨é€Ÿåº¦å ´æ¢ä»¶æ•¸ Îº(V)ï¼Œè€Œé Gram çŸ©é™£ Îº(V @ V^T)
        # åŸå› ï¼šå°æ–¼ K >> d çš„ä½ç§©çŸ©é™£ï¼ŒGram çŸ©é™£æœ‰ (K-d) å€‹é›¶ç‰¹å¾µå€¼ï¼Œ
        #       æ•¸å€¼èª¤å·®æœƒå°è‡´æ¢ä»¶æ•¸è¨ˆç®—å‡ºç¾èª¤å°æ€§å¤©æ–‡æ•¸å­—
        try:
            _, s, _ = svd(selected_data, full_matrices=False)
            cond_number = s[0] / s[-1] if s[-1] > 1e-15 else np.inf
        except:
            cond_number = np.inf
        
        # è¡Œåˆ—å¼ (é«”ç©)
        try:
            det_value = np.linalg.det(selected_data @ selected_data.T + self.regularization * np.eye(len(selected_indices)))
            log_det = np.log(max(det_value, 1e-16))
        except:
            log_det = -np.inf
        
        # è¦†è“‹ç‡ (å­ç©ºé–“è§’åº¦) èˆ‡ èƒ½é‡æ¯”ä¾‹
        # æ­£ç¢ºè¨ˆç®—ï¼šæ¯”è¼ƒé¸ä¸­é»çš„å·¦å¥‡ç•°å‘é‡èƒ½å¦é‡å»ºå…¨æ•¸æ“šçš„ä¸»è¦æ¨¡æ…‹
        coverage = 0.0
        energy_ratio = 0.0
        
        try:
            # å…¨æ•¸æ“šçš„ SVDï¼šdata_matrix = U_full @ diag(s_full) @ Vt_full
            # U_full: [n_locations, n_features], ç©ºé–“æ¨¡æ…‹
            # Vt_full: [n_features, n_features], ç‰¹å¾µæ¨¡æ…‹
            U_full, s_full, Vt_full = svd(data_matrix, full_matrices=False)
            
            # é¸ä¸­é»çš„ SVDï¼šselected_data = U_selected @ diag(s_selected) @ Vt_selected
            # U_selected: [n_sensors, n_features]
            # Vt_selected: [n_features, n_features]
            U_selected, s_selected, Vt_selected = svd(selected_data, full_matrices=False)
            
            # æ¯”è¼ƒç‰¹å¾µæ¨¡æ…‹çš„ä¸€è‡´æ€§ï¼ˆåœ¨ç‰¹å¾µç©ºé–“ä¸­æ¯”è¼ƒï¼‰
            # Vt_full å’Œ Vt_selected éƒ½æ˜¯ [n_features, ...], å¯ä»¥ç›´æ¥æ¯”è¼ƒ
            if len(s_selected) > 0 and len(s_full) > 0:
                n_compare = min(len(s_selected), len(s_full), min(Vt_full.shape[1], Vt_selected.shape[1]))
                
                # å­ç©ºé–“è¦†è“‹ç‡ï¼šæ¸¬é‡é¸ä¸­é»çš„ç‰¹å¾µæ¨¡æ…‹èˆ‡å…¨æ•¸æ“šç‰¹å¾µæ¨¡æ…‹çš„ä¸€è‡´æ€§
                # ä½¿ç”¨ Frobenius norm çš„æŠ•å½±æ¯”ä¾‹
                # Vt_full[:n_compare, :]: (n_compare, n_features)
                # Vt_selected[:n_compare, :].conj().T: (n_features, n_compare)
                # overlap: (n_compare, n_compare) - æŠ•å½±çŸ©é™£
                overlap = Vt_full[:n_compare, :] @ Vt_selected[:n_compare, :].conj().T
                # è¨ˆç®—æ­£äº¤æŠ•å½±çš„ Frobenius normï¼ˆæ­¸ä¸€åŒ–åˆ° [0, 1]ï¼‰
                coverage = float(np.linalg.norm(overlap, 'fro')**2 / n_compare)
                
                # èƒ½é‡æ¯”ä¾‹ï¼šä½¿ç”¨å­ç©ºé–“è¦†è“‹ç‡ä½œç‚ºèƒ½é‡æ•æ‰èƒ½åŠ›çš„ä¼°è¨ˆ
                # 
                # ç†è«–ä¾æ“šï¼š
                # - å­ç©ºé–“è¦†è“‹ç‡ (coverage) è¡¡é‡ã€Œé¸ä¸­é»çš„æ¨¡æ…‹èƒ½å¤šå¤§ç¨‹åº¦å°é½Šå…¨å ´ä¸»æ¨¡æ…‹ã€
                # - é€™ç›´æ¥åæ˜ é‡å»ºèƒ½åŠ›ï¼šé«˜è¦†è“‹ç‡ â†’ é¸ä¸­é»èƒ½æœ‰æ•ˆé‡å»ºå…¨å ´ â†’ é«˜èƒ½é‡æ•æ‰
                # 
                # ç‚ºä½•ä¸ç›´æ¥æ¯”è¼ƒå¥‡ç•°å€¼èƒ½é‡ï¼š
                # - s_selected ä¾†è‡ª [n_sensors, n_features] çŸ©é™£ï¼ˆ50 å€‹ç©ºé–“é»ï¼‰
                # - s_full ä¾†è‡ª [n_locations, n_features] çŸ©é™£ï¼ˆ16384 å€‹ç©ºé–“é»ï¼‰
                # - å…©è€…çš„å¥‡ç•°å€¼å°ºåº¦ä¸å¯æ¯”ï¼ˆç©ºé–“ç¶­åº¦å·®ç•° 300+ å€ï¼‰
                # - ç›´æ¥æ¯”è¼ƒæœƒå¾—åˆ° ~0.05 çš„èª¤å°æ€§ä½å€¼ï¼ˆåƒ…åæ˜ æ¡æ¨£æ¯”ä¾‹ï¼Œè€Œéé‡å»ºèƒ½åŠ›ï¼‰
                # 
                # ä½¿ç”¨è¦†è“‹ç‡çš„ç‰©ç†æ„ç¾©ï¼š
                # - è¦†è“‹ç‡ â‰ˆ 1.0: é¸ä¸­é»çš„æ¨¡æ…‹å®Œç¾å°é½Šå…¨å ´æ¨¡æ…‹ â†’ èƒ½æ•æ‰ ~100% èƒ½é‡
                # - è¦†è“‹ç‡ â‰ˆ 0.8: é¸ä¸­é»èƒ½æ•æ‰ ~80% çš„ä¸»è¦æ¨¡æ…‹æ–¹å‘ â†’ è‰¯å¥½é‡å»º
                # - è¦†è“‹ç‡ < 0.5: é¸ä¸­é»éºæ¼é‡è¦æ¨¡æ…‹ â†’ é‡å»ºä¸è¶³
                energy_ratio = float(coverage)
            
        except Exception as e:
            # éœé»˜å¤±æ•—ï¼Œé¿å…ä¸­æ–·æµç¨‹
            pass
        
        return {
            'condition_number': float(cond_number),
            'log_determinant': float(log_det),
            'subspace_coverage': float(coverage),
            'energy_ratio': float(energy_ratio),
            'n_sensors': len(selected_indices)
        }


class PODBasedSelector(BaseSensorSelector):
    """
    åŸºæ–¼ POD çš„æ„Ÿæ¸¬é»é¸æ“‡å™¨
    
    å…ˆé€²è¡Œ POD åˆ†è§£ï¼Œç„¶å¾Œåœ¨ POD æ¨¡æ…‹ç©ºé–“ä¸­é€²è¡Œæ„Ÿæ¸¬é»é¸æ“‡ã€‚
    é©ç”¨æ–¼å…·æœ‰æ˜ç¢ºä½ç¶­çµæ§‹çš„æµå ´è³‡æ–™ã€‚
    """
    
    def __init__(self,
                 n_modes: Optional[int] = None,
                 energy_threshold: float = 0.99,
                 mode_weighting: str = 'energy'):
        """
        Args:
            n_modes: POD æ¨¡æ…‹æ•¸é‡ (None ç‚ºè‡ªå‹•é¸æ“‡)
            energy_threshold: èƒ½é‡ä¿ç•™é–¾å€¼
            mode_weighting: æ¨¡æ…‹æ¬Šé‡ç­–ç•¥ ('energy', 'uniform', 'decay')
        """
        self.n_modes = n_modes
        self.energy_threshold = energy_threshold
        self.mode_weighting = mode_weighting
        
    def select_sensors(self, 
                      data_matrix: np.ndarray,
                      n_sensors: int) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        åŸºæ–¼ POD çš„æ„Ÿæ¸¬é»é¸æ“‡
        
        Args:
            data_matrix: å¿«ç…§çŸ©é™£ [n_locations, n_snapshots]
            n_sensors: æ„Ÿæ¸¬é»æ•¸é‡
            
        Returns:
            (selected_indices, metrics)
        """
        # ç¢ºä¿æ•¸æ“šç‚º numpy æ•¸çµ„
        if isinstance(data_matrix, torch.Tensor):
            data_matrix = data_matrix.detach().cpu().numpy()
        
        # POD åˆ†è§£
        U, s, Vt = svd(data_matrix, full_matrices=False)
        
        # ç¢ºå®š POD æ¨¡æ…‹æ•¸é‡
        if self.n_modes is None:
            cumulative_energy = np.cumsum(s**2) / np.sum(s**2)
            n_modes = np.argmax(cumulative_energy >= self.energy_threshold) + 1
            n_modes = min(n_modes, len(s))
        else:
            n_modes = min(self.n_modes, len(s))
        
        # æå– POD æ¨¡æ…‹
        pod_modes = U[:, :n_modes]  # [n_locations, n_modes]
        
        # æ ¹æ“šæ¨¡æ…‹æ¬Šé‡ç­–ç•¥èª¿æ•´
        if self.mode_weighting == 'energy':
            # ä½¿ç”¨å¥‡ç•°å€¼ä½œç‚ºæ¬Šé‡
            weights = s[:n_modes]
            weighted_modes = pod_modes * weights[np.newaxis, :]
        elif self.mode_weighting == 'uniform':
            # çµ±ä¸€æ¬Šé‡
            weighted_modes = pod_modes
        elif self.mode_weighting == 'decay':
            # æŒ‡æ•¸è¡°æ¸›æ¬Šé‡
            weights = np.exp(-np.arange(n_modes) / max(1, n_modes / 3))
            weighted_modes = pod_modes * weights[np.newaxis, :]
        else:
            weighted_modes = pod_modes
        
        # åœ¨ POD æ¨¡æ…‹ç©ºé–“ä¸­ä½¿ç”¨ QR-pivot é¸æ“‡
        qr_selector = QRPivotSelector(mode='row', pivoting=True)
        selected_indices, qr_metrics = qr_selector.select_sensors(weighted_modes, n_sensors)
        
        # è¨ˆç®— POD ç›¸é—œæŒ‡æ¨™
        pod_metrics = {
            'n_pod_modes': n_modes,
            'pod_energy_ratio': float(np.sum(s[:n_modes]**2) / np.sum(s**2)),
            'effective_rank': float(np.sum(s**2)**2 / np.sum(s**4)),  # æœ‰æ•ˆç§©
        }
        
        # åˆä½µæŒ‡æ¨™
        metrics = {**qr_metrics, **pod_metrics}
        
        return selected_indices, metrics


class GreedySelector(BaseSensorSelector):
    """
    è²ªå¿ƒæ„Ÿæ¸¬é»é¸æ“‡å™¨
    
    ä½¿ç”¨è²ªå¿ƒç®—æ³•é€æ­¥é¸æ“‡æœ€å¤§åŒ–æŸå€‹ç›®æ¨™å‡½æ•¸çš„æ„Ÿæ¸¬é»ã€‚
    æ”¯æ´å¤šç¨®ç›®æ¨™å‡½æ•¸ï¼šè³‡è¨Šå¢ç›Šã€æ¢ä»¶æ•¸æœ€é©åŒ–ã€èƒ½é‡æœ€å¤§åŒ–ç­‰ã€‚
    """
    
    def __init__(self,
                 objective: str = 'info_gain',
                 regularization: float = 1e-8):
        """
        Args:
            objective: ç›®æ¨™å‡½æ•¸ ('info_gain', 'condition', 'energy', 'determinant')
            regularization: æ­£å‰‡åŒ–åƒæ•¸
        """
        self.objective = objective
        self.regularization = regularization
        
    def select_sensors(self, 
                      data_matrix: np.ndarray,
                      n_sensors: int) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        è²ªå¿ƒæ„Ÿæ¸¬é»é¸æ“‡
        
        Args:
            data_matrix: è³‡æ–™çŸ©é™£ [n_locations, n_features]
            n_sensors: æ„Ÿæ¸¬é»æ•¸é‡
            
        Returns:
            (selected_indices, metrics)
        """
        if isinstance(data_matrix, torch.Tensor):
            data_matrix = data_matrix.detach().cpu().numpy()
        
        n_locations, n_features = data_matrix.shape
        n_sensors = min(n_sensors, n_locations)
        
        selected_indices = []
        remaining_indices = list(range(n_locations))
        objective_values = []
        
        for step in range(n_sensors):
            best_idx = None
            best_objective = -np.inf
            
            for candidate_idx in remaining_indices:
                # æš«æ™‚æ·»åŠ å€™é¸é»
                test_indices = selected_indices + [candidate_idx]
                test_data = data_matrix[test_indices, :]
                
                # è¨ˆç®—ç›®æ¨™å‡½æ•¸å€¼
                objective_val = self._compute_objective(test_data)
                
                if objective_val > best_objective:
                    best_objective = objective_val
                    best_idx = candidate_idx
            
            # æ·»åŠ æœ€ä½³å€™é¸é»
            if best_idx is not None:
                selected_indices.append(best_idx)
                remaining_indices.remove(best_idx)
                objective_values.append(best_objective)
            else:
                logger.warning(f"ç„¡æ³•åœ¨ç¬¬ {step+1} æ­¥æ‰¾åˆ°æœ‰æ•ˆçš„æ„Ÿæ¸¬é»")
                break
        
        selected_indices = np.array(selected_indices)
        
        # è¨ˆç®—æœ€çµ‚æŒ‡æ¨™
        final_data = data_matrix[selected_indices, :]
        metrics = {
            'final_objective': float(best_objective),
            'objective_progression': objective_values,
            'greedy_efficiency': float(len(selected_indices) / n_sensors),
        }
        
        # æ·»åŠ åŸºæœ¬æŒ‡æ¨™
        qr_selector = QRPivotSelector()
        basic_metrics = qr_selector._compute_metrics(data_matrix, selected_indices)
        metrics.update(basic_metrics)
        
        return selected_indices, metrics
    
    def _compute_objective(self, data_subset: np.ndarray) -> float:
        """è¨ˆç®—ç›®æ¨™å‡½æ•¸å€¼"""
        
        if data_subset.shape[0] == 0:
            return -np.inf
        
        try:
            gram_matrix = data_subset @ data_subset.T + self.regularization * np.eye(data_subset.shape[0])
            
            if self.objective == 'info_gain':
                # è³‡è¨Šå¢ç›Š = log det(Gram)
                sign, logdet = np.linalg.slogdet(gram_matrix)
                return logdet if sign > 0 else -np.inf
                
            elif self.objective == 'condition':
                # æ¢ä»¶æ•¸çš„å€’æ•¸ (è¶Šå¤§è¶Šå¥½)
                # ä½¿ç”¨é€Ÿåº¦å ´æ¢ä»¶æ•¸è€Œé Gram çŸ©é™£æ¢ä»¶æ•¸
                _, s, _ = svd(data_subset, full_matrices=False)
                cond = s[0] / s[-1] if s[-1] > 1e-15 else np.inf
                return -np.log(cond + 1e-16)
                
            elif self.objective == 'energy':
                # èƒ½é‡ = trace(Gram)
                return np.trace(gram_matrix)
                
            elif self.objective == 'determinant':
                # è¡Œåˆ—å¼
                det = np.linalg.det(gram_matrix)
                return det if det > 0 else -np.inf
                
            else:
                raise ValueError(f"æœªçŸ¥çš„ç›®æ¨™å‡½æ•¸: {self.objective}")
                
        except np.linalg.LinAlgError:
            return -np.inf


class MultiObjectiveSelector(BaseSensorSelector):
    """
    å¤šç›®æ¨™æ„Ÿæ¸¬é»é¸æ“‡å™¨
    
    åŒæ™‚æœ€é©åŒ–å¤šå€‹ç›®æ¨™ï¼šç²¾åº¦ã€ç©©å¥æ€§ã€æ„Ÿæ¸¬é»æ•¸é‡ç­‰ã€‚
    ä½¿ç”¨é€²åŒ–ç®—æ³•æˆ–æ¢¯åº¦ç‚ºåŸºç¤çš„å¤šç›®æ¨™æœ€é©åŒ–ã€‚
    """
    
    def __init__(self,
                 objectives: List[str] = ['accuracy', 'robustness', 'efficiency'],
                 weights: Optional[List[float]] = None,
                 method: str = 'weighted_sum',
                 max_iterations: int = 100):
        """
        Args:
            objectives: ç›®æ¨™å‡½æ•¸åˆ—è¡¨
            weights: ç›®æ¨™æ¬Šé‡ (None ç‚ºç­‰æ¬Šé‡)
            method: å¤šç›®æ¨™æ–¹æ³• ('weighted_sum', 'pareto', 'lexicographic')
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•¸
        """
        self.objectives = objectives
        self.weights = weights or [1.0/len(objectives)] * len(objectives)
        self.method = method
        self.max_iterations = max_iterations
        
    def select_sensors(self, 
                      data_matrix: np.ndarray,
                      n_sensors: int,
                      noise_level: float = 0.01) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        å¤šç›®æ¨™æ„Ÿæ¸¬é»é¸æ“‡
        
        Args:
            data_matrix: è³‡æ–™çŸ©é™£
            n_sensors: æ„Ÿæ¸¬é»æ•¸é‡
            noise_level: é›œè¨Šæ°´æº– (ç”¨æ–¼ç©©å¥æ€§è©•ä¼°)
            
        Returns:
            (selected_indices, metrics)
        """
        if isinstance(data_matrix, torch.Tensor):
            data_matrix = data_matrix.detach().cpu().numpy()
        
        n_locations = data_matrix.shape[0]
        
        if self.method == 'weighted_sum':
            return self._weighted_sum_optimization(data_matrix, n_sensors, noise_level)
        elif self.method == 'pareto':
            return self._pareto_optimization(data_matrix, n_sensors, noise_level)
        else:
            # å›é€€åˆ° QR-pivot
            logger.warning(f"æœªå¯¦ç¾çš„å¤šç›®æ¨™æ–¹æ³• {self.method}ï¼Œä½¿ç”¨ QR-pivot")
            qr_selector = QRPivotSelector()
            return qr_selector.select_sensors(data_matrix, n_sensors)
    
    def _weighted_sum_optimization(self, 
                                 data_matrix: np.ndarray, 
                                 n_sensors: int, 
                                 noise_level: float) -> Tuple[np.ndarray, Dict[str, float]]:
        """åŠ æ¬Šå’Œå¤šç›®æ¨™æœ€é©åŒ–"""
        
        n_locations = data_matrix.shape[0]
        
        def objective_function(binary_selection):
            """ç›®æ¨™å‡½æ•¸ï¼šäºŒé€²åˆ¶é¸æ“‡å‘é‡ -> æ¨™é‡ç›®æ¨™å€¼"""
            indices = np.where(binary_selection > 0.5)[0]
            if len(indices) == 0:
                return 1e10  # æ‡²ç½°ç©ºé¸æ“‡
            
            # èª¿æ•´é¸æ“‡çš„æ„Ÿæ¸¬é»æ•¸é‡
            if len(indices) > n_sensors:
                # å¦‚æœé¸æ“‡å¤ªå¤šï¼Œä¿ç•™æœ€é‡è¦çš„
                importance = np.sum(np.abs(data_matrix[indices, :]), axis=1)
                top_indices = np.argsort(importance)[-n_sensors:]
                indices = indices[top_indices]
            
            objectives_values = self._compute_multi_objectives(data_matrix, indices, noise_level)
            
            # åŠ æ¬Šçµ„åˆ
            weighted_objective = sum(w * obj for w, obj in zip(self.weights, objectives_values))
            
            # æ‡²ç½°é …ï¼šæ„Ÿæ¸¬é»æ•¸é‡åå·®
            count_penalty = abs(len(indices) - n_sensors) * 0.1
            
            return -weighted_objective + count_penalty  # è² è™Ÿå› ç‚ºè¦æœ€å¤§åŒ–
        
        # ä½¿ç”¨å·®åˆ†é€²åŒ–ç®—æ³•
        bounds = [(0, 1)] * n_locations
        
        result = differential_evolution(
            objective_function,
            bounds,
            maxiter=self.max_iterations,
            popsize=min(15, max(10, n_locations // 10)),
            seed=42,
            atol=1e-6,
            tol=1e-6
        )
        
        # æå–é¸æ“‡çš„æ„Ÿæ¸¬é»
        binary_solution = result.x
        selected_indices = np.where(binary_solution > 0.5)[0]
        
        # å¦‚æœæ•¸é‡ä¸å°ï¼Œä½¿ç”¨è²ªå¿ƒèª¿æ•´
        if len(selected_indices) != n_sensors:
            if len(selected_indices) > n_sensors:
                # ç§»é™¤é‡è¦æ€§è¼ƒä½çš„é»
                importance = np.sum(np.abs(data_matrix[selected_indices, :]), axis=1)
                top_k = np.argsort(importance)[-n_sensors:]
                selected_indices = selected_indices[top_k]
            else:
                # æ·»åŠ é‡è¦æ€§è¼ƒé«˜çš„é»
                remaining = np.setdiff1d(np.arange(n_locations), selected_indices)
                importance = np.sum(np.abs(data_matrix[remaining, :]), axis=1)
                n_add = n_sensors - len(selected_indices)
                top_add = np.argsort(importance)[-n_add:]
                selected_indices = np.concatenate([selected_indices, remaining[top_add]])
        
        # è¨ˆç®—æœ€çµ‚æŒ‡æ¨™
        final_objectives = self._compute_multi_objectives(data_matrix, selected_indices, noise_level)
        
        metrics = {
            'multi_objective_score': float(-result.fun),
            'optimization_success': bool(result.success),
            'n_iterations': int(result.nit),
        }
        
        # æ·»åŠ å„å€‹ç›®æ¨™çš„å€¼
        for i, obj_name in enumerate(self.objectives):
            metrics[f'objective_{obj_name}'] = float(final_objectives[i])
        
        return selected_indices, metrics
    
    def _compute_multi_objectives(self, 
                                data_matrix: np.ndarray, 
                                indices: np.ndarray, 
                                noise_level: float) -> List[float]:
        """è¨ˆç®—å¤šå€‹ç›®æ¨™å‡½æ•¸å€¼"""
        
        if len(indices) == 0:
            return [0.0] * len(self.objectives)
        
        selected_data = data_matrix[indices, :]
        objectives_values = []
        
        for obj_name in self.objectives:
            if obj_name == 'accuracy':
                # ç²¾åº¦ï¼šä½¿ç”¨é€Ÿåº¦å ´æ¢ä»¶æ•¸çš„å€’æ•¸ï¼ˆé¿å… Gram çŸ©é™£ä½ç§©å•é¡Œï¼‰
                try:
                    s = np.linalg.svd(selected_data, compute_uv=False)
                    if s[-1] > 1e-15:
                        cond = s[0] / s[-1]
                    else:
                        cond = np.inf
                    accuracy = 1.0 / (1.0 + np.log(cond + 1e-16))
                except:
                    accuracy = 0.0
                objectives_values.append(accuracy)
                
            elif obj_name == 'robustness':
                # ç©©å¥æ€§ï¼šå°é›œè¨Šçš„æ•æ„Ÿåº¦
                try:
                    # æ·»åŠ é›œè¨Šä¸¦è¨ˆç®—é‡å»ºèª¤å·®
                    noisy_data = selected_data + noise_level * np.random.randn(*selected_data.shape)
                    reconstruction_error = np.linalg.norm(noisy_data - selected_data, 'fro')
                    robustness = 1.0 / (1.0 + reconstruction_error)
                except:
                    robustness = 0.0
                objectives_values.append(robustness)
                
            elif obj_name == 'efficiency':
                # æ•ˆç‡ï¼šå–®ä½æ„Ÿæ¸¬é»çš„è³‡è¨Šé‡
                try:
                    info_content = np.linalg.slogdet(selected_data @ selected_data.T + 1e-12 * np.eye(len(indices)))[1]
                    efficiency = info_content / max(1, len(indices))
                except:
                    efficiency = 0.0
                objectives_values.append(efficiency)
                
            elif obj_name == 'coverage':
                # è¦†è“‹ç‡ï¼šç©ºé–“åˆ†ä½ˆçš„å‡å‹»æ€§
                if len(indices) > 1:
                    # è¨ˆç®—æ„Ÿæ¸¬é»ä¹‹é–“çš„æœ€å°è·é›¢
                    min_dist = np.min([np.linalg.norm(data_matrix[i] - data_matrix[j]) 
                                     for i in indices for j in indices if i != j])
                    coverage = min_dist / (np.linalg.norm(data_matrix.max(axis=0) - data_matrix.min(axis=0)) + 1e-16)
                else:
                    coverage = 0.0
                objectives_values.append(coverage)
                
            else:
                objectives_values.append(0.0)
        
        return objectives_values
    
    def _pareto_optimization(self, 
                           data_matrix: np.ndarray, 
                           n_sensors: int, 
                           noise_level: float) -> Tuple[np.ndarray, Dict[str, float]]:
        """Pareto å‰æ²¿å¤šç›®æ¨™æœ€é©åŒ– (ç°¡åŒ–ç‰ˆ)"""
        
        # ç°¡åŒ–å¯¦ç¾ï¼šç”Ÿæˆå¤šå€‹å€™é¸è§£ï¼Œé¸æ“‡ Pareto æœ€é©
        n_candidates = min(50, data_matrix.shape[0])
        candidates = []
        
        # ä½¿ç”¨ä¸åŒç­–ç•¥ç”Ÿæˆå€™é¸è§£
        selectors = [
            QRPivotSelector(mode='column'),
            PODBasedSelector(n_modes=min(10, data_matrix.shape[1] // 2)),
            GreedySelector(objective='info_gain'),
            GreedySelector(objective='condition')
        ]
        
        for selector in selectors:
            try:
                indices, _ = selector.select_sensors(data_matrix, n_sensors)
                objectives = self._compute_multi_objectives(data_matrix, indices, noise_level)
                candidates.append((indices, objectives))
            except:
                continue
        
        # æ·»åŠ éš¨æ©Ÿå€™é¸
        for _ in range(n_candidates - len(candidates)):
            random_indices = np.random.choice(data_matrix.shape[0], n_sensors, replace=False)
            objectives = self._compute_multi_objectives(data_matrix, random_indices, noise_level)
            candidates.append((random_indices, objectives))
        
        # æ‰¾åˆ° Pareto å‰æ²¿
        pareto_candidates = self._find_pareto_front(candidates)
        
        if pareto_candidates:
            # å¾ Pareto å‰æ²¿ä¸­é¸æ“‡åŠ æ¬Šæœ€ä½³è§£
            best_score = -np.inf
            best_solution = None
            
            for indices, objectives in pareto_candidates:
                weighted_score = sum(w * obj for w, obj in zip(self.weights, objectives))
                if weighted_score > best_score:
                    best_score = weighted_score
                    best_solution = (indices, objectives)
            
            selected_indices, final_objectives = best_solution
        else:
            # å›é€€åˆ°ç¬¬ä¸€å€‹å€™é¸
            selected_indices, final_objectives = candidates[0]
        
        metrics = {
            'pareto_front_size': len(pareto_candidates),
            'n_candidates_evaluated': len(candidates),
            'pareto_score': float(best_score),
        }
        
        for i, obj_name in enumerate(self.objectives):
            metrics[f'objective_{obj_name}'] = float(final_objectives[i])
        
        return selected_indices, metrics
    
    def _find_pareto_front(self, candidates: List[Tuple]) -> List[Tuple]:
        """æ‰¾åˆ° Pareto å‰æ²¿"""
        pareto_front = []
        
        for candidate in candidates:
            is_dominated = False
            
            for other in candidates:
                if candidate == other:
                    continue
                
                # æª¢æŸ¥æ˜¯å¦è¢«æ”¯é…ï¼ˆæ‰€æœ‰ç›®æ¨™éƒ½ä¸å„ªæ–¼å…¶ä»–è§£ï¼‰
                candidate_objectives = candidate[1]
                other_objectives = other[1]
                
                if all(c <= o for c, o in zip(candidate_objectives, other_objectives)) and \
                   any(c < o for c, o in zip(candidate_objectives, other_objectives)):
                    is_dominated = True
                    break
            
            if not is_dominated:
                pareto_front.append(candidate)
        
        return pareto_front


class SensorOptimizer:
    """
    æ„Ÿæ¸¬é»æœ€é©åŒ–å™¨
    
    æä¾›é«˜å±¤ç´šçš„æ„Ÿæ¸¬é»é¸æ“‡æ¥å£ï¼Œæ•´åˆå¤šç¨®ç®—æ³•ä¸¦æ”¯æ´è‡ªå‹•è¶…åƒæ•¸èª¿å„ªã€‚
    """
    
    def __init__(self,
                 strategy: str = 'auto',
                 config: Optional[Dict] = None):
        """
        Args:
            strategy: é¸æ“‡ç­–ç•¥ ('qr_pivot', 'pod_based', 'greedy', 'multi_objective', 'auto')
            config: ç­–ç•¥é…ç½®å­—å…¸
        """
        self.strategy = strategy
        self.config = config or {}
        
    def optimize_sensor_placement(self,
                                 data_matrix: np.ndarray,
                                 n_sensors: int,
                                 validation_data: Optional[np.ndarray] = None) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        æœ€é©åŒ–æ„Ÿæ¸¬é»é…ç½®
        
        Args:
            data_matrix: è¨“ç·´è³‡æ–™çŸ©é™£
            n_sensors: æ„Ÿæ¸¬é»æ•¸é‡
            validation_data: é©—è­‰è³‡æ–™ (ç”¨æ–¼è©•ä¼°)
            
        Returns:
            (optimal_indices, comprehensive_metrics)
        """
        if self.strategy == 'auto':
            return self._auto_strategy_selection(data_matrix, n_sensors, validation_data)
        else:
            selector = self._create_selector(self.strategy)
            selected_indices, metrics = selector.select_sensors(data_matrix, n_sensors)
            
            # å¦‚æœæœ‰é©—è­‰è³‡æ–™ï¼Œè¨ˆç®—é©—è­‰æŒ‡æ¨™
            if validation_data is not None:
                validation_metrics = self._evaluate_on_validation(
                    data_matrix, validation_data, selected_indices)
                metrics.update(validation_metrics)
            
            return selected_indices, metrics
    
    def _create_selector(self, strategy: str) -> BaseSensorSelector:
        """å‰µå»ºç‰¹å®šç­–ç•¥çš„é¸æ“‡å™¨"""
        
        if strategy == 'qr_pivot':
            return QRPivotSelector(**self.config.get('qr_pivot', {}))
        elif strategy == 'pod_based':
            return PODBasedSelector(**self.config.get('pod_based', {}))
        elif strategy == 'greedy':
            return GreedySelector(**self.config.get('greedy', {}))
        elif strategy == 'multi_objective':
            return MultiObjectiveSelector(**self.config.get('multi_objective', {}))
        else:
            raise ValueError(f"æœªçŸ¥çš„æ„Ÿæ¸¬é»é¸æ“‡ç­–ç•¥: {strategy}")
    
    def _auto_strategy_selection(self,
                               data_matrix: np.ndarray,
                               n_sensors: int,
                               validation_data: Optional[np.ndarray]) -> Tuple[np.ndarray, Dict[str, Any]]:
        """è‡ªå‹•ç­–ç•¥é¸æ“‡"""
        
        # åˆ†æè³‡æ–™ç‰¹æ€§
        n_locations, n_features = data_matrix.shape
        data_rank = np.linalg.matrix_rank(data_matrix)
        aspect_ratio = n_features / n_locations
        
        # æ ¹æ“šè³‡æ–™ç‰¹æ€§é¸æ“‡ç­–ç•¥
        if data_rank < min(n_locations, n_features) * 0.8:
            # ä½ç§©è³‡æ–™ï¼šä½¿ç”¨ POD
            strategy = 'pod_based'
            logger.info("æª¢æ¸¬åˆ°ä½ç§©çµæ§‹ï¼Œä½¿ç”¨ POD-based ç­–ç•¥")
        elif aspect_ratio > 2.0:
            # å¯¬çŸ©é™£ï¼šä½¿ç”¨ QR-pivot
            strategy = 'qr_pivot'
            logger.info("æª¢æ¸¬åˆ°å¯¬çŸ©é™£çµæ§‹ï¼Œä½¿ç”¨ QR-pivot ç­–ç•¥")
        elif n_sensors / n_locations < 0.1:
            # æ¥µç¨€ç–æ„Ÿæ¸¬ï¼šä½¿ç”¨å¤šç›®æ¨™æœ€é©åŒ–
            strategy = 'multi_objective'
            logger.info("æª¢æ¸¬åˆ°æ¥µç¨€ç–æ„Ÿæ¸¬éœ€æ±‚ï¼Œä½¿ç”¨å¤šç›®æ¨™æœ€é©åŒ–")
        else:
            # é è¨­ï¼šè²ªå¿ƒç®—æ³•
            strategy = 'greedy'
            logger.info("ä½¿ç”¨é è¨­è²ªå¿ƒç­–ç•¥")
        
        # åŸ·è¡Œé¸æ“‡
        selector = self._create_selector(strategy)
        selected_indices, metrics = selector.select_sensors(data_matrix, n_sensors)
        
        # æ·»åŠ è‡ªå‹•é¸æ“‡ä¿¡æ¯
        metrics['auto_selected_strategy'] = strategy
        metrics['data_analysis'] = {
            'rank': int(data_rank),
            'aspect_ratio': float(aspect_ratio),
            'sparsity_ratio': float(n_sensors / n_locations)
        }
        
        # é©—è­‰è©•ä¼°
        if validation_data is not None:
            validation_metrics = self._evaluate_on_validation(
                data_matrix, validation_data, selected_indices)
            metrics.update(validation_metrics)
        
        return selected_indices, metrics
    
    def _evaluate_on_validation(self,
                              train_data: np.ndarray,
                              validation_data: np.ndarray,
                              selected_indices: np.ndarray) -> Dict[str, float]:
        """åœ¨é©—è­‰è³‡æ–™ä¸Šè©•ä¼°æ„Ÿæ¸¬é»é…ç½®"""
        
        try:
            # ä½¿ç”¨é¸æ“‡çš„æ„Ÿæ¸¬é»é€²è¡Œé‡å»º
            sensor_data_train = train_data[selected_indices, :]
            sensor_data_val = validation_data[selected_indices, :]
            
            # è¨ˆç®—é‡å»ºèª¤å·®ï¼ˆç°¡å–®ç·šæ€§é‡å»ºï¼‰
            if sensor_data_train.shape[0] >= sensor_data_train.shape[1]:
                # è¶…å®šç³»çµ±
                reconstruction_matrix = np.linalg.pinv(sensor_data_train)
                coefficients = reconstruction_matrix @ validation_data
                reconstructed = sensor_data_train @ coefficients
            else:
                # æ¬ å®šç³»çµ±
                regularization = 1e-6
                gram = sensor_data_train @ sensor_data_train.T + regularization * np.eye(sensor_data_train.shape[0])
                reconstruction_matrix = sensor_data_train.T @ np.linalg.pinv(gram)
                coefficients = reconstruction_matrix @ sensor_data_val
                reconstructed = train_data @ coefficients
            
            # è¨ˆç®—èª¤å·®æŒ‡æ¨™
            mse = np.mean((validation_data - reconstructed)**2)
            relative_error = np.linalg.norm(validation_data - reconstructed, 'fro') / \
                           (np.linalg.norm(validation_data, 'fro') + 1e-16)
            
            return {
                'validation_mse': float(mse),
                'validation_relative_error': float(relative_error),
                'reconstruction_rank': int(np.linalg.matrix_rank(reconstruction_matrix))
            }
            
        except Exception as e:
            logger.warning(f"é©—è­‰è©•ä¼°å¤±æ•—: {e}")
            return {
                'validation_mse': np.inf,
                'validation_relative_error': np.inf,
                'reconstruction_rank': 0
            }


def evaluate_sensor_placement(data_matrix: np.ndarray,
                            selected_indices: np.ndarray,
                            test_data: Optional[np.ndarray] = None,
                            noise_levels: List[float] = [0.01, 0.05, 0.1]) -> Dict[str, Any]:
    """
    è©•ä¼°æ„Ÿæ¸¬é»é…ç½®çš„å“è³ª
    
    Args:
        data_matrix: åŸå§‹è³‡æ–™çŸ©é™£
        selected_indices: é¸æ“‡çš„æ„Ÿæ¸¬é»ç´¢å¼•
        test_data: æ¸¬è©¦è³‡æ–™ (å¯é¸)
        noise_levels: é›œè¨Šæ°´æº–åˆ—è¡¨
        
    Returns:
        ç¶œåˆè©•ä¼°æŒ‡æ¨™å­—å…¸
    """
    metrics = {}
    
    # åŸºæœ¬æŒ‡æ¨™
    qr_selector = QRPivotSelector()
    basic_metrics = qr_selector._compute_metrics(data_matrix, selected_indices)
    metrics.update(basic_metrics)
    
    # é›œè¨Šç©©å¥æ€§æ¸¬è©¦
    if test_data is not None:
        robustness_metrics = {}
        
        for noise_level in noise_levels:
            try:
                # æ·»åŠ é›œè¨Š
                noisy_test = test_data + noise_level * np.random.randn(*test_data.shape)
                
                # é‡å»ºæ¸¬è©¦
                sensor_train = data_matrix[selected_indices, :]
                sensor_test = noisy_test[selected_indices, :]
                
                # ç°¡å–®ç·šæ€§é‡å»º
                reconstruction_matrix = np.linalg.pinv(sensor_train)
                reconstructed = sensor_train @ (reconstruction_matrix @ test_data)
                
                # è¨ˆç®—èª¤å·®
                reconstruction_error = np.linalg.norm(reconstructed - test_data, 'fro') / \
                                     (np.linalg.norm(test_data, 'fro') + 1e-16)
                
                robustness_metrics[f'noise_{noise_level}_error'] = float(reconstruction_error)
                
            except Exception as e:
                robustness_metrics[f'noise_{noise_level}_error'] = np.inf
        
        metrics['robustness'] = robustness_metrics
    
    # å¹¾ä½•åˆ†ä½ˆåˆ†æ
    if len(selected_indices) > 1:
        coordinates = data_matrix[selected_indices, :2] if data_matrix.shape[1] >= 2 else data_matrix[selected_indices, :]
        
        # è¨ˆç®—æœ€å°è·é›¢
        min_distance = np.inf
        max_distance = 0.0
        
        for i in range(len(selected_indices)):
            for j in range(i+1, len(selected_indices)):
                dist = np.linalg.norm(coordinates[i] - coordinates[j])
                min_distance = min(min_distance, dist)
                max_distance = max(max_distance, dist)
        
        metrics['geometry'] = {
            'min_sensor_distance': float(min_distance),
            'max_sensor_distance': float(max_distance),
            'distance_ratio': float(max_distance / (min_distance + 1e-16))
        }
    
    return metrics


def create_sensor_selector(strategy: str = 'qr_pivot', 
                         **kwargs) -> BaseSensorSelector:
    """
    å‰µå»ºæ„Ÿæ¸¬é»é¸æ“‡å™¨çš„ä¾¿æ·å‡½æ•¸
    
    Args:
        strategy: é¸æ“‡ç­–ç•¥
        **kwargs: ç­–ç•¥ç‰¹å®šåƒæ•¸
        
    Returns:
        æ„Ÿæ¸¬é»é¸æ“‡å™¨å¯¦ä¾‹
    """
    if strategy == 'qr_pivot':
        return QRPivotSelector(**kwargs)
    elif strategy == 'pod_based':
        return PODBasedSelector(**kwargs)
    elif strategy == 'greedy':
        return GreedySelector(**kwargs)
    elif strategy == 'multi_objective':
        return MultiObjectiveSelector(**kwargs)
    else:
        raise ValueError(f"æœªçŸ¥çš„æ„Ÿæ¸¬é»é¸æ“‡ç­–ç•¥: {strategy}")


if __name__ == "__main__":
    # æ¸¬è©¦ç¨‹å¼ç¢¼
    print("ğŸ§ª æ¸¬è©¦æ„Ÿæ¸¬é»é¸æ“‡æ¨¡çµ„...")
    
    # å‰µå»ºæ¸¬è©¦è³‡æ–™
    np.random.seed(42)
    n_locations = 100
    n_snapshots = 50
    
    # æ¨¡æ“¬ä½ç¶­æµå ´è³‡æ–™
    t = np.linspace(0, 2*np.pi, n_snapshots)
    x = np.linspace(0, 1, n_locations)
    
    # å‰µå»ºå«æœ‰å¹¾å€‹ä¸»è¦æ¨¡æ…‹çš„è³‡æ–™
    data_matrix = np.zeros((n_locations, n_snapshots))
    for i in range(3):  # 3å€‹ä¸»è¦æ¨¡æ…‹
        mode = np.sin((i+1) * np.pi * x[:, np.newaxis])
        coeff = np.cos((i+1) * t) * np.exp(-0.1 * i)
        data_matrix += mode @ coeff[np.newaxis, :]
    
    # æ·»åŠ é›œè¨Š
    data_matrix += 0.01 * np.random.randn(n_locations, n_snapshots)
    
    n_sensors = 8
    
    # æ¸¬è©¦ä¸åŒçš„é¸æ“‡ç­–ç•¥
    strategies = {
        'QR-Pivot': QRPivotSelector(),
        'POD-based': PODBasedSelector(n_modes=5),
        'Greedy': GreedySelector(objective='info_gain'),
        'Multi-objective': MultiObjectiveSelector(objectives=['accuracy', 'robustness'])
    }
    
    results = {}
    
    for name, selector in strategies.items():
        print(f"\næ¸¬è©¦ {name} ç­–ç•¥...")
        try:
            indices, metrics = selector.select_sensors(data_matrix, n_sensors)
            results[name] = {
                'indices': indices,
                'condition_number': metrics.get('condition_number', np.inf),
                'energy_ratio': metrics.get('energy_ratio', 0.0),
                'n_selected': len(indices)
            }
            print(f"  é¸æ“‡æ„Ÿæ¸¬é»: {len(indices)} å€‹")
            print(f"  æ¢ä»¶æ•¸: {metrics.get('condition_number', 'N/A'):.2f}")
            print(f"  èƒ½é‡æ¯”ä¾‹: {metrics.get('energy_ratio', 0.0):.3f}")
        except Exception as e:
            print(f"  âŒ å¤±æ•—: {e}")
            results[name] = {'error': str(e)}
    
    # æ¸¬è©¦è‡ªå‹•ç­–ç•¥é¸æ“‡
    print(f"\næ¸¬è©¦è‡ªå‹•ç­–ç•¥é¸æ“‡...")
    optimizer = SensorOptimizer(strategy='auto')
    auto_indices, auto_metrics = optimizer.optimize_sensor_placement(data_matrix, n_sensors)
    print(f"  è‡ªå‹•é¸æ“‡ç­–ç•¥: {auto_metrics.get('auto_selected_strategy', 'unknown')}")
    print(f"  é¸æ“‡æ„Ÿæ¸¬é»: {len(auto_indices)} å€‹")
    
    # è©•ä¼°æ‰€æœ‰ç­–ç•¥
    print(f"\nç¶œåˆè©•ä¼°...")
    for name, result in results.items():
        if 'error' not in result:
            eval_metrics = evaluate_sensor_placement(data_matrix, result['indices'])
            print(f"  {name}: æ¢ä»¶æ•¸={eval_metrics.get('condition_number', 'N/A'):.2f}, "
                  f"è¦†è“‹ç‡={eval_metrics.get('subspace_coverage', 0.0):.3f}")
    
    print("âœ… æ„Ÿæ¸¬é»é¸æ“‡æ¨¡çµ„æ¸¬è©¦å®Œæˆï¼")


class PhysicsGuidedQRPivotSelector(QRPivotSelector):
    """
    ç‰©ç†å¼•å° QR-Pivot æ„Ÿæ¸¬é»é¸æ“‡å™¨
    
    åœ¨æ¨™æº– QR-Pivot åŸºç¤ä¸Šå¼•å…¥ç‰©ç†å…ˆé©—ï¼ˆå£é¢é‚Šç•Œæ¢ä»¶ï¼‰ï¼Œ
    é€šéå° POD æ¨¡æ…‹çŸ©é™£é€²è¡Œç‰©ç†åŠ æ¬Šï¼Œå„ªå…ˆé¸æ“‡å£é¢é«˜æ¢¯åº¦å€åŸŸçš„æ„Ÿæ¸¬é»ã€‚
    
    æ ¸å¿ƒæ”¹é€²ï¼š
    1. å£é¢å€åŸŸè­˜åˆ¥ï¼ˆåŸºæ–¼ y+ æˆ– y/hï¼‰
    2. ç‰©ç†æ¬Šé‡çŸ©é™£ï¼ˆå£é¢æ¬Šé‡æ”¾å¤§ï¼‰
    3. åŠ æ¬Š QR-Pivotï¼ˆåœ¨åŠ æ¬Šæ¨¡æ…‹ç©ºé–“ä¸­é¸é»ï¼‰
    4. å£é¢è¦†è“‹ç‡çµ±è¨ˆï¼ˆé©—è­‰ç­–ç•¥æœ‰æ•ˆæ€§ï¼‰
    
    é©ç”¨å ´æ™¯ï¼š
    - æ¹æµé€šé“æµï¼ˆå£é¢å‰ªæ‡‰åŠ›é‡è¦ï¼‰
    - é‚Šç•Œå±¤æµå‹•ï¼ˆå£é¢æ¢¯åº¦æ•æ„Ÿï¼‰
    - ä»»ä½•éœ€è¦å„ªå…ˆæ•æ‰é‚Šç•Œæ¢ä»¶çš„æµå ´
    
    åƒè€ƒæ–‡ç»ï¼š
    - Manohar et al. (2018): Data-driven sparse sensor placement
    - æœ¬å°ˆæ¡ˆ PDE ç´„æŸæ¶ˆèå¯¦é©—ï¼šExp3 (Wall No-Center) è­‰å¯¦å£é¢å¯†é›†æ¡æ¨£çš„å„ªå‹¢
    """
    
    def __init__(self, 
                 mode: str = 'column',
                 pivoting: bool = True,
                 regularization: float = 1e-12,
                 wall_weight: float = 5.0,
                 wall_threshold: float = 0.1,
                 threshold_type: str = 'y_over_h'):
        """
        Args:
            mode: é¸æ“‡æ¨¡å¼ ('column' é¸åˆ—)
            pivoting: æ˜¯å¦ä½¿ç”¨é¸ä¸»å…ƒ
            regularization: æ­£å‰‡åŒ–é …é¿å…æ•¸å€¼ä¸ç©©å®š
            wall_weight: å£é¢å€åŸŸæ¬Šé‡å€æ•¸ï¼ˆé è¨­ 5.0ï¼ŒåŸºæ–¼ Exp3 æœ€å„ªé…ç½®ï¼‰
            wall_threshold: å£é¢å€åŸŸé–¾å€¼
                - threshold_type='y_over_h': y/h < 0.1 (å°æ‡‰ y+ â‰ˆ 100 at Re_Ï„=1000)
                - threshold_type='y_plus': y+ < 100 (é»æ€§åº•å±¤ + ç·©è¡å±¤)
            threshold_type: å£é¢è­˜åˆ¥é¡å‹ ('y_over_h' æˆ– 'y_plus')
        """
        super().__init__(mode=mode, pivoting=pivoting, regularization=regularization)
        self.wall_weight = wall_weight
        self.wall_threshold = wall_threshold
        self.threshold_type = threshold_type
        
        # è¨˜éŒ„å£é¢æ¬Šé‡æ‡‰ç”¨ç‹€æ…‹
        self._wall_mask = None
        self._wall_coverage = 0.0
    
    def select_sensors(self, 
                      data_matrix: np.ndarray,
                      n_sensors: int,
                      coords: Optional[np.ndarray] = None,
                      re_tau: float = 1000.0,
                      return_qr: bool = False) -> Tuple[np.ndarray, Dict[str, float]]:
        """
        ä½¿ç”¨ç‰©ç†å¼•å° QR-pivot é¸æ“‡æ„Ÿæ¸¬é»
        
        Args:
            data_matrix: POD æ¨¡æ…‹çŸ©é™£ [n_locations, n_modes] æˆ–å¿«ç…§çŸ©é™£ [n_locations, n_snapshots]
            n_sensors: æ„Ÿæ¸¬é»æ•¸é‡ K
            coords: ç©ºé–“åº§æ¨™ [n_locations, 3] (x, y, z)ï¼Œå¿…é ˆæä¾›ç”¨æ–¼è¨ˆç®—å£é¢è·é›¢
            re_tau: æ‘©æ“¦é›·è«¾æ•¸ï¼ˆç”¨æ–¼ y+ è¨ˆç®—ï¼Œé è¨­ 1000.0 å°æ‡‰ JHTDB Channel Flowï¼‰
            return_qr: æ˜¯å¦è¿”å› QR åˆ†è§£çµæœ
            
        Returns:
            (selected_indices, metrics)
            
        Raises:
            ValueError: å¦‚æœæœªæä¾› coords ä¸”éœ€è¦è¨ˆç®—å£é¢è·é›¢
        """
        # ç¢ºä¿æ•¸æ“šç‚º numpy æ•¸çµ„
        if isinstance(data_matrix, torch.Tensor):
            data_matrix = data_matrix.detach().cpu().numpy()
        if coords is not None and isinstance(coords, torch.Tensor):
            coords = coords.detach().cpu().numpy()
        
        # é©—è­‰åº§æ¨™è¼¸å…¥
        if coords is None:
            raise ValueError(
                "PhysicsGuidedQRPivotSelector éœ€è¦æä¾›ç©ºé–“åº§æ¨™ 'coords' ç”¨æ–¼è¨ˆç®—å£é¢è·é›¢ã€‚"
                "åº§æ¨™æ ¼å¼ï¼š[n_locations, 3] (x, y, z)"
            )
        
        if coords.shape[0] != data_matrix.shape[0]:
            raise ValueError(
                f"åº§æ¨™æ•¸é‡ ({coords.shape[0]}) èˆ‡è³‡æ–™é»æ•¸é‡ ({data_matrix.shape[0]}) ä¸åŒ¹é…"
            )
        
        X = data_matrix.copy()
        n_locations, n_features = X.shape
        
        # æ¨™æº–åŒ–è³‡æ–™ï¼ˆZ-Scoreï¼‰
        X_mean = X.mean(axis=0, keepdims=True)
        X_std = X.std(axis=0, keepdims=True) + 1e-8
        X = (X - X_mean) / X_std
        
        # é™åˆ¶æ„Ÿæ¸¬é»æ•¸é‡
        n_sensors = min(n_sensors, n_locations)
        
        # === æ ¸å¿ƒæ”¹é€²ï¼šç‰©ç†å¼•å°åŠ æ¬Š ===
        
        # 1. è­˜åˆ¥å£é¢å€åŸŸ
        wall_mask = self._identify_wall_region(coords, re_tau)
        self._wall_mask = wall_mask  # è¨˜éŒ„ç”¨æ–¼å¾ŒçºŒçµ±è¨ˆ
        
        # 2. å»ºç«‹ç‰©ç†æ¬Šé‡çŸ©é™£ï¼ˆå°è§’çŸ©é™£ï¼‰
        weights = np.ones(n_locations, dtype=np.float64)
        weights[wall_mask] = self.wall_weight  # å£é¢å€åŸŸæ¬Šé‡æ”¾å¤§
        W = np.diag(weights)
        
        # 3. å° POD æ¨¡æ…‹çŸ©é™£é€²è¡Œç‰©ç†åŠ æ¬Š
        # weighted_modes: [n_locations, n_features]
        # å£é¢é»çš„æ¨¡æ…‹ä¿‚æ•¸è¢«æ”¾å¤§ï¼Œåœ¨ QR-Pivot ä¸­å„ªå…ˆé¸æ“‡
        X_weighted = W @ X
        
        logger.info(
            f"ç‰©ç†å¼•å° QR-Pivot: å£é¢é» {wall_mask.sum()}/{n_locations} "
            f"({100*wall_mask.sum()/n_locations:.1f}%), æ¬Šé‡ {self.wall_weight:.1f}x"
        )
        
        # 4. å°åŠ æ¬ŠçŸ©é™£åŸ·è¡Œ QR-Pivot
        Q = None
        R = None
        try:
            if self.pivoting:
                # å° X_weighted^T åš QR åˆ†è§£
                Q, R, piv = qr(X_weighted.T, mode='economic', pivoting=True)
                selected_indices = piv[:n_sensors]
            else:
                # æ¨™æº– QR åˆ†è§£ï¼ˆä¸æ¨è–¦ï¼ŒåŠ æ¬Šå¾Œä»æ‡‰ä½¿ç”¨ pivotingï¼‰
                Q, R = qr(X_weighted.T if self.mode == 'column' else X_weighted, mode='economic')
                diag_importance = np.abs(np.diag(R))
                selected_indices = np.argsort(diag_importance)[-n_sensors:][::-1]
        
        except np.linalg.LinAlgError as e:
            logger.warning(f"QR åˆ†è§£å¤±æ•—ï¼Œä½¿ç”¨ SVD å›é€€: {e}")
            # å›é€€åˆ° SVD æ–¹æ³•
            U, s, Vt = svd(X_weighted, full_matrices=False)
            importance = np.sum(np.abs(Vt.T) * s, axis=1)
            selected_indices = np.argsort(importance)[-n_sensors:][::-1]
        
        # ç¢ºä¿ç´¢å¼•åœ¨æœ‰æ•ˆç¯„åœå…§
        selected_indices = selected_indices[selected_indices < n_locations]
        selected_indices = selected_indices[:n_sensors]
        
        # 5. è¨ˆç®—å“è³ªæŒ‡æ¨™ï¼ˆä½¿ç”¨åŸå§‹æœªåŠ æ¬ŠçŸ©é™£ï¼‰
        metrics = self._compute_metrics(X, selected_indices)
        
        # 6. æ·»åŠ ç‰©ç†å¼•å°ç‰¹å®šæŒ‡æ¨™
        wall_coverage = wall_mask[selected_indices].sum() / len(selected_indices)
        self._wall_coverage = wall_coverage
        
        physics_metrics = {
            'wall_coverage': float(wall_coverage),  # å£é¢è¦†è“‹ç‡ï¼ˆé¸ä¸­é»ä¸­å£é¢é»çš„æ¯”ä¾‹ï¼‰
            'wall_weight': float(self.wall_weight),
            'wall_threshold': float(self.wall_threshold),
            'threshold_type': self.threshold_type,
            'total_wall_points': int(wall_mask.sum()),
            'selected_wall_points': int(wall_mask[selected_indices].sum()),
        }
        metrics.update(physics_metrics)
        
        result = (selected_indices, metrics)
        if return_qr:
            result = (*result, Q, R)
        
        return result
    
    def _identify_wall_region(self, coords: np.ndarray, re_tau: float) -> np.ndarray:
        """
        è­˜åˆ¥å£é¢å€åŸŸ
        
        Args:
            coords: ç©ºé–“åº§æ¨™ [n_locations, 3] (x, y, z)
            re_tau: æ‘©æ“¦é›·è«¾æ•¸
            
        Returns:
            wall_mask: å¸ƒæ—é™£åˆ— [n_locations]ï¼ŒTrue è¡¨ç¤ºå£é¢å€åŸŸ
        """
        # å‡è¨­é€šé“æµå¹¾ä½•ï¼šy âˆˆ [-h, h]ï¼Œh=1
        # å£é¢ä½æ–¼ y=-1 å’Œ y=1
        y_coords = coords[:, 1]  # æå– y åº§æ¨™
        
        if self.threshold_type == 'y_over_h':
            # ä½¿ç”¨ç„¡å› æ¬¡è·é›¢ y/h
            # è¨ˆç®—åˆ°æœ€è¿‘å£é¢çš„è·é›¢ï¼ˆæ­¸ä¸€åŒ–ï¼‰
            h = 1.0  # é€šé“åŠé«˜
            y_min, y_max = -h, h
            
            # åˆ°ä¸Šä¸‹å£é¢çš„è·é›¢
            dist_to_lower_wall = np.abs(y_coords - y_min)
            dist_to_upper_wall = np.abs(y_coords - y_max)
            dist_to_wall = np.minimum(dist_to_lower_wall, dist_to_upper_wall)
            
            # æ­¸ä¸€åŒ–è·é›¢ (0 åœ¨å£é¢, 1 åœ¨ä¸­å¿ƒ)
            y_over_h = dist_to_wall / h
            
            # å£é¢å€åŸŸï¼šy/h < thresholdï¼ˆä¾‹å¦‚ 0.1 å°æ‡‰ y+ â‰ˆ 100ï¼‰
            wall_mask = y_over_h < self.wall_threshold
            
        elif self.threshold_type == 'y_plus':
            # ä½¿ç”¨å£é¢åº§æ¨™ y+ï¼ˆéœ€è¦æ‘©æ“¦é€Ÿåº¦ u_Ï„ï¼‰
            # JHTDB Channel Flow Re_Ï„=1000:
            #   u_Ï„ = 0.04997
            #   Î½ = 5e-5
            #   Î´_Î½ = Î½/u_Ï„ â‰ˆ 1.0e-3
            
            u_tau = 0.04997  # JHTDB çµ±è¨ˆé‡
            nu = 5.0e-5      # JHTDB é»æ»¯ä¿‚æ•¸
            delta_nu = nu / u_tau  # é»æ€§é•·åº¦å°ºåº¦
            
            # è¨ˆç®—åˆ°æœ€è¿‘å£é¢çš„ç‰©ç†è·é›¢
            h = 1.0
            y_min, y_max = -h, h
            dist_to_lower_wall = np.abs(y_coords - y_min)
            dist_to_upper_wall = np.abs(y_coords - y_max)
            dist_to_wall = np.minimum(dist_to_lower_wall, dist_to_upper_wall)
            
            # å£é¢åº§æ¨™ y+ = y_physical / Î´_Î½
            y_plus = dist_to_wall / delta_nu
            
            # å£é¢å€åŸŸï¼šy+ < thresholdï¼ˆä¾‹å¦‚ 100 å°æ‡‰é»æ€§åº•å±¤ + ç·©è¡å±¤ï¼‰
            wall_mask = y_plus < self.wall_threshold
            
        else:
            raise ValueError(f"æœªçŸ¥çš„å£é¢è­˜åˆ¥é¡å‹: {self.threshold_type}")
        
        return wall_mask
    
    def get_wall_statistics(self) -> Dict[str, Any]:
        """
        ç²å–å£é¢çµ±è¨ˆä¿¡æ¯ï¼ˆéœ€åœ¨ select_sensors å¾Œèª¿ç”¨ï¼‰
        
        Returns:
            çµ±è¨ˆå­—å…¸
        """
        if self._wall_mask is None:
            raise RuntimeError("è«‹å…ˆèª¿ç”¨ select_sensors() æ–¹æ³•")
        
        return {
            'wall_coverage': float(self._wall_coverage),
            'total_wall_points': int(self._wall_mask.sum()),
            'wall_ratio': float(self._wall_mask.sum() / len(self._wall_mask)),
            'wall_weight': float(self.wall_weight),
            'threshold': float(self.wall_threshold),
            'threshold_type': self.threshold_type,
        }
