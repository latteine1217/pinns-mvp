{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒŠ PINNs-MVP å®Œæ•´å°ˆæ¡ˆæŒ‡å—\n",
    "## Physics-Informed Neural Networks for Sparse-Data Turbulent Flow Reconstruction\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š æœ¬ Notebook å…§å®¹æ¦‚è¦½\n",
    "\n",
    "#### Part 1: å°ˆæ¡ˆä»‹ç´¹èˆ‡ç’°å¢ƒè¨­å®š\n",
    "- 1.1 å°ˆæ¡ˆç›®æ¨™èˆ‡æ ¸å¿ƒæŠ€è¡“\n",
    "- 1.2 ç’°å¢ƒæª¢æŸ¥èˆ‡ä¾è³´å®‰è£\n",
    "- 1.3 å°ˆæ¡ˆçµæ§‹å°è¦½\n",
    "\n",
    "#### Part 2: è³‡æ–™æº–å‚™èˆ‡æ¢ç´¢\n",
    "- 2.1 JHTDB è³‡æ–™ä¸‹è¼‰èˆ‡è¼‰å…¥\n",
    "- 2.2 æ„Ÿæ¸¬é»é¸æ“‡ç­–ç•¥ï¼ˆQR-Pivotï¼‰\n",
    "- 2.3 è³‡æ–™è¦–è¦ºåŒ–èˆ‡çµ±è¨ˆåˆ†æ\n",
    "\n",
    "#### Part 3: æ¨¡å‹æ¶æ§‹æ·±å…¥è§£æ\n",
    "- 3.1 Fourier Features åŸç†\n",
    "- 3.2 VS-PINN è®Šæ•¸å°ºåº¦åŒ–\n",
    "- 3.3 ç¶²è·¯æ¶æ§‹è¨­è¨ˆ\n",
    "\n",
    "#### Part 4: è¨“ç·´ç­–ç•¥èˆ‡æŠ€å·§\n",
    "- 4.1 å¿«é€ŸåŸºç·šè¨“ç·´ï¼ˆ100 epochsï¼‰\n",
    "- 4.2 Reynolds æ•¸éå¢ Curriculum\n",
    "- 4.3 GradNorm å‹•æ…‹æ¬Šé‡å¹³è¡¡\n",
    "- 4.4 è¨“ç·´ç›£æ§èˆ‡è¨ºæ–·\n",
    "\n",
    "#### Part 5: è©•ä¼°èˆ‡è¦–è¦ºåŒ–\n",
    "- 5.1 ç‰©ç†ä¸€è‡´æ€§é©—è­‰\n",
    "- 5.2 å ´é‡å»ºèª¤å·®åˆ†æ\n",
    "- 5.3 æ¹æµçµ±è¨ˆé‡å°æ¯”\n",
    "- 5.4 å£é¢å‰ªæ‡‰åŠ›è©•ä¼°\n",
    "\n",
    "#### Part 6: é€²éšå¯¦é©—\n",
    "- 6.1 K-scan å¯¦é©—ï¼ˆæœ€å°‘æ„Ÿæ¸¬é»æ•¸ï¼‰\n",
    "- 6.2 Ablation Studyï¼ˆæ¶ˆèå¯¦é©—ï¼‰\n",
    "- 6.3 Ensemble ä¸ç¢ºå®šæ€§é‡åŒ–\n",
    "\n",
    "#### Part 7: æ•…éšœæ’é™¤èˆ‡æœ€ä½³å¯¦è¸\n",
    "- 7.1 å¸¸è¦‹å•é¡Œè¨ºæ–·\n",
    "- 7.2 æ€§èƒ½å„ªåŒ–å»ºè­°\n",
    "- 7.3 æª¢æŸ¥é»ç®¡ç†\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "å®Œæˆæœ¬ Notebook å¾Œï¼Œæ‚¨å°‡èƒ½å¤ ï¼š\n",
    "- âœ… ç†è§£ PINNs åœ¨ç¨€ç–è³‡æ–™æµå ´é‡å»ºä¸­çš„æ‡‰ç”¨\n",
    "- âœ… æŒæ¡ Fourier Features èˆ‡ VS-PINN çš„æ ¸å¿ƒåŸç†\n",
    "- âœ… åŸ·è¡Œå®Œæ•´çš„è¨“ç·´-è©•ä¼°-è¨ºæ–·æµç¨‹\n",
    "- âœ… åˆ†æä¸¦å„ªåŒ–æ¨¡å‹æ€§èƒ½\n",
    "- âœ… é€²è¡Œå¯é‡ç¾çš„ç§‘ç ”å¯¦é©—\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ é‹è¡Œç’°å¢ƒå»ºè­°\n",
    "\n",
    "| ç’°å¢ƒ | æ¨è–¦é…ç½® | é æœŸæ™‚é–“ |\n",
    "|------|---------|----------|\n",
    "| **æœ¬åœ° GPU** | RTX 3090 / A6000 | 2-4 å°æ™‚ï¼ˆå®Œæ•´è¨“ç·´ï¼‰ |\n",
    "| **Google Colab Pro** | A100 (40GB) | 1-2 å°æ™‚ |\n",
    "| **æœ¬åœ° CPU** | 16 æ ¸å¿ƒä»¥ä¸Š | 12-24 å°æ™‚ |\n",
    "\n",
    "---\n",
    "\n",
    "**æœ€å¾Œæ›´æ–°**: 2025-10-19  \n",
    "**ç‰ˆæœ¬**: v2.0  \n",
    "**ä½œè€…**: PINNs-MVP Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš¡ å¿«é€Ÿé–‹å§‹æŒ‡å—\n",
    "\n",
    "### æ–°ç”¨æˆ¶ï¼ˆç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼‰\n",
    "\n",
    "1. **ç’°å¢ƒè¨­å®š** â†’ åŸ·è¡Œ Part 1.2 çš„æ‰€æœ‰ Cell\n",
    "2. **è³‡æ–™æº–å‚™** â†’ æª¢æŸ¥ Part 2.1 è³‡æ–™æ˜¯å¦å­˜åœ¨\n",
    "3. **å¿«é€Ÿè¨“ç·´** â†’ ä½¿ç”¨ Part 4.1 çš„åŸºç·šé…ç½®ï¼ˆ10 åˆ†é˜ï¼‰\n",
    "4. **çµæœè©•ä¼°** â†’ åƒè€ƒ Part 5.1-5.3\n",
    "\n",
    "### é€²éšç”¨æˆ¶\n",
    "\n",
    "- **Curriculum Learning**: Part 4.2ï¼ˆ2-4 å°æ™‚ï¼Œæœ€ä½³æ€§èƒ½ï¼‰\n",
    "- **GradNorm èª¿å„ª**: Part 4.3ï¼ˆé—œéµåƒæ•¸ alpha=1.5ï¼‰\n",
    "- **Ablation Study**: Part 6.2ï¼ˆé‡åŒ–çµ„ä»¶è²¢ç»ï¼‰\n",
    "- **æ•…éšœè¨ºæ–·**: Part 7.1ï¼ˆå¸¸è¦‹å•é¡Œè§£æ±ºï¼‰\n",
    "\n",
    "### é‡è¦æé†’\n",
    "\n",
    "âš ï¸ **è¨“ç·´å»ºè­°ä½¿ç”¨å‘½ä»¤è¡Œè€Œé Notebook**:\n",
    "```bash\n",
    "python scripts/train.py --cfg configs/my_exp.yml\n",
    "```\n",
    "\n",
    "Notebook ä¸»è¦ç”¨æ–¼ï¼šç†è§£åŸç†ã€è¦–è¦ºåŒ–ã€å¿«é€Ÿé©—è­‰ã€çµæœåˆ†æ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f70563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€Ÿé–‹å§‹è¨“ç·´ï¼ˆå–æ¶ˆè¨»è§£å¾ŒåŸ·è¡Œï¼‰\n",
    "# !python scripts/train.py --cfg configs/my_exp.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: å°ˆæ¡ˆä»‹ç´¹èˆ‡ç’°å¢ƒè¨­å®š\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 å°ˆæ¡ˆç›®æ¨™èˆ‡æ ¸å¿ƒæŠ€è¡“\n",
    "\n",
    "### ğŸ¯ ç ”ç©¶å•é¡Œ\n",
    "\n",
    "**æŒ‘æˆ°**: å¦‚ä½•å¾æ¥µç¨€ç–çš„æ„Ÿæ¸¬é»è³‡æ–™ï¼ˆK â‰¤ 50-500 é»ï¼‰é‡å»ºå®Œæ•´çš„ 3D æ¹æµå ´ï¼Ÿ\n",
    "\n",
    "**å‚³çµ±æ–¹æ³•çš„é™åˆ¶**:\n",
    "- æ’å€¼æ–¹æ³•ï¼šç„¡æ³•æ•æ‰æ¹æµå°å°ºåº¦çµæ§‹\n",
    "- è³‡æ–™åŒåŒ–ï¼šéœ€è¦èƒŒæ™¯å ´ä¸”è¨ˆç®—æ˜‚è²´\n",
    "- ç´”æ•¸æ“šé©…å‹•ï¼šç¨€ç–è³‡æ–™ä¸‹åš´é‡éæ“¬åˆ\n",
    "\n",
    "**æˆ‘å€‘çš„è§£æ±ºæ–¹æ¡ˆ**: **Physics-Informed Neural Networks (PINNs)**\n",
    "\n",
    "### ğŸ”¬ æ ¸å¿ƒæŠ€è¡“æ£§\n",
    "\n",
    "#### 1. **Fourier Features (Ïƒ=2-5)**\n",
    "```python\n",
    "# å¼·åŒ–é«˜é »çµæ§‹æ•æ‰èƒ½åŠ›\n",
    "z = 2Ï€ * x @ B  # B ~ N(0, ÏƒÂ²)\n",
    "Ï†(x) = [cos(z), sin(z)]\n",
    "```\n",
    "**ä½œç”¨**: æ•æ‰å£é¢é‚Šç•Œå±¤é«˜é »æ¢¯åº¦ï¼ˆdu/dy|_wall â‰ˆ 1000ï¼‰\n",
    "\n",
    "#### 2. **VS-PINN è®Šæ•¸å°ºåº¦åŒ–**\n",
    "```python\n",
    "# é‡å°å„å‘ç•°æ€§æµå ´å„ªåŒ–\n",
    "(X, Y, Z) = (N_xÂ·x, N_yÂ·y, N_zÂ·z)\n",
    "# å£æ³•å‘ N_y=12.0 > æµå‘ N_x=2.0\n",
    "```\n",
    "**ä½œç”¨**: å¹³è¡¡å„æ–¹å‘çš„æ¢¯åº¦å°ºåº¦ï¼Œç©©å®šè¨“ç·´\n",
    "\n",
    "#### 3. **GradNorm å‹•æ…‹æ¬Šé‡**\n",
    "```python\n",
    "# è‡ªå‹•å¹³è¡¡å¤šæå¤±é …\n",
    "Î»_i â† Î»_i * (G_i / G_avg)^(-alpha)\n",
    "# alpha=1.5, æ¯ 1000 æ­¥æ›´æ–°\n",
    "```\n",
    "**ä½œç”¨**: ç¢ºä¿ PDE Loss Ratio â‰¥ 30%\n",
    "\n",
    "#### 4. **Reynolds æ•¸éå¢ Curriculum**\n",
    "```python\n",
    "# å¾ä½ Re_tau é€æ­¥åˆ°é«˜ Re_tau\n",
    "Re_tau: 500 â†’ 750 â†’ 1000\n",
    "```\n",
    "**ä½œç”¨**: é¿å…é«˜ Re ç›´æ¥è¨“ç·´çš„æ•¸å€¼ä¸ç©©å®š\n",
    "\n",
    "### ğŸ—‚ï¸ è³‡æ–™é›†\n",
    "\n",
    "**Johns Hopkins Turbulence Database (JHTDB)**\n",
    "- **æµå ´**: Channel Flow Re_Ï„=1000\n",
    "- **è§£æåº¦**: 2048Ã—512Ã—1536 (wavemodes)\n",
    "- **åŸŸå¤§å°**: (L_x, L_y, L_z) = (8Ï€h Ã— 2h Ã— 3Ï€h), h=1\n",
    "- **è®Šæ•¸**: [u, v, w, p] (é€Ÿåº¦ + å£“åŠ›)\n",
    "\n",
    "### ğŸ“– åƒè€ƒæ–‡ç»\n",
    "\n",
    "1. Tancik et al. (2020) - *Fourier Features Let Networks Learn High Frequency Functions*\n",
    "2. Chen et al. (2018) - *GradNorm: Gradient Normalization for Adaptive Loss Balancing*\n",
    "3. VS-PINN (arXiv:2308.08468) - *Variable-Scaling Physics-Informed Neural Networks*\n",
    "4. Raissi et al. (2019) - *Physics-informed neural networks: A deep learning framework*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 ç’°å¢ƒæª¢æŸ¥èˆ‡ä¾è³´å®‰è£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥ Python ç‰ˆæœ¬\n",
    "import sys\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "assert sys.version_info >= (3, 10), \"âŒ éœ€è¦ Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬\"\n",
    "print(\"âœ… Python ç‰ˆæœ¬ç¬¦åˆéœ€æ±‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥ PyTorch èˆ‡ GPU\n",
    "import torch\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU è¨­å‚™: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"ä½¿ç”¨ Apple Silicon MPS\")\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    print(\"âš ï¸ åƒ… CPU å¯ç”¨ï¼Œè¨“ç·´é€Ÿåº¦æœƒè¼ƒæ…¢\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\nâœ… ä½¿ç”¨è¨­å‚™: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£ä¾è³´ï¼ˆå¦‚éœ€è¦ï¼‰\n",
    "# å–æ¶ˆè¨»é‡‹ä»¥ä¸‹è¡Œä¾†å®‰è£ç¼ºå¤±çš„å¥—ä»¶\n",
    "\n",
    "# !pip install pyyaml h5py scipy matplotlib seaborn tensorboard\n",
    "# !pip install netCDF4  # ç”¨æ–¼ RANS ä½ä¿çœŸå ´ï¼ˆå¯é¸ï¼‰\n",
    "\n",
    "# é©—è­‰é—œéµå¥—ä»¶\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰é—œéµä¾è³´å·²å®‰è£\")\n",
    "print(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")\n",
    "print(f\"Matplotlib ç‰ˆæœ¬: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9ac31",
   "metadata": {},
   "source": [
    "### åœ¨ Google Colab æ›è¼‰ Google Drive\n",
    "\n",
    "è‹¥åœ¨ Colab åŸ·è¡Œ Notebookï¼Œè«‹å…ˆæ›è¼‰ Drive ä»¥è®€å¯« `pinns-mvp` å°ˆæ¡ˆèˆ‡è³‡æ–™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a34d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ Google Colab æ›è¼‰ Google Drive ä¸¦åˆ‡æ›åˆ°å°ˆæ¡ˆè³‡æ–™å¤¾\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Google Colab æœªå®‰è£ï¼Œç•¥éæ›è¼‰æ­¥é©Ÿã€‚\")\n",
    "else:\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    %cd /content/drive/MyDrive/pinns-mvp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 å°ˆæ¡ˆçµæ§‹å°è¦½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥å°ˆæ¡ˆçµæ§‹\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# å¦‚æœåœ¨ Colabï¼Œéœ€è¦å…ˆåˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„\n",
    "# %cd /content/pinns-mvp\n",
    "\n",
    "project_root = Path.cwd()\n",
    "print(f\"å°ˆæ¡ˆæ ¹ç›®éŒ„: {project_root}\\n\")\n",
    "\n",
    "# æª¢æŸ¥é—œéµç›®éŒ„\n",
    "key_dirs = {\n",
    "    'pinnx': 'æ ¸å¿ƒæ¡†æ¶ï¼ˆæ¨¡å‹ã€ç‰©ç†ã€è¨“ç·´ï¼‰',\n",
    "    'configs': 'é…ç½®æ–‡ä»¶ç¯„ä¾‹',\n",
    "    'scripts': 'è¨“ç·´èˆ‡è©•ä¼°è…³æœ¬',\n",
    "    'tests': 'å–®å…ƒæ¸¬è©¦',\n",
    "    'data': 'è³‡æ–™ç›®éŒ„ï¼ˆJHTDB æ„Ÿæ¸¬é»ï¼‰',\n",
    "    'docs': 'æ–‡æª”èˆ‡æŒ‡å—',\n",
    "}\n",
    "\n",
    "for dir_name, desc in key_dirs.items():\n",
    "    dir_path = project_root / dir_name\n",
    "    status = 'âœ…' if dir_path.exists() else 'âŒ'\n",
    "    print(f\"{status} {dir_name:15s} - {desc}\")\n",
    "\n",
    "# åˆ—å‡ºæ¨¡æ¿é…ç½®\n",
    "template_dir = project_root / 'configs' / 'templates'\n",
    "if template_dir.exists():\n",
    "    print(f\"\\nğŸ“ å¯ç”¨é…ç½®æ¨¡æ¿:\")\n",
    "    for yml_file in sorted(template_dir.glob('*.yml')):\n",
    "        print(f\"   - {yml_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å°ˆæ¡ˆæ¶æ§‹èªªæ˜\n",
    "\n",
    "```\n",
    "pinns-mvp/\n",
    "â”œâ”€â”€ pinnx/                    # æ ¸å¿ƒæ¡†æ¶\n",
    "â”‚   â”œâ”€â”€ models/              # FourierMLP, SIREN, Wrappers\n",
    "â”‚   â”œâ”€â”€ physics/             # NS Equations, VS-PINN, RANS\n",
    "â”‚   â”œâ”€â”€ losses/              # GradNorm, Residuals, Priors\n",
    "â”‚   â”œâ”€â”€ sensors/             # QR-Pivot, Stratified Sampling\n",
    "â”‚   â”œâ”€â”€ train/               # Trainer, Factory, Config Loader\n",
    "â”‚   â””â”€â”€ utils/               # Normalization, Denormalization\n",
    "â”‚\n",
    "â”œâ”€â”€ configs/\n",
    "â”‚   â”œâ”€â”€ templates/           # æ¨™æº–åŒ–é…ç½®ç¯„ä¾‹\n",
    "â”‚   â”‚   â”œâ”€â”€ 2d_quick_baseline.yml\n",
    "â”‚   â”‚   â”œâ”€â”€ 2d_medium_ablation.yml\n",
    "â”‚   â”‚   â”œâ”€â”€ 3d_slab_curriculum.yml\n",
    "â”‚   â”‚   â””â”€â”€ 3d_full_production.yml\n",
    "â”‚   â””â”€â”€ main.yml             # ä¸»é…ç½®æ–‡ä»¶\n",
    "â”‚\n",
    "â”œâ”€â”€ scripts/\n",
    "â”‚   â”œâ”€â”€ train.py             # ä¸»è¨“ç·´è…³æœ¬\n",
    "â”‚   â”œâ”€â”€ evaluate_checkpoint.py\n",
    "â”‚   â””â”€â”€ comprehensive_evaluation.py\n",
    "â”‚\n",
    "â”œâ”€â”€ data/jhtdb/              # JHTDB è³‡æ–™\n",
    "â”‚   â”œâ”€â”€ sensors_K500.npz     # QR-Pivot æ„Ÿæ¸¬é»\n",
    "â”‚   â””â”€â”€ channel_flow_re1000/ # å®Œæ•´æµå ´è³‡æ–™\n",
    "â”‚\n",
    "â””â”€â”€ docs/                    # å°ˆæ¡ˆæ–‡æª”\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: è³‡æ–™æº–å‚™èˆ‡æ¢ç´¢\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 JHTDB è³‡æ–™ä¸‹è¼‰èˆ‡è¼‰å…¥\n",
    "\n",
    "### é¸é … A: ä½¿ç”¨é ç”Ÿæˆçš„æ„Ÿæ¸¬é»è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥é ç”Ÿæˆçš„ K=500 æ„Ÿæ¸¬é»è³‡æ–™\n",
    "data_path = 'data/jhtdb/sensors_K500.npz'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    data = np.load(data_path)\n",
    "    \n",
    "    print(\"âœ… è³‡æ–™è¼‰å…¥æˆåŠŸ\\n\")\n",
    "    print(f\"æ„Ÿæ¸¬é»æ•¸é‡: {data['K']}\")\n",
    "    print(f\"åº§æ¨™å½¢ç‹€: {data['sensor_coords'].shape}\")\n",
    "    print(f\"å ´å€¼å½¢ç‹€: {data['sensor_values'].shape}\")\n",
    "    print(f\"\\nè®Šæ•¸é †åº: {list(data['variable_names'])}\")\n",
    "    print(f\"\\nåŸŸé‚Šç•Œ:\")\n",
    "    print(f\"  x âˆˆ [{data['domain_bounds']['x'][0]:.2f}, {data['domain_bounds']['x'][1]:.2f}]\")\n",
    "    print(f\"  y âˆˆ [{data['domain_bounds']['y'][0]:.2f}, {data['domain_bounds']['y'][1]:.2f}]\")\n",
    "    print(f\"  z âˆˆ [{data['domain_bounds']['z'][0]:.2f}, {data['domain_bounds']['z'][1]:.2f}]\")\n",
    "    \n",
    "    # æå–è³‡æ–™\n",
    "    sensor_coords = data['sensor_coords']\n",
    "    sensor_values = data['sensor_values']\n",
    "    K = int(data['K'])\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ è³‡æ–™æ–‡ä»¶ä¸å­˜åœ¨: {data_path}\")\n",
    "    print(\"è«‹åƒè€ƒ Part 2.1 é¸é … B æˆ– C ç”Ÿæˆè³‡æ–™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é¸é … B: å¾ JHTDB API å‹•æ…‹ä¸‹è¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¾ JHTDB ä¸‹è¼‰è³‡æ–™ï¼ˆéœ€è¦ç¶²è·¯é€£æ¥èˆ‡æˆæ¬Šï¼‰\n",
    "# å–æ¶ˆè¨»é‡‹ä»¥ä¸‹ä»£ç¢¼ä»¥åŸ·è¡Œ\n",
    "\n",
    "# from pinnx.dataio.jhtdb_client import create_jhtdb_manager\n",
    "# from pinnx.sensors.qr_pivot import qr_pivot_sensor_selection\n",
    "\n",
    "# # è¨­å®šåƒæ•¸\n",
    "# K = 50  # æ„Ÿæ¸¬é»æ•¸é‡\n",
    "# time = 0.0  # æ™‚é–“é»\n",
    "\n",
    "# # å‰µå»º JHTDB ç®¡ç†å™¨\n",
    "# manager = create_jhtdb_manager()\n",
    "\n",
    "# # å®šç¾©æ„Ÿæ¸¬é»ä½ç½®ï¼ˆå‡å‹»åˆ†ä½ˆï¼‰\n",
    "# x = np.linspace(0, 25.13, 50)\n",
    "# y = np.linspace(-1.0, 1.0, 20)\n",
    "# z = np.linspace(0, 9.42, 30)\n",
    "# X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n",
    "# all_coords = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)\n",
    "\n",
    "# # QR-Pivot é¸æ“‡æœ€å„ªæ„Ÿæ¸¬é»\n",
    "# sensor_indices = qr_pivot_sensor_selection(all_coords, K=K)\n",
    "# sensor_coords = all_coords[sensor_indices]\n",
    "\n",
    "# # å¾ JHTDB ç²å–å ´å€¼\n",
    "# velocity = manager.get_velocity(sensor_coords[:, 0], sensor_coords[:, 1], sensor_coords[:, 2], time)\n",
    "# pressure = manager.get_pressure(sensor_coords[:, 0], sensor_coords[:, 1], sensor_coords[:, 2], time)\n",
    "\n",
    "# sensor_values = np.concatenate([velocity, pressure.reshape(-1, 1)], axis=1)\n",
    "# print(f\"âœ… å¾ JHTDB ä¸‹è¼‰ {K} å€‹æ„Ÿæ¸¬é»è³‡æ–™å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 æ„Ÿæ¸¬é»é¸æ“‡ç­–ç•¥ï¼ˆQR-Pivotï¼‰\n",
    "\n",
    "### QR-Pivot åŸç†\n",
    "\n",
    "**ç›®æ¨™**: å¾ N å€‹å€™é¸é»ä¸­é¸æ“‡ K å€‹æœ€å…·è³‡è¨Šé‡çš„æ„Ÿæ¸¬é»\n",
    "\n",
    "**æ–¹æ³•**: QR åˆ†è§£çš„åˆ—ä¸»å…ƒç­–ç•¥\n",
    "```\n",
    "1. æ§‹å»ºè§€æ¸¬çŸ©é™£ Î¦ âˆˆ R^{NÃ—M}ï¼ˆFourier ç‰¹å¾µï¼‰\n",
    "2. QR åˆ†è§£: Î¦ @ P = Q @ Rï¼ˆP ç‚ºç½®æ›çŸ©é™£ï¼‰\n",
    "3. é¸æ“‡å‰ K å€‹åˆ—ä¸»å…ƒå°æ‡‰çš„åº§æ¨™\n",
    "```\n",
    "\n",
    "**å„ªå‹¢**:\n",
    "- âœ… æœ€å¤§åŒ–è§€æ¸¬çŸ©é™£çš„æ¢ä»¶æ•¸ï¼ˆé™ä½é‡å»ºèª¤å·®ï¼‰\n",
    "- âœ… ä¿è­‰ç©ºé–“è¦†è“‹ç‡ï¼ˆé¿å…èšé›†ï¼‰\n",
    "- âœ… è¨ˆç®—æ•ˆç‡é«˜ï¼ˆO(NMÂ²)ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ– QR-Pivot é¸æ“‡çš„æ„Ÿæ¸¬é»åˆ†ä½ˆ\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 3D åˆ†ä½ˆ\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(sensor_coords[:, 0], sensor_coords[:, 1], sensor_coords[:, 2], \n",
    "            c=sensor_values[:, 0], cmap='RdBu_r', s=50, alpha=0.6)\n",
    "ax1.set_xlabel('x (streamwise)')\n",
    "ax1.set_ylabel('y (wall-normal)')\n",
    "ax1.set_zlabel('z (spanwise)')\n",
    "ax1.set_title(f'QR-Pivot æ„Ÿæ¸¬é»åˆ†ä½ˆ (K={K})')\n",
    "\n",
    "# x-y å¹³é¢æŠ•å½±\n",
    "ax2 = fig.add_subplot(132)\n",
    "sc = ax2.scatter(sensor_coords[:, 0], sensor_coords[:, 1], \n",
    "                 c=sensor_values[:, 0], cmap='RdBu_r', s=100, alpha=0.7, edgecolors='k')\n",
    "ax2.set_xlabel('x (streamwise)')\n",
    "ax2.set_ylabel('y (wall-normal)')\n",
    "ax2.set_title('x-y å¹³é¢æŠ•å½±')\n",
    "ax2.axhline(y=-1.0, color='r', linestyle='--', label='å£é¢')\n",
    "ax2.axhline(y=1.0, color='r', linestyle='--')\n",
    "ax2.legend()\n",
    "plt.colorbar(sc, ax=ax2, label='u é€Ÿåº¦')\n",
    "\n",
    "# y æ–¹å‘åˆ†ä½ˆç›´æ–¹åœ–\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.hist(sensor_coords[:, 1], bins=20, alpha=0.7, edgecolor='k')\n",
    "ax3.set_xlabel('y (wall-normal)')\n",
    "ax3.set_ylabel('æ„Ÿæ¸¬é»æ•¸é‡')\n",
    "ax3.set_title('å£æ³•å‘åˆ†ä½ˆ')\n",
    "ax3.axvline(x=-1.0, color='r', linestyle='--', label='å£é¢')\n",
    "ax3.axvline(x=1.0, color='r', linestyle='--')\n",
    "ax3.axvline(x=0.0, color='g', linestyle='--', label='ä¸­å¿ƒç·š')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ“Š å£æ³•å‘åˆ†ä½ˆçµ±è¨ˆ:\")\n",
    "print(f\"  å£é¢é™„è¿‘ (|y| > 0.8): {np.sum(np.abs(sensor_coords[:, 1]) > 0.8)} é» ({np.sum(np.abs(sensor_coords[:, 1]) > 0.8)/K*100:.1f}%)\")\n",
    "print(f\"  ä¸­å¿ƒå€åŸŸ (|y| < 0.5): {np.sum(np.abs(sensor_coords[:, 1]) < 0.5)} é» ({np.sum(np.abs(sensor_coords[:, 1]) < 0.5)/K*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 è³‡æ–™è¦–è¦ºåŒ–èˆ‡çµ±è¨ˆåˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±è¨ˆåˆ†æ\n",
    "import pandas as pd\n",
    "\n",
    "# å‰µå»º DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'x': sensor_coords[:, 0],\n",
    "    'y': sensor_coords[:, 1],\n",
    "    'z': sensor_coords[:, 2],\n",
    "    'u': sensor_values[:, 0],\n",
    "    'v': sensor_values[:, 1],\n",
    "    'w': sensor_values[:, 2],\n",
    "    'p': sensor_values[:, 3]\n",
    "})\n",
    "\n",
    "print(\"ğŸ“Š å ´è®Šé‡çµ±è¨ˆæ‘˜è¦:\\n\")\n",
    "print(df[['u', 'v', 'w', 'p']].describe())\n",
    "\n",
    "# è¦–è¦ºåŒ–åˆ†ä½ˆ\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for idx, var in enumerate(['u', 'v', 'w', 'p']):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # ç›´æ–¹åœ– + KDE\n",
    "    ax.hist(df[var], bins=30, alpha=0.6, density=True, edgecolor='k', label='ç›´æ–¹åœ–')\n",
    "    \n",
    "    # çµ±è¨ˆè³‡è¨Š\n",
    "    mean = df[var].mean()\n",
    "    std = df[var].std()\n",
    "    ax.axvline(mean, color='r', linestyle='--', linewidth=2, label=f'å‡å€¼={mean:.3f}')\n",
    "    ax.axvline(mean + std, color='orange', linestyle=':', label=f'Â±1Ïƒ')\n",
    "    ax.axvline(mean - std, color='orange', linestyle=':')\n",
    "    \n",
    "    ax.set_xlabel(f'{var} å€¼')\n",
    "    ax.set_ylabel('å¯†åº¦')\n",
    "    ax.set_title(f'{var} åˆ†ä½ˆ (mean={mean:.3f}, std={std:.3f})')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: æ¨¡å‹æ¶æ§‹æ·±å…¥è§£æ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 å ´é‡å»ºèª¤å·®åˆ†æ\n",
    "\n",
    "### è©•ä¼°æŒ‡æ¨™\n",
    "\n",
    "1. **Relative L2 Error**:\n",
    "   $$\\text{L2}(f) = \\frac{\\|f_{\\text{pred}} - f_{\\text{true}}\\|_2}{\\|f_{\\text{true}}\\|_2}$$\n",
    "\n",
    "2. **Point-wise RMSE**:\n",
    "   $$\\text{RMSE}(f) = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N (f_{\\text{pred},i} - f_{\\text{true},i})^2}$$\n",
    "\n",
    "3. **Spectrum Error** (é »åŸŸåˆ†æ):\n",
    "   $$\\text{Spectrum RMSE} = \\frac{\\|\\hat{f}_{\\text{pred}} - \\hat{f}_{\\text{true}}\\|_2}{\\|\\hat{f}_{\\text{true}}\\|_2}$$\n",
    "\n",
    "### è©•ä¼°å‘½ä»¤\n",
    "\n",
    "```bash\n",
    "# è©•ä¼°æª¢æŸ¥é»\n",
    "python scripts/evaluate_checkpoint.py \\\n",
    "    --checkpoint checkpoints/my_exp/best_model.pth \\\n",
    "    --config configs/my_exp.yml\n",
    "\n",
    "# ç¶œåˆè©•ä¼°\n",
    "python scripts/comprehensive_evaluation.py \\\n",
    "    --checkpoint checkpoints/my_exp/best_model.pth\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdcfba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥é»èˆ‡ç¶œåˆè©•ä¼°ï¼ˆå–æ¶ˆè¨»è§£å¾ŒåŸ·è¡Œï¼‰\n",
    "# !python scripts/evaluate_checkpoint.py --checkpoint checkpoints/my_exp/best_model.pth --config configs/my_exp.yml\n",
    "# !python scripts/comprehensive_evaluation.py --checkpoint checkpoints/my_exp/best_model.pth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 æ¹æµçµ±è¨ˆé‡å°æ¯”\n",
    "\n",
    "### é—œéµçµ±è¨ˆé‡\n",
    "\n",
    "1. **å¹³å‡é€Ÿåº¦å‰–é¢** (Mean Velocity Profile):\n",
    "   $$\\langle u \\rangle(y) = \\frac{1}{L_x L_z} \\int_0^{L_x} \\int_0^{L_z} u(x,y,z) \\, dx \\, dz$$\n",
    "\n",
    "2. **Reynolds æ‡‰åŠ›** (Reynolds Stress):\n",
    "   $$\\langle u'v' \\rangle, \\langle u'u' \\rangle, \\langle v'v' \\rangle, \\langle w'w' \\rangle$$\n",
    "\n",
    "3. **æ¹å‹•èƒ½** (Turbulent Kinetic Energy):\n",
    "   $$k = \\frac{1}{2}(\\langle u'^2 \\rangle + \\langle v'^2 \\rangle + \\langle w'^2 \\rangle)$$\n",
    "\n",
    "### æˆåŠŸæ¨™æº–\n",
    "\n",
    "- Mean profile correlation > 0.95\n",
    "- Reynolds stress relative error < 30%\n",
    "- TKE relative error < 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: é€²éšå¯¦é©—\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 K-scan å¯¦é©—ï¼ˆæœ€å°‘æ„Ÿæ¸¬é»æ•¸ï¼‰\n",
    "\n",
    "### ç›®æ¨™\n",
    "\n",
    "æ‰¾åˆ°ç¶­æŒé‡å»ºç²¾åº¦çš„**æœ€å°æ„Ÿæ¸¬é»æ•¸** K_minã€‚\n",
    "\n",
    "### å¯¦é©—è¨­è¨ˆ\n",
    "\n",
    "æ¸¬è©¦ K âˆˆ {50, 100, 200, 500, 1000}:\n",
    "\n",
    "```yaml\n",
    "sensors:\n",
    "  K: 50  # ä¿®æ”¹æ­¤åƒæ•¸\n",
    "  selection_method: \"qr_pivot\"\n",
    "```\n",
    "\n",
    "### é æœŸçµæœï¼ˆåŸºæ–¼æ–‡ç»ï¼‰\n",
    "\n",
    "| K | Relative L2 | Wall Ï„ Error | å‚™è¨» |\n",
    "|---|-------------|--------------|------|\n",
    "| 50 | ~50% | ~60% | æ¬ æ¡æ¨£ |\n",
    "| 100 | ~35% | ~40% | å¯æ¥å— |\n",
    "| 200 | ~28% | ~25% | æ¨è–¦ |\n",
    "| 500 | ~22% | ~18% | å„ªè‰¯ |\n",
    "| 1000 | ~18% | ~15% | æœ€ä½³ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Ablation Studyï¼ˆæ¶ˆèå¯¦é©—ï¼‰\n",
    "\n",
    "### ç›®çš„\n",
    "\n",
    "é‡åŒ–å„çµ„ä»¶çš„è²¢ç»ï¼š\n",
    "\n",
    "1. **Fourier Features** (on/off)\n",
    "2. **VS-PINN Scaling** (on/off)\n",
    "3. **GradNorm** (on/off)\n",
    "4. **Curriculum Learning** (single-stage vs multi-stage)\n",
    "\n",
    "### ç¤ºä¾‹é…ç½®\n",
    "\n",
    "```yaml\n",
    "# Baseline: ç„¡ Fourier\n",
    "model:\n",
    "  use_fourier: false\n",
    "\n",
    "# vs\n",
    "\n",
    "# Enhanced: æœ‰ Fourier\n",
    "model:\n",
    "  use_fourier: true\n",
    "  fourier_m: 64\n",
    "  fourier_sigma: 3.0\n",
    "```\n",
    "\n",
    "### é æœŸæ”¹å–„\n",
    "\n",
    "| çµ„ä»¶ | L2 Error æ”¹å–„ | åŸå›  |\n",
    "|------|--------------|------|\n",
    "| Fourier Features | -15% | é«˜é »æ•æ‰ |\n",
    "| VS-PINN | -20% | æ¢¯åº¦å¹³è¡¡ |\n",
    "| GradNorm | -25% | å¤šç›®æ¨™å„ªåŒ– |\n",
    "| Curriculum | -30% | ç©©å®šæ”¶æ–‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: æ•…éšœæ’é™¤èˆ‡æœ€ä½³å¯¦è¸\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 å¸¸è¦‹å•é¡Œè¨ºæ–·è¡¨\n",
    "\n",
    "| ç—‡ç‹€ | å¯èƒ½åŸå›  | è§£æ±ºæ–¹æ¡ˆ |\n",
    "|------|---------|----------|\n",
    "| Loss â†’ NaN | å­¸ç¿’ç‡éé«˜ | é™ä½ lr æˆ–å•Ÿç”¨æ¢¯åº¦è£å‰ª |\n",
    "| PDE Ratio < 10% | GradNorm alpha å¤ªå° | æå‡è‡³ 1.5 |\n",
    "| Ï„_w â‰ˆ 0 | å£é¢æ¬Šé‡ä¸è¶³ | å¢åŠ  wall_constraint_weight |\n",
    "| éæ“¬åˆæ„Ÿæ¸¬é» | Data weight éå¤§ | é™ä½ data_weight æˆ–å¢åŠ  PDE weight |\n",
    "| è¨“ç·´ç·©æ…¢ | æ‰¹æ¬¡å¤§å°å¤ªå° | å¢åŠ  batch_size (4096-8192) |\n",
    "| è¨˜æ†¶é«”ä¸è¶³ | æ¨¡å‹å¤ªå¤§æˆ–æ‰¹æ¬¡éå¤§ | æ¸›å° width/depth æˆ–æ‰¹æ¬¡ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 æ€§èƒ½å„ªåŒ–å»ºè­°\n",
    "\n",
    "### 1. ç¡¬é«”åŠ é€Ÿ\n",
    "\n",
    "```yaml\n",
    "training:\n",
    "  use_amp: true  # è‡ªå‹•æ··åˆç²¾åº¦ï¼ˆç¯€çœ 40% è¨˜æ†¶é«”ï¼‰\n",
    "  device: \"auto\"  # è‡ªå‹•é¸æ“‡ GPU/MPS\n",
    "```\n",
    "\n",
    "### 2. æ•¸æ“šä¸¦è¡Œï¼ˆå¤š GPUï¼‰\n",
    "\n",
    "```bash\n",
    "# ä½¿ç”¨ PyTorch DistributedDataParallel\n",
    "python -m torch.distributed.launch --nproc_per_node=2 scripts/train.py --cfg configs/my_exp.yml\n",
    "```\n",
    "\n",
    "### 3. æ¢¯åº¦æª¢æŸ¥é»ï¼ˆç¯€çœè¨˜æ†¶é«”ï¼‰\n",
    "\n",
    "```yaml\n",
    "physics:\n",
    "  use_gradient_checkpointing: false  # âš ï¸ PINNs ä¸å»ºè­°å•Ÿç”¨\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 æª¢æŸ¥é»ç®¡ç†\n",
    "\n",
    "### ä¿å­˜ç­–ç•¥\n",
    "\n",
    "```yaml\n",
    "logging:\n",
    "  save_freq: 200  # æ¯ 200 epoch ä¿å­˜\n",
    "  save_stage_checkpoints: true  # Curriculum éšæ®µçµæŸä¿å­˜\n",
    "```\n",
    "\n",
    "### æ¢å¾©è¨“ç·´\n",
    "\n",
    "```bash\n",
    "# å¾æª¢æŸ¥é»æ¢å¾©\n",
    "python scripts/train.py --cfg configs/my_exp.yml --resume checkpoints/my_exp/epoch_800.pth\n",
    "```\n",
    "\n",
    "### æª¢æŸ¥é»å…§å®¹\n",
    "\n",
    "- `model_state_dict`: æ¨¡å‹åƒæ•¸\n",
    "- `optimizer_state_dict`: å„ªåŒ–å™¨ç‹€æ…‹\n",
    "- `normalizer_stats`: æ­¸ä¸€åŒ–çµ±è¨ˆé‡\n",
    "- `training_history`: è¨“ç·´æ­·å²\n",
    "- `config`: å®Œæ•´é…ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… å®Œæˆï¼\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å»ºè­°\n",
    "\n",
    "1. **å¿«é€Ÿé©—è­‰**: é‹è¡Œ `configs/templates/2d_quick_baseline.yml` (10 åˆ†é˜)\n",
    "2. **å®Œæ•´è¨“ç·´**: å˜—è©¦ `configs/templates/curriculum_reynolds_ramp.yml` (2-4 å°æ™‚)\n",
    "3. **é€²éšå¯¦é©—**: K-scan æˆ– Ablation Study\n",
    "4. **è«–æ–‡è¤‡ç¾**: åƒè€ƒ `TECHNICAL_DOCUMENTATION.md`\n",
    "\n",
    "### ç›¸é—œè³‡æº\n",
    "\n",
    "- **AGENTS.md**: å®Œæ•´å°ˆæ¡ˆæŒ‡å—\n",
    "- **docs/TRAINING_STABILIZATION_STRATEGIES.md**: è¨“ç·´ç­–ç•¥è©³è§£\n",
    "- **docs/**: æ‰€æœ‰æŠ€è¡“æ–‡æª”\n",
    "\n",
    "---\n",
    "\n",
    "**ç¥è¨“ç·´é †åˆ©ï¼ ğŸš€**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 è¨“ç·´ç›£æ§èˆ‡è¨ºæ–·\n",
    "\n",
    "### é—œéµæŒ‡æ¨™\n",
    "\n",
    "è¨“ç·´éç¨‹ä¸­éœ€è¦ç›£æ§ä»¥ä¸‹æŒ‡æ¨™ï¼š\n",
    "\n",
    "| æŒ‡æ¨™ | ç›®æ¨™å€¼ | è¨ºæ–·æ„ç¾© |\n",
    "|------|--------|----------|\n",
    "| **PDE Loss Ratio** | **â‰¥ 30%** | ç‰©ç†ç´„æŸåŸ·è¡Œå¼·åº¦ |\n",
    "| **Wall Shear Stress** | **> 0.0005** | å£é¢æ¢ä»¶æ»¿è¶³ï¼ˆç†è«–å€¼ 0.0025ï¼‰ |\n",
    "| **Mass Conservation** | **< 1%** | é€£çºŒæ€§æ–¹ç¨‹èª¤å·® |\n",
    "| **L2 Error** | **< 30%** | é‡å»ºç²¾åº¦ |\n",
    "| **Training Loss** | ç©©å®šä¸‹é™ | æ”¶æ–‚æ€§ |\n",
    "\n",
    "### æ•…éšœè¨ºæ–·æµç¨‹\n",
    "\n",
    "```bash\n",
    "# ä½¿ç”¨è¨ºæ–·å·¥å…·\n",
    "python scripts/debug/diagnose_piratenet_failure.py \\\n",
    "    --checkpoint checkpoints/my_exp/epoch_X.pth \\\n",
    "    --config configs/my_exp.yml \\\n",
    "    --output results/diagnosis/\n",
    "```\n",
    "\n",
    "**å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ**:\n",
    "\n",
    "1. **PDE Loss Ratio < 10%**\n",
    "   - **åŸå› **: GradNorm alpha å¤ªå°\n",
    "   - **è§£æ±º**: æå‡ alpha è‡³ 1.5\n",
    "\n",
    "2. **Wall Shear Stress â‰ˆ 0**\n",
    "   - **åŸå› **: å£é¢ç´„æŸæ¬Šé‡ä¸è¶³\n",
    "   - **è§£æ±º**: å¢åŠ  `wall_constraint_weight` è‡³ 10-15\n",
    "\n",
    "3. **Loss è®Šæˆ NaN**\n",
    "   - **åŸå› **: å­¸ç¿’ç‡éé«˜æˆ–æ¢¯åº¦çˆ†ç‚¸\n",
    "   - **è§£æ±º**: å•Ÿç”¨æ¢¯åº¦è£å‰ª `gradient_clip_val: 1.0`\n",
    "\n",
    "---\n",
    "\n",
    "# Part 5: è©•ä¼°èˆ‡è¦–è¦ºåŒ–\n",
    "\n",
    "---\n",
    "\n",
    "## 5.1 ç‰©ç†ä¸€è‡´æ€§é©—è­‰\n",
    "\n",
    "### é©—è­‰é …ç›®\n",
    "\n",
    "1. **è³ªé‡å®ˆæ†** (é€£çºŒæ€§æ–¹ç¨‹):\n",
    "   $$\\nabla \\cdot \\mathbf{u} = \\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} + \\frac{\\partial w}{\\partial z} \\approx 0$$\n",
    "   \n",
    "2. **å‹•é‡å®ˆæ†** (NS æ–¹ç¨‹æ®˜å·®):\n",
    "   $$\\frac{\\partial u}{\\partial t} + \\mathbf{u} \\cdot \\nabla u = -\\frac{1}{\\rho}\\nabla p + \\nu \\nabla^2 u + f$$\n",
    "\n",
    "3. **é‚Šç•Œæ¢ä»¶**:\n",
    "   - å£é¢: $u = v = w = 0$ at $y = \\pm 1$\n",
    "   - å‘¨æœŸæ€§: $u(x, y, 0) = u(x, y, 3\\pi)$\n",
    "\n",
    "4. **å£é¢å‰ªæ‡‰åŠ›**:\n",
    "   $$\\tau_w = \\mu \\frac{\\partial u}{\\partial y}\\bigg|_{y=\\pm1} \\approx 0.0025$$\n",
    "\n",
    "### é©—è­‰å·¥å…·\n",
    "\n",
    "```bash\n",
    "# ç‰©ç†ä¸€è‡´æ€§é©—è­‰\n",
    "pytest tests/test_physics.py\n",
    "pytest tests/test_physics_validation.py\n",
    "\n",
    "# å®ˆæ†å¾‹é©—è­‰\n",
    "python scripts/validation/validate_ns_conservation.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´å¤±æ•—è¨ºæ–·èˆ‡ç‰©ç†é©—è­‰ï¼ˆå–æ¶ˆè¨»è§£å¾ŒåŸ·è¡Œï¼‰\n",
    "# !python scripts/debug/diagnose_piratenet_failure.py --checkpoint checkpoints/my_exp/epoch_X.pth --config configs/my_exp.yml --output results/diagnosis/\n",
    "\n",
    "# !pytest tests/test_physics.py\n",
    "# !pytest tests/test_physics_validation.py\n",
    "# !python scripts/validation/validate_ns_conservation.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 GradNorm å‹•æ…‹æ¬Šé‡å¹³è¡¡\n",
    "\n",
    "### å•é¡Œï¼šå¤šç›®æ¨™å„ªåŒ–çš„æŒ‘æˆ°\n",
    "\n",
    "PINNs éœ€è¦åŒæ™‚å„ªåŒ–å¤šå€‹æå¤±é …ï¼š\n",
    "- **Data Loss**: æ„Ÿæ¸¬é»æ“¬åˆ\n",
    "- **PDE Residuals**: ç‰©ç†æ–¹ç¨‹æ»¿è¶³\n",
    "- **Boundary Conditions**: é‚Šç•Œæ¢ä»¶\n",
    "- **Priors**: å…ˆé©—çŸ¥è­˜ï¼ˆå¯é¸ï¼‰\n",
    "\n",
    "**å›ºå®šæ¬Šé‡çš„å•é¡Œ**:\n",
    "- ä¸åŒæå¤±é …å°ºåº¦å·®ç•°å·¨å¤§ï¼ˆ10^-5 åˆ° 10^2ï¼‰\n",
    "- è¨“ç·´éç¨‹ä¸­ç›¸å°é‡è¦æ€§æœƒè®ŠåŒ–\n",
    "- å®¹æ˜“é™·å…¥ trivial solutionï¼ˆéæ“¬åˆæ„Ÿæ¸¬é»ï¼Œå¿½ç•¥ç‰©ç†ï¼‰\n",
    "\n",
    "### GradNorm è§£æ±ºæ–¹æ¡ˆ\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**: å‹•æ…‹èª¿æ•´æ¬Šé‡ï¼Œä½¿å„æå¤±é …çš„æ¢¯åº¦ç¯„æ•¸ä¿æŒå¹³è¡¡\n",
    "\n",
    "$$\n",
    "\\lambda_i(t+1) = \\lambda_i(t) \\cdot \\left( \\frac{\\|\\nabla_\\theta L_i\\|}{\\bar{G}(t)} \\right)^{-\\alpha}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $\\|\\nabla_\\theta L_i\\|$: æå¤±é … $i$ çš„æ¢¯åº¦ç¯„æ•¸\n",
    "- $\\bar{G}(t)$: æ‰€æœ‰æå¤±é …æ¢¯åº¦ç¯„æ•¸çš„å¹³å‡å€¼\n",
    "- $\\alpha$: èª¿æ•´å¼·åº¦ï¼ˆ**é—œéµåƒæ•¸**ï¼‰\n",
    "\n",
    "### åƒæ•¸é…ç½®ï¼ˆåŸºæ–¼ SYSTEM_COUPLING_ANALYSIS_LESSONS.mdï¼‰\n",
    "\n",
    "| åƒæ•¸ | æ¨è–¦å€¼ | èªªæ˜ |\n",
    "|------|--------|------|\n",
    "| **alpha** | **1.5** | éŸ¿æ‡‰å¼·åº¦ï¼ˆ0.12 å¤ªå° â†’ PDE Ratio < 10%ï¼‰ |\n",
    "| **update_freq** | **1000** | æ›´æ–°é »ç‡ï¼ˆé¿å…è¨ˆç®—é–‹éŠ·èˆ‡éœ‡ç›ªï¼‰ |\n",
    "\n",
    "**éŒ¯èª¤ç¤ºç¯„**ï¼ˆPirateNet å¤±æ•—æ¡ˆä¾‹ï¼‰:\n",
    "```yaml\n",
    "# âŒ ä¸æ¨è–¦\n",
    "losses:\n",
    "  grad_norm_alpha: 0.12  # å¤ªå°ï¼Œç„¡æ³•æœ‰æ•ˆå¹³è¡¡\n",
    "  weight_update_freq: 50  # éæ–¼é »ç¹\n",
    "```\n",
    "\n",
    "**æ­£ç¢ºé…ç½®**:\n",
    "```yaml\n",
    "# âœ… æ¨è–¦\n",
    "losses:\n",
    "  adaptive_weighting: true\n",
    "  grad_norm_alpha: 1.5\n",
    "  weight_update_freq: 1000\n",
    "```\n",
    "\n",
    "### é æœŸæ•ˆæœ\n",
    "\n",
    "- **PDE Loss Ratio**: å¾ 0.7% æå‡è‡³ â‰¥ 30%\n",
    "- **å£é¢å‰ªæ‡‰åŠ›**: å¾ ~0 æ¢å¾©è‡³ç†è«–å€¼é™„è¿‘ï¼ˆÏ„_w â‰ˆ 0.0025ï¼‰\n",
    "- **è¨“ç·´ç©©å®šæ€§**: é¡¯è‘—æ”¹å–„ï¼Œæå¤±å¹³æ»‘ä¸‹é™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Reynolds æ•¸éå¢ Curriculum\n",
    "\n",
    "### å‹•æ©Ÿ\n",
    "\n",
    "**å•é¡Œ**: ç›´æ¥åœ¨é«˜ Reynolds æ•¸ï¼ˆRe_Ï„=1000ï¼‰ä¸‹è¨“ç·´æ¨¡å‹ï¼Œå®¹æ˜“å› æ¢¯åº¦éæ–¼å‰›æ€§ï¼ˆstiffï¼‰è€Œå°è‡´æ•¸å€¼ä¸ç©©å®šã€æ”¶æ–‚å›°é›£ã€‚\n",
    "\n",
    "**è§£æ±ºæ–¹æ¡ˆ**: æ¡ç”¨èª²ç¨‹å­¸ç¿’ï¼Œå¾ä¸€å€‹è¼ƒç°¡å–®çš„ç‰©ç†å ´æ™¯ï¼ˆä½ Re_Ï„ï¼‰é–‹å§‹ï¼Œè®“æ¨¡å‹å­¸æœƒåŸºæœ¬çš„æµå‹•çµæ§‹ï¼Œç„¶å¾Œé€æ­¥å¢åŠ è¤‡é›œæ€§ï¼ˆæå‡ Re_Ï„ï¼‰ï¼Œæœ€çµ‚åœ¨ç›®æ¨™ Reynolds æ•¸ä¸‹é€²è¡Œç²¾ç…‰ã€‚\n",
    "\n",
    "### æ–°çš„ 3 éšæ®µ Curriculum ç­–ç•¥\n",
    "\n",
    "æˆ‘å€‘çš„æ–°é è¨­èª²ç¨‹ (`3d_full_production.yml`) åŒ…å«ä¸‰å€‹éšæ®µï¼š\n",
    "\n",
    "| éšæ®µ | Epochs | Re_tau | Î½ (é»åº¦) | å­¸ç¿’ç‡ | ä¸»è¦ç›®æ¨™ |\n",
    "|---|---|---|---|---|---|\n",
    "| **Stage 1** | 0-1500 | 500 | 1.0e-4 | 1.0e-3 | ç©©å®šå»ºç«‹åŸºæœ¬æµå ´ |\n",
    "| **Stage 2** | 1500-3500 | 750 | 6.67e-5 | 0.9e-3 | éæ¸¡åˆ°æ›´è¤‡é›œçš„æ¹æµçµæ§‹ |\n",
    "| **Stage 3** | 3500-5000 | 1000 | 5.0e-5 | 0.729e-3 | åœ¨ç›®æ¨™ Re æ•¸ä¸‹ç²¾ç…‰ç´°ç¯€ |\n",
    "\n",
    "### è¨“ç·´å‘½ä»¤\n",
    "\n",
    "```bash\n",
    "# èª²ç¨‹å­¸ç¿’æ˜¯æ–°é è¨­ï¼Œç›´æ¥åŸ·è¡Œç”Ÿç”¢æ¨¡æ¿å³å¯\n",
    "python scripts/train.py --cfg configs/templates/3d_full_production.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebbe7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# èª²ç¨‹å­¸ç¿’è¨“ç·´ï¼ˆå–æ¶ˆè¨»è§£å¾ŒåŸ·è¡Œï¼‰\n",
    "# !python scripts/train.py --cfg configs/templates/3d_full_production.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€ŸåŸºç·šè¨“ç·´ç¤ºä¾‹ï¼ˆå¦‚æœåœ¨ Notebook ä¸­ç›´æ¥è¨“ç·´ï¼‰\n",
    "# å¯¦éš›è¨“ç·´å»ºè­°ä½¿ç”¨å‘½ä»¤è¡Œ: python scripts/train.py --cfg configs/my_exp.yml\n",
    "\n",
    "# é€™è£¡å±•ç¤ºå¦‚ä½•é€éé…ç½®å‰µå»ºè¨“ç·´å™¨\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# è¼‰å…¥å¿«é€ŸåŸºç·šé…ç½®\n",
    "config_path = Path('configs/templates/2d_quick_baseline.yml')\n",
    "\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"âš™ï¸ å¿«é€ŸåŸºç·šé…ç½®æ‘˜è¦:\\n\")\n",
    "    print(f\"   å¯¦é©—åç¨±: {config['experiment']['name']}\")\n",
    "    print(f\"   è¨“ç·´è¼ªæ•¸: {config['training']['epochs']}\")\n",
    "    print(f\"   å­¸ç¿’ç‡: {config['training']['optimizer']['lr']}\")\n",
    "    print(f\"   æ‰¹æ¬¡å¤§å°: {config['training']['batch_size']}\")\n",
    "    print(f\"\\n   æ„Ÿæ¸¬é»æ•¸: K={config['sensors']['K']}\")\n",
    "    print(f\"   é¸æ“‡ç­–ç•¥: {config['sensors']['selection_method']}\")\n",
    "    print(f\"\\n   æ¨¡å‹å¯¬åº¦: {config['model']['width']}\")\n",
    "    print(f\"   æ¨¡å‹æ·±åº¦: {config['model']['depth']}\")\n",
    "    print(f\"   Fourier Ïƒ: {config['model'].get('fourier_sigma', 'N/A')}\")\n",
    "    print(f\"\\n   é æœŸæ™‚é–“: {config.get('expected_duration', '5-10 åˆ†é˜')}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ è¨“ç·´å‘½ä»¤:\")\n",
    "    print(f\"   python scripts/train.py --cfg {config_path}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}\")\n",
    "    print(\"è«‹ç¢ºèªå°ˆæ¡ˆç›®éŒ„çµæ§‹æ­£ç¢º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: è¨“ç·´ç­–ç•¥èˆ‡æŠ€å·§\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 å¿«é€ŸåŸºç·šè¨“ç·´ï¼ˆ100 epochsï¼Œ5-10 åˆ†é˜ï¼‰\n",
    "\n",
    "### ç›®æ¨™\n",
    "- é©—è­‰ç’°å¢ƒé…ç½®æ­£ç¢º\n",
    "- å¿«é€Ÿæ¸¬è©¦æ„Ÿæ¸¬é»æ•¸æ“šè³ªé‡\n",
    "- å»ºç«‹æ€§èƒ½åŸºç·š\n",
    "\n",
    "### é…ç½®æ–‡ä»¶\n",
    "\n",
    "ä½¿ç”¨ `configs/templates/2d_quick_baseline.yml` ä½œç‚ºèµ·é»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰µå»ºä¸¦æª¢æŸ¥æ¨¡å‹æ¶æ§‹\n",
    "from pinnx.models.fourier_mlp import create_pinn_model\n",
    "\n",
    "# é…ç½®ï¼šEnhanced æ¨¡å¼\n",
    "model_config = {\n",
    "    'type': 'enhanced_fourier_mlp',\n",
    "    'in_dim': 3,\n",
    "    'out_dim': 4,\n",
    "    'width': 256,\n",
    "    'depth': 6,\n",
    "    'fourier_m': 64,\n",
    "    'fourier_sigma': 3.0,\n",
    "    'activation': 'swish',\n",
    "    'use_fourier': True,\n",
    "    'use_residual': True,\n",
    "    'use_layer_norm': False,\n",
    "    'dropout': 0.0\n",
    "}\n",
    "\n",
    "model = create_pinn_model(model_config)\n",
    "model_summary = model.get_model_summary()\n",
    "\n",
    "print(\"ğŸ—ï¸ æ¨¡å‹æ¶æ§‹æ‘˜è¦:\\n\")\n",
    "for key, value in model_summary.items():\n",
    "    if key == 'total_params':\n",
    "        print(f\"   {key:20s}: {value:,}\")\n",
    "    else:\n",
    "        print(f\"   {key:20s}: {value}\")\n",
    "\n",
    "print(f\"\\nğŸ“ æ¨¡å‹çµæ§‹è©³ç´°:\")\n",
    "print(model)\n",
    "\n",
    "# æ¸¬è©¦å‰å‘å‚³æ’­\n",
    "test_coords = torch.randn(10, 3)  # 10 å€‹æ¸¬è©¦é»\n",
    "test_coords.requires_grad = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_coords)\n",
    "\n",
    "print(f\"\\nâœ… å‰å‘å‚³æ’­æ¸¬è©¦:\")\n",
    "print(f\"   è¼¸å…¥å½¢ç‹€: {test_coords.shape}\")\n",
    "print(f\"   è¼¸å‡ºå½¢ç‹€: {predictions.shape}\")\n",
    "print(f\"   è¼¸å‡ºç¯„åœ: [{predictions.min():.3f}, {predictions.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 å®Œæ•´ç¶²è·¯æ¶æ§‹\n",
    "\n",
    "### ç¶²è·¯æµç¨‹åœ–\n",
    "\n",
    "```\n",
    "è¼¸å…¥åº§æ¨™ (x, y, z)\n",
    "    â†“\n",
    "[å¯é¸] VS-PINN ç¸®æ”¾: (X, Y, Z) = (N_xÂ·x, N_yÂ·y, N_zÂ·z)\n",
    "    â†“\n",
    "Fourier Features ç·¨ç¢¼: Ï†(X,Y,Z) âˆˆ R^{2m}\n",
    "    â†“\n",
    "[å¯é¸] æŠ•å½±å±¤: Linear(2m â†’ width) + Swish\n",
    "    â†“\n",
    "éš±è—å±¤ Ã— depth: \n",
    "  â”œâ”€ [RWF]Linear(width â†’ width)\n",
    "  â”œâ”€ [å¯é¸] LayerNorm\n",
    "  â”œâ”€ Activation (tanh/swish/sine)\n",
    "  â”œâ”€ [å¯é¸] Dropout\n",
    "  â””â”€ [å¯é¸] Residual Connection\n",
    "    â†“\n",
    "è¼¸å‡ºå±¤: Linear(width â†’ 4)  # [u, v, w, p]\n",
    "    â†“\n",
    "è¼¸å‡ºåæ­¸ä¸€åŒ–ï¼ˆæ¢å¾©ç‰©ç†å°ºåº¦ï¼‰\n",
    "```\n",
    "\n",
    "### é…ç½®ç¯„ä¾‹å°æ¯”\n",
    "\n",
    "| é…ç½® | Width | Depth | Fourier m | Activation | Residual | RWF | åƒæ•¸é‡ | é©ç”¨å ´æ™¯ |\n",
    "|------|-------|-------|-----------|------------|----------|-----|--------|---------|\n",
    "| **Standard** | 128 | 4 | 32 | tanh | âŒ | âŒ | ~130K | å¿«é€Ÿé©—è­‰ |\n",
    "| **Enhanced** | 256 | 6 | 64 | swish | âœ… | âŒ | ~580K | ç”Ÿç”¢è¨“ç·´ |\n",
    "| **PirateNet** | 200 | 8 | 256 | sine | âœ… | âœ… | ~1.2M | é«˜ç²¾åº¦ç ”ç©¶ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ– VS-PINN ç¸®æ”¾æ•ˆæœ\n",
    "from pinnx.physics.vs_pinn_channel_flow import VSPINNChannelFlow\n",
    "\n",
    "# å‰µå»º VS-PINN ç‰©ç†æ¨¡çµ„\n",
    "vs_pinn = VSPINNChannelFlow(\n",
    "    scaling_factors={'N_x': 2.0, 'N_y': 12.0, 'N_z': 2.0},\n",
    "    physics_params={'nu': 5e-5, 'dP_dx': 0.0025, 'rho': 1.0}\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ VS-PINN ç¸®æ”¾ä¿‚æ•¸:\")\n",
    "print(f\"   N_x (æµå‘): {vs_pinn.N_x.item():.1f}\")\n",
    "print(f\"   N_y (å£æ³•å‘): {vs_pinn.N_y.item():.1f}\")\n",
    "print(f\"   N_z (å±•å‘): {vs_pinn.N_z.item():.1f}\")\n",
    "\n",
    "# æ¨¡æ“¬ç¸®æ”¾å‰å¾Œçš„æ¢¯åº¦å°ºåº¦\n",
    "y_coords = np.linspace(-1, 1, 100)\n",
    "du_dy_physical = 1000 * (1 - y_coords**2)  # æ¨¡æ“¬å£æ³•å‘æ¢¯åº¦ï¼ˆç°¡åŒ–ï¼‰\n",
    "\n",
    "# ç¸®æ”¾å¾Œçš„åº§æ¨™\n",
    "Y_scaled = vs_pinn.N_y.item() * y_coords\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# å·¦åœ–ï¼šç¸®æ”¾å‰\n",
    "axes[0].plot(y_coords, du_dy_physical, 'b-', linewidth=2, label='âˆ‚u/âˆ‚y (ç‰©ç†ç©ºé–“)')\n",
    "axes[0].set_xlabel('y (å£æ³•å‘)', fontsize=12)\n",
    "axes[0].set_ylabel('âˆ‚u/âˆ‚y', fontsize=12)\n",
    "axes[0].set_title('ç¸®æ”¾å‰ï¼šæ¢¯åº¦å°ºåº¦æ¥µç«¯ä¸å¹³è¡¡', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].legend()\n",
    "axes[0].axhline(y=0, color='k', linestyle='--', linewidth=0.5)\n",
    "axes[0].text(0.05, 0.95, f'æœ€å¤§æ¢¯åº¦: {du_dy_physical.max():.0f}', \n",
    "             transform=axes[0].transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "# å³åœ–ï¼šç¸®æ”¾å¾Œ\n",
    "du_dY_scaled = du_dy_physical / vs_pinn.N_y.item()  # éˆå¼æ³•å‰‡è£œå„Ÿ\n",
    "axes[1].plot(Y_scaled, du_dY_scaled, 'r-', linewidth=2, label='âˆ‚u/âˆ‚Y (ç¸®æ”¾ç©ºé–“)')\n",
    "axes[1].set_xlabel('Y = N_y Â· y (ç¸®æ”¾åº§æ¨™)', fontsize=12)\n",
    "axes[1].set_ylabel('âˆ‚u/âˆ‚Y', fontsize=12)\n",
    "axes[1].set_title('ç¸®æ”¾å¾Œï¼šæ¢¯åº¦å°ºåº¦å¹³è¡¡', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].legend()\n",
    "axes[1].axhline(y=0, color='k', linestyle='--', linewidth=0.5)\n",
    "axes[1].text(0.05, 0.95, f'æœ€å¤§æ¢¯åº¦: {du_dY_scaled.max():.0f}', \n",
    "             transform=axes[1].transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… ç¸®æ”¾æ•ˆæœ:\")\n",
    "print(f\"   ç¸®æ”¾å‰æœ€å¤§æ¢¯åº¦: {du_dy_physical.max():.0f}\")\n",
    "print(f\"   ç¸®æ”¾å¾Œæœ€å¤§æ¢¯åº¦: {du_dY_scaled.max():.0f} (é™ä½ {vs_pinn.N_y.item():.0f}x)\")\n",
    "print(f\"   æ¢¯åº¦å¹³è¡¡æ¯”: {du_dy_physical.max() / du_dY_scaled.max():.1f} â‰ˆ N_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 VS-PINN è®Šæ•¸å°ºåº¦åŒ–\n",
    "\n",
    "### å‹•æ©Ÿ\n",
    "\n",
    "Channel Flow æ˜¯**å„å‘ç•°æ€§æµå ´**ï¼š\n",
    "- æµå‘ (x): ç‰¹å¾µå°ºåº¦ $L_x \\sim 8\\pi$\n",
    "- å£æ³•å‘ (y): ç‰¹å¾µå°ºåº¦ $\\delta_\\nu \\sim 0.001$ (é‚Šç•Œå±¤åšåº¦)\n",
    "- å±•å‘ (z): ç‰¹å¾µå°ºåº¦ $L_z \\sim 3\\pi$\n",
    "\n",
    "**å•é¡Œ**: æ¨™æº– PINN åœ¨å„æ–¹å‘ä½¿ç”¨ç›¸åŒæ¬Šé‡ï¼Œå°è‡´ï¼š\n",
    "- å£æ³•å‘æ¢¯åº¦ ($\\frac{\\partial u}{\\partial y}$) æ•¸å€¼é å¤§æ–¼æµå‘æ¢¯åº¦\n",
    "- è¨“ç·´ä¸ç©©å®šï¼Œæå¤±å‡½æ•¸é›£ä»¥å¹³è¡¡\n",
    "\n",
    "### VS-PINN è§£æ±ºæ–¹æ¡ˆ\n",
    "\n",
    "**åº§æ¨™è®Šæ›**:\n",
    "$$\n",
    "(X, Y, Z) = (N_x \\cdot x, N_y \\cdot y, N_z \\cdot z)\n",
    "$$\n",
    "\n",
    "**éˆå¼æ³•å‰‡**:\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial x} = N_x \\cdot \\frac{\\partial u}{\\partial X}, \\quad \n",
    "\\nabla^2 u = N_x^2 \\frac{\\partial^2 u}{\\partial X^2} + N_y^2 \\frac{\\partial^2 u}{\\partial Y^2} + N_z^2 \\frac{\\partial^2 u}{\\partial Z^2}\n",
    "$$\n",
    "\n",
    "**æ¨è–¦å€¼** (åŸºæ–¼ VS-PINN è«–æ–‡èˆ‡å¯¦é©—):\n",
    "- $N_x = 2.0$ (æµå‘ï¼Œæœ€æŸ”è»Ÿ)\n",
    "- $N_y = 12.0$ (å£æ³•å‘ï¼Œæœ€å‰›æ€§)\n",
    "- $N_z = 2.0$ (å±•å‘ï¼Œèˆ‡æµå‘ç›¸ä¼¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ– Fourier Features çš„ä½œç”¨\n",
    "import torch\n",
    "from pinnx.models.fourier_mlp import FourierFeatures\n",
    "\n",
    "# å‰µå»ºä¸åŒ sigma çš„ Fourier ç·¨ç¢¼å™¨\n",
    "sigmas = [1.0, 3.0, 5.0]\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1D æ¸¬è©¦å‡½æ•¸ï¼šé«˜é » sine æ³¢\n",
    "x_test = torch.linspace(-1, 1, 1000).unsqueeze(1)  # [1000, 1]\n",
    "y_true = torch.sin(20 * np.pi * x_test)  # é«˜é »å‡½æ•¸\n",
    "\n",
    "for idx, (sigma, color) in enumerate(zip(sigmas, colors)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # å‰µå»º Fourier Features\n",
    "    fourier = FourierFeatures(in_dim=1, m=32, sigma=sigma, multiscale=False)\n",
    "    \n",
    "    # ç·¨ç¢¼\n",
    "    with torch.no_grad():\n",
    "        features = fourier(x_test)  # [1000, 64]\n",
    "    \n",
    "    # å¯è¦–åŒ–å‰ 10 å€‹ç‰¹å¾µ\n",
    "    ax.plot(x_test.numpy(), features[:, :10].numpy(), alpha=0.3, linewidth=0.8)\n",
    "    ax.set_title(f'Fourier Features (Ïƒ={sigma})', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('Feature Value')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.axhline(y=0, color='k', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # çµ±è¨ˆè³‡è¨Š\n",
    "    feature_freq = features.std(dim=0).mean().item()\n",
    "    ax.text(0.05, 0.95, f'å¹³å‡æŒ¯å¹…: {feature_freq:.2f}', \n",
    "            transform=ax.transAxes, fontsize=10, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¡ é—œéµè§€å¯Ÿ:\")\n",
    "print(f\"   Ïƒ=1.0: ä½é »ç‰¹å¾µï¼ŒæŒ¯å¹…è¼ƒå°ï¼Œé©åˆå…¨å±€è¶¨å‹¢\")\n",
    "print(f\"   Ïƒ=3.0: ä¸­é »ç‰¹å¾µï¼ŒæŒ¯å¹…é©ä¸­ï¼Œå¹³è¡¡å…¨å±€èˆ‡ç´°ç¯€\")\n",
    "print(f\"   Ïƒ=5.0: é«˜é »ç‰¹å¾µï¼ŒæŒ¯å¹…è¼ƒå¤§ï¼Œæ•æ‰é‚Šç•Œå±¤æ¢¯åº¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Fourier Features åŸç†èˆ‡è¦–è¦ºåŒ–\n",
    "\n",
    "### ç†è«–åŸºç¤\n",
    "\n",
    "**å•é¡Œ**: æ¨™æº– MLP é›£ä»¥æ•æ‰é«˜é »å‡½æ•¸ï¼ˆRahaman et al., 2019ï¼‰\n",
    "\n",
    "**è§£æ±ºæ–¹æ¡ˆ**: Random Fourier Features (RFF)\n",
    "\n",
    "$$\n",
    "\\phi(x) = [\\cos(2\\pi B x), \\sin(2\\pi B x)]\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ $B \\in \\mathbb{R}^{d \\times m}$ï¼Œ$B_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "\n",
    "**åƒæ•¸ $\\sigma$ çš„ä½œç”¨**:\n",
    "- $\\sigma$ å°ï¼ˆâ‰ˆ0.5-1.0ï¼‰ï¼šæ•æ‰ä½é »ç‰¹å¾µï¼ˆå…¨å±€è¶¨å‹¢ï¼‰\n",
    "- $\\sigma$ å¤§ï¼ˆâ‰ˆ5-10ï¼‰ï¼šæ•æ‰é«˜é »ç‰¹å¾µï¼ˆé‚Šç•Œå±¤æ¢¯åº¦ï¼‰\n",
    "\n",
    "**Channel Flow çš„é¸æ“‡**: $\\sigma = 2-5$ï¼ˆTRAINING_STABILIZATION_STRATEGIES.mdï¼‰\n",
    "- ç†ç”±ï¼šå£é¢å‰ªæ‡‰åŠ›æ¢¯åº¦ $\\frac{du}{dy}|_{\\text{wall}} \\approx 1000$\n",
    "- é‚Šç•Œå±¤åšåº¦ï¼š$\\delta_\\nu = \\frac{1}{\\text{Re}_\\tau} \\approx 0.001$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
