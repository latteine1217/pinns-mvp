#!/usr/bin/env python3
"""
Task-014: 3D å‡ç´šç‰ˆçœŸå¯¦JHTDBæ•¸æ“šèˆ‡PINNsè¨“ç·´ç®¡ç·šæ•´åˆæ¸¬è©¦
=========================================================

ç›®æ¨™ï¼šå°‡é‡å»ºç²¾åº¦å¾ç•¶å‰2Dæ¨¡å‹çš„ >80% é™è‡³ <30%

é—œéµå‡ç´šï¼š
1. è¼¸å…¥ç¶­åº¦ï¼š[x,y] â†’ [x,y,z] (3Dç©ºé–“)
2. è¼¸å‡ºç¶­åº¦ï¼š[u,v,p] â†’ [u,v,w,p] (åŒ…å«wåˆ†é‡)
3. ç¶²è·¯æ¶æ§‹ï¼šå¢å¼·ç‰ˆFourier MLP (8å±¤Ã—256å¯¬åº¦)
4. ç‰©ç†ç´„æŸï¼š3D NSæ–¹ç¨‹ + æ™‚é–“ä¾è³´é …
5. QR-pivotï¼š3Då¿«ç…§çŸ©é™£ç­–ç•¥

åŸºæ–¼åˆ†æï¼šwåˆ†é‡é‡è¦æ€§70.2%ï¼Œå€¼å¾—32å€è¨ˆç®—æˆæœ¬
"""

import numpy as np
import torch
import h5py
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
warnings.filterwarnings("ignore")

# PINNx å°å…¥
import pinnx
from pinnx.models.enhanced_fourier_mlp import EnhancedPINNNet
from pinnx.physics.ns_3d_temporal import NSEquations3DTemporal
from pinnx.sensors.qr_pivot import QRPivotSelector
from pinnx.losses.residuals import NSResidualLoss
from pinnx.losses.weighting import GradNormWeighter

def load_real_jhtdb_3d_data():
    """è¼‰å…¥å®Œæ•´3DçœŸå¯¦JHTDB Channel Flowæ•¸æ“š"""
    print("ğŸ“ è¼‰å…¥å®Œæ•´3DçœŸå¯¦JHTDB Channel Flowæ•¸æ“š...")
    
    cache_file = Path("data/jhtdb/channel_34e525c703a89036170603d28e552870.h5")
    if not cache_file.exists():
        raise FileNotFoundError(f"çœŸå¯¦JHTDBæ•¸æ“šå¿«å–ä¸å­˜åœ¨: {cache_file}")
    
    with h5py.File(cache_file, 'r') as f:
        # è¼‰å…¥å®Œæ•´3Dæ•¸æ“š
        u_data = np.array(f['u'])  # (64, 32, 32) = (x, y, z)
        v_data = np.array(f['v'])
        w_data = np.array(f['w'])  # é—œéµï¼šç¾åœ¨åŒ…å«wåˆ†é‡
        p_data = np.array(f['p'])
        
        data = {
            'u': u_data,
            'v': v_data,
            'w': w_data,  # æ–°å¢wåˆ†é‡
            'p': p_data
        }
    
    print(f"âœ… 3Dæ•¸æ“šè¼‰å…¥æˆåŠŸ:")
    print(f"   u: {data['u'].shape}, ç¯„åœ: [{np.min(data['u']):.3f}, {np.max(data['u']):.3f}]")
    print(f"   v: {data['v'].shape}, ç¯„åœ: [{np.min(data['v']):.3f}, {np.max(data['v']):.3f}]")
    print(f"   w: {data['w'].shape}, ç¯„åœ: [{np.min(data['w']):.3f}, {np.max(data['w']):.3f}]")
    print(f"   p: {data['p'].shape}, ç¯„åœ: [{np.min(data['p']):.3f}, {np.max(data['p']):.3f}]")
    
    # wåˆ†é‡é‡è¦æ€§åˆ†æ
    w_std = np.std(data['w'])
    u_std = np.std(data['u'])
    print(f"   wåˆ†é‡é‡è¦æ€§: {w_std/u_std:.1%} (ç›¸å°uåˆ†é‡æ¨™æº–å·®)")
    
    return data

def setup_3d_coordinates(data):
    """å»ºç«‹3Dåº§æ¨™ç¶²æ ¼"""
    print("ğŸ“ å»ºç«‹3Dåº§æ¨™ç¶²æ ¼...")
    
    nx, ny, nz = data['u'].shape
    
    # Channel Flow çœŸå¯¦ç‰©ç†åŸŸ
    x = np.linspace(0, 6.28, nx)      # æµå‘ (é€±æœŸæ€§)
    y = np.linspace(-1, 1, ny)        # æ³•å‘ (å£é¢é‚Šç•Œ)
    z = np.linspace(0, 3.14, nz)      # å±•å‘ (é€±æœŸæ€§)
    
    # å»ºç«‹3Dç¶²æ ¼
    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
    
    coordinates = {
        'x': X,  # (64, 32, 32)
        'y': Y,
        'z': Z
    }
    
    print(f"âœ… 3Dåº§æ¨™ç¶²æ ¼å»ºç«‹å®Œæˆ:")
    print(f"   xåŸŸ: [{x.min():.2f}, {x.max():.2f}] (æµå‘)")
    print(f"   yåŸŸ: [{y.min():.2f}, {y.max():.2f}] (æ³•å‘)")  
    print(f"   zåŸŸ: [{z.min():.2f}, {z.max():.2f}] (å±•å‘)")
    print(f"   ç¸½ç©ºé–“é»æ•¸: {X.size:,}")
    
    return coordinates

def setup_3d_qr_pivot_sensors(data, coordinates, K=15):
    """ä½¿ç”¨3D QR-pivoté¸æ“‡æ„Ÿæ¸¬é»ï¼ˆåŒ…å«wåˆ†é‡ä¿¡æ¯ï¼‰"""
    print(f"ğŸ¯ ä½¿ç”¨3D QR-pivoté¸æ“‡ {K} å€‹æ„Ÿæ¸¬é»ï¼ˆåŒ…å«wåˆ†é‡ï¼‰...")
    
    nx, ny, nz = data['u'].shape
    total_points = nx * ny * nz
    
    # å°‡3Då ´æ•¸æ“šé‡æ•´ç‚ºçŸ©é™£å½¢å¼
    u_flat = data['u'].flatten()
    v_flat = data['v'].flatten()
    w_flat = data['w'].flatten()  # é—œéµï¼šåŒ…å«wåˆ†é‡
    p_flat = data['p'].flatten()
    
    print(f"ğŸ“Š 3Dæ•¸æ“šçµ±è¨ˆ:")
    print(f"   ç¸½ç©ºé–“é»æ•¸: {total_points:,}")
    print(f"   u_flat: {u_flat.shape}, std={np.std(u_flat):.3f}")
    print(f"   w_flat: {w_flat.shape}, std={np.std(w_flat):.3f}")
    
    # æ§‹å»º3Då¢å¼·å¿«ç…§çŸ©é™£ï¼šåŒ…å«åŸå§‹å ´ã€æ¢¯åº¦å’Œç‰©ç†é‡
    u_3d = data['u']
    v_3d = data['v']
    w_3d = data['w']  # é—œéµ3Dä¿¡æ¯
    p_3d = data['p']
    
    # è¨ˆç®—3Dæ¢¯åº¦ï¼ˆç°¡å–®å·®åˆ†ï¼‰
    u_dx = np.gradient(u_3d, axis=0).flatten()
    u_dy = np.gradient(u_3d, axis=1).flatten()
    u_dz = np.gradient(u_3d, axis=2).flatten()  # æ–°å¢zæ–¹å‘æ¢¯åº¦
    
    v_dx = np.gradient(v_3d, axis=0).flatten()
    v_dy = np.gradient(v_3d, axis=1).flatten()
    v_dz = np.gradient(v_3d, axis=2).flatten()
    
    w_dx = np.gradient(w_3d, axis=0).flatten()  # wåˆ†é‡æ¢¯åº¦
    w_dy = np.gradient(w_3d, axis=1).flatten()
    w_dz = np.gradient(w_3d, axis=2).flatten()
    
    p_dx = np.gradient(p_3d, axis=0).flatten()
    p_dy = np.gradient(p_3d, axis=1).flatten()
    p_dz = np.gradient(p_3d, axis=2).flatten()
    
    # è¨ˆç®—3Dç‰©ç†é‡
    # 3Dæ¸¦é‡ï¼šÏ‰ = âˆ‡ Ã— u
    vorticity_x = (w_dy - v_dz)  # Ï‰x = âˆ‚w/âˆ‚y - âˆ‚v/âˆ‚z
    vorticity_y = (u_dz - w_dx)  # Ï‰y = âˆ‚u/âˆ‚z - âˆ‚w/âˆ‚x
    vorticity_z = (v_dx - u_dy)  # Ï‰z = âˆ‚v/âˆ‚x - âˆ‚u/âˆ‚y
    
    # 3Dæ•£åº¦ï¼šâˆ‡Â·u
    divergence_3d = (u_dx + v_dy + w_dz)  # âˆ‚u/âˆ‚x + âˆ‚v/âˆ‚y + âˆ‚w/âˆ‚z
    
    # æ§‹å»ºæœ€å¤§3Då¿«ç…§çŸ©é™£ï¼š[è®Šæ•¸, ç©ºé–“é»]
    snapshots_3d = np.row_stack([
        u_flat, v_flat, w_flat, p_flat,        # åŸå§‹å ´ (4)
        u_dx, u_dy, u_dz,                      # uæ¢¯åº¦ (3) 
        v_dx, v_dy, v_dz,                      # væ¢¯åº¦ (3)
        w_dx, w_dy, w_dz,                      # wæ¢¯åº¦ (3) - é—œéµï¼
        p_dx, p_dy, p_dz,                      # å£“åŠ›æ¢¯åº¦ (3)
        vorticity_x, vorticity_y, vorticity_z, # 3Dæ¸¦é‡ (3)
        divergence_3d                          # æ•£åº¦ (1)
    ])  # (23, 65536)
    
    print(f"ğŸ“Š 3Då¿«ç…§çŸ©é™£ç¶­åº¦: {snapshots_3d.shape}")
    print(f"ğŸ“Š çŸ©é™£ç§©: {np.linalg.matrix_rank(snapshots_3d)}")
    print(f"ğŸ“Š wåˆ†é‡è²¢ç»: æ¢¯åº¦{w_dx.std():.3f}, æ¸¦é‡{vorticity_x.std():.3f}")
    
    # ä½¿ç”¨QR-pivoté¸æ“‡æ„Ÿæ¸¬é»
    sensor = QRPivotSelector()
    try:
        # QR-pivotåœ¨è¡Œï¼ˆç©ºé–“é»ï¼‰ä¸Šé¸æ“‡
        selected_indices, metrics = sensor.select_sensors(snapshots_3d.T, n_sensors=K)
        print(f"ğŸ“Š 3D QR-pivotçµæœ: é¸æ“‡äº† {len(selected_indices)} å€‹é»")
        print(f"ğŸ“Š æ¢ä»¶æ•¸: {metrics.get('condition_number', 'N/A'):.2f}")
    except Exception as e:
        print(f"âŒ QR-pivotå¤±æ•—: {e}")
        # å›é€€åˆ°3Då‡å‹»æ¡æ¨£
        selected_indices = np.linspace(0, total_points-1, K, dtype=int)
        print(f"ğŸ”„ å›é€€åˆ°3Då‡å‹»æ¡æ¨£: {len(selected_indices)} å€‹é»")
    
    # ç¢ºä¿é¸æ“‡çš„é»æ•¸ä¸è¶…éè«‹æ±‚æ•¸é‡
    selected_indices = selected_indices[:K]
    
    # å¾å¹³å¦ç´¢å¼•è½‰æ›ç‚º3Dåº§æ¨™
    selected_coords = []
    selected_values = []
    
    for idx in selected_indices:
        i, j, k = np.unravel_index(idx, (nx, ny, nz))
        x_coord = coordinates['x'][i, j, k]
        y_coord = coordinates['y'][i, j, k]
        z_coord = coordinates['z'][i, j, k]  # æ–°å¢zåº§æ¨™
        
        selected_coords.append([x_coord, y_coord, z_coord])
        selected_values.append([
            data['u'][i, j, k],
            data['v'][i, j, k],
            data['w'][i, j, k],  # æ–°å¢wåˆ†é‡
            data['p'][i, j, k]
        ])
    
    selected_coords = np.array(selected_coords)    # (K, 3) = [x,y,z]
    selected_values = np.array(selected_values)    # (K, 4) = [u,v,w,p]
    
    print(f"âœ… 3Dæ„Ÿæ¸¬é»é¸æ“‡å®Œæˆ:")
    print(f"   åº§æ¨™å½¢ç‹€: {selected_coords.shape}")
    print(f"   å€¼å½¢ç‹€: {selected_values.shape}")
    print(f"   zåº§æ¨™ç¯„åœ: [{selected_coords[:,2].min():.2f}, {selected_coords[:,2].max():.2f}]")
    
    return selected_coords, selected_values

def setup_enhanced_3d_pinns_model():
    """å»ºç«‹å¢å¼·ç‰ˆ3D PINNsæ¨¡å‹"""
    print("ğŸ§  å»ºç«‹å¢å¼·ç‰ˆ3D PINNsæ¨¡å‹...")
    
    # Task-014å°ˆç”¨3Då„ªåŒ–é…ç½® - ä¿®å¾©4Dè¼¸å…¥
    config = {
        'in_dim': 4,         # [t, x, y, z] 4Dæ™‚ç©ºè¼¸å…¥ï¼ˆç©©æ…‹t=0ï¼‰
        'out_dim': 4,        # [u, v, w, p] åŒ…å«wåˆ†é‡
        'width': 256,        # å¢åŠ å¯¬åº¦ä»¥æ‡‰å°3Dè¤‡é›œæ€§
        'depth': 8,          # æ›´æ·±ç¶²è·¯æ•æ‰3Dç‰¹å¾µ
        'fourier_m': 64,     # å¢å¼·Fourierç‰¹å¾µ
        'fourier_sigma': 5.0,
        'activation': 'swish', # æ›´å¥½çš„æ¢¯åº¦å‚³æ’­
        'use_residual': True,  # æ®˜å·®é€£æ¥ç©©å®šæ·±åº¦ç¶²è·¯
        'use_layer_norm': True, # å±¤æ­¸ä¸€åŒ–
        'dropout': 0.1         # é˜²æ­¢éæ“¬åˆ
    }
    
    model = EnhancedPINNNet(**config)
    
    print(f"âœ… å¢å¼·ç‰ˆ3Dæ¨¡å‹å»ºç«‹å®Œæˆ:")
    print(f"   è¼¸å…¥: 4Dæ™‚ç©º [t,x,y,z] (ç©©æ…‹)")
    print(f"   è¼¸å‡º: 4Då ´ [u,v,w,p]")
    print(f"   åƒæ•¸æ•¸é‡: {model.get_num_params():,}")
    print(f"   ç›¸å°åŸºç·šå¢é•·: {model.get_num_params()/58243:.1f}x")
    
    return model

def setup_3d_physics_constraints():
    """å»ºç«‹3Dç‰©ç†ç´„æŸ"""
    print("âš–ï¸ å»ºç«‹3Dç‰©ç†ç´„æŸ...")
    
    # Channel Flow Re=1000 å°æ‡‰çš„ç‰©ç†åƒæ•¸
    Re = 1000
    nu = 1.0 / Re  # å‹•é»æ»¯ä¿‚æ•¸
    
    physics = NSEquations3DTemporal(viscosity=nu, density=1.0)
    
    print(f"âœ… 3D NSæ–¹ç¨‹ç´„æŸå»ºç«‹:")
    print(f"   é›·è«¾æ•¸: Re = {Re}")
    print(f"   é»æ»¯ä¿‚æ•¸: Î½ = {nu:.6f}")
    print(f"   ç´„æŸé …: 3Då‹•é‡ + é€£çºŒæ€§æ–¹ç¨‹")
    
    return physics

def run_enhanced_3d_training(model, sensor_coords, sensor_values, physics, full_data, coordinates):
    """é‹è¡Œå¢å¼·ç‰ˆ3D PINNsè¨“ç·´"""
    print("ğŸš€ é–‹å§‹å¢å¼·ç‰ˆ3D PINNsè¨“ç·´...")
    
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    model = model.to(device)
    
    # æº–å‚™3Dæ„Ÿæ¸¬æ•¸æ“š - æ·»åŠ æ™‚é–“ç¶­åº¦ï¼ˆt=0 ç©©æ…‹å‡è¨­ï¼‰
    sensor_coords_4d = np.zeros((len(sensor_coords), 4))  # [t, x, y, z]
    sensor_coords_4d[:, 0] = 0.0  # æ™‚é–“è¨­ç‚º0ï¼ˆç©©æ…‹ï¼‰
    sensor_coords_4d[:, 1:] = sensor_coords  # x, y, z
    
    coords_tensor = torch.tensor(sensor_coords_4d, dtype=torch.float32, device=device)
    values_tensor = torch.tensor(sensor_values, dtype=torch.float32, device=device)
    
    print(f"ğŸ“Š 3Dè¨“ç·´æ•¸æ“š:")
    print(f"   åº§æ¨™: {coords_tensor.shape} [t,x,y,z]")
    print(f"   å€¼: {values_tensor.shape} [u,v,w,p]")
    print(f"   æ™‚é–“: {coords_tensor[:,0].min():.2f} (ç©©æ…‹)")
    print(f"   xç¯„åœ: [{coords_tensor[:,1].min():.2f},{coords_tensor[:,1].max():.2f}]")
    print(f"   zç¯„åœ: [{coords_tensor[:,3].min():.2f},{coords_tensor[:,3].max():.2f}]")
    print(f"   wåˆ†é‡ç¯„åœ: [{values_tensor[:,2].min():.2f},{values_tensor[:,2].max():.2f}]")
    
    # æº–å‚™ç‰©ç†ç´„æŸé»ï¼ˆè¼ƒå°‘ä½†è¦†è“‹3DåŸŸï¼‰ - æ·»åŠ æ™‚é–“ç¶­åº¦
    nx, ny, nz = full_data['u'].shape
    # ç¨€ç–æ¡æ¨£3Dç‰©ç†ç´„æŸé»
    physics_coords_3d = []
    for i in range(0, nx, 8):  # 8å€ç¨€ç–æ¡æ¨£
        for j in range(0, ny, 4):
            for k in range(0, nz, 4):
                x_coord = coordinates['x'][i, j, k]
                y_coord = coordinates['y'][i, j, k]
                z_coord = coordinates['z'][i, j, k]
                # æ·»åŠ æ™‚é–“ç¶­åº¦ [t, x, y, z]
                physics_coords_3d.append([0.0, x_coord, y_coord, z_coord])
    
    physics_coords_3d = np.array(physics_coords_3d)
    physics_tensor = torch.tensor(physics_coords_3d, dtype=torch.float32, device=device)
    
    print(f"ğŸ“Š 3Dç‰©ç†ç´„æŸé»: {physics_tensor.shape} [t,x,y,z]")
    
    # å„ªåŒ–å™¨è¨­ç½®
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, factor=0.8)
    
    # è¨“ç·´è¿´åœˆ
    losses = []
    data_losses = []
    physics_losses = []
    
    # === åˆ†ææ•¸æ“šçµ±è¨ˆç‰¹æ€§ç”¨æ–¼æ¬Šé‡å¹³è¡¡ ===
    print("ğŸ” åˆ†æå ´çµ±è¨ˆç‰¹æ€§...")
    values_np = values_tensor.detach().cpu().numpy()
    field_stats = {}
    field_names = ['U', 'V', 'W', 'P']
    
    for i, name in enumerate(field_names):
        std_val = np.std(values_np[:, i])
        mean_val = np.mean(values_np[:, i])
        field_stats[name] = {
            'std': std_val,
            'mean': mean_val,
            'range': [np.min(values_np[:, i]), np.max(values_np[:, i])]
        }
        print(f"{name}å ´: std={std_val:.6f}, mean={mean_val:.6f}, range={field_stats[name]['range']}")
    
    # è¨ˆç®—å°ºåº¦å¹³è¡¡æ¬Šé‡ - åŸºæ–¼æ¨™æº–å·®å€’æ•¸
    base_std = field_stats['U']['std']  # ä»¥Uå ´ç‚ºåŸºæº–
    scale_weights = {}
    for i, name in enumerate(field_names):
        if field_stats[name]['std'] > 1e-8:
            scale_weights[name] = base_std / field_stats[name]['std']
        else:
            scale_weights[name] = 1.0
        print(f"{name}å ´å°ºåº¦æ¬Šé‡: {scale_weights[name]:.4f}")
    
    print("ğŸ”„ é–‹å§‹3Då¢å¼·è¨“ç·´è¿´åœˆ...")
    for epoch in range(200):  # æ›´å¤šepochè™•ç†3Dè¤‡é›œæ€§
        optimizer.zero_grad()
        
        # === æ•¸æ“šæå¤±ï¼ˆç›£ç£å­¸ç¿’ï¼‰- æ¡ç”¨å°ºåº¦å¹³è¡¡ ===
        pred_data = model(coords_tensor)
        
        # åˆ†åˆ¥è¨ˆç®—å„åˆ†é‡æå¤±ä¸¦æ‡‰ç”¨å°ºåº¦æ¬Šé‡
        field_losses = []
        for i, name in enumerate(field_names):
            field_pred = pred_data[:, i:i+1]
            field_true = values_tensor[:, i:i+1]
            field_loss = torch.nn.MSELoss()(field_pred, field_true)
            weighted_loss = scale_weights[name] * field_loss
            field_losses.append(weighted_loss)
        
        data_loss = sum(field_losses) / len(field_losses)  # å¹³å‡åŠ æ¬Šæå¤±
        
        # === ç‰©ç†ç´„æŸæå¤± ===
        pred_physics = model(physics_tensor)
        u_pred = pred_physics[:, 0:1]
        v_pred = pred_physics[:, 1:2] 
        w_pred = pred_physics[:, 2:3]
        p_pred = pred_physics[:, 3:4]
        
        # 3D NSæ–¹ç¨‹æ®˜å·®ï¼ˆç°¡åŒ–ç‰ˆæœ¬ç”¨æ–¼è¨“ç·´ï¼‰
        velocity_pred = torch.cat([u_pred, v_pred, w_pred], dim=1)
        
        # è¨ˆç®—é€£çºŒæ€§æ–¹ç¨‹æ®˜å·® - ä½¿ç”¨æ›´ç©©å¥çš„æ¢¯åº¦è¨ˆç®—
        physics_tensor.requires_grad_(True)
        
        # æª¢æŸ¥æ¢¯åº¦è¨ˆç®—
        try:
            # å°æ–¼4Dè¼¸å…¥ [t,x,y,z]ï¼Œç©ºé–“å°æ•¸ç´¢å¼•ç‚º [1,2,3]
            u_grads = torch.autograd.grad(u_pred.sum(), physics_tensor, create_graph=True, retain_graph=True)[0]
            v_grads = torch.autograd.grad(v_pred.sum(), physics_tensor, create_graph=True, retain_graph=True)[0]  
            w_grads = torch.autograd.grad(w_pred.sum(), physics_tensor, create_graph=True, retain_graph=True)[0]
            
            u_x = u_grads[:, 1:2]  # âˆ‚u/âˆ‚x
            v_y = v_grads[:, 2:3]  # âˆ‚v/âˆ‚y
            w_z = w_grads[:, 3:4]  # âˆ‚w/âˆ‚z
            
            continuity_residual = u_x + v_y + w_z
            physics_loss = torch.mean(continuity_residual**2)
            
        except Exception as e:
            print(f"âš ï¸ æ¢¯åº¦è¨ˆç®—å¤±æ•—: {e}")
            # fallback: ç°¡åŒ–ç‰©ç†æå¤±
            physics_loss = torch.tensor(0.0, device=device, requires_grad=True)
        
        # === ç¸½æå¤± ===
        lambda_data = 10.0      # æ•¸æ“šé …æ¬Šé‡
        lambda_physics = 1.0    # ç‰©ç†é …æ¬Šé‡
        
        total_loss = lambda_data * data_loss + lambda_physics * physics_loss
        
        # æ­£å‰‡åŒ–é …
        reg_loss = 1e-6 * sum(torch.norm(param)**2 for param in model.parameters())
        total_loss += reg_loss
        
        total_loss.backward()
        
        # æ¢¯åº¦è£å‰ªé˜²æ­¢çˆ†ç‚¸
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        scheduler.step(total_loss)
        
        # è¨˜éŒ„æå¤±
        losses.append(total_loss.item())
        data_losses.append(data_loss.item())
        physics_losses.append(physics_loss.item())
        
        if epoch % 25 == 0:
            print(f"  Epoch {epoch:3d}: ç¸½æå¤±={total_loss.item():.2e}, "
                  f"æ•¸æ“š={data_loss.item():.2e}, ç‰©ç†={physics_loss.item():.2e}")
            print(f"             å­¸ç¿’ç‡={optimizer.param_groups[0]['lr']:.2e}")
    
    print(f"âœ… 3Då¢å¼·è¨“ç·´å®Œæˆï¼æœ€çµ‚æå¤±: {losses[-1]:.2e}")
    
    return model, {'total': losses, 'data': data_losses, 'physics': physics_losses}

def evaluate_3d_reconstruction(model, full_data, coordinates):
    """è©•ä¼°3Dé‡å»ºæ•ˆæœ"""
    print("ğŸ“Š è©•ä¼°3Dé‡å»ºæ•ˆæœ...")
    
    device = next(model.parameters()).device
    nx, ny, nz = full_data['u'].shape
    
    # æº–å‚™3Dè©•ä¼°ç¶²æ ¼ï¼ˆç¨€ç–æ¡æ¨£ä»¥ç¯€çœè¨˜æ†¶é«”ï¼‰
    eval_coords_3d = []
    eval_indices = []
    
    # ç¨€ç–æ¡æ¨£é€²è¡Œè©•ä¼°
    for i in range(0, nx, 2):  # 2å€ç¨€ç–æ¡æ¨£
        for j in range(0, ny, 1):  # yæ–¹å‘ä¿æŒå®Œæ•´ï¼ˆé‡è¦é‚Šç•Œï¼‰
            for k in range(0, nz, 2):
                x_coord = coordinates['x'][i, j, k]
                y_coord = coordinates['y'][i, j, k]
                z_coord = coordinates['z'][i, j, k]
                # æ·»åŠ æ™‚é–“ç¶­åº¦ [t, x, y, z]
                eval_coords_3d.append([0.0, x_coord, y_coord, z_coord])
                eval_indices.append((i, j, k))
    
    eval_coords_3d = np.array(eval_coords_3d)
    eval_tensor = torch.tensor(eval_coords_3d, dtype=torch.float32, device=device)
    
    print(f"ğŸ“Š 3Dè©•ä¼°é»æ•¸: {eval_tensor.shape[0]:,} (4Dè¼¸å…¥)")
    
    # é æ¸¬
    model.eval()
    with torch.no_grad():
        pred = model(eval_tensor).cpu().numpy()
    
    # é‡çµ„çœŸå¯¦å ´å€¼ç”¨æ–¼æ¯”è¼ƒ
    u_true_eval = []
    v_true_eval = []
    w_true_eval = []
    p_true_eval = []
    
    for (i, j, k) in eval_indices:
        u_true_eval.append(full_data['u'][i, j, k])
        v_true_eval.append(full_data['v'][i, j, k])
        w_true_eval.append(full_data['w'][i, j, k])
        p_true_eval.append(full_data['p'][i, j, k])
    
    u_true_eval = np.array(u_true_eval)
    v_true_eval = np.array(v_true_eval)
    w_true_eval = np.array(w_true_eval)
    p_true_eval = np.array(p_true_eval)
    
    # é æ¸¬å€¼
    u_pred_eval = pred[:, 0]
    v_pred_eval = pred[:, 1]
    w_pred_eval = pred[:, 2]  # é—œéµï¼šwåˆ†é‡é æ¸¬
    p_pred_eval = pred[:, 3]
    
    # è¨ˆç®—ç›¸å°L2èª¤å·®
    u_error = np.sqrt(np.mean((u_pred_eval - u_true_eval)**2)) / np.sqrt(np.mean(u_true_eval**2))
    v_error = np.sqrt(np.mean((v_pred_eval - v_true_eval)**2)) / np.sqrt(np.mean(v_true_eval**2))
    w_error = np.sqrt(np.mean((w_pred_eval - w_true_eval)**2)) / np.sqrt(np.mean(w_true_eval**2))
    p_error = np.sqrt(np.mean((p_pred_eval - p_true_eval)**2)) / np.sqrt(np.mean(p_true_eval**2))
    
    print(f"ğŸ“ˆ 3Dé‡å»ºèª¤å·®åˆ†æ:")
    print(f"  uå ´ç›¸å°L2èª¤å·®: {u_error:.1%} (ç›®æ¨™: â‰¤30%)")
    print(f"  vå ´ç›¸å°L2èª¤å·®: {v_error:.1%} (ç›®æ¨™: â‰¤30%)")
    print(f"  wå ´ç›¸å°L2èª¤å·®: {w_error:.1%} (ç›®æ¨™: â‰¤30%) â­æ–°å¢")
    print(f"  på ´ç›¸å°L2èª¤å·®: {p_error:.1%} (ç›®æ¨™: â‰¤30%)")
    
    # æ•´é«”æ€§èƒ½æŒ‡æ¨™
    avg_error = (u_error + v_error + w_error + p_error) / 4
    print(f"  å¹³å‡èª¤å·®: {avg_error:.1%}")
    
    # èˆ‡2DåŸºç·šå°æ¯”
    print(f"\nğŸ“Š èˆ‡2DåŸºç·šå°æ¯”:")
    print(f"  2DåŸºç·š - u: 91.1%, v: 81.2%, p: 86.4%")
    print(f"  3Då‡ç´š - u: {u_error:.1%}, v: {v_error:.1%}, w: {w_error:.1%}, p: {p_error:.1%}")
    
    return {
        'u_pred': u_pred_eval,
        'v_pred': v_pred_eval,
        'w_pred': w_pred_eval,
        'p_pred': p_pred_eval,
        'u_true': u_true_eval,
        'v_true': v_true_eval,
        'w_true': w_true_eval,
        'p_true': p_true_eval,
        'coords': eval_coords_3d,
        'errors': {'u': u_error, 'v': v_error, 'w': w_error, 'p': p_error, 'avg': avg_error}
    }

def create_3d_visualization(sensor_coords, results, losses):
    """å‰µå»º3Då‡ç´šçµæœå¯è¦–åŒ–"""
    print("ğŸ¨ å‰µå»º3Då‡ç´šçµæœå¯è¦–åŒ–...")
    
    fig = plt.figure(figsize=(20, 12))
    
    # 1. æå¤±æ›²ç·š
    ax1 = plt.subplot(2, 4, 1)
    epochs = range(len(losses['total']))
    plt.plot(epochs, losses['total'], 'b-', label='Total Loss', linewidth=2)
    plt.plot(epochs, losses['data'], 'g-', label='Data Loss', linewidth=2)
    plt.plot(epochs, losses['physics'], 'r-', label='Physics Loss', linewidth=2)
    plt.yscale('log')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('3D Enhanced Training Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 2. èª¤å·®å°æ¯”åœ–
    ax2 = plt.subplot(2, 4, 2)
    fields = ['u', 'v', 'w', 'p']
    baseline_2d = [91.1, 81.2, None, 86.4]  # 2DåŸºç·šï¼ˆwç„¡æ•¸æ“šï¼‰
    enhanced_3d = [results['errors'][f]*100 for f in fields]
    
    x_pos = np.arange(len(fields))
    width = 0.35
    
    # 2DåŸºç·š
    baseline_values = [baseline_2d[i] if baseline_2d[i] is not None else 0 for i in range(len(fields))]
    bars1 = plt.bar(x_pos - width/2, baseline_values, width, label='2D Baseline', alpha=0.7, color='lightcoral')
    
    # 3Då‡ç´š
    bars2 = plt.bar(x_pos + width/2, enhanced_3d, width, label='3D Enhanced', alpha=0.7, color='skyblue')
    
    plt.axhline(y=30, color='red', linestyle='--', alpha=0.8, label='Target (30%)')
    plt.xlabel('Field Components')
    plt.ylabel('L2 Relative Error (%)')
    plt.title('2D vs 3D Performance Comparison')
    plt.xticks(x_pos, fields)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):
        if baseline_2d[i] is not None:
            plt.text(bar1.get_x() + bar1.get_width()/2, bar1.get_height() + 2, 
                    f'{baseline_2d[i]:.1f}%', ha='center', va='bottom', fontsize=9)
        plt.text(bar2.get_x() + bar2.get_width()/2, bar2.get_height() + 2, 
                f'{enhanced_3d[i]:.1f}%', ha='center', va='bottom', fontsize=9)
    
    # 3. æ„Ÿæ¸¬é»3Dåˆ†å¸ƒï¼ˆæŠ•å½±åˆ°xyå¹³é¢ï¼‰
    ax3 = plt.subplot(2, 4, 3)
    scatter = plt.scatter(sensor_coords[:, 0], sensor_coords[:, 1], 
                         c=sensor_coords[:, 2], s=100, cmap='viridis', 
                         edgecolors='black', linewidth=1)
    plt.colorbar(scatter, label='z-coordinate')
    plt.xlabel('x (streamwise)')
    plt.ylabel('y (wall-normal)')
    plt.title(f'3D Sensor Locations (N={len(sensor_coords)})')
    plt.grid(True, alpha=0.3)
    
    # 4-7. å ´é‡å»ºæ¯”è¼ƒï¼ˆé¸æ“‡ä¸­é–“zåˆ‡ç‰‡ï¼‰
    n_eval = len(results['u_pred'])
    mid_idx = n_eval // 2
    
    for i, field in enumerate(['u', 'v', 'w', 'p']):
        ax = plt.subplot(2, 4, 4 + i)
        
        pred_values = results[f'{field}_pred']
        true_values = results[f'{field}_true']
        
        # æ•£é»åœ–æ¯”è¼ƒ
        plt.scatter(true_values[::10], pred_values[::10], alpha=0.6, s=20)
        
        # ç†æƒ³ç·š
        min_val = min(np.min(true_values), np.min(pred_values))
        max_val = max(np.max(true_values), np.max(pred_values))
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
        
        plt.xlabel(f'{field.upper()} True')
        plt.ylabel(f'{field.upper()} Predicted')
        plt.title(f'{field.upper()} Field: Error {results["errors"][field]:.1%}')
        plt.grid(True, alpha=0.3)
        
        # RÂ²è¨ˆç®—
        r2 = np.corrcoef(true_values, pred_values)[0, 1]**2
        plt.text(0.05, 0.95, f'RÂ² = {r2:.3f}', transform=ax.transAxes, 
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    plt.suptitle('Task-014: 3D Enhanced PINNs Reconstruction Results', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    output_path = "tasks/task-014/3d_enhanced_reconstruction_results.png"
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ“Š 3Då¯è¦–åŒ–å·²ä¿å­˜: {output_path}")
    
    return output_path

def main():
    """ä¸»å‡½æ•¸ - Task-014 3Då‡ç´šå¯¦æ–½"""
    print("ğŸš€ Task-014: 3D Enhanced PINNs Reconstruction é–‹å§‹...\n")
    
    try:
        # 1. è¼‰å…¥å®Œæ•´3DçœŸå¯¦JHTDBæ•¸æ“š
        jhtdb_data_3d = load_real_jhtdb_3d_data()
        
        # 2. å»ºç«‹3Dåº§æ¨™ç¶²æ ¼
        coordinates_3d = setup_3d_coordinates(jhtdb_data_3d)
        
        # 3. 3D QR-pivotæ„Ÿæ¸¬é»é¸æ“‡ï¼ˆåŒ…å«wåˆ†é‡ï¼‰
        sensor_coords_3d, sensor_values_3d = setup_3d_qr_pivot_sensors(
            jhtdb_data_3d, coordinates_3d, K=15
        )
        
        # 4. å»ºç«‹å¢å¼·ç‰ˆ3D PINNsæ¨¡å‹
        enhanced_model_3d = setup_enhanced_3d_pinns_model()
        
        # 5. å»ºç«‹3Dç‰©ç†ç´„æŸ
        physics_3d = setup_3d_physics_constraints()
        
        # 6. é‹è¡Œå¢å¼·ç‰ˆ3Dè¨“ç·´
        trained_model_3d, training_losses = run_enhanced_3d_training(
            enhanced_model_3d, sensor_coords_3d, sensor_values_3d, 
            physics_3d, jhtdb_data_3d, coordinates_3d
        )
        
        # 7. è©•ä¼°3Dé‡å»ºæ•ˆæœ
        results_3d = evaluate_3d_reconstruction(trained_model_3d, jhtdb_data_3d, coordinates_3d)
        
        # 8. å‰µå»ºçµæœå¯è¦–åŒ–
        viz_path = create_3d_visualization(sensor_coords_3d, results_3d, training_losses)
        
        # 9. æœ€çµ‚ç¸½çµ
        print(f"\nğŸ‰ Task-014 3Då‡ç´šæˆåŠŸå®Œæˆï¼")
        print(f"\nğŸ“ˆ é—œéµæˆå°±å°æ¯”:")
        print(f"{'':>12} {'2DåŸºç·š':>12} {'3Då‡ç´š':>12} {'æ”¹å–„':>12}")
        print(f"{'='*50}")
        
        baseline_errors = {'u': 91.1, 'v': 81.2, 'p': 86.4}
        enhanced_errors = results_3d['errors']
        
        for field in ['u', 'v', 'p']:
            baseline = baseline_errors[field]
            enhanced = enhanced_errors[field] * 100
            improvement = ((baseline - enhanced) / baseline) * 100
            print(f"{field.upper() + 'å ´èª¤å·®':>12} {baseline:>10.1f}% {enhanced:>10.1f}% {improvement:>+9.1f}%")
        
        # wåˆ†é‡æ˜¯æ–°å¢çš„
        w_error = enhanced_errors['w'] * 100
        print(f"{'Wå ´èª¤å·®':>12} {'æ–°å¢':>10} {w_error:>10.1f}% {'N/A':>12}")
        
        avg_error = enhanced_errors['avg'] * 100
        print(f"{'å¹³å‡èª¤å·®':>12} {'N/A':>10} {avg_error:>10.1f}% {'N/A':>12}")
        
        print(f"\nâœ… æˆåŠŸæŒ‡æ¨™é”æˆæƒ…æ³:")
        for field in ['u', 'v', 'w', 'p']:
            error_pct = enhanced_errors[field] * 100
            status = "âœ… é”æ¨™" if error_pct <= 30 else "âŒ æœªé”æ¨™"
            print(f"   {field.upper()}å ´ â‰¤ 30%: {error_pct:.1f}% {status}")
        
        print(f"\nğŸ“Š å¯è¦–åŒ–å ±å‘Š: {viz_path}")
        print(f"ğŸ“ è©³ç´°çµæœ: tasks/task-014/")
        
        # ä¿å­˜çµæœåˆ°ä»»å‹™ç›®éŒ„
        results_summary = {
            'task_id': 'task-014',
            'objective': '3D Enhanced PINNs Reconstruction',
            'sensor_points': len(sensor_coords_3d),
            'model_params': enhanced_model_3d.get_num_params(),
            'training_epochs': len(training_losses['total']),
            'final_loss': training_losses['total'][-1],
            'errors_pct': {k: v*100 for k, v in enhanced_errors.items()},
            'target_achieved': all(enhanced_errors[f] <= 0.30 for f in ['u', 'v', 'w', 'p']),
            'improvement_vs_2d': {
                'u': ((baseline_errors['u'] - enhanced_errors['u']*100) / baseline_errors['u']) * 100,
                'v': ((baseline_errors['v'] - enhanced_errors['v']*100) / baseline_errors['v']) * 100,
                'p': ((baseline_errors['p'] - enhanced_errors['p']*100) / baseline_errors['p']) * 100
            }
        }
        
        # å¯«å…¥ä»»å‹™å®Œæˆå ±å‘Š
        import json
        with open('tasks/task-014/completion_summary.json', 'w') as f:
            json.dump(results_summary, f, indent=2)
        
        print(f"ğŸ“ ä»»å‹™å ±å‘Šå·²ä¿å­˜: tasks/task-014/completion_summary.json")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Task-014 3Då‡ç´šå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)