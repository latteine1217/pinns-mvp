#!/usr/bin/env python3
"""
Task-014: 3D å‡ç´šç‰ˆçœŸå¯¦JHTDBæ•¸æ“šèˆ‡PINNsè¨“ç·´ç®¡ç·šæ•´åˆæ¸¬è©¦ - ä¿®å¾©ç‰ˆ
=================================================================

ä¿®å¾©ç­–ç•¥ï¼š
1. Vå ´æ¬Šé‡å¤±è¡¡å•é¡Œ - åŸºæ–¼å ´çµ±è¨ˆç‰¹æ€§çš„å°ºåº¦æ¬Šé‡
2. å®Œæ•´3D NSå‹•é‡æ–¹ç¨‹å¯¦ç¾
3. å¢å¼·å£é¢é‚Šç•Œæ¢ä»¶è™•ç†

ç›®æ¨™ï¼šå°‡é‡å»ºç²¾åº¦å¾115.5%é™è‡³<30%
"""

import numpy as np
import torch
import h5py
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
warnings.filterwarnings("ignore")

def load_real_jhtdb_3d_data():
    """è¼‰å…¥å®Œæ•´3DçœŸå¯¦JHTDB Channel Flowæ•¸æ“š"""
    print("ğŸ“ è¼‰å…¥å®Œæ•´3DçœŸå¯¦JHTDB Channel Flowæ•¸æ“š...")
    
    cache_file = Path("data/jhtdb/channel_34e525c703a89036170603d28e552870.h5")
    if not cache_file.exists():
        raise FileNotFoundError(f"çœŸå¯¦JHTDBæ•¸æ“šå¿«å–ä¸å­˜åœ¨: {cache_file}")
    
    with h5py.File(cache_file, 'r') as f:
        print(f"   æ•¸æ“šé›†å¯ç”¨éµ: {list(f.keys())}")
        
        # è®€å–3Dåæ¨™èˆ‡4Då ´æ•¸æ“š (u,v,w,p) - ä¿®å¾©é¡å‹è™•ç†
        coords_data = f['coordinates']
        velocity_data = f['velocity']
        pressure_data = f['pressure']
        
        # è½‰æ›ç‚ºnumpyæ•¸çµ„
        coords = np.array(coords_data)     # [N, 4] - (t,x,y,z)
        velocity = np.array(velocity_data)      # [N, 3] - (u,v,w)
        pressure = np.array(pressure_data)      # [N, 1] - (p)
        
        # ç¢ºä¿æ­£ç¢ºçš„å½¢ç‹€
        if pressure.ndim == 1:
            pressure = pressure.reshape(-1, 1)
        
        # åˆä½µç‚ºå®Œæ•´ç‹€æ…‹å‘é‡
        values = np.concatenate([velocity, pressure], axis=1)  # [N, 4]
        
        print(f"   åº§æ¨™ç¶­åº¦: {coords.shape} (t,x,y,z)")
        print(f"   ç‹€æ…‹ç¶­åº¦: {values.shape} (u,v,w,p)")
        print(f"   åº§æ¨™ç¯„åœ: tâˆˆ[{coords[:,0].min():.3f},{coords[:,0].max():.3f}]")
        print(f"              xâˆˆ[{coords[:,1].min():.3f},{coords[:,1].max():.3f}]")
        print(f"              yâˆˆ[{coords[:,2].min():.3f},{coords[:,2].max():.3f}]")
        print(f"              zâˆˆ[{coords[:,3].min():.3f},{coords[:,3].max():.3f}]")
        
        return coords, values

class Enhanced3DPINNNet(torch.nn.Module):
    """å¢å¼·ç‰ˆ3D PINNsç¶²è·¯ - é‡å°ç²¾åº¦å„ªåŒ–"""
    
    def __init__(self, layers=[4, 256, 256, 256, 256, 256, 256, 256, 256, 4], 
                 fourier_features=None, activation='swish'):
        super().__init__()
        
        self.layers = layers
        self.activation_name = activation
        
        # è¨­å®šæ¿€æ´»å‡½æ•¸
        if activation == 'swish':
            self.activation = lambda x: x * torch.sigmoid(x)
        elif activation == 'gelu':
            self.activation = torch.nn.functional.gelu
        else:
            self.activation = torch.tanh
            
        # Fourierç‰¹å¾µç·¨ç¢¼ï¼ˆå¯é¸ï¼‰
        self.fourier_features = fourier_features
        if fourier_features:
            self.B = torch.randn(fourier_features, 4) * 2.0  # 4Dè¼¸å…¥
            layers[0] = fourier_features * 2
        
        # æ§‹å»ºå±¤
        self.linears = torch.nn.ModuleList()
        for i in range(len(layers) - 1):
            self.linears.append(torch.nn.Linear(layers[i], layers[i+1]))
            
        # æ¬Šé‡åˆå§‹åŒ–
        self._initialize_weights()
        
        print(f"   ğŸ”§ å¢å¼·3Dç¶²è·¯: {layers}, æ¿€æ´»={activation}")
        print(f"   ğŸ“Š åƒæ•¸ç¸½æ•¸: {sum(p.numel() for p in self.parameters()):,}")
    
    def _initialize_weights(self):
        """Xavieråˆå§‹åŒ–æ¬Šé‡"""
        for m in self.linears:
            if isinstance(m, torch.nn.Linear):
                torch.nn.init.xavier_normal_(m.weight)
                torch.nn.init.zeros_(m.bias)
    
    def forward(self, x):
        """å‰å‘å‚³æ’­"""
        # Fourierç‰¹å¾µç·¨ç¢¼
        if self.fourier_features:
            if not hasattr(self, 'B'):
                self.B = self.B.to(x.device)
            x_proj = 2 * torch.pi * x @ self.B.T
            x = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)
        
        # æ·±åº¦å‰å‘å‚³æ’­
        for i, layer in enumerate(self.linears[:-1]):
            x = layer(x)
            x = self.activation(x)
            
        # è¼¸å‡ºå±¤ï¼ˆç·šæ€§ï¼‰
        x = self.linears[-1](x)
        return x

def compute_3d_ns_residual(model, physics_coords, Re=1000, density=1.0):
    """
    è¨ˆç®—å®Œæ•´3D Navier-Stokesæ–¹ç¨‹æ®˜å·®
    åŒ…å«ï¼šé€£çºŒæ€§æ–¹ç¨‹ + 3å€‹å‹•é‡æ–¹ç¨‹
    """
    physics_coords.requires_grad_(True)
    pred = model(physics_coords)
    
    # æå–å„åˆ†é‡
    u = pred[:, 0:1]
    v = pred[:, 1:2]  
    w = pred[:, 2:3]
    p = pred[:, 3:4]
    
    # è¨ˆç®—æ‰€æœ‰æ¢¯åº¦
    u_grads = torch.autograd.grad(u.sum(), physics_coords, create_graph=True, retain_graph=True)[0]
    v_grads = torch.autograd.grad(v.sum(), physics_coords, create_graph=True, retain_graph=True)[0]
    w_grads = torch.autograd.grad(w.sum(), physics_coords, create_graph=True, retain_graph=True)[0]
    p_grads = torch.autograd.grad(p.sum(), physics_coords, create_graph=True, retain_graph=True)[0]
    
    # ä¸€éšå°æ•¸ [t,x,y,z]ç´¢å¼•=[0,1,2,3]
    u_t, u_x, u_y, u_z = u_grads[:,0:1], u_grads[:,1:2], u_grads[:,2:3], u_grads[:,3:4]
    v_t, v_x, v_y, v_z = v_grads[:,0:1], v_grads[:,1:2], v_grads[:,2:3], v_grads[:,3:4]
    w_t, w_x, w_y, w_z = w_grads[:,0:1], w_grads[:,1:2], w_grads[:,2:3], w_grads[:,3:4]
    p_x, p_y, p_z = p_grads[:,1:2], p_grads[:,2:3], p_grads[:,3:4]
    
    # äºŒéšå°æ•¸ï¼ˆfor æ‹‰æ™®æ‹‰æ–¯é …ï¼‰
    u_xx = torch.autograd.grad(u_x.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,1:2]
    u_yy = torch.autograd.grad(u_y.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,2:3]
    u_zz = torch.autograd.grad(u_z.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,3:4]
    
    v_xx = torch.autograd.grad(v_x.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,1:2]
    v_yy = torch.autograd.grad(v_y.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,2:3]
    v_zz = torch.autograd.grad(v_z.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,3:4]
    
    w_xx = torch.autograd.grad(w_x.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,1:2]
    w_yy = torch.autograd.grad(w_y.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,2:3]
    w_zz = torch.autograd.grad(w_z.sum(), physics_coords, create_graph=True, retain_graph=True)[0][:,3:4]
    
    # é€£çºŒæ€§æ–¹ç¨‹ï¼šâˆ‡Â·u = 0
    continuity = u_x + v_y + w_z
    
    # å‹•é‡æ–¹ç¨‹ (ä¸å«é«”ç©åŠ›):
    # âˆ‚u/âˆ‚t + uâˆ‡u = -âˆ‡p/Ï + Î½âˆ‡Â²u
    nu = 1.0 / Re  # é‹å‹•ç²˜åº¦
    
    # Xå‹•é‡æ–¹ç¨‹
    momentum_x = (u_t + u*u_x + v*u_y + w*u_z + p_x/density - 
                  nu*(u_xx + u_yy + u_zz))
    
    # Yå‹•é‡æ–¹ç¨‹
    momentum_y = (v_t + u*v_x + v*v_y + w*v_z + p_y/density - 
                  nu*(v_xx + v_yy + v_zz))
    
    # Zå‹•é‡æ–¹ç¨‹  
    momentum_z = (w_t + u*w_x + v*w_y + w*w_z + p_z/density - 
                  nu*(w_xx + w_yy + w_zz))
    
    return {
        'continuity': continuity,
        'momentum_x': momentum_x,
        'momentum_y': momentum_y,
        'momentum_z': momentum_z
    }

def apply_qr_pivot_selection_3d(coords, values, n_sensors=16, random_seed=42):
    """3D QR-pivotæ„Ÿæ¸¬é»é¸æ“‡"""
    print(f"ğŸ¯ ä½¿ç”¨3D QR-pivoté¸æ“‡ {n_sensors} å€‹æœ€å„ªæ„Ÿæ¸¬é»...")
    
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    
    # ç©ºé–“åæ¨™æ§‹å»ºå¿«ç…§çŸ©é™£ (æ’é™¤æ™‚é–“ç¶­åº¦)
    spatial_coords = coords[:, 1:]  # [x,y,z]
    
    # æ§‹å»ºåŸºæ–¼å€¼çš„å¿«ç…§çŸ©é™£
    snapshot_matrix = values.T  # [4, N] - (u,v,w,p)çš„è½‰ç½®
    
    # QRåˆ†è§£é¸æ“‡ä¸»è¦é»
    U, sigma, Vt = np.linalg.svd(snapshot_matrix, full_matrices=False)
    
    # åŸºæ–¼å¥‡ç•°å€¼çš„é‡è¦åº¦é¸æ“‡
    importance = np.sum(Vt[:n_sensors]**2, axis=0)
    selected_indices = np.argsort(importance)[-n_sensors:]
    
    selected_coords = coords[selected_indices]
    selected_values = values[selected_indices]
    
    print(f"   âœ… å·²é¸æ“‡æ„Ÿæ¸¬é»ï¼Œè¦†è“‹ç©ºé–“ç¯„åœï¼š")
    print(f"      X: [{selected_coords[:,1].min():.3f}, {selected_coords[:,1].max():.3f}]")
    print(f"      Y: [{selected_coords[:,2].min():.3f}, {selected_coords[:,2].max():.3f}]")
    print(f"      Z: [{selected_coords[:,3].min():.3f}, {selected_coords[:,3].max():.3f}]")
    
    return selected_coords, selected_values, selected_indices

def train_enhanced_3d_pinns():
    """ä¸»è¨“ç·´å‡½æ•¸ - æ¡ç”¨å°ºåº¦å¹³è¡¡ç­–ç•¥"""
    print("ğŸš€ å¯åŠ¨å¢å¼·ç‰ˆ3D PINNsè¨“ç·´...")
    
    # è¼‰å…¥æ•¸æ“š
    coords, values = load_real_jhtdb_3d_data()
    
    # QR-pivotæ„Ÿæ¸¬é»é¸æ“‡
    sensor_coords, sensor_values, sensor_indices = apply_qr_pivot_selection_3d(
        coords, values, n_sensors=16, random_seed=42
    )
    
    # è½‰æ›ç‚ºtensor
    coords_tensor = torch.FloatTensor(sensor_coords)
    values_tensor = torch.FloatTensor(sensor_values)
    
    # ç‰©ç†ç´„æŸé»ï¼ˆä½¿ç”¨å…¨æ•¸æ“šï¼‰
    physics_tensor = torch.FloatTensor(coords)
    
    # === åˆ†ææ•¸æ“šçµ±è¨ˆç‰¹æ€§ç”¨æ–¼æ¬Šé‡å¹³è¡¡ ===
    print("ğŸ” åˆ†æå ´çµ±è¨ˆç‰¹æ€§...")
    values_np = values_tensor.detach().cpu().numpy()
    field_stats = {}
    field_names = ['U', 'V', 'W', 'P']
    
    for i, name in enumerate(field_names):
        std_val = np.std(values_np[:, i])
        mean_val = np.mean(values_np[:, i])
        field_stats[name] = {
            'std': std_val,
            'mean': mean_val,
            'range': [np.min(values_np[:, i]), np.max(values_np[:, i])]
        }
        print(f"{name}å ´: std={std_val:.6f}, mean={mean_val:.6f}, range={field_stats[name]['range']}")
    
    # è¨ˆç®—å°ºåº¦å¹³è¡¡æ¬Šé‡ - åŸºæ–¼æ¨™æº–å·®å€’æ•¸
    base_std = field_stats['U']['std']  # ä»¥Uå ´ç‚ºåŸºæº–
    scale_weights = {}
    for i, name in enumerate(field_names):
        if field_stats[name]['std'] > 1e-8:
            scale_weights[name] = base_std / field_stats[name]['std']
        else:
            scale_weights[name] = 1.0
        print(f"{name}å ´å°ºåº¦æ¬Šé‡: {scale_weights[name]:.4f}")
    
    # åˆå§‹åŒ–å¢å¼·ç¶²è·¯
    model = Enhanced3DPINNNet(
        layers=[4, 256, 256, 256, 256, 256, 256, 256, 256, 4],
        fourier_features=64,
        activation='swish'
    )
    
    # å„ªåŒ–å™¨
    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.8)
    
    # è¨“ç·´è¨˜éŒ„
    losses = []
    field_losses_history = {name: [] for name in field_names}
    
    print("ğŸ”„ é–‹å§‹3Då¢å¼·è¨“ç·´è¿´åœˆ...")
    for epoch in range(300):  # å¢åŠ epochæ•¸
        optimizer.zero_grad()
        
        # === æ•¸æ“šæå¤±ï¼ˆç›£ç£å­¸ç¿’ï¼‰- æ¡ç”¨å°ºåº¦å¹³è¡¡ ===
        pred_data = model(coords_tensor)
        
        # åˆ†åˆ¥è¨ˆç®—å„åˆ†é‡æå¤±ä¸¦æ‡‰ç”¨å°ºåº¦æ¬Šé‡
        field_losses = []
        for i, name in enumerate(field_names):
            field_pred = pred_data[:, i:i+1]
            field_true = values_tensor[:, i:i+1]
            field_loss = torch.nn.MSELoss()(field_pred, field_true)
            weighted_loss = scale_weights[name] * field_loss
            field_losses.append(weighted_loss)
            field_losses_history[name].append(field_loss.item())
        
        data_loss = sum(field_losses) / len(field_losses)  # å¹³å‡åŠ æ¬Šæå¤±
        
        # === å®Œæ•´3D NSç‰©ç†ç´„æŸæå¤± ===
        residuals = compute_3d_ns_residual(model, physics_tensor, Re=1000)
        
        # å„æ–¹ç¨‹æ®˜å·®çš„MSE
        continuity_loss = torch.mean(residuals['continuity']**2)
        momentum_x_loss = torch.mean(residuals['momentum_x']**2)
        momentum_y_loss = torch.mean(residuals['momentum_y']**2)
        momentum_z_loss = torch.mean(residuals['momentum_z']**2)
        
        # ç¸½ç‰©ç†æå¤±
        physics_loss = (continuity_loss + momentum_x_loss + 
                       momentum_y_loss + momentum_z_loss) / 4.0
        
        # === é‚Šç•Œæ¢ä»¶ç´„æŸ ===
        # å£é¢é‚Šç•Œï¼šy=Â±1è™•é€Ÿåº¦ç‚ºé›¶
        wall_mask = torch.abs(physics_tensor[:, 2] - 1.0) < 0.01  # y=1å£é¢
        if wall_mask.sum() > 0:
            wall_pred = model(physics_tensor[wall_mask])
            wall_bc_loss = torch.mean(wall_pred[:, :3]**2)  # u=v=w=0
        else:
            wall_bc_loss = torch.tensor(0.0)
        
        # === ç¸½æå¤± ===
        lambda_data = 10.0      # æ•¸æ“šé …æ¬Šé‡
        lambda_physics = 2.0    # å¢å¼·ç‰©ç†é …æ¬Šé‡
        lambda_bc = 5.0         # é‚Šç•Œæ¢ä»¶æ¬Šé‡
        
        total_loss = (lambda_data * data_loss + 
                     lambda_physics * physics_loss + 
                     lambda_bc * wall_bc_loss)
        
        # æ­£å‰‡åŒ–é …
        reg_loss = 1e-6 * sum(torch.norm(param)**2 for param in model.parameters())
        total_loss += reg_loss
        
        total_loss.backward()
        
        # æ¢¯åº¦è£å‰ªé˜²æ­¢çˆ†ç‚¸
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        scheduler.step(total_loss)
        
        # è¨˜éŒ„æå¤±
        losses.append(total_loss.item())
        
        # è¨“ç·´é€²åº¦å ±å‘Š
        if epoch % 20 == 0:
            print(f"Epoch {epoch:3d}: ç¸½æå¤±={total_loss.item():.6f}, "
                  f"æ•¸æ“š={data_loss.item():.6f}, ç‰©ç†={physics_loss.item():.6f}, "
                  f"é‚Šç•Œ={wall_bc_loss.item():.6f}")
            
            # æ‰“å°å„å ´åˆ†é‡æå¤±
            for i, name in enumerate(field_names):
                print(f"   {name}å ´æå¤±: {field_losses_history[name][-1]:.6f}")
    
    print("âœ… 3Då¢å¼·è¨“ç·´å®Œæˆ!")
    
    # è©•ä¼°æ€§èƒ½
    evaluate_enhanced_3d_performance(model, coords, values, sensor_indices)
    
    return model, losses, field_losses_history

def evaluate_enhanced_3d_performance(model, coords, values, sensor_indices):
    """è©•ä¼°3Då¢å¼·æ¨¡å‹æ€§èƒ½"""
    print("\nğŸ” è©•ä¼°3Då¢å¼·æ¨¡å‹æ€§èƒ½...")
    
    # å…¨åŸŸé æ¸¬
    coords_tensor = torch.FloatTensor(coords)
    values_tensor = torch.FloatTensor(values)
    
    with torch.no_grad():
        pred_full = model(coords_tensor).numpy()
    
    # è¨ˆç®—å„åˆ†é‡èª¤å·®
    field_names = ['U', 'V', 'W', 'P']
    errors = {}
    
    print("=== åˆ†é‡åˆ¥é‡å»ºèª¤å·® ===")
    for i, name in enumerate(field_names):
        true_field = values[:, i]
        pred_field = pred_full[:, i]
        
        l2_error = np.sqrt(np.mean((pred_field - true_field)**2))
        rel_error = l2_error / (np.sqrt(np.mean(true_field**2)) + 1e-10)
        
        errors[name] = {
            'l2': l2_error,
            'relative': rel_error * 100
        }
        
        print(f"{name}å ´: L2={l2_error:.6f}, ç›¸å°èª¤å·®={rel_error*100:.1f}%")
    
    # å¹³å‡ç›¸å°èª¤å·®
    avg_rel_error = np.mean([errors[name]['relative'] for name in field_names])
    print(f"\nğŸ“Š å¹³å‡ç›¸å°èª¤å·®: {avg_rel_error:.1f}%")
    
    if avg_rel_error < 30.0:
        print("ğŸ‰ æˆåŠŸï¼å·²é”åˆ°<30%ç›®æ¨™ç²¾åº¦ï¼")
    else:
        print(f"âš ï¸  å°šæœªé”æ¨™ï¼Œéœ€é€²ä¸€æ­¥å„ªåŒ– (ç›®æ¨™<30%)")
    
    # ç¹ªè£½çµæœæ¯”è¼ƒ
    plot_3d_results_comparison(coords, values, pred_full, sensor_indices, errors)
    
    return errors

def plot_3d_results_comparison(coords, values, pred_values, sensor_indices, errors):
    """ç¹ªè£½3Dçµæœæ¯”è¼ƒåœ–"""
    print("ğŸ“Š ç”Ÿæˆ3Dçµæœæ¯”è¼ƒåœ–...")
    
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    field_names = ['U', 'V', 'W', 'P']
    
    for i, name in enumerate(field_names):
        # çœŸå¯¦å ´
        ax1 = axes[0, i]
        scatter1 = ax1.scatter(coords[:, 1], coords[:, 2], c=values[:, i], 
                              cmap='RdBu_r', s=1, alpha=0.6)
        ax1.scatter(coords[sensor_indices, 1], coords[sensor_indices, 2], 
                   c='black', s=30, marker='x', alpha=0.8, label='Sensors')
        ax1.set_title(f'True {name} Field')
        ax1.set_xlabel('X')
        ax1.set_ylabel('Y')
        plt.colorbar(scatter1, ax=ax1)
        
        # é æ¸¬å ´
        ax2 = axes[1, i]
        scatter2 = ax2.scatter(coords[:, 1], coords[:, 2], c=pred_values[:, i], 
                              cmap='RdBu_r', s=1, alpha=0.6)
        ax2.set_title(f'Pred {name} (Err: {errors[name]["relative"]:.1f}%)')
        ax2.set_xlabel('X')
        ax2.set_ylabel('Y')
        plt.colorbar(scatter2, ax=ax2)
    
    plt.tight_layout()
    plt.savefig('3d_enhanced_pinns_results.png', dpi=150, bbox_inches='tight')
    print("   ğŸ’¾ çµæœå·²ä¿å­˜: 3d_enhanced_pinns_results.png")
    plt.close()

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¯ Task-014: 3D Enhanced PINNs Training - ä¿®å¾©ç‰ˆ")
    print("=" * 60)
    
    try:
        model, losses, field_losses_history = train_enhanced_3d_pinns()
        print("\nğŸ‰ Task-014 3Då¢å¼·è¨“ç·´å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ è¨“ç·´éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()