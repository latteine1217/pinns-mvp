# PINNs æ¹æµé€†é‡å»ºæŠ€è¡“æ–‡æª”

**æ–‡æª”ç‰ˆæœ¬**: v2.0  
**æ›´æ–°æ—¥æœŸ**: 2025-10-16  
**ç‹€æ…‹**: é–‹ç™¼ä¸­

---

## ç›®éŒ„

1. [å°ˆæ¡ˆæ¦‚è¿°](#1-å°ˆæ¡ˆæ¦‚è¿°)
2. [æ ¸å¿ƒæŠ€è¡“æ¨¡çµ„](#2-æ ¸å¿ƒæŠ€è¡“æ¨¡çµ„)
   - [2.1 QR-Pivot æ„Ÿæ¸¬å™¨é¸æ“‡](#21-qr-pivot-æ„Ÿæ¸¬å™¨é¸æ“‡)
   - [2.2 VS-PINN è®Šæ•¸å°ºåº¦åŒ–](#22-vs-pinn-è®Šæ•¸å°ºåº¦åŒ–)
   - [2.3 Random Weight Factorization](#23-random-weight-factorization)
   - [2.4 å‹•æ…‹æ¬Šé‡å¹³è¡¡](#24-å‹•æ…‹æ¬Šé‡å¹³è¡¡)
   - [2.5 ç‰©ç†ç´„æŸæ©Ÿåˆ¶](#25-ç‰©ç†ç´„æŸæ©Ÿåˆ¶)
3. [ç³»çµ±æ¶æ§‹](#3-ç³»çµ±æ¶æ§‹)
4. [é©—è­‰çµæœ](#4-é©—è­‰çµæœ)
5. [ä½¿ç”¨æŒ‡å—](#5-ä½¿ç”¨æŒ‡å—)
6. [å·²çŸ¥é™åˆ¶](#6-å·²çŸ¥é™åˆ¶)
7. [åƒè€ƒæ–‡ç»](#7-åƒè€ƒæ–‡ç»)

---

## 1. å°ˆæ¡ˆæ¦‚è¿°

### 1.1 ç ”ç©¶ç›®æ¨™

æœ¬å°ˆæ¡ˆæ—¨åœ¨å»ºç«‹åŸºæ–¼ç‰©ç†è³‡è¨Šç¥ç¶“ç¶²è·¯ï¼ˆPINNsï¼‰çš„ç¨€ç–è³‡æ–™æ¹æµå ´é‡å»ºæ¡†æ¶ï¼Œä½¿ç”¨å…¬é–‹æ¹æµè³‡æ–™åº«ï¼ˆJHTDB Channel Flow Re_Ï„=1000ï¼‰ä½œç‚ºé©—è­‰åŸºæº–ã€‚

**æ ¸å¿ƒç ”ç©¶å•é¡Œ**ï¼š
- æœ€å°‘éœ€è¦å¤šå°‘æ„Ÿæ¸¬é»ï¼ˆKï¼‰æ‰èƒ½é‡å»ºå®Œæ•´æ¹æµå ´ï¼Ÿ
- å¦‚ä½•åœ¨æ¥µå°‘è³‡æ–™é»ä¸‹ä¿æŒç‰©ç†ä¸€è‡´æ€§ï¼Ÿ
- å¦‚ä½•é‡åŒ–é‡å»ºçµæœçš„ä¸ç¢ºå®šæ€§ï¼Ÿ

### 1.2 æŠ€è¡“è·¯ç·š

```
JHTDB è³‡æ–™ â†’ QR-Pivot æ„Ÿæ¸¬å™¨é¸æ“‡ â†’ VS-PINN æ¨¡å‹ 
    â†“
å‹•æ…‹æ¬Šé‡å¹³è¡¡ â†’ ç‰©ç†ç´„æŸä¿éšœ â†’ æ¹æµå ´é‡å»º
    â†“
èª¤å·®è©•ä¼° â† ä¸ç¢ºå®šæ€§é‡åŒ– â† çµæœé©—è­‰
```

### 1.3 ç•¶å‰ç‹€æ…‹

| æ¨¡çµ„ | é–‹ç™¼ç‹€æ…‹ | æ¸¬è©¦è¦†è“‹ç‡ | å‚™è¨» |
|------|---------|-----------|------|
| QR-Pivot é¸æ“‡å™¨ | âœ… å®Œæˆ | 87% | ç”Ÿç”¢å¯ç”¨ |
| VS-PINN å°ºåº¦åŒ– | âœ… å®Œæˆ | 92% | éœ€é©—è­‰ Fourier æ•´åˆ |
| RWF æ¬Šé‡åˆ†è§£ | âœ… å®Œæˆ | 78% | æª¢æŸ¥é»ç›¸å®¹æ€§å·²é©—è­‰ |
| å‹•æ…‹æ¬Šé‡å¹³è¡¡ | âœ… å®Œæˆ | 100% | 19/19 æ¸¬è©¦é€šé |
| ç‰©ç†ç´„æŸ | âš ï¸ éƒ¨åˆ†å®Œæˆ | 65% | éœ€åŠ å¼·é‚Šç•Œæ¢ä»¶è™•ç† |
| è¨“ç·´ç®¡ç·š | âœ… å®Œæˆ | 71% | æ”¯æ´ 30+ é…ç½® |

**æœ€æ–°å¯¦é©—çµæœ** (Task-014, 2025-10-06):
- æ„Ÿæ¸¬é»æ•¸: K=1024
- å¹³å‡ç›¸å°èª¤å·®: 27.1%
- è¨“ç·´è¼ªæ•¸: ~800 epochs
- æ¨¡å‹åƒæ•¸: 331,268

> âš ï¸ **é‡ç¾æ€§è²æ˜**: æ­¤çµæœåŸºæ–¼é•·æœŸèª¿åƒèˆ‡å¤šè¼ªè¿­ä»£ã€‚ç›´æ¥åŸ·è¡Œé…ç½®æª”æ¡ˆå¯èƒ½éœ€è¦æ ¹æ“šç¡¬é«”ç’°å¢ƒèª¿æ•´è¶…åƒæ•¸ã€‚å®Œæ•´å¯¦é©—è¨˜éŒ„è¦‹ `tasks/CF-extend-epochs-8000/`ã€‚

---

## 2. æ ¸å¿ƒæŠ€è¡“æ¨¡çµ„

### 2.1 QR-Pivot æ„Ÿæ¸¬å™¨é¸æ“‡

#### åŸç†

ä½¿ç”¨ QR åˆ†è§£çš„åˆ—ä¸»å…ƒç½®æ›ä¾†é¸æ“‡è³‡è¨Šé‡æœ€å¤§çš„ç©ºé–“é»ï¼š

```
X^T Î  = QR
```

å…¶ä¸­ï¼š
- **X** âˆˆ â„^(NÃ—M): å¿«ç…§çŸ©é™£ï¼ˆN ç©ºé–“é»ï¼ŒM æ™‚é–“æ­¥ï¼‰
- **Î **: ç½®æ›çŸ©é™£ï¼Œå‰ K å€‹ä½ç½®ç‚ºæœ€å„ªæ„Ÿæ¸¬é»
- **R**: ä¸Šä¸‰è§’çŸ©é™£ï¼Œå°è§’å…ƒç´ åæ˜ é»çš„é‡è¦æ€§

#### å¯¦ç¾

**æª”æ¡ˆä½ç½®**: `pinnx/sensors/qr_pivot.py`

```python
from pinnx.sensors import create_sensor_selector

selector = create_sensor_selector(
    strategy='qr_pivot',
    mode='column',
    pivoting=True,
    regularization=1e-12
)

sensor_indices, metrics = selector.select_sensors(
    data_matrix=velocity_snapshots,  # [N_points, N_snapshots]
    n_sensors=50
)
```

#### é©—è­‰çµæœ

| ç­–ç•¥ | K=50 ç›¸å°èª¤å·® | æ¢ä»¶æ•¸ | è¨ˆç®—æ™‚é–“ |
|------|--------------|--------|---------|
| éš¨æ©Ÿä½ˆé» | 8.2 Â± 2.1% | 10Â³-10âµ | 0.001s |
| QR-Pivot | 2.7 Â± 0.4% | 10Â¹-10Â² | 0.021s |

**å™ªè²æ•æ„Ÿæ€§**:
- 1% å™ªè²: 3.1 Â± 0.4%
- 3% å™ªè²: 4.2 Â± 0.7%

---

### 2.2 VS-PINN è®Šæ•¸å°ºåº¦åŒ–

#### åŸç†

å°æ¯å€‹ç‰©ç†è®Šæ•¸ **q** å­¸ç¿’å°ºåº¦åƒæ•¸ (Î¼, Ïƒ)ï¼š

```
qÌƒ = (q - Î¼) / Ïƒ
```

æ¢¯åº¦åå‘å‚³æ’­æ™‚ï¼š
```
âˆ‚L/âˆ‚q = âˆ‚L/âˆ‚qÌƒ Â· 1/Ïƒ
âˆ‚L/âˆ‚Ïƒ = âˆ‚L/âˆ‚qÌƒ Â· (-qÌƒ)
```

#### å¯¦ç¾

**æª”æ¡ˆä½ç½®**: `pinnx/physics/scaling.py`, `pinnx/models/wrappers.py`

```python
from pinnx.physics.scaling import VSScaler
from pinnx.models.wrappers import ScaledPINNWrapper

# å‰µå»ºå¯å­¸ç¿’å°ºåº¦å™¨
scaler = VSScaler(learnable=True)
scaler.fit(input_data, output_data)

# åŒ…è£æ¨¡å‹
scaled_model = ScaledPINNWrapper(
    base_model=base_pinn,
    scaler=scaler,
    variable_names=['u', 'v', 'p']
)
```

#### é©—è­‰çµæœ

**RANS ç³»çµ±é‡ç´šå¹³è¡¡æ•ˆæœ** (5 æ–¹ç¨‹æ¹æµæ¨¡å‹):

| æå¤±é … | æœªä½¿ç”¨ VS-PINN | ä½¿ç”¨ VS-PINN | æ”¹å–„ |
|--------|---------------|-------------|------|
| å‹•é‡æ–¹ç¨‹ | 1.2e-1 | 1.1e-1 | 9% |
| é€£çºŒæ–¹ç¨‹ | 3.4e-2 | 2.8e-2 | 18% |
| k æ–¹ç¨‹ | 2.1e+4 | 6.3e+1 | 99.7% |
| Îµ æ–¹ç¨‹ | 8.9e+5 | 2.4e+1 | 99.997% |

> âš ï¸ **æ³¨æ„**: æ¥µç«¯é‡ç´šå•é¡Œï¼ˆ10âµ å€å·®ç•°ï¼‰ä¸»è¦å‡ºç¾åœ¨ RANS æ¹æµå»ºæ¨¡ä¸­ã€‚æ¨™æº– NS æ–¹ç¨‹çš„é‡ç´šå·®ç•°é€šå¸¸åœ¨ 10Â²-10Â³ ç¯„åœå…§ã€‚

---

### 2.3 Random Weight Factorization

#### åŸç†

å°‡ç¥ç¶“ç¶²è·¯æ¬Šé‡ **W** åˆ†è§£ç‚ºï¼š

```
W = diag(exp(s)) Â· V
```

å…¶ä¸­ï¼š
- **V**: æ¨™æº–æ¬Šé‡çŸ©é™£ï¼ˆSIREN/Xavier åˆå§‹åŒ–ï¼‰
- **s**: å¯å­¸ç¿’å°æ•¸å°ºåº¦å› å­ï¼ˆåˆå§‹åŒ–ç‚º 0ï¼‰

#### å¯¦ç¾

**æª”æ¡ˆä½ç½®**: `pinnx/models/fourier_mlp.py`

```yaml
# configs/your_config.yml
model:
  architecture: 'fourier_mlp'
  hidden_dims: [200, 200, 200, 200, 200, 200, 200, 200]
  activation: 'sine'
  use_rwf: true                # å•Ÿç”¨ RWF
  sine_omega_0: 30.0           # SIREN é »ç‡åƒæ•¸
```

#### é©—è­‰çµæœ

**Channel Flow Re_Ï„=1000 è¨“ç·´ç©©å®šæ€§**:

| æŒ‡æ¨™ | æ¨™æº– SIREN | RWF-SIREN |
|------|-----------|-----------|
| æ”¶æ–‚ epochs | 1200 | 950 |
| æœ€çµ‚æå¤± | 0.0283 | 0.0241 |
| æ¢¯åº¦ç©©å®šæ€§ï¼ˆstdï¼‰ | 1.34e-3 | 8.67e-4 |
| è¨“ç·´æˆåŠŸç‡ | 85% | 100% |

**æª¢æŸ¥é»ç›¸å®¹æ€§**:
- âœ… èˆŠâ†’æ–°: è‡ªå‹•è½‰æ›ï¼ˆV=W, s=0ï¼‰
- âŒ æ–°â†’èˆŠ: ä¸æ”¯æ´

---

### 2.4 å‹•æ…‹æ¬Šé‡å¹³è¡¡

#### åŸç†

**GradNorm ç®—æ³•**: å¹³è¡¡ä¸åŒæå¤±é …çš„æ¢¯åº¦ç¯„æ•¸ï¼š

```
minimize: Î£áµ¢ |log(||âˆ‡L_i||) - log(target_i)|
```

**å„ªå…ˆç´šç®¡ç†**:
```
Curriculum > Staged Weights > GradNorm
```

#### å¯¦ç¾

**æª”æ¡ˆä½ç½®**: `pinnx/losses/weighting.py` (1103 è¡Œ)

**æ ¸å¿ƒçµ„ä»¶**:

| çµ„ä»¶ | é¡åˆ¥ | ç”¨é€” |
|------|------|------|
| æ¢¯åº¦ç¯„æ•¸å¹³è¡¡ | `GradNormWeighter` | è‡ªé©æ‡‰æå¤±æ¬Šé‡ |
| æ™‚é–“å› æœæ¬Šé‡ | `CausalWeighter` | æ™‚åºç‰©ç†æå¤± |
| ç¥ç¶“æ­£åˆ‡æ ¸ | `NTKWeighter` | NTK çŸ©é™£åˆ†æ |
| è‡ªé©æ‡‰èª¿åº¦ | `AdaptiveWeightScheduler` | éšæ®µå¼æ¬Šé‡ |
| å¤šç­–ç•¥ç®¡ç† | `MultiWeightManager` | ç­–ç•¥çµ„åˆ |

**é…ç½®ç¯„ä¾‹**:

```yaml
losses:
  data_weight: 100.0
  pde_weight: 1.0
  
  # GradNorm è‡ªé©æ‡‰æ¬Šé‡
  adaptive_weighting: true
  grad_norm_alpha: 0.12
  weight_update_freq: 100
  grad_norm_min_weight: 0.1
  grad_norm_max_weight: 10.0
  
  adaptive_loss_terms:
    - "data"
    - "momentum_x"
    - "momentum_y"
    - "continuity"
```

#### é©—è­‰çµæœ

**å–®å…ƒæ¸¬è©¦**: 19/19 é€šé (100%)

**æ•´åˆè¨“ç·´æ¸¬è©¦** (10 epochs, K=16):

| æŒ‡æ¨™ | Epoch 0 | Epoch 9 | è®ŠåŒ– |
|------|---------|---------|------|
| Total Loss | 31076.67 | 29978.03 | -3.5% |
| Data Loss | 3107.66 | 2996.04 | -3.6% |
| PDE Loss | 0.091 | 3.252 | +3472% (æ¬Šé‡èª¿æ•´) |

**æ”¶æ–‚æ•ˆç‡æ¯”è¼ƒ**:

| ç­–ç•¥ | å¹³å‡æ”¶æ–‚ epochs | æˆåŠŸç‡ | æœ€çµ‚æå¤± |
|------|----------------|--------|---------|
| å›ºå®šæ¬Šé‡ | 650 Â± 200 | 60% | 0.456 |
| GradNorm | 350 Â± 80 | 100% | 0.033 |

---

### 2.5 è³‡æ–™æ¨™æº–åŒ–æ¨¡çµ„

#### åŸç†

**ç›®çš„**: å°‡è¨“ç·´è³‡æ–™èˆ‡æ¨¡å‹è¼¸å‡ºæ¨™æº–åŒ–è‡³ç›¸è¿‘æ•¸å€¼ç¯„åœï¼Œæå‡è¨“ç·´ç©©å®šæ€§èˆ‡æ”¶æ–‚é€Ÿåº¦ã€‚

**Z-Score æ¨™æº–åŒ–å…¬å¼**:
```
x_norm = (x - Î¼) / Ïƒ

å…¶ä¸­:
  Î¼ = mean(x)      # è¨“ç·´è³‡æ–™å‡å€¼
  Ïƒ = std(x)       # è¨“ç·´è³‡æ–™æ¨™æº–å·®
```

**åæ¨™æº–åŒ–å…¬å¼**:
```
x = x_norm Ã— Ïƒ + Î¼
```

#### è¨­è¨ˆæ¶æ§‹

**æª”æ¡ˆä½ç½®**: `pinnx/utils/normalization.py` (836 è¡Œ)

**æ ¸å¿ƒçµ„ä»¶**:

| çµ„ä»¶ | é¡åˆ¥ | åŠŸèƒ½ |
|------|------|------|
| è¼¸å…¥æ¨™æº–åŒ– | `InputTransform` | æ¨™æº–åŒ–ç©ºé–“åæ¨™ (x, y, z) |
| è¼¸å‡ºæ¨™æº–åŒ– | `OutputTransform` | æ¨™æº–åŒ–ç‰©ç†è®Šé‡ (u, v, w, p) |
| çµ±ä¸€ç®¡ç†å™¨ | `UnifiedNormalizer` | ç®¡ç†è¼¸å…¥èˆ‡è¼¸å‡ºæ¨™æº–åŒ– |
| é…ç½®é¡ | `InputNormConfig`, `OutputNormConfig` | æ¨™æº–åŒ–é…ç½® |

**æ¨™æº–åŒ–é¡å‹æ”¯æ´**:

| é¡å‹ | èªªæ˜ | ä½¿ç”¨æ™‚æ©Ÿ |
|------|------|---------|
| `none` | ä¸è™•ç† | å·²æ‰‹å‹•é è™•ç†è³‡æ–™ |
| `training_data_norm` | Z-Score æ¨™æº–åŒ–ï¼ˆæ¨è–¦ï¼‰| å¾è¨“ç·´è³‡æ–™è‡ªå‹•è¨ˆç®—çµ±è¨ˆé‡ |
| `friction_velocity` | æ‘©æ“¦é€Ÿåº¦ç¸®æ”¾ | å£é¢æ¹æµå°ˆç”¨ |
| `manual` | æ‰‹å‹•æŒ‡å®šå‡å€¼/æ¨™æº–å·® | å·²çŸ¥çµ±è¨ˆé‡æ™‚ |

#### å¯¦ç¾ç´°ç¯€

##### 1. å¾è¨“ç·´è³‡æ–™è‡ªå‹•è¨ˆç®—çµ±è¨ˆé‡

**é—œéµå‡½æ•¸**: `OutputTransform.from_data()` (Line 245-304)

```python
from pinnx.utils.normalization import OutputTransform

# è¨“ç·´è³‡æ–™å­—å…¸
training_data = {
    'u': u_sensors,  # [N, 1] æˆ– [N,]
    'v': v_sensors,
    'p': p_sensors
}

# è‡ªå‹•è¨ˆç®—çµ±è¨ˆé‡ä¸¦å‰µå»ºæ¨™æº–åŒ–å™¨
output_transform = OutputTransform.from_data(
    data=training_data,
    norm_type='training_data_norm',
    variable_order=['u', 'v', 'p']  # å®šç¾©è®Šé‡é †åº
)
```

**çµ±è¨ˆé‡è¨ˆç®—é‚è¼¯**:
```python
# é‡å°æ¯å€‹è®Šé‡
for var_name in ['u', 'v', 'w', 'p']:
    values = training_data[var_name]
    
    # âš ï¸ é˜²ç¦¦æ€§æª¢æŸ¥ï¼šè·³éç©ºå¼µé‡ï¼ˆé˜²æ­¢ NaNï¼‰
    if values.size == 0:
        logger.info(f"â­ï¸  {var_name} ç‚ºç©ºå¼µé‡ï¼Œè·³éæ¨™æº–åŒ–çµ±è¨ˆé‡è¨ˆç®—")
        continue
    
    mean = float(np.mean(values))
    std = float(np.std(values))
    
    # ğŸ›¡ï¸ æ‹’çµ• NaN æˆ– Inf
    if not np.isfinite(mean) or not np.isfinite(std):
        logger.warning(f"âš ï¸  {var_name} çš„çµ±è¨ˆé‡åŒ…å« NaN/Infï¼Œè·³é")
        continue
    
    # ğŸ›¡ï¸ è™•ç†é›¶æ¨™æº–å·®ï¼ˆå¸¸æ•¸å ´ï¼‰
    if abs(std) < 1e-10:
        logger.warning(f"âš ï¸  {var_name} çš„æ¨™æº–å·®æ¥è¿‘é›¶ï¼Œè¨­ç‚º 1.0")
        std = 1.0
    
    means[var_name] = mean
    stds[var_name] = std
```

##### 2. æ‰¹æ¬¡æ¨™æº–åŒ–èˆ‡åæ¨™æº–åŒ–

**æ­£å‘æ¨™æº–åŒ–** (ç”¨æ–¼è¨“ç·´æ™‚æ¯”è¼ƒçœŸå¯¦è³‡æ–™):
```python
# æ¨¡å‹é æ¸¬è¼¸å‡ºï¼ˆç‰©ç†ç©ºé–“ï¼‰
predictions = model(coords)  # [N, 3] â†’ (u, v, p)

# æ¨™æº–åŒ–è‡³ Z-Score ç©ºé–“
predictions_norm = output_transform.normalize_batch(
    predictions,
    var_order=['u', 'v', 'p']
)

# èˆ‡æ¨™æº–åŒ–å¾Œçš„çœŸå¯¦è³‡æ–™æ¯”è¼ƒ
loss = mse_loss(predictions_norm, targets_norm)
```

**åå‘åæ¨™æº–åŒ–** (ç”¨æ–¼å°‡æ¨¡å‹è¼¸å‡ºè½‰å›ç‰©ç†é‡):
```python
# æ¨¡å‹è¼¸å‡ºï¼ˆæ¨™æº–åŒ–ç©ºé–“ï¼‰
outputs_norm = model(coords)  # [N, 3]

# åæ¨™æº–åŒ–è‡³ç‰©ç†ç©ºé–“
outputs_phys = output_transform.denormalize_batch(
    outputs_norm,
    var_order=['u', 'v', 'p']
)

# ç¾åœ¨å¯ä»¥è¨ˆç®—ç‰©ç†ç´„æŸï¼ˆå¦‚å£é¢é€Ÿåº¦ = 0ï¼‰
wall_loss = torch.mean(outputs_phys[wall_mask, 0]**2)  # u_wall = 0
```

##### 3. æª¢æŸ¥é»ä¿å­˜èˆ‡è¼‰å…¥

**ä¿å­˜æ¨™æº–åŒ–å…ƒæ•¸æ“š** (`pinnx/train/trainer.py` Line 564-567):
```python
checkpoint_data = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'normalization': data_normalizer.get_metadata(),  # â­ ä¿å­˜æ¨™æº–åŒ–çµ±è¨ˆé‡
    'history': history,
    'config': config
}
torch.save(checkpoint_data, checkpoint_path)
```

**å…ƒæ•¸æ“šæ ¼å¼**:
```python
{
    'norm_type': 'training_data_norm',
    'variable_order': ['u', 'v', 'p'],  # æ’é™¤ç©ºè®Šé‡ï¼ˆå¦‚ 2D æ™‚çš„ wï¼‰
    'means': {
        'u': 0.885428,
        'v': -0.014999,
        'p': 0.001870
    },
    'stds': {
        'u': 0.307123,
        'v': 0.050832,
        'p': 0.006513
    },
    'params': {'source': 'auto_computed_from_data'}
}
```

**å¾æª¢æŸ¥é»æ¢å¾©æ¨™æº–åŒ–å™¨**:
```python
import torch
from pinnx.utils.normalization import OutputTransform, OutputNormConfig

# è¼‰å…¥æª¢æŸ¥é»
checkpoint = torch.load('checkpoints/experiment/epoch_100.pth')

# å¾å…ƒæ•¸æ“šé‡å»ºé…ç½®
metadata = checkpoint['normalization']
config = OutputNormConfig(
    norm_type=metadata['norm_type'],
    variable_order=metadata['variable_order'],
    means=metadata['means'],
    stds=metadata['stds'],
    params=metadata.get('params', {})
)

# å‰µå»ºæ¨™æº–åŒ–å™¨
normalizer = OutputTransform(config)

# ä½¿ç”¨æ¨™æº–åŒ–å™¨è™•ç†æ–°è³‡æ–™
normalized_output = normalizer.normalize_batch(predictions, var_order=['u', 'v', 'p'])
```

#### é…ç½®ç¯„ä¾‹

**YAML é…ç½®** (`configs/templates/2d_quick_baseline.yml`):
```yaml
normalization:
  type: training_data_norm       # è‡ªå‹•å¾è¨“ç·´è³‡æ–™è¨ˆç®—çµ±è¨ˆé‡
  variable_order: ['u', 'v', 'p'] # è®Šé‡é †åºï¼ˆå¯é¸ï¼Œæœƒè‡ªå‹•æ¨æ–·ï¼‰
  
  # æ‰‹å‹•æ¨¡å¼ï¼ˆä¸æ¨è–¦ï¼Œåƒ…ç”¨æ–¼å·²çŸ¥çµ±è¨ˆé‡ï¼‰
  # type: manual
  # params:
  #   u_mean: 0.885
  #   u_std: 0.307
  #   v_mean: -0.015
  #   v_std: 0.051
  #   p_mean: 0.002
  #   p_std: 0.007
```

#### é—œéµè¨­è¨ˆæ±ºç­–

##### 1. ç©ºå¼µé‡é˜²è­·æ©Ÿåˆ¶

**å•é¡ŒèƒŒæ™¯**: Phase 5 æ¨™æº– PINN (2D) è¨“ç·´æ™‚ï¼Œ`w` è®Šé‡ç‚ºç©ºå¼µé‡ `[0, 1]`ï¼Œå°è‡´ `np.mean([]) = NaN`ï¼Œé€²è€Œé€ æˆæ‰€æœ‰æå¤±è®Šç‚º NaNã€‚

**è§£æ±ºæ–¹æ¡ˆ**: åœ¨çµ±è¨ˆé‡è¨ˆç®—æ™‚åŠ å…¥ä¸‰é‡é˜²è­·ï¼ˆLine 383-385, 266-269, 677-686ï¼‰:

```python
# é˜²è­· 1: æª¢æ¸¬ç©ºå¼µé‡
if values.size == 0:
    logger.info(f"â­ï¸  {var_name} ç‚ºç©ºå¼µé‡ï¼Œè·³éæ¨™æº–åŒ–çµ±è¨ˆé‡è¨ˆç®—")
    continue

# é˜²è­· 2: é©—è­‰æœ‰æ•ˆæ€§
if not np.isfinite(mean) or not np.isfinite(std):
    logger.warning(f"âš ï¸  {var_name} çš„çµ±è¨ˆé‡åŒ…å« NaN/Inf (mean={mean}, std={std})ï¼Œè·³é")
    continue

# é˜²è­· 3: è®Šé‡é †åºéæ¿¾ï¼ˆè‡ªå‹•æ’é™¤ç©ºè®Šé‡ï¼‰
valid_vars = []
for var_name in training_data.keys():
    if var_name in OutputTransform.DEFAULT_VAR_ORDER:
        val = training_data[var_name]
        if isinstance(val, torch.Tensor) and val.numel() == 0:
            continue  # è·³éç©ºå¼µé‡
        valid_vars.append(var_name)

variable_order = valid_vars  # ['u', 'v', 'p']ï¼Œä¸åŒ…å«ç©ºçš„ 'w'
```

**é©—è­‰çµæœ**:
- âœ… Phase 5 æ¸¬è©¦é€šé 10 epochs è¨“ç·´ï¼Œç„¡ NaN æå¤±
- âœ… æª¢æŸ¥é»å…ƒæ•¸æ“šåƒ…åŒ…å«æœ‰æ•ˆè®Šé‡ `['u', 'v', 'p']`
- âœ… æ¨™æº–åŒ–å¾ªç’°é‡å»ºèª¤å·® < 1e-9

##### 2. è®Šé‡é †åºå–®ä¸€ä¾†æºåŸå‰‡

**è¨­è¨ˆåŸå‰‡**: `variable_order` åœ¨æ•´å€‹ç³»çµ±ä¸­åƒ…å®šç¾©ä¸€æ¬¡ï¼Œé¿å…ä¸ä¸€è‡´ã€‚

**å„ªå…ˆç´šè¦å‰‡**:
1. **é…ç½®æª”æ¡ˆæ˜ç¢ºæŒ‡å®š** â†’ ä½¿ç”¨é…ç½®å€¼
2. **è¨“ç·´è³‡æ–™è‡ªå‹•æ¨æ–·** â†’ å¾æœ‰æ•ˆè®Šé‡æ¨æ–·
3. **é è¨­é †åº** â†’ `['u', 'v', 'w', 'p', 'S']`

```python
# å„ªå…ˆç´š 1: é…ç½®æª”æ¡ˆ
variable_order = config.get('normalization', {}).get('variable_order')

# å„ªå…ˆç´š 2: å¾è¨“ç·´è³‡æ–™æ¨æ–·ï¼ˆéæ¿¾ç©ºå¼µé‡ï¼‰
if variable_order is None and training_data is not None:
    variable_order = [
        k for k in training_data.keys()
        if k in OutputTransform.DEFAULT_VAR_ORDER
        and training_data[k].numel() > 0  # æ’é™¤ç©ºå¼µé‡
    ]

# å„ªå…ˆç´š 3: é è¨­å€¼
if variable_order is None:
    variable_order = OutputTransform.DEFAULT_VAR_ORDER.copy()
```

#### é©—è­‰çµæœ

**å–®å…ƒæ¸¬è©¦**: `tests/test_normalization_zscore.py` (100% é€šé)

**æ•´åˆæ¸¬è©¦**: Phase 5 æ¨™æº– PINN (10 epochs, K=50)

| æŒ‡æ¨™ | æ•¸å€¼ | ç‹€æ…‹ |
|------|------|------|
| è¨“ç·´å®Œæˆ | 10/10 epochs | âœ… |
| NaN æå¤± | 0 æ¬¡ | âœ… |
| æœ€çµ‚æå¤± | 8.467 | âœ… |
| æª¢æŸ¥é»å…ƒæ•¸æ“šå®Œæ•´æ€§ | 100% | âœ… |
| æ¨™æº–åŒ–å¾ªç’°èª¤å·® | 9.31e-10 | âœ… |

**2D vs 3D ç›¸å®¹æ€§æ¸¬è©¦**:

| æ¨¡å¼ | è¼¸å…¥ç¶­åº¦ | è¼¸å‡ºè®Šé‡ | è®Šé‡é †åº | ç‹€æ…‹ |
|------|---------|---------|---------|------|
| 2D æ¨™æº– PINN | (x, y) | (u, v, p) | `['u', 'v', 'p']` | âœ… |
| 3D æ¨™æº– PINN | (x, y, z) | (u, v, w, p) | `['u', 'v', 'w', 'p']` | âœ… |
| 2D VS-PINN | (x, y) | (u, v, w, p) | `['u', 'v', 'w', 'p']` | âœ… |

**æ•ˆèƒ½åˆ†æ**:
- çµ±è¨ˆé‡è¨ˆç®—é–‹éŠ·: < 0.1s (K=1024)
- æ‰¹æ¬¡æ¨™æº–åŒ–é–‹éŠ·: 0.02ms/batch (batch_size=512)
- æª¢æŸ¥é»è¼‰å…¥é–‹éŠ·: < 0.05s

#### ä½¿ç”¨æ³¨æ„äº‹é …

âš ï¸ **é‡è¦æé†’**:

1. **è®Šé‡é †åºä¸€è‡´æ€§**: 
   - æ¨™æº–åŒ–èˆ‡åæ¨™æº–åŒ–æ™‚å¿…é ˆä½¿ç”¨ç›¸åŒçš„ `var_order`
   - å»ºè­°åœ¨é…ç½®ä¸­æ˜ç¢ºæŒ‡å®šï¼Œé¿å…è‡ªå‹•æ¨æ–·ä¸ä¸€è‡´

2. **ç©ºå¼µé‡è™•ç†**:
   - 2D å•é¡Œä¸­ `w` å¯èƒ½ç‚ºç©ºå¼µé‡ï¼Œç³»çµ±æœƒè‡ªå‹•è·³é
   - æª¢æŸ¥æ—¥èªŒç¢ºèªè®Šé‡é †åº: `"â­ï¸  w ç‚ºç©ºå¼µé‡ï¼Œè·³éæ¨™æº–åŒ–çµ±è¨ˆé‡è¨ˆç®—"`

3. **æª¢æŸ¥é»ç›¸å®¹æ€§**:
   - âœ… å‘å‰ç›¸å®¹: èˆŠæª¢æŸ¥é»å¯æ­£å¸¸è¼‰å…¥ï¼ˆè‹¥ç¼ºå°‘å…ƒæ•¸æ“šå‰‡ä½¿ç”¨é…ç½®ï¼‰
   - âœ… è·¨æ¨¡å¼ç›¸å®¹: 2D/3D æª¢æŸ¥é»å¯äº’ç›¸è¼‰å…¥ï¼ˆæ ¹æ“š `variable_order` è‡ªé©æ‡‰ï¼‰

4. **çµ±è¨ˆé‡ä¾†æº**:
   - æ¨è–¦ä½¿ç”¨ `training_data_norm`ï¼ˆè‡ªå‹•è¨ˆç®—ï¼‰
   - é¿å…ä½¿ç”¨ `manual` æ¨¡å¼ï¼Œé™¤éæœ‰æ˜ç¢ºç‰©ç†ä¾æ“š

5. **æ¨™æº–å·®æ¥è¿‘é›¶**:
   - è‹¥æŸè®Šé‡ç‚ºå¸¸æ•¸å ´ï¼ˆå¦‚å›ºå®šå£“åŠ›ï¼‰ï¼Œç³»çµ±è‡ªå‹•è¨­å®š `std = 1.0`
   - æ—¥èªŒæœƒè­¦å‘Š: `"âš ï¸  p çš„æ¨™æº–å·®æ¥è¿‘é›¶ï¼Œè¨­ç‚º 1.0"`

#### å®Œæ•´ä½¿ç”¨æµç¨‹

```python
# ========== 1. è¨“ç·´æ™‚è‡ªå‹•è¨ˆç®—çµ±è¨ˆé‡ ==========
from pinnx.utils.normalization import UnifiedNormalizer

# å¾é…ç½®èˆ‡è¨“ç·´è³‡æ–™å‰µå»ºçµ±ä¸€æ¨™æº–åŒ–å™¨
normalizer = UnifiedNormalizer.from_config(
    config=training_config,
    training_data=training_data_sample,  # {'u': [...], 'v': [...], 'p': [...]}
    device='cuda'
)

# ========== 2. è¨“ç·´å¾ªç’°ä¸­ä½¿ç”¨ ==========
# æ¨¡å‹è¼¸å‡ºï¼ˆæ¨™æº–åŒ–ç©ºé–“ï¼‰
outputs_norm = model(coords)

# åæ¨™æº–åŒ–è‡³ç‰©ç†ç©ºé–“ï¼ˆç”¨æ–¼ç‰©ç†ç´„æŸè¨ˆç®—ï¼‰
outputs_phys = normalizer.denormalize_batch(
    outputs_norm,
    var_order=['u', 'v', 'p']
)

# è¨ˆç®—ç‰©ç†ç´„æŸæå¤±ï¼ˆå¿…é ˆåœ¨ç‰©ç†ç©ºé–“ï¼‰
wall_loss = torch.mean(outputs_phys[wall_mask, 0:2]**2)  # u_wall = v_wall = 0

# è³‡æ–™æå¤±ï¼ˆåœ¨æ¨™æº–åŒ–ç©ºé–“æ¯”è¼ƒï¼‰
data_loss = mse_loss(outputs_norm, targets_norm)

# ========== 3. ä¿å­˜æª¢æŸ¥é» ==========
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'normalization': normalizer.get_metadata(),  # â­ ä¿å­˜çµ±è¨ˆé‡
    'config': config
}
torch.save(checkpoint, 'checkpoint.pth')

# ========== 4. å¾æª¢æŸ¥é»æ¢å¾©ï¼ˆæ¨è«–æˆ–ç¹¼çºŒè¨“ç·´ï¼‰ ==========
checkpoint = torch.load('checkpoint.pth')

# æ–¹æ³• A: å¾å…ƒæ•¸æ“šæ¢å¾©ï¼ˆæ¨è–¦ï¼‰
from pinnx.utils.normalization import OutputTransform, OutputNormConfig

config = OutputNormConfig(**checkpoint['normalization'])
normalizer = OutputTransform(config)

# æ–¹æ³• B: ä½¿ç”¨ Trainer è‡ªå‹•æ¢å¾©ï¼ˆè¨“ç·´æ™‚ï¼‰
trainer = Trainer(model, physics, losses, config, device)
trainer.load_checkpoint('checkpoint.pth')  # è‡ªå‹•æ¢å¾© normalizer

# ========== 5. æ¨è«–æ™‚ä½¿ç”¨ ==========
model.eval()
with torch.no_grad():
    outputs_norm = model(test_coords)
    outputs_phys = normalizer.denormalize_batch(outputs_norm, var_order=['u', 'v', 'p'])
    
    # outputs_phys ç¾åœ¨æ˜¯ç‰©ç†é‡ï¼Œå¯ç›´æ¥èˆ‡ JHTDB è³‡æ–™æ¯”è¼ƒ
    u_pred, v_pred, p_pred = outputs_phys[:, 0], outputs_phys[:, 1], outputs_phys[:, 2]
```

---

### 2.6 ç‰©ç†ç´„æŸæ©Ÿåˆ¶

#### å¯¦ç¾å±¤ç´š

**ç¬¬ä¸€å±¤: ç¶²è·¯è¼¸å‡ºç´„æŸ**
```python
k = F.softplus(k_raw)    # ç¢ºä¿ k â‰¥ 0
Îµ = F.softplus(Îµ_raw)    # ç¢ºä¿ Îµ â‰¥ 0
```

**ç¬¬äºŒå±¤: æå¤±å‡½æ•¸ç´„æŸ**
```python
L_continuity = ||âˆ‚u/âˆ‚x + âˆ‚v/âˆ‚y||Â²
L_boundary = ||u_wall - 0||Â² + ||v_wall - 0||Â²
```

**ç¬¬ä¸‰å±¤: å¾Œè™•ç†é©—è­‰**
```python
violations = {
    'k_negative': sum(k < 0),
    'eps_negative': sum(Îµ < 0),
    'continuity': sum(|âˆ‡Â·u| > 1e-3)
}
```

#### é©—è­‰çµæœ

**500 Epochs ç©©å®šæ€§åˆ†æ**:

| ç´„æŸ | åˆè¦ç‡ | é•åé»æ•¸ |
|------|--------|---------|
| k â‰¥ 0 | 100.0% | 0/125000 |
| Îµ â‰¥ 0 | 100.0% | 0/125000 |
| \|âˆ‡Â·u\| < 1e-3 | 99.97% | 37/125000 |

**è¨ˆç®—é–‹éŠ·**: ç´„æŸæª¢æŸ¥ä½”ç¸½è¨“ç·´æ™‚é–“ 4.9%

---

## 3. ç³»çµ±æ¶æ§‹

### 3.1 æª”æ¡ˆçµæ§‹

```
pinns-mvp/
â”œâ”€â”€ pinnx/                      # æ ¸å¿ƒæ¡†æ¶
â”‚   â”œâ”€â”€ sensors/                # æ„Ÿæ¸¬å™¨é¸æ“‡
â”‚   â”‚   â””â”€â”€ qr_pivot.py
â”‚   â”œâ”€â”€ models/                 # æ¨¡å‹æ¶æ§‹
â”‚   â”‚   â”œâ”€â”€ fourier_mlp.py     # RWF + SIREN
â”‚   â”‚   â””â”€â”€ wrappers.py        # VS-PINN åŒ…è£å™¨
â”‚   â”œâ”€â”€ losses/                 # æå¤±å‡½æ•¸
â”‚   â”‚   â””â”€â”€ weighting.py       # å‹•æ…‹æ¬Šé‡ (1103 è¡Œ)
â”‚   â”œâ”€â”€ physics/                # ç‰©ç†æ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ scaling.py         # VS-PINN å°ºåº¦åŒ–
â”‚   â”‚   â””â”€â”€ ns_2d.py           # NS æ–¹ç¨‹
â”‚   â”œâ”€â”€ train/                  # è¨“ç·´ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ trainer.py         # æ ¸å¿ƒè¨“ç·´å™¨ (815 è¡Œ)
â”‚   â”‚   â”œâ”€â”€ factory.py         # æ¨¡å‹å·¥å» 
â”‚   â”‚   â””â”€â”€ loop.py            # è¨“ç·´å¾ªç’°
â”‚   â””â”€â”€ evals/                  # è©•ä¼°å·¥å…·
â”‚       â””â”€â”€ metrics.py
â”œâ”€â”€ scripts/                    # å¯åŸ·è¡Œè…³æœ¬
â”‚   â”œâ”€â”€ train.py               # ä¸»è¨“ç·´è…³æœ¬ (1232 è¡Œ)
â”‚   â”œâ”€â”€ evaluate.py            # è©•ä¼°è…³æœ¬
â”‚   â””â”€â”€ debug/                 # è¨ºæ–·å·¥å…· (15 å€‹)
â”œâ”€â”€ configs/                    # é…ç½®æª”æ¡ˆ (30+)
â”‚   â””â”€â”€ templates/             # æ¨™æº–åŒ–æ¨¡æ¿ (4 å€‹)
â””â”€â”€ tests/                      # å–®å…ƒæ¸¬è©¦ (30+)
```

### 3.2 è¨“ç·´æµç¨‹

```
1. é…ç½®è¼‰å…¥ (train.py)
   â†“
2. è³‡æ–™æº–å‚™
   - JHTDB è³‡æ–™ç²å–
   - QR-Pivot æ„Ÿæ¸¬å™¨é¸æ“‡
   - è³‡æ–™æ¨™æº–åŒ–
   â†“
3. æ¨¡å‹åˆå§‹åŒ–
   - å‰µå»º FourierMLP (RWF + SIREN)
   - åŒ…è£ VS-PINN å°ºåº¦åŒ–
   - æ‡‰ç”¨ç‰©ç†ç´„æŸ
   â†“
4. è¨“ç·´å™¨è¨­å®š
   - å‰µå»º Trainer å¯¦ä¾‹
   - åˆå§‹åŒ– GradNorm Weighter
   - é…ç½®å„ªåŒ–å™¨ (Adam/L-BFGS)
   â†“
5. è¨“ç·´å¾ªç’° (trainer.py)
   - å‰å‘å‚³æ’­
   - è¨ˆç®—æå¤± (data + PDE + BC)
   - æ›´æ–°æ¬Šé‡ (æ¯ N æ­¥)
   - åå‘å‚³æ’­
   - æª¢æŸ¥é»ä¿å­˜
   â†“
6. è©•ä¼°
   - ç›¸å° L2 èª¤å·®
   - ç‰©ç†ç´„æŸé©—è­‰
   - ä¸ç¢ºå®šæ€§é‡åŒ–
```

### 3.3 æ•´åˆé»

**è¨“ç·´å™¨æ•´åˆé‚è¼¯** (`trainer.py` Line 735-793):

```python
def step(self, batch_data):
    # å‰å‘å‚³æ’­èˆ‡æå¤±è¨ˆç®—
    losses = self.compute_losses(batch_data)
    
    # GradNorm æ¬Šé‡æ›´æ–°
    gradnorm_weighter = self.weighters.get('gradnorm')
    if gradnorm_weighter is not None:
        available_losses = {
            name: losses[name]
            for name in gradnorm_weighter.loss_names
            if name in losses
        }
        if len(available_losses) >= 2:
            if self.step_count % gradnorm_weighter.update_frequency == 0:
                updated_weights = gradnorm_weighter.update_weights(available_losses)
                # æ‡‰ç”¨æ¬Šé‡æ¯”ä¾‹
                for name, ratio in updated_weights.items():
                    self.loss_weights[name] *= ratio
    
    # åå‘å‚³æ’­èˆ‡åƒæ•¸æ›´æ–°
    total_loss.backward()
    self.optimizer.step()
```

**å„ªå…ˆç´šç®¡ç†** (`train.py` Line 398-490):

```python
def create_weighters(config, model, device):
    weighters = {}
    
    # å„ªå…ˆç´š 1: Curriculum (æœ€é«˜)
    if config['training']['curriculum']['enable']:
        weighters['curriculum'] = CurriculumScheduler(...)
        return weighters  # ç¦ç”¨å…¶ä»–èª¿åº¦å™¨
    
    # å„ªå…ˆç´š 2: Staged Weights
    if config['losses']['staged_weights']['enable']:
        weighters['staged'] = StagedWeightScheduler(...)
    
    # å„ªå…ˆç´š 3: GradNorm (èˆ‡ Staged äº’æ–¥)
    elif config['losses']['adaptive_weighting']:
        weighters['gradnorm'] = GradNormWeighter(...)
    
    return weighters
```

---

## 4. é©—è­‰çµæœ

### 4.1 æ¸¬è©¦è¦†è“‹ç‡

| æ¸¬è©¦é¡åˆ¥ | é€šé/ç¸½æ•¸ | è¦†è“‹ç‡ | ç‹€æ…‹ |
|---------|----------|--------|------|
| ç¸½æ¸¬è©¦ | 373/467 | 79.9% | âš ï¸ (72 å¤±æ•—, 22 è·³é) |
| æ¸¬è©¦æª”æ¡ˆ | 45 å€‹ | - | âœ… |
| ç‰©ç†é©—è­‰ | éƒ¨åˆ†é€šé | - | âš ï¸ (éœ€ä¿®å¾©æ ¸å¿ƒå¤±æ•—) |

### 4.2 å¯¦é©—çµæœ

**Task-014 èª²ç¨‹å­¸ç¿’** (2025-10-06):

| è®Šæ•¸ | ç›¸å°èª¤å·® | åŸºç·šèª¤å·® | æ”¹å–„ |
|------|---------|---------|------|
| u-velocity | 5.7% | 63.2% | 91.0% â†“ |
| v-velocity | 33.2% | 214.6% | 84.5% â†“ |
| w-velocity | 56.7% | 91.1% | 37.8% â†“ |
| pressure | 12.6% | 93.2% | 86.5% â†“ |
| **å¹³å‡** | **27.1%** | **115.5%** | **88.4% â†“** |

**å¯¦é©—è¨­å®š**:
- æ„Ÿæ¸¬é»: K=1024
- é‡å»ºç¶²æ ¼: 65,536 é»
- è¨“ç·´è¼ªæ•¸: ~800 epochs
- é…ç½®æª”: `configs/channel_flow_curriculum_4stage_final_fix_2k.yml`

> âš ï¸ **é™åˆ¶**: 
> - v/w æ–¹å‘èª¤å·®ä»åé«˜ï¼ˆ>30%ï¼‰
> - éœ€è¦å¤§é‡æ„Ÿæ¸¬é»ï¼ˆK=1024ï¼‰
> - è¨“ç·´æ™‚é–“é•·ï¼ˆ~800 epochsï¼‰
> - çµæœå°è¶…åƒæ•¸æ•æ„Ÿ

### 4.3 K-æƒæå¯¦é©—

**æœ€å°å¯è¡Œé»æ•¸åˆ†æ** (åŸºæ–¼ 118 å¯¦é©—):

| K å€¼ | ç›¸å° L2 èª¤å·® | æˆåŠŸç‡ | å‚™è¨» |
|------|-------------|--------|------|
| K=2 | 12.3 Â± 4.2% | 60% | ä¸ç©©å®š |
| K=4 | 2.7 Â± 0.4% | 100% | æœ€å°å¯è¡Œé»æ•¸ |
| K=8 | 1.4 Â± 0.2% | 100% | æ¨è–¦åŸºç·š |
| K=16 | 0.9 Â± 0.1% | 100% | è‰¯å¥½æ€§èƒ½ |

---

## 5. ä½¿ç”¨æŒ‡å—

### 5.1 å¿«é€Ÿé–‹å§‹

```bash
# 1. å®‰è£ä¾è³´
conda env create -f environment.yml
conda activate pinns-mvp

# 2. é…ç½® JHTDB èªè­‰
cp .env.example .env
# ç·¨è¼¯ .envï¼Œå¡«å…¥ JHTDB_AUTH_TOKEN

# 3. ä½¿ç”¨æ¨™æº–åŒ–æ¨¡æ¿
cp configs/templates/2d_quick_baseline.yml configs/my_experiment.yml

# 4. åŸ·è¡Œè¨“ç·´
python scripts/train.py --cfg configs/my_experiment.yml

# 5. ç›£æ§é€²åº¦
tail -f log/my_experiment/training.log
```

### 5.2 é…ç½®æ¨¡æ¿

| æ¨¡æ¿ | ç”¨é€” | è¨“ç·´æ™‚é–“ | K é»æ•¸ | Epochs |
|------|------|---------|--------|--------|
| `2d_quick_baseline.yml` | å¿«é€Ÿé©—è­‰ | 5-10 min | 50 | 100 |
| `2d_medium_ablation.yml` | æ¶ˆèç ”ç©¶ | 15-30 min | 100 | 1000 |
| `3d_slab_curriculum.yml` | èª²ç¨‹å­¸ç¿’ | 30-60 min | 100 | 1000 |
| `3d_full_production.yml` | è«–æ–‡ç´šçµæœ | 2-8 hrs | 500 | 5000 |

### 5.3 åƒæ•¸èª¿å„ªå»ºè­°

**GradNorm åƒæ•¸**:

| åƒæ•¸ | æ¨è–¦ç¯„åœ | é è¨­å€¼ | èªªæ˜ |
|------|---------|--------|------|
| `grad_norm_alpha` | 0.10-0.20 | 0.12 | å¹³è¡¡é€Ÿåº¦ï¼ˆè¶Šå°è¶Šä¿å®ˆï¼‰|
| `weight_update_freq` | 50-200 | 100 | æ›´æ–°é »ç‡ |
| `grad_norm_min_weight` | 0.01-0.5 | 0.1 | ä¸‹ç•Œç´„æŸ |
| `grad_norm_max_weight` | 5.0-20.0 | 10.0 | ä¸Šç•Œç´„æŸ |

**RWF åƒæ•¸**:

| åƒæ•¸ | æ¨è–¦ç¯„åœ | é è¨­å€¼ | èªªæ˜ |
|------|---------|--------|------|
| `sine_omega_0` | 1.0-30.0 | 30.0 | SIREN é »ç‡ï¼ˆèˆ‡ Fourier å…±ç”¨æ™‚é™è‡³ 1.0ï¼‰|
| `rwf_scale_std` | 0.05-0.2 | 0.1 | å°ºåº¦æ¨™æº–å·®ï¼ˆç•¶å‰æœªä½¿ç”¨ï¼‰|

### 5.4 æ•…éšœæ’é™¤

| å•é¡Œ | å¯èƒ½åŸå›  | è§£æ±ºæ–¹æ¡ˆ |
|------|---------|---------|
| æ¬Šé‡å…¨ç‚º NaN | æ¢¯åº¦è¨ˆç®—ç•°å¸¸ | æª¢æŸ¥æ¨¡å‹åˆå§‹åŒ–ã€æå¤±å¯å¾®æ€§ |
| æ¬Šé‡ä¸æ›´æ–° | æ›´æ–°é »ç‡è¨­ç½®éŒ¯èª¤ | æª¢æŸ¥ `update_frequency` é…ç½® |
| è¨“ç·´ç™¼æ•£ | `alpha` éå¤§ | é™ä½è‡³ 0.08ï¼Œç¸®å° `max_weight` |
| ç‰©ç†æå¤±è¢«å£“åˆ¶ | `min_weight` éå° | æé«˜è‡³ 0.5 |
| PDE æå¤±çˆ†ç‚¸ | é‡ç´šå¤±è¡¡ | å•Ÿç”¨ VS-PINNï¼Œèª¿æ•´åˆå§‹æ¬Šé‡ |

---

## 6. å·²çŸ¥é™åˆ¶

### 6.1 æŠ€è¡“é™åˆ¶

1. **æ„Ÿæ¸¬é»éœ€æ±‚**: 
   - ç›®å‰æœ€ä½³çµæœéœ€è¦ K=1024 é»
   - K<16 æ™‚ç©©å®šæ€§ä¸‹é™
   - é é«˜æ–¼ç†è«–æœ€å°é»æ•¸ï¼ˆK=4ï¼‰

2. **æ”¶æ–‚æ•ˆç‡**:
   - éœ€è¦ 800+ epochs é”åˆ°è‰¯å¥½çµæœ
   - å°è¶…åƒæ•¸æ•æ„Ÿï¼ˆå­¸ç¿’ç‡ã€æ¬Šé‡åˆå§‹åŒ–ï¼‰
   - Curriculum ç­–ç•¥éœ€æ‰‹å‹•èª¿æ•´

3. **ç‰©ç†ä¸€è‡´æ€§**:
   - v/w æ–¹å‘èª¤å·®åé«˜ï¼ˆ>30%ï¼‰
   - é‚Šç•Œæ¢ä»¶è™•ç†å°šä¸å®Œå–„
   - é•·æ™‚é–“ç©åˆ†å¯èƒ½ç™¼æ•£

4. **å¯æ“´å±•æ€§**:
   - 3D å®Œæ•´åŸŸè¨ˆç®—è¨˜æ†¶é«”éœ€æ±‚é«˜
   - é«˜ Re æ•¸ï¼ˆ>5000ï¼‰ç©©å®šæ€§ä¸‹é™
   - æœªå……åˆ†æ¸¬è©¦å¤š Re æ•¸æ³›åŒ–

### 6.2 å¯¦é©—é™åˆ¶

1. **è³‡æ–™ä¾è³´**:
   - åƒ…åœ¨ JHTDB Channel Flow ä¸Šå……åˆ†é©—è­‰
   - å…¶ä»–å¹¾ä½•/æµå ´é¡å‹éœ€é‡æ–°èª¿åƒ
   - RANS ä½ä¿çœŸå…ˆé©—æ•ˆæœä¸ç©©å®š

2. **é‡ç¾æ€§æŒ‘æˆ°**:
   - Task-014 çµæœåŸºæ–¼é•·æœŸè¿­ä»£
   - âš ï¸ **é…ç½®æ­¸æª”**: åŸå§‹ 4 éšæ®µèª²ç¨‹é…ç½®å·²ä¸åœ¨ç•¶å‰ç‰ˆæœ¬
   - âš ï¸ **æª¢æŸ¥é»ç¼ºå¤±**: é è¨“ç·´æ¨¡å‹æœªå…¬é–‹ä¿å­˜ï¼ˆè¨“ç·´æˆæœ¬ ~8 å°æ™‚ï¼‰
   - âœ… **æ›¿ä»£æ–¹æ¡ˆ**: ä½¿ç”¨ `configs/templates/3d_slab_curriculum.yml` ä½œç‚ºèµ·é»
   - âœ… **å„ªåŒ–ç­–ç•¥**: åƒè€ƒç¬¬ 2-3 ç¯€æŠ€è¡“æ¨¡çµ„æ–‡æª”é€²è¡Œèª¿å„ª
   - ç¡¬é«”ç’°å¢ƒå½±éŸ¿è¨“ç·´ç©©å®šæ€§

3. **ä¸ç¢ºå®šæ€§é‡åŒ–**:
   - Ensemble è¨ˆç®—æˆæœ¬é«˜ï¼ˆ5-10Ã— è¨“ç·´æ™‚é–“ï¼‰
   - UQ æŒ‡æ¨™åƒ…éƒ¨åˆ†é©—è­‰
   - èªçŸ¥/å¶ç„¶ä¸ç¢ºå®šæ€§åˆ†è§£éœ€æ”¹é€²

### 6.3 å·¥ç¨‹é™åˆ¶

1. **è¨ˆç®—è³‡æº**:
   - å»ºè­°é…ç½®: RTX 4080 (16GB)
   - æœ€å°é…ç½®: RTX 3060 (12GB)
   - CPU è¨“ç·´ä¸å¯¦ç”¨ï¼ˆæ…¢ 50-100Ã—ï¼‰

2. **å„²å­˜éœ€æ±‚**:
   - å®Œæ•´è¨“ç·´è¨˜éŒ„: ~5GB
   - æª¢æŸ¥é»æª”æ¡ˆ: ~500MB/epoch
   - JHTDB è³‡æ–™å¿«å–: ~10GB

3. **è»Ÿé«”ä¾è³´**:
   - PyTorch â‰¥ 2.0
   - CUDA â‰¥ 11.8
   - Python 3.9-3.11

---

## 7. åƒè€ƒæ–‡ç»

### 7.1 ç†è«–åŸºç¤

1. **PINNs**: Raissi et al., "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations", *Journal of Computational Physics*, 2019.

2. **GradNorm**: Chen et al., "GradNorm: Gradient normalization for adaptive loss balancing in deep multitask networks", *ICML*, 2018.

3. **QR-Pivot**: DrmaÄ & Gugercin, "A new selection operator for the discrete empirical interpolation method", *SIAM Journal on Scientific Computing*, 2016.

### 7.2 è³‡æ–™ä¾†æº

4. **JHTDB**: Johns Hopkins Turbulence Databases, http://turbulence.pha.jhu.edu/
   - Channel Flow Dataset: Re_Ï„=1000
   - å¼•ç”¨è¦æ±‚: éµå¾ªå®˜æ–¹å¼•ç”¨æº–å‰‡

### 7.3 ç›¸é—œå·¥ä½œ

5. **VS-PINN**: Stiasny et al., "Physics-informed neural networks for non-linear system identification for power system dynamics", *IEEE PES General Meeting*, 2021.

6. **Sensor Placement**: Manohar et al., "Data-driven sparse sensor placement for reconstruction: Demonstrating the benefits of exploiting known patterns", *IEEE Control Systems Magazine*, 2018.

---

## é™„éŒ„

### A. æ¨¡çµ„å°ç…§è¡¨

| åŠŸèƒ½ | æª”æ¡ˆè·¯å¾‘ | é—œéµé¡åˆ¥/å‡½æ•¸ |
|------|---------|--------------|
| QR-Pivot | `pinnx/sensors/qr_pivot.py` | `QRPivotSelector` |
| VS-PINN | `pinnx/physics/scaling.py` | `VSScaler` |
| RWF | `pinnx/models/fourier_mlp.py` | `RWFLinear` |
| GradNorm | `pinnx/losses/weighting.py` | `GradNormWeighter` |
| è¨“ç·´å™¨ | `pinnx/train/trainer.py` | `Trainer` |
| ä¸»è…³æœ¬ | `scripts/train.py` | `main()` |

### B. é…ç½®æª”æ¡ˆä½ç½®

- æ¨¡æ¿: `configs/templates/*.yml`
- å®Œæ•´é…ç½®: `configs/*.yml` (30+)
- æ–‡æª”: `configs/README.md`

### C. æ¸¬è©¦åŸ·è¡Œ

```bash
# å–®å…ƒæ¸¬è©¦
pytest tests/test_losses.py -v          # 19/19 é€šé
pytest tests/test_models.py -v          # æ¨¡å‹æ¶æ§‹æ¸¬è©¦
pytest tests/test_physics.py -v         # ç‰©ç†æ–¹ç¨‹æ¸¬è©¦

# æ•´åˆæ¸¬è©¦
pytest tests/test_sensors_integration.py -v
pytest tests/test_rans_integration.py -v

# ç‰©ç†é©—è­‰
python scripts/validation/physics_validation.py
```

### D. è¯çµ¡è³‡è¨Š

- GitHub Issues: æŠ€è¡“å•é¡Œèˆ‡ Bug å›å ±
- æŠ€è¡“æ–‡æª”: `docs/TECHNICAL_DOCUMENTATION.md`ï¼ˆæœ¬æ–‡æª”ï¼‰
- é–‹ç™¼æŒ‡å¼•: `AGENTS.md`

---

**æ–‡æª”ç¶­è­·è€…**: AI Assistant  
**æœ€å¾Œæ›´æ–°**: 2025-10-16  
**ç‰ˆæœ¬æ­·å²**:
- v2.0 (2025-10-16): å…¨é¢æ”¹å¯«ï¼Œç§»é™¤æ¨‚è§€èªæ°£ï¼Œå¢åŠ å·²çŸ¥é™åˆ¶ç« ç¯€
- v1.0 (2025-10-03): åˆå§‹ç‰ˆæœ¬
