"""
æ¸¬è©¦ Trainer æœ€ä½³æ¨¡å‹è‡ªå‹•ä¿å­˜åŠŸèƒ½

é©—è­‰ TASK-008 ä¿®å¾©ï¼š
- ç™¼ç¾æ–°æœ€ä½³æ¨¡å‹æ™‚ç«‹å³ä¿å­˜åˆ°ç£ç¢Ÿ
- æª¢æŸ¥é»åŒ…å«æ­£ç¢ºçš„ metrics
- best_model.pth æ–‡ä»¶æ­£ç¢ºå‰µå»º
"""
import pytest
import torch
import tempfile
from pathlib import Path
from pinnx.train.trainer import Trainer


def test_best_model_auto_save(tmp_path):
    """æ¸¬è©¦æœ€ä½³æ¨¡å‹è‡ªå‹•ä¿å­˜åˆ°ç£ç¢Ÿ"""
    
    # ç°¡å–®æ¨¡å‹å’Œé…ç½®
    model = torch.nn.Sequential(
        torch.nn.Linear(3, 50),
        torch.nn.Tanh(),
        torch.nn.Linear(50, 4)
    )
    
    config = {
        'training': {
            'optimizer': 'adam',
            'lr': 1e-3,
            'early_stopping': {
                'enabled': True,
                'patience': 10,
                'min_delta': 1e-6,
                'restore_best_weights': True
            },
            'epochs': 100
        },
        'losses': {
            'data_weight': 1.0,
            'pde_weight': 1.0
        },
        'output': {
            'checkpoint_dir': str(tmp_path)
        }
    }
    
    # å‰µå»ºè¨“ç·´å™¨
    trainer = Trainer(
        model=model,
        physics=None,
        losses={},
        config=config,
        device=torch.device('cpu')
    )
    
    # æ¨¡æ“¬ç™¼ç¾æ–°æœ€ä½³æ¨¡å‹ï¼ˆåˆå§‹ val_loss=100ï¼‰
    trainer.best_val_loss = 100.0
    trainer.epoch = 10
    
    # æª¢æŸ¥åˆå§‹ç‹€æ…‹
    best_model_path = tmp_path / "best_model.pth"
    assert not best_model_path.exists(), "æœ€ä½³æ¨¡å‹æ–‡ä»¶ä¸æ‡‰åœ¨åˆå§‹åŒ–æ™‚å­˜åœ¨"
    
    # è§¸ç™¼æ–°æœ€ä½³æ¨¡å‹ï¼ˆval_loss=50 < 100ï¼‰
    should_stop = trainer.check_early_stopping(50.0)
    
    # é©—è­‰çµæœ
    assert not should_stop, "ä¸æ‡‰è§¸ç™¼æ—©åœï¼ˆå‰›æ›´æ–°æœ€ä½³æ¨¡å‹ï¼‰"
    assert trainer.best_val_loss == 50.0, "æœ€ä½³æå¤±æ‡‰æ›´æ–°"
    assert trainer.best_epoch == 10, "æœ€ä½³ epoch æ‡‰è¨˜éŒ„"
    assert trainer.patience_counter == 0, "è€å¿ƒè¨ˆæ•¸å™¨æ‡‰é‡ç½®"
    
    # ğŸ¯ é—œéµæ¸¬è©¦ï¼šæª¢æŸ¥ best_model.pth æ˜¯å¦è‡ªå‹•å‰µå»º
    assert best_model_path.exists(), "âŒ æœ€ä½³æ¨¡å‹æ–‡ä»¶æ‡‰è‡ªå‹•ä¿å­˜åˆ°ç£ç¢Ÿ"
    
    # é©—è­‰æª¢æŸ¥é»å…§å®¹
    checkpoint = torch.load(best_model_path)
    assert 'model_state_dict' in checkpoint, "æª¢æŸ¥é»æ‡‰åŒ…å«æ¨¡å‹ç‹€æ…‹"
    assert 'metrics' in checkpoint, "æª¢æŸ¥é»æ‡‰åŒ…å«æŒ‡æ¨™"
    assert checkpoint['metrics']['val_loss'] == 50.0, "æ‡‰è¨˜éŒ„æ­£ç¢ºçš„ val_loss"
    assert checkpoint['metrics']['best_epoch'] == 10, "æ‡‰è¨˜éŒ„æ­£ç¢ºçš„ best_epoch"
    assert checkpoint['epoch'] == 10, "æª¢æŸ¥é»æ‡‰è¨˜éŒ„æ­£ç¢ºçš„ epoch"
    
    print("âœ… æ¸¬è©¦é€šéï¼šæœ€ä½³æ¨¡å‹è‡ªå‹•ä¿å­˜åŠŸèƒ½æ­£å¸¸")


def test_early_stopping_restores_best_model(tmp_path):
    """æ¸¬è©¦æ—©åœè§¸ç™¼æ™‚æ¢å¾©æœ€ä½³æ¨¡å‹"""
    
    model = torch.nn.Sequential(
        torch.nn.Linear(3, 50),
        torch.nn.Tanh(),
        torch.nn.Linear(50, 4)
    )
    
    config = {
        'training': {
            'optimizer': 'adam',
            'lr': 1e-3,
            'early_stopping': {
                'enabled': True,
                'patience': 3,
                'min_delta': 1e-6,
                'restore_best_weights': True
            },
            'epochs': 100
        },
        'losses': {},
        'output': {
            'checkpoint_dir': str(tmp_path)
        }
    }
    
    trainer = Trainer(model, None, {}, config, device=torch.device('cpu'))
    
    # æ¨¡æ“¬è¨“ç·´æ­·å²
    trainer.epoch = 5
    trainer.check_early_stopping(10.0)  # epoch=5: best=10.0
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹æ™‚çš„æ¬Šé‡å¿«ç…§
    best_weights_sum = sum(p.sum().item() for p in model.parameters())
    
    # æ¨¡æ“¬å¾ŒçºŒè¨“ç·´ï¼ˆæ¨¡å‹æ¬Šé‡æ”¹è®Šï¼‰
    trainer.epoch = 6
    for p in model.parameters():
        p.data += 0.1
    trainer.check_early_stopping(12.0)  # epoch=6: loss è®Šå·®ï¼ˆpatience=1ï¼‰
    
    trainer.epoch = 7
    trainer.check_early_stopping(13.0)  # epoch=7: loss æŒçºŒè®Šå·®ï¼ˆpatience=2ï¼‰
    
    trainer.epoch = 8
    should_stop = trainer.check_early_stopping(14.0)  # epoch=8: è§¸ç™¼æ—©åœï¼ˆpatience=3ï¼‰
    
    assert should_stop, "æ‡‰è§¸ç™¼æ—©åœ"
    
    # é©—è­‰æœ€ä½³æ¨¡å‹å·²æ¢å¾©ï¼ˆç”±è¨“ç·´å¾ªç’°è² è²¬æ¢å¾©ï¼‰
    # é€™è£¡æª¢æŸ¥ best_model_state æ˜¯å¦æ­£ç¢ºä¿å­˜
    assert trainer.best_model_state is not None, "æœ€ä½³æ¨¡å‹ç‹€æ…‹æ‡‰å·²ä¿å­˜"
    assert trainer.best_epoch == 5, "æœ€ä½³ epoch æ‡‰ç‚º 5"
    
    # é©—è­‰ç£ç¢Ÿæ–‡ä»¶å­˜åœ¨
    best_model_path = tmp_path / "best_model.pth"
    assert best_model_path.exists(), "æœ€ä½³æ¨¡å‹æ–‡ä»¶æ‡‰å­˜åœ¨æ–¼ç£ç¢Ÿ"
    
    print("âœ… æ¸¬è©¦é€šéï¼šæ—©åœæ¢å¾©æœ€ä½³æ¨¡å‹åŠŸèƒ½æ­£å¸¸")


if __name__ == "__main__":
    import tempfile
    
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_path = Path(tmpdir)
        
        print("=" * 60)
        print("æ¸¬è©¦ 1: æœ€ä½³æ¨¡å‹è‡ªå‹•ä¿å­˜")
        print("=" * 60)
        test_best_model_auto_save(tmp_path / "test1")
        
        print("\n" + "=" * 60)
        print("æ¸¬è©¦ 2: æ—©åœæ¢å¾©æœ€ä½³æ¨¡å‹")
        print("=" * 60)
        test_early_stopping_restores_best_model(tmp_path / "test2")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        print("=" * 60)
