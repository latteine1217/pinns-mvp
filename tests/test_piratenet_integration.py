"""
PirateNet æ•´åˆæ¸¬è©¦

é©—è­‰é …ç›®:
1. SOAP å„ªåŒ–å™¨åˆå§‹åŒ–èˆ‡åƒæ•¸
2. Swish (SiLU) æ¿€æ´»å‡½æ•¸è¼¸å‡ºæ­£ç¢ºæ€§
3. Steps-based Warmup Scheduler èª¿åº¦è¡Œç‚º
4. RWF åƒæ•¸é…ç½®ï¼ˆÎ¼=1.0, Ïƒ=0.1ï¼‰
5. å®Œæ•´é…ç½®è¼‰å…¥ç„¡éŒ¯èª¤
"""

import pytest
import torch
import torch.nn as nn
from pathlib import Path
import yaml
import sys

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

# å°å…¥æ ¸å¿ƒæ¨¡çµ„
from pinnx.optim.soap import SOAP
from pinnx.models.fourier_mlp import PINNNet, RWFLinear
from pinnx.train.schedulers import StepsBasedWarmupScheduler


# ============================================
# 1. SOAP å„ªåŒ–å™¨æ¸¬è©¦
# ============================================

def test_soap_optimizer_initialization():
    """æ¸¬è©¦ SOAP å„ªåŒ–å™¨åˆå§‹åŒ–èˆ‡åƒæ•¸è¨­ç½®"""
    # å‰µå»ºç°¡å–®æ¨¡å‹
    model = nn.Linear(10, 5)
    
    # åˆå§‹åŒ– SOAP å„ªåŒ–å™¨
    optimizer = SOAP(
        model.parameters(),
        lr=1e-3,
        betas=(0.9, 0.999),
        weight_decay=0.0,
        precondition_frequency=2
    )
    
    # é©—è­‰åƒæ•¸
    assert optimizer.defaults['lr'] == 1e-3
    assert optimizer.defaults['betas'] == (0.9, 0.999)
    assert optimizer.defaults['weight_decay'] == 0.0
    assert optimizer.defaults['precondition_frequency'] == 2
    
    print("âœ… SOAP optimizer åˆå§‹åŒ–æ¸¬è©¦é€šé")


def test_soap_optimizer_step():
    """æ¸¬è©¦ SOAP å„ªåŒ–å™¨åŸ·è¡Œæ­¥é©Ÿ"""
    # å‰µå»ºç°¡å–®æ¨¡å‹èˆ‡è³‡æ–™
    model = nn.Linear(10, 1)
    optimizer = SOAP(model.parameters(), lr=1e-2)  # å¢åŠ å­¸ç¿’ç‡ä»¥ä¾¿è§€å¯Ÿè®ŠåŒ–
    
    # å„²å­˜åˆå§‹æ¬Šé‡
    initial_weight = model.weight.data.clone()
    
    # åŸ·è¡Œå¤šæ¬¡è¨“ç·´æ­¥é©Ÿï¼ˆSOAP éœ€è¦å¹¾æ­¥ä¾†åˆå§‹åŒ– preconditionerï¼‰
    x = torch.randn(32, 10)
    y = torch.randn(32, 1)
    
    for _ in range(5):  # åŸ·è¡Œ 5 æ­¥ç¢ºä¿å„ªåŒ–å™¨å®Œå…¨å•Ÿå‹•
        loss = nn.MSELoss()(model(x), y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    # é©—è­‰æ¬Šé‡å·²æ›´æ–°
    assert not torch.allclose(model.weight.data, initial_weight, atol=1e-6), \
        "æ¬Šé‡æ‡‰åœ¨ 5 æ­¥è¨“ç·´å¾Œæœ‰é¡¯è‘—è®ŠåŒ–"
    
    print("âœ… SOAP optimizer step åŸ·è¡Œæ¸¬è©¦é€šé")


# ============================================
# 2. Swish æ¿€æ´»å‡½æ•¸æ¸¬è©¦
# ============================================

def test_swish_activation():
    """æ¸¬è©¦ Swish (SiLU) æ¿€æ´»å‡½æ•¸è¼¸å‡ºæ­£ç¢ºæ€§"""
    # PyTorch å…§å»º SiLU
    swish = nn.SiLU()
    
    # æ¸¬è©¦è¼¸å…¥
    x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])
    
    # è¨ˆç®—è¼¸å‡º
    output = swish(x)
    
    # æ‰‹å‹•è¨ˆç®— Swish: x * sigmoid(x)
    expected = x * torch.sigmoid(x)
    
    # é©—è­‰è¼¸å‡º
    assert torch.allclose(output, expected, atol=1e-6)
    
    # é©—è­‰é›¶é»é™„è¿‘è¡Œç‚ºï¼ˆæ‡‰è©²æ¥è¿‘ç·šæ€§ï¼‰
    assert torch.abs(swish(torch.tensor(0.0)) - 0.0) < 1e-6
    
    print("âœ… Swish æ¿€æ´»å‡½æ•¸è¼¸å‡ºæ¸¬è©¦é€šé")


def test_swish_in_model():
    """æ¸¬è©¦ Swish åœ¨æ¨¡å‹ä¸­æ­£ç¢ºä½¿ç”¨"""
    # å‰µå»ºä½¿ç”¨ Swish çš„æ¨¡å‹
    model = PINNNet(
        in_dim=3,
        out_dim=4,
        depth=2,
        width=32,
        activation='swish',
        use_fourier=False,
        use_rwf=False
    )
    
    # æª¢æŸ¥æ¿€æ´»å‡½æ•¸é¡å‹
    # åœ¨ DenseLayer ä¸­ï¼Œactivation æ‡‰è©²æ˜¯ SiLU
    for layer in model.hidden_layers:
        assert isinstance(layer.activation, nn.SiLU), \
            f"Expected SiLU, got {type(layer.activation)}"
    
    # æ¸¬è©¦å‰å‘å‚³æ’­
    x = torch.randn(16, 3)
    output = model(x)
    
    # é©—è­‰è¼¸å‡ºå½¢ç‹€
    assert output.shape == (16, 4)
    assert not torch.isnan(output).any()
    
    print("âœ… Swish åœ¨æ¨¡å‹ä¸­ä½¿ç”¨æ¸¬è©¦é€šé")


# ============================================
# 3. Steps-based Scheduler æ¸¬è©¦
# ============================================

def test_steps_based_scheduler_warmup():
    """æ¸¬è©¦ Steps-based Warmup Scheduler çš„ warmup éšæ®µ"""
    model = nn.Linear(10, 1)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    scheduler = StepsBasedWarmupScheduler(
        optimizer,
        base_lr=1e-3,
        warmup_steps=100,
        total_steps=1000,
        decay_steps=200,
        gamma=0.9
    )
    
    # è¨˜éŒ„å­¸ç¿’ç‡è®ŠåŒ–ï¼ˆåœ¨ step() ä¹‹å¾Œè¨˜éŒ„ï¼‰
    lrs = []
    for step in range(100):
        scheduler.step()  # å…ˆæ›´æ–°å­¸ç¿’ç‡
        lrs.append(optimizer.param_groups[0]['lr'])
    
    # é©—è­‰ warmup éšæ®µå­¸ç¿’ç‡éå¢
    assert lrs[0] < lrs[50] < lrs[99], \
        f"Warmup éšæ®µå­¸ç¿’ç‡æ‡‰éå¢: lr[0]={lrs[0]:.6f}, lr[50]={lrs[50]:.6f}, lr[99]={lrs[99]:.6f}"
    assert abs(lrs[99] - 1e-3) < 1e-6, \
        f"Warmup çµæŸæ™‚æ‡‰é”åˆ° base_lr=1e-3, å¯¦éš›ç‚º {lrs[99]:.6f}"
    
    print("âœ… Steps-based scheduler warmup æ¸¬è©¦é€šé")


def test_steps_based_scheduler_decay():
    """æ¸¬è©¦ Steps-based Scheduler çš„ decay éšæ®µ"""
    model = nn.Linear(10, 1)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    scheduler = StepsBasedWarmupScheduler(
        optimizer,
        base_lr=1e-3,
        warmup_steps=100,
        total_steps=10000,
        decay_steps=200,
        gamma=0.9
    )
    
    # è·³é warmup éšæ®µï¼ˆåŸ·è¡Œ 100 æ­¥åˆ°é” base_lrï¼‰
    for _ in range(100):
        scheduler.step()
    
    lr_before_decay = optimizer.param_groups[0]['lr']
    
    # åŸ·è¡Œ 201 æ­¥ï¼ˆè§¸ç™¼ä¸€æ¬¡ decayï¼‰
    # è¨»: scheduler åœ¨è¨­å®š LR æ™‚ä½¿ç”¨ current_stepï¼Œç„¶å¾Œæ‰éå¢
    # æ‰€ä»¥éœ€è¦ 201 æ­¥æ‰èƒ½è®“ current_step=300 æ™‚è¨­å®š LR
    for _ in range(201):
        scheduler.step()
    
    lr_after_decay = optimizer.param_groups[0]['lr']
    
    # é©—è­‰å­¸ç¿’ç‡è¡°æ¸›
    expected_lr = lr_before_decay * 0.9
    assert abs(lr_after_decay - expected_lr) < 1e-7, \
        f"Expected LR={expected_lr:.8f}, got {lr_after_decay:.8f}"
    
    print("âœ… Steps-based scheduler decay æ¸¬è©¦é€šé")


# ============================================
# 4. RWF åƒæ•¸é…ç½®æ¸¬è©¦
# ============================================

def test_rwf_scale_mean_parameter():
    """æ¸¬è©¦ RWF scale_mean åƒæ•¸å¯é…ç½®æ€§"""
    # æ¸¬è©¦ Î¼=1.0 é…ç½®
    rwf_layer = RWFLinear(
        in_features=32,
        out_features=64,
        scale_mean=1.0,
        scale_std=0.1
    )
    
    # é©—è­‰åƒæ•¸è¨­ç½®
    assert rwf_layer.scale_mean == 1.0
    assert rwf_layer.scale_std == 0.1
    
    # æª¢æŸ¥ç¸®æ”¾åƒæ•¸çš„çµ±è¨ˆç‰¹æ€§ï¼ˆå¤§è‡´ç¬¦åˆ N(1.0, 0.1)ï¼‰
    scale_mean = rwf_layer.s.mean().item()
    scale_std = rwf_layer.s.std().item()
    
    # å…è¨±ä¸€å®šèª¤å·®ï¼ˆçµ±è¨ˆä¼°è¨ˆï¼‰
    assert 0.8 < scale_mean < 1.2, f"Mean={scale_mean} æ‡‰æ¥è¿‘ 1.0"
    assert 0.05 < scale_std < 0.15, f"Std={scale_std} æ‡‰æ¥è¿‘ 0.1"
    
    print("âœ… RWF scale_mean åƒæ•¸æ¸¬è©¦é€šé")


def test_rwf_in_enhanced_fourier_mlp():
    """æ¸¬è©¦ RWF åœ¨ PINNNet ä¸­æ­£ç¢ºé…ç½®"""
    model = PINNNet(
        in_dim=3,
        out_dim=4,
        depth=4,
        width=128,
        activation='swish',
        use_rwf=True,
        rwf_scale_mean=1.0,
        rwf_scale_std=0.1
    )
    
    # æª¢æŸ¥æ‰€æœ‰éš±è—å±¤æ˜¯å¦ä½¿ç”¨ RWF
    for layer in model.hidden_layers:
        assert hasattr(layer.linear, 's'), "æ‡‰åŒ…å« RWF ç¸®æ”¾åƒæ•¸ 's'"
        # é©—è­‰ç¸®æ”¾åƒæ•¸å½¢ç‹€æ­£ç¢º
        assert layer.linear.s.shape == (layer.linear.out_features,)
    
    # æ¸¬è©¦å‰å‘å‚³æ’­
    x = torch.randn(16, 3)
    output = model(x)
    assert output.shape == (16, 4)
    assert not torch.isnan(output).any()
    
    print("âœ… RWF åœ¨ PINNNet ä¸­é…ç½®æ¸¬è©¦é€šé")


# ============================================
# 5. å®Œæ•´é…ç½®è¼‰å…¥æ¸¬è©¦
# ============================================

def test_piratenet_config_loading():
    """æ¸¬è©¦ PirateNet é…ç½®æª”æ¡ˆè¼‰å…¥ç„¡éŒ¯èª¤"""
    config_path = Path(__file__).parent.parent / "configs/templates/piratenet_baseline.yml"
    
    # æª¢æŸ¥é…ç½®æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    assert config_path.exists(), f"é…ç½®æª”æ¡ˆä¸å­˜åœ¨: {config_path}"
    
    # è¼‰å…¥é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # é©—è­‰é—œéµåƒæ•¸
    assert config['model']['activation'] == 'swish'
    assert config['model']['depth'] == 6
    assert config['model']['width'] == 768
    assert config['model']['rwf_scale_mean'] == 1.0
    assert config['model']['rwf_scale_std'] == 0.1
    assert config['model']['fourier_sigma'] == 2.0
    
    assert config['training']['optimizer']['type'] == 'soap'
    assert config['training']['optimizer']['betas'] == [0.9, 0.999]
    assert config['training']['optimizer']['precondition_frequency'] == 2
    
    assert config['training']['scheduler']['type'] == 'warmup_exponential_steps'
    assert config['training']['scheduler']['warmup_steps'] == 2000
    assert config['training']['scheduler']['decay_steps'] == 2000
    assert config['training']['scheduler']['decay_gamma'] == 0.9
    
    print("âœ… PirateNet é…ç½®è¼‰å…¥æ¸¬è©¦é€šé")


def test_piratenet_model_creation_from_config():
    """æ¸¬è©¦å¾é…ç½®å‰µå»º PirateNet æ¨¡å‹"""
    from pinnx.models.fourier_mlp import create_pinn_model
    
    config_path = Path(__file__).parent.parent / "configs/templates/piratenet_baseline.yml"
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # å‰µå»ºæ¨¡å‹ (ä½¿ç”¨å·¥å» å‡½æ•¸)
    model = create_pinn_model(config['model'])
    
    # é©—è­‰æ¨¡å‹çµæ§‹
    assert len(model.hidden_layers) == config['model']['depth']
    
    # é©—è­‰æ¿€æ´»å‡½æ•¸
    for layer in model.hidden_layers:
        assert isinstance(layer.activation, nn.SiLU)
    
    # é©—è­‰ RWF
    for layer in model.hidden_layers:
        assert hasattr(layer.linear, 's')
    
    # æ¸¬è©¦å‰å‘å‚³æ’­
    x = torch.randn(8, 3)
    output = model(x)
    assert output.shape == (8, 4)
    assert not torch.isnan(output).any()
    
    print("âœ… PirateNet æ¨¡å‹å‰µå»ºæ¸¬è©¦é€šé")


# ============================================
# 6. æ•´åˆæ¸¬è©¦
# ============================================

def test_piratenet_full_integration():
    """å®Œæ•´æ•´åˆæ¸¬è©¦: æ¨¡å‹ + SOAP + Scheduler"""
    # å‰µå»ºæ¨¡å‹
    model = PINNNet(
        in_dim=3,
        out_dim=4,
        depth=6,
        width=768,
        activation='swish',
        use_fourier=True,
        fourier_m=64,
        fourier_sigma=2.0,
        use_rwf=True,
        rwf_scale_mean=1.0,
        rwf_scale_std=0.1
    )
    
    # å‰µå»º SOAP å„ªåŒ–å™¨
    optimizer = SOAP(
        model.parameters(),
        lr=1e-3,
        betas=(0.9, 0.999),
        precondition_frequency=2
    )
    
    # å‰µå»º Steps-based Scheduler
    scheduler = StepsBasedWarmupScheduler(
        optimizer,
        base_lr=1e-3,
        warmup_steps=2000,
        total_steps=100000,
        decay_steps=2000,
        gamma=0.9
    )
    
    # æ¨¡æ“¬è¨“ç·´æ­¥é©Ÿ
    x = torch.randn(32, 3)
    y = torch.randn(32, 4)
    
    for step in range(10):
        # å‰å‘å‚³æ’­
        output = model(x)
        loss = nn.MSELoss()(output, y)
        
        # å¾Œå‘å‚³æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        scheduler.step()
        
        # é©—è­‰ç„¡ NaN
        assert not torch.isnan(loss).item()
        assert not torch.isnan(output).any()
    
    print("âœ… PirateNet å®Œæ•´æ•´åˆæ¸¬è©¦é€šé")


# ============================================
# åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
# ============================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("é–‹å§‹ PirateNet æ•´åˆæ¸¬è©¦")
    print("="*60 + "\n")
    
    # 1. SOAP å„ªåŒ–å™¨
    print("1ï¸âƒ£  æ¸¬è©¦ SOAP å„ªåŒ–å™¨...")
    test_soap_optimizer_initialization()
    test_soap_optimizer_step()
    
    # 2. Swish æ¿€æ´»å‡½æ•¸
    print("\n2ï¸âƒ£  æ¸¬è©¦ Swish æ¿€æ´»å‡½æ•¸...")
    test_swish_activation()
    test_swish_in_model()
    
    # 3. Steps-based Scheduler
    print("\n3ï¸âƒ£  æ¸¬è©¦ Steps-based Scheduler...")
    test_steps_based_scheduler_warmup()
    test_steps_based_scheduler_decay()
    
    # 4. RWF åƒæ•¸
    print("\n4ï¸âƒ£  æ¸¬è©¦ RWF åƒæ•¸é…ç½®...")
    test_rwf_scale_mean_parameter()
    test_rwf_in_enhanced_fourier_mlp()
    
    # 5. é…ç½®è¼‰å…¥
    print("\n5ï¸âƒ£  æ¸¬è©¦é…ç½®è¼‰å…¥...")
    test_piratenet_config_loading()
    test_piratenet_model_creation_from_config()
    
    # 6. å®Œæ•´æ•´åˆ
    print("\n6ï¸âƒ£  æ¸¬è©¦å®Œæ•´æ•´åˆ...")
    test_piratenet_full_integration()
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼PirateNet æ•´åˆæˆåŠŸ")
    print("="*60 + "\n")
