#!/usr/bin/env python3
"""
æ¸¬è©¦é‚Šç•Œæ¢ä»¶ä¿®å¾©æ•ˆæœ
å¿«é€Ÿè¨“ç·´ 100 epochsï¼Œé©—è­‰å£é¢ç´„æŸæ˜¯å¦ç”Ÿæ•ˆ
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import torch
import yaml
import numpy as np
from pathlib import Path
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def main():
    # è¼‰å…¥é…ç½®
    config_path = Path("configs/channel_flow_re1000_K80_wall_balanced.yml")
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # ä¿®æ”¹è¨“ç·´åƒæ•¸ï¼šå¿«é€Ÿæ¸¬è©¦
    config['training']['max_epochs'] = 100
    config['training']['validation_freq'] = 25
    config['logging']['log_freq'] = 25
    
    # å¼·åˆ¶ä½¿ç”¨ CPUï¼ˆé¿å… CUDA å•é¡Œï¼‰
    device = torch.device('cpu')
    config['experiment']['device'] = 'cpu'
    
    logging.info("="*60)
    logging.info("ğŸ§ª é‚Šç•Œæ¢ä»¶ä¿®å¾©é©—è­‰æ¸¬è©¦")
    logging.info("="*60)
    logging.info(f"é…ç½®æª”æ¡ˆ: {config_path}")
    logging.info(f"è¨“ç·´è¼ªæ•¸: {config['training']['max_epochs']}")
    logging.info(f"è¨­å‚™: {device}")
    logging.info(f"å£é¢ç´„æŸæ¬Šé‡: {config['losses']['wall_constraint_weight']}")
    logging.info(f"é€±æœŸæ€§æ¬Šé‡: {config['losses']['periodicity_weight']}")
    logging.info(f"é‚Šç•Œæ¡æ¨£é»æ•¸: {config['training']['sampling']['boundary_points']}")
    logging.info("="*60)
    
    # å°å…¥è¨“ç·´å‡½æ•¸
    from train import train
    
    # é–‹å§‹è¨“ç·´
    try:
        model, trainer_state = train(config)
        
        logging.info("\n" + "="*60)
        logging.info("âœ… è¨“ç·´å®Œæˆï¼æº–å‚™è¨ºæ–·é‚Šç•Œæ¢ä»¶...")
        logging.info("="*60)
        
        # è¨ºæ–·é‚Šç•Œæ¢ä»¶
        diagnose_boundary_conditions(model, config, device)
        
    except Exception as e:
        logging.error(f"âŒ è¨“ç·´å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


def diagnose_boundary_conditions(model, config, device):
    """è¨ºæ–·é‚Šç•Œæ¢ä»¶æ˜¯å¦æ»¿è¶³"""
    
    # ç”Ÿæˆå£é¢æ¸¬è©¦é»
    n_test = 200
    x_range = config['physics']['domain']['x_range']
    
    # æ¨™æº–åŒ–å‡½æ•¸
    def normalize_x(x):
        return 2.0 * (x - x_range[0]) / (x_range[1] - x_range[0]) - 1.0
    
    def normalize_y(y):
        return y  # y å·²ç¶“åœ¨ [-1, 1]
    
    # ä¸‹å£é¢æ¸¬è©¦é» (y = -1.0)
    x_bottom = np.linspace(x_range[0], x_range[1], n_test)
    y_bottom = np.full(n_test, -1.0)
    coords_bottom = np.stack([normalize_x(x_bottom), normalize_y(y_bottom)], axis=1)
    
    # ä¸Šå£é¢æ¸¬è©¦é» (y = +1.0)
    x_top = np.linspace(x_range[0], x_range[1], n_test)
    y_top = np.full(n_test, 1.0)
    coords_top = np.stack([normalize_x(x_top), normalize_y(y_top)], axis=1)
    
    # è½‰æ›ç‚º Tensor
    coords_bottom_t = torch.from_numpy(coords_bottom).float().to(device)
    coords_top_t = torch.from_numpy(coords_top).float().to(device)
    
    # æ¨¡å‹é æ¸¬
    model.eval()
    with torch.no_grad():
        pred_bottom = model(coords_bottom_t).cpu().numpy()
        pred_top = model(coords_top_t).cpu().numpy()
    
    # æå–é€Ÿåº¦åˆ†é‡
    u_bottom = pred_bottom[:, 0]
    v_bottom = pred_bottom[:, 1]
    u_top = pred_top[:, 0]
    v_top = pred_top[:, 1]
    
    # è¨ˆç®—çµ±è¨ˆé‡
    logging.info("\n" + "="*60)
    logging.info("ğŸ“Š é‚Šç•Œæ¢ä»¶è¨ºæ–·çµæœ")
    logging.info("="*60)
    
    logging.info(f"\nğŸ”½ ä¸‹å£é¢ (y = -1.0, {n_test} é»):")
    logging.info(f"  U_mean = {u_bottom.mean():+.6f}  (æ‡‰ç‚º 0)")
    logging.info(f"  U_max  = {np.abs(u_bottom).max():+.6f}")
    logging.info(f"  U_std  = {u_bottom.std():.6f}")
    logging.info(f"  V_mean = {v_bottom.mean():+.6f}  (æ‡‰ç‚º 0)")
    logging.info(f"  V_max  = {np.abs(v_bottom).max():+.6f}")
    logging.info(f"  V_std  = {v_bottom.std():.6f}")
    
    logging.info(f"\nğŸ”¼ ä¸Šå£é¢ (y = +1.0, {n_test} é»):")
    logging.info(f"  U_mean = {u_top.mean():+.6f}  (æ‡‰ç‚º 0)")
    logging.info(f"  U_max  = {np.abs(u_top).max():+.6f}")
    logging.info(f"  U_std  = {u_top.std():.6f}")
    logging.info(f"  V_mean = {v_top.mean():+.6f}  (æ‡‰ç‚º 0)")
    logging.info(f"  V_max  = {np.abs(v_top).max():+.6f}")
    logging.info(f"  V_std  = {v_top.std():.6f}")
    
    # åˆ¤æ–·æ˜¯å¦æ»¿è¶³æ¢ä»¶
    tolerance = 0.01  # å®¹å·®
    
    checks = {
        'bottom_u': np.abs(u_bottom.mean()) < tolerance,
        'bottom_v': np.abs(v_bottom.mean()) < tolerance,
        'top_u': np.abs(u_top.mean()) < tolerance,
        'top_v': np.abs(v_top.mean()) < tolerance,
    }
    
    logging.info("\n" + "="*60)
    logging.info("ğŸ¯ é©—æ”¶çµæœ (å®¹å·® = 0.01):")
    logging.info("="*60)
    
    for key, passed in checks.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        logging.info(f"  {key:15s}: {status}")
    
    total_passed = sum(checks.values())
    total_checks = len(checks)
    
    logging.info(f"\nç¸½è¨ˆ: {total_passed}/{total_checks} é€šé")
    
    if total_passed == total_checks:
        logging.info("\nğŸ‰ æ‰€æœ‰é‚Šç•Œæ¢ä»¶æª¢æŸ¥é€šéï¼")
    else:
        logging.warning(f"\nâš ï¸ æœ‰ {total_checks - total_passed} é …æª¢æŸ¥æœªé€šéï¼Œéœ€è¦é€²ä¸€æ­¥èª¿æ•´")
    
    logging.info("="*60)


if __name__ == '__main__':
    sys.exit(main())
