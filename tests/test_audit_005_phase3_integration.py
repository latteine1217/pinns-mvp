"""
TASK-audit-005 Phase 3: æ•´åˆé©—è­‰æ¸¬è©¦
ç«¯åˆ°ç«¯é©—è­‰æ¨™æº–åŒ–æµç¨‹åœ¨çœŸå¯¦è¨“ç·´å ´æ™¯ä¸­çš„ç©©å®šæ€§èˆ‡æ€§èƒ½

æ¸¬è©¦é …ç›®ï¼š
- Test 8: ç«¯åˆ°ç«¯è¨“ç·´ç©©å®šæ€§ï¼ˆ50 epochsï¼‰
- Test 9: æª¢æŸ¥é»å¯é‡ç¾æ€§ï¼ˆä¿å­˜/è¼‰å…¥é©—è­‰ï¼‰
- Test 10: æ€§èƒ½åŸºæº–æ¸¬è©¦ï¼ˆç°¡åŒ–ç‰ˆï¼š2 ç¨®é…ç½®å°æ¯”ï¼‰

åŸ·è¡Œæ™‚é–“ï¼šç´„ 30-40 åˆ†é˜
"""

import pytest
import torch
import torch.nn as nn
import numpy as np
import yaml
import time
import os
import sys
from pathlib import Path
from typing import Dict, Any, Tuple

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pinnx.train.trainer import Trainer
from pinnx.train.config_loader import load_config
from pinnx.utils.normalization import UnifiedNormalizer
from pinnx.models.fourier_mlp import PINNNet
from pinnx.train.factory import create_physics  # âœ… ä½¿ç”¨å·¥å» å‡½æ•¸å‰µå»º physics
from pinnx.losses.residuals import NSResidualLoss, BoundaryConditionLoss


# =============================================================================
# æ¸¬è©¦é…ç½®èˆ‡å·¥å…·å‡½æ•¸
# =============================================================================

def create_test_config(
    experiment_name: str,
    input_norm: str = 'standard',
    output_norm: str = 'manual',
    epochs: int = 10
) -> Dict[str, Any]:
    """å‰µå»ºæ¸¬è©¦é…ç½®"""
    config = {
        'experiment': {
            'name': experiment_name,
            'version': 'v1.0',
            'seed': 42,
            'device': 'cpu',  # CPU æ¸¬è©¦ï¼ˆé¿å… GPU ä¾è³´ï¼‰
            'precision': 'float32'
        },
        'model': {
            'type': 'fourier_mlp',
            'in_dim': 3,
            'out_dim': 4,
            'width': 64,  # å°ç¶²è·¯ï¼ˆå¿«é€Ÿï¼‰
            'depth': 3,
            'activation': 'sine',
            'scaling': {
                'learnable': False,
                'input_norm': input_norm,
                'input_norm_range': [-1.0, 1.0]
            },
            'fourier_features': {
                'type': 'basic',
                'fourier_m': 8,
                'fourier_sigma': 1.0
            }
        },
        'normalization': {
            'type': output_norm,
            'variable_order': ['u', 'v', 'w', 'p'],
            'params': {
                'u_mean': 1.0,
                'u_std': 0.5,
                'v_mean': 0.0,
                'v_std': 0.3,
                'w_mean': 0.0,
                'w_std': 0.3,
                'p_mean': 0.0,
                'p_std': 0.1
            }
        },
        'physics': {
            'type': 'vs_pinn_channel_flow',
            'nu': 5.0e-5,
            'rho': 1.0,
            'channel_flow': {
                'Re_tau': 1000.0,
                'u_tau': 0.04997,
                'pressure_gradient': 0.0025
            },
            'domain': {
                'x_range': [0.0, 25.13],
                'y_range': [-1.0, 1.0],
                'z_range': [0.0, 9.42]
            },
            'vs_pinn': {
                'use_gradient_checkpointing': False
            }
        },
        'training': {
            'optimizer': 'adam',
            'lr': 1.0e-3,
            'epochs': epochs,
            'batch_size': 256,
            'validation_freq': max(epochs // 4, 1),
            'checkpoint_freq': max(epochs // 2, 1),
            'log_interval': max(epochs // 10, 1),
            'gradient_clip': 1.0,
            'sampling': {
                'pde_points': 512,
                'boundary_points': 256
            }
        },
        'losses': {
            'data_weight': 5.0,
            'boundary_weight': 5.0,
            'momentum_x_weight': 1.0,
            'momentum_y_weight': 1.0,
            'momentum_z_weight': 1.0,
            'continuity_weight': 1.0,
            'adaptive_weighting': False
        },
        'output': {
            'checkpoint_dir': './results/audit_005_phase3/checkpoints',
            'results_dir': './results/audit_005_phase3/results',
            'visualization_dir': './results/audit_005_phase3/visualizations'
        },
        'logging': {
            'level': 'warning',  # æ¸›å°‘æ—¥èªŒè¼¸å‡º
            'log_freq': max(epochs // 5, 1),
            'save_predictions': False,
            'tensorboard': False,
            'wandb': False
        }
    }
    return config


def compare_metadata(meta1: Any, meta2: Any, path: str = "root") -> bool:
    """
    éè¿´æ¯”è¼ƒ Metadataï¼ˆè™•ç† Tensorã€Dictã€Listï¼‰
    
    Args:
        meta1, meta2: å¾…æ¯”è¼ƒçš„ç‰©ä»¶
        path: ç•¶å‰æ¯”è¼ƒè·¯å¾‘ï¼ˆç”¨æ–¼éŒ¯èª¤è¨Šæ¯ï¼‰
    
    Returns:
        bool: æ˜¯å¦å®Œå…¨ä¸€è‡´
    
    Raises:
        AssertionError: è‹¥ä¸ä¸€è‡´ï¼ŒåŒ…å«è©³ç´°å·®ç•°è·¯å¾‘
    """
    # é¡å‹æª¢æŸ¥
    if type(meta1) != type(meta2):
        raise AssertionError(
            f"âŒ Metadata é¡å‹ä¸ä¸€è‡´ @ {path}\n"
            f"   meta1: {type(meta1).__name__}\n"
            f"   meta2: {type(meta2).__name__}"
        )
    
    # Tensor æ¯”è¼ƒ
    if isinstance(meta1, torch.Tensor):
        if not torch.equal(meta1, meta2):
            raise AssertionError(
                f"âŒ Tensor å€¼ä¸ä¸€è‡´ @ {path}\n"
                f"   meta1: {meta1}\n"
                f"   meta2: {meta2}"
            )
        return True
    
    # Dict æ¯”è¼ƒ
    if isinstance(meta1, dict):
        if set(meta1.keys()) != set(meta2.keys()):
            raise AssertionError(
                f"âŒ Dict éµä¸ä¸€è‡´ @ {path}\n"
                f"   meta1 keys: {set(meta1.keys())}\n"
                f"   meta2 keys: {set(meta2.keys())}"
            )
        for key in meta1.keys():
            compare_metadata(meta1[key], meta2[key], path=f"{path}.{key}")
        return True
    
    # List/Tuple æ¯”è¼ƒ
    if isinstance(meta1, (list, tuple)):
        if len(meta1) != len(meta2):
            raise AssertionError(
                f"âŒ åºåˆ—é•·åº¦ä¸ä¸€è‡´ @ {path}\n"
                f"   meta1: {len(meta1)}\n"
                f"   meta2: {len(meta2)}"
            )
        for i, (v1, v2) in enumerate(zip(meta1, meta2)):
            compare_metadata(v1, v2, path=f"{path}[{i}]")
        return True
    
    # åŸºæœ¬é¡å‹æ¯”è¼ƒ
    if meta1 != meta2:
        raise AssertionError(
            f"âŒ å€¼ä¸ä¸€è‡´ @ {path}\n"
            f"   meta1: {meta1}\n"
            f"   meta2: {meta2}"
        )
    return True


def create_mock_training_data(n_points: int = 100, n_sensors: int = 20, n_bc: int = 50) -> Dict[str, torch.Tensor]:
    """
    å‰µå»ºæ¨¡æ“¬è¨“ç·´è³‡æ–™ï¼ˆç¬¦åˆ Trainer.step() æœŸæœ›çš„æ ¼å¼ï¼‰
    
    Returns:
        å­—å…¸åŒ…å«ï¼š
        - PDE é»ï¼šx_pde, y_pde, z_pde, t_pde
        - é‚Šç•Œé»ï¼šx_bc, y_bc, z_bc, t_bc, u_bc, v_bc, w_bc, p_bc
        - æ„Ÿæ¸¬é»ï¼šx_sensors, y_sensors, z_sensors, t_sensors, u_sensors, v_sensors, w_sensors, p_sensors
    """
    torch.manual_seed(42)
    
    # === PDE é»ï¼ˆç”¨æ–¼è¨ˆç®—ç‰©ç†æ®˜å·®ï¼‰===
    x_pde = torch.rand(n_points, 1) * 25.13
    y_pde = torch.rand(n_points, 1) * 2.0 - 1.0
    z_pde = torch.rand(n_points, 1) * 9.42
    t_pde = torch.zeros(n_points, 1)  # ç©©æ…‹å•é¡Œ
    
    # === é‚Šç•Œé»ï¼ˆä¸Šä¸‹å£é¢ y=Â±1ï¼‰===
    x_bc = torch.rand(n_bc, 1) * 25.13
    y_bc = torch.where(torch.rand(n_bc, 1) > 0.5, 
                       torch.ones(n_bc, 1), 
                       -torch.ones(n_bc, 1))  # éš¨æ©Ÿåˆ†é…åˆ°ä¸Šå£æˆ–ä¸‹å£
    z_bc = torch.rand(n_bc, 1) * 9.42
    t_bc = torch.zeros(n_bc, 1)
    
    # é‚Šç•Œæ¢ä»¶ï¼ˆç„¡æ»‘ç§»ï¼šu=v=w=0ï¼‰
    u_bc = torch.zeros(n_bc, 1)
    v_bc = torch.zeros(n_bc, 1)
    w_bc = torch.zeros(n_bc, 1)
    p_bc = torch.zeros(n_bc, 1)  # å£“åŠ›å¯é¸
    
    # === æ„Ÿæ¸¬é»ï¼ˆç¨€ç–è§€æ¸¬è³‡æ–™ï¼‰===
    x_sensors = torch.rand(n_sensors, 1) * 25.13
    y_sensors = torch.rand(n_sensors, 1) * 2.0 - 1.0
    z_sensors = torch.rand(n_sensors, 1) * 9.42
    t_sensors = torch.zeros(n_sensors, 1)
    
    # æ¨¡æ“¬é€Ÿåº¦å ´ï¼ˆç°¡å–® Poiseuille æµ + å™ªè²ï¼‰
    u_sensors = 1.0 * (1.0 - y_sensors**2) + 0.01 * torch.randn(n_sensors, 1)
    v_sensors = 0.01 * torch.randn(n_sensors, 1)
    w_sensors = 0.01 * torch.randn(n_sensors, 1)
    p_sensors = torch.zeros(n_sensors, 1)
    
    return {
        # PDE é»
        'x_pde': x_pde, 'y_pde': y_pde, 'z_pde': z_pde, 't_pde': t_pde,
        # é‚Šç•Œé»
        'x_bc': x_bc, 'y_bc': y_bc, 'z_bc': z_bc, 't_bc': t_bc,
        'u_bc': u_bc, 'v_bc': v_bc, 'w_bc': w_bc, 'p_bc': p_bc,
        # æ„Ÿæ¸¬é»
        'x_sensors': x_sensors, 'y_sensors': y_sensors, 'z_sensors': z_sensors, 't_sensors': t_sensors,
        'u_sensors': u_sensors, 'v_sensors': v_sensors, 'w_sensors': w_sensors, 'p_sensors': p_sensors
    }


def initialize_trainer(config: Dict[str, Any]) -> Tuple[Trainer, UnifiedNormalizer]:
    """
    åˆå§‹åŒ– Trainer èˆ‡ UnifiedNormalizerï¼ˆéµå¾ªå¯¦éš› APIï¼‰
    
    Returns:
        (trainer, normalizer): è¨“ç·´å™¨èˆ‡æ¨™æº–åŒ–å™¨
    """
    device = torch.device(config['experiment']['device'])
    
    # 1. å‰µå»ºæ¨¡å‹
    model = PINNNet(
        in_dim=config['model']['in_dim'],
        out_dim=config['model']['out_dim'],
        width=config['model']['width'],
        depth=config['model']['depth'],
        activation=config['model']['activation'],
        use_fourier=True,
        fourier_m=config['model']['fourier_features']['fourier_m'],
        fourier_sigma=config['model']['fourier_features']['fourier_sigma']
    ).to(device)
    
    # 2. å‰µå»ºç‰©ç†æ¨¡çµ„ï¼ˆä½¿ç”¨å·¥å» å‡½æ•¸ï¼‰
    physics = create_physics(config, device)
    
    # 3. å‰µå»ºæå¤±å‡½æ•¸å­—å…¸
    losses = {
        'ns_residual': NSResidualLoss(),
        'boundary': BoundaryConditionLoss()
    }
    
    # 4. å‰µå»º UnifiedNormalizerï¼ˆç¨ç«‹ç®¡ç†ï¼‰
    normalizer = UnifiedNormalizer.from_config(config, device=device)
    
    # 5. å‰µå»º Trainer
    trainer = Trainer(
        model=model,
        physics=physics,
        losses=losses,
        config=config,
        device=device,
        weighters=None,  # ç°¡åŒ–æ¸¬è©¦ä¸ä½¿ç”¨å‹•æ…‹æ¬Šé‡
        input_normalizer=None  # UnifiedNormalizer ç¨ç«‹ç®¡ç†
    )
    
    return trainer, normalizer


# =============================================================================
# Test 8: ç«¯åˆ°ç«¯è¨“ç·´ç©©å®šæ€§æ¸¬è©¦
# =============================================================================

def test_8_end_to_end_training_stability():
    """
    Test 8: ç«¯åˆ°ç«¯è¨“ç·´ç©©å®šæ€§
    
    é©—æ”¶æ¨™æº–ï¼š
    - âœ… è¨“ç·´å®Œæˆç„¡ NaN/Inf
    - âœ… æå¤±å€¼æŒçºŒä¸‹é™ï¼ˆæœ€çµ‚ < åˆå§‹ Ã— 0.5ï¼‰
    - âœ… Normalizer metadata åœ¨è¨“ç·´éç¨‹ä¸­ä¿æŒä¸€è‡´
    """
    print("\n" + "="*80)
    print("Test 8: ç«¯åˆ°ç«¯è¨“ç·´ç©©å®šæ€§æ¸¬è©¦")
    print("="*80)
    
    # å‰µå»ºé…ç½®ï¼ˆ50 epochsï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡æ”¶æ–‚ï¼‰
    config = create_test_config(
        experiment_name='test_8_end_to_end',
        input_norm='standard',
        output_norm='manual',
        epochs=50
    )
    
    # åˆå§‹åŒ– Trainer èˆ‡ Normalizer
    print("\n[1/5] åˆå§‹åŒ– Trainer èˆ‡ Normalizer...")
    trainer, normalizer = initialize_trainer(config)
    
    # æº–å‚™è¨“ç·´è³‡æ–™
    print("[2/5] æº–å‚™è¨“ç·´è³‡æ–™...")
    training_data = create_mock_training_data(n_points=500, n_sensors=50, n_bc=100)
    trainer.training_data = training_data
    
    # è¨˜éŒ„åˆå§‹ metadata
    print("[3/5] è¨˜éŒ„åˆå§‹ metadata...")
    metadata_epoch_0 = normalizer.get_metadata()
    
    # åŸ·è¡Œè¨“ç·´
    print("[4/5] é–‹å§‹è¨“ç·´ï¼ˆ50 epochsï¼‰...")
    print("    é è¨ˆæ™‚é–“ï¼š3-5 åˆ†é˜")
    start_time = time.time()
    
    train_result = trainer.train()
    
    elapsed_time = time.time() - start_time
    print(f"    è¨“ç·´å®Œæˆï¼Œè€—æ™‚ï¼š{elapsed_time:.1f} ç§’")
    
    # é©—è­‰çµæœ
    print("[5/5] é©—è­‰è¨“ç·´çµæœ...")
    
    # æª¢æŸ¥ 1: æå¤±å€¼ç„¡ NaN/Inf
    final_loss = train_result['final_loss']
    assert np.isfinite(final_loss), f"âŒ æœ€çµ‚æå¤±ç‚º NaN/Inf: {final_loss}"
    print(f"    âœ… æœ€çµ‚æå¤±æœ‰æ•ˆ: {final_loss:.6f}")
    
    # æª¢æŸ¥ 2: æå¤±ä¸‹é™
    history = train_result.get('history', {})
    if 'total_loss' in history and len(history['total_loss']) > 0:
        initial_loss = history['total_loss'][0]
        loss_ratio = final_loss / initial_loss
        assert loss_ratio < 0.5, f"âŒ æå¤±ä¸‹é™ä¸è¶³: {loss_ratio:.2%} (æœŸæœ› < 50%)"
        print(f"    âœ… æå¤±ä¸‹é™: {initial_loss:.6f} â†’ {final_loss:.6f} ({loss_ratio:.2%})")
    
    # æª¢æŸ¥ 3: Metadata ä¸€è‡´æ€§
    metadata_epoch_50 = normalizer.get_metadata()
    
    # æ¯”è¼ƒ input_transform metadata
    input_meta_0 = metadata_epoch_0['input']  # âœ… ä¿®æ­£éµå
    input_meta_50 = metadata_epoch_50['input']
    assert input_meta_0['norm_type'] == input_meta_50['norm_type'], "âŒ Input norm_type æ”¹è®Š"
    # feature_range æ˜¯ tensorï¼Œéœ€ä½¿ç”¨ torch.equal
    if 'feature_range' in input_meta_0 and 'feature_range' in input_meta_50:
        assert torch.equal(input_meta_0['feature_range'], input_meta_50['feature_range']), "âŒ Feature range æ”¹è®Š"
    
    # æ¯”è¼ƒ output_transform metadata
    output_meta_0 = metadata_epoch_0['output']  # âœ… ä¿®æ­£éµå
    output_meta_50 = metadata_epoch_50['output']
    assert output_meta_0['norm_type'] == output_meta_50['norm_type'], "âŒ Output norm_type æ”¹è®Š"
    assert output_meta_0['variable_order'] == output_meta_50['variable_order'], "âŒ Variable order æ”¹è®Š"
    
    print("    âœ… Metadata ä¸€è‡´æ€§é€šé")
    
    print("\n" + "="*80)
    print("âœ… Test 8 é€šé: ç«¯åˆ°ç«¯è¨“ç·´ç©©å®š")
    print("="*80)
    return True


# =============================================================================
# Test 9: æª¢æŸ¥é»å¯é‡ç¾æ€§æ¸¬è©¦
# =============================================================================

def test_9_checkpoint_reproducibility():
    """
    Test 9: æª¢æŸ¥é»å¯é‡ç¾æ€§
    
    é©—æ”¶æ¨™æº–ï¼š
    - âœ… ä¿å­˜æª¢æŸ¥é»æˆåŠŸ
    - âœ… è¼‰å…¥æª¢æŸ¥é»å¾Œé æ¸¬èª¤å·® < 1e-5
    - âœ… Metadata å®Œå…¨ä¸€è‡´
    """
    print("\n" + "="*80)
    print("Test 9: æª¢æŸ¥é»å¯é‡ç¾æ€§æ¸¬è©¦")
    print("="*80)
    
    # å‰µå»ºé…ç½®ï¼ˆ10 epochsï¼Œå¿«é€Ÿï¼‰
    config = create_test_config(
        experiment_name='test_9_checkpoint',
        input_norm='standard',
        output_norm='manual',
        epochs=10
    )
    
    # åˆå§‹åŒ–ç¬¬ä¸€å€‹ Trainer
    print("\n[1/6] è¨“ç·´ç¬¬ä¸€å€‹æ¨¡å‹...")
    trainer_1, normalizer_1 = initialize_trainer(config)
    training_data = create_mock_training_data(n_points=100)
    trainer_1.training_data = training_data
    
    # è¨“ç·´
    start_time = time.time()
    train_result_1 = trainer_1.train()
    elapsed_time = time.time() - start_time
    print(f"    è¨“ç·´å®Œæˆï¼Œè€—æ™‚ï¼š{elapsed_time:.1f} ç§’")
    
    # ä¿å­˜æª¢æŸ¥é»
    print("[2/6] ä¿å­˜æª¢æŸ¥é»...")
    # âœ… save_checkpoint() æœƒè‡ªå‹•ä½¿ç”¨ config['output']['checkpoint_dir']
    trainer_1.save_checkpoint(epoch=10, metrics={'test_loss': 0.1}, is_best=False)
    
    # æª¢æŸ¥é»è·¯å¾‘ç‚º checkpoint_dir/epoch_10.pth
    checkpoint_path = Path(config['output']['checkpoint_dir']) / 'epoch_10.pth'
    assert checkpoint_path.exists(), f"âŒ æª¢æŸ¥é»æœªä¿å­˜: {checkpoint_path}"
    print(f"    âœ… æª¢æŸ¥é»å·²ä¿å­˜: {checkpoint_path}")
    
    # ç”Ÿæˆæ¸¬è©¦é æ¸¬
    print("[3/6] ç”Ÿæˆæ¸¬è©¦é æ¸¬ï¼ˆæ¨¡å‹ 1ï¼‰...")
    test_coords = torch.rand(50, 3) * torch.tensor([25.13, 2.0, 9.42]) + torch.tensor([0.0, -1.0, 0.0])
    
    trainer_1.model.eval()
    with torch.no_grad():
        pred_1 = trainer_1.model(test_coords)
    
    # åˆå§‹åŒ–ç¬¬äºŒå€‹ Trainer ä¸¦è¼‰å…¥æª¢æŸ¥é»
    print("[4/6] åˆå§‹åŒ–ç¬¬äºŒå€‹æ¨¡å‹ä¸¦è¼‰å…¥æª¢æŸ¥é»...")
    trainer_2, normalizer_2 = initialize_trainer(config)
    
    trainer_2.load_checkpoint(str(checkpoint_path))
    print("    âœ… æª¢æŸ¥é»å·²è¼‰å…¥")
    
    # ç”Ÿæˆæ¸¬è©¦é æ¸¬ï¼ˆæ¨¡å‹ 2ï¼‰
    print("[5/6] ç”Ÿæˆæ¸¬è©¦é æ¸¬ï¼ˆæ¨¡å‹ 2ï¼‰...")
    trainer_2.model.eval()
    with torch.no_grad():
        pred_2 = trainer_2.model(test_coords)
    
    # é©—è­‰é æ¸¬ä¸€è‡´æ€§
    print("[6/6] é©—è­‰é æ¸¬ä¸€è‡´æ€§...")
    pred_error = torch.abs(pred_1 - pred_2).max().item()
    assert pred_error < 1e-5, f"âŒ é æ¸¬èª¤å·®éå¤§: {pred_error:.2e} (æœŸæœ› < 1e-5)"
    print(f"    âœ… é æ¸¬èª¤å·®: {pred_error:.2e} < 1e-5")
    
    # é©—è­‰ Metadata ä¸€è‡´æ€§
    metadata_1 = normalizer_1.get_metadata()
    metadata_2 = normalizer_2.get_metadata()
    
    try:
        compare_metadata(metadata_1, metadata_2)
        print("    âœ… Metadata å®Œå…¨ä¸€è‡´")
    except AssertionError as e:
        pytest.fail(str(e))
    
    print("\n" + "="*80)
    print("âœ… Test 9 é€šé: æª¢æŸ¥é»å¯é‡ç¾æ€§é©—è­‰")
    print("="*80)
    return True


# =============================================================================
# Test 10: æ€§èƒ½åŸºæº–æ¸¬è©¦ï¼ˆç°¡åŒ–ç‰ˆï¼‰
# =============================================================================

def test_10_performance_benchmark():
    """
    Test 10: æ€§èƒ½åŸºæº–æ¸¬è©¦ï¼ˆç°¡åŒ–ç‰ˆï¼‰
    
    é©—æ”¶æ¨™æº–ï¼š
    - âœ… Baseline é…ç½®è¨“ç·´æˆåŠŸ
    - âœ… Full é…ç½®è¨“ç·´æˆåŠŸ
    - âœ… ç”Ÿæˆæ€§èƒ½å°æ¯”å ±å‘Š
    """
    print("\n" + "="*80)
    print("Test 10: æ€§èƒ½åŸºæº–æ¸¬è©¦ï¼ˆç°¡åŒ–ç‰ˆï¼‰")
    print("="*80)
    
    results = {}
    
    # é…ç½® 1: Baselineï¼ˆç„¡æ¨™æº–åŒ–ï¼‰
    print("\n[1/3] Baseline é…ç½®ï¼ˆç„¡æ¨™æº–åŒ–ï¼‰...")
    config_baseline = create_test_config(
        experiment_name='test_10_baseline',
        input_norm='none',
        output_norm='none',
        epochs=20
    )
    
    trainer_baseline, _ = initialize_trainer(config_baseline)
    trainer_baseline.training_data = create_mock_training_data(n_points=200)
    
    start_time = time.time()
    result_baseline = trainer_baseline.train()
    elapsed_baseline = time.time() - start_time
    
    results['baseline'] = {
        'final_loss': result_baseline['final_loss'],
        'time': elapsed_baseline
    }
    print(f"    âœ… Baseline: Loss={result_baseline['final_loss']:.6f}, Time={elapsed_baseline:.1f}s")
    
    # é…ç½® 2: Fullï¼ˆæ¨™æº–åŒ–ï¼‰
    print("\n[2/3] Full é…ç½®ï¼ˆæ¨™æº–åŒ–ï¼‰...")
    config_full = create_test_config(
        experiment_name='test_10_full',
        input_norm='standard',
        output_norm='manual',
        epochs=20
    )
    
    trainer_full, _ = initialize_trainer(config_full)
    trainer_full.training_data = create_mock_training_data(n_points=200)
    
    start_time = time.time()
    result_full = trainer_full.train()
    elapsed_full = time.time() - start_time
    
    results['full'] = {
        'final_loss': result_full['final_loss'],
        'time': elapsed_full
    }
    print(f"    âœ… Full: Loss={result_full['final_loss']:.6f}, Time={elapsed_full:.1f}s")
    
    # ç”Ÿæˆå°æ¯”å ±å‘Š
    print("\n[3/3] ç”Ÿæˆæ€§èƒ½å°æ¯”å ±å‘Š...")
    print("\n" + "-"*80)
    print("æ€§èƒ½å°æ¯”çµæœï¼š")
    print("-"*80)
    print(f"{'é…ç½®':<15} {'æœ€çµ‚æå¤±':<15} {'è¨“ç·´æ™‚é–“ (s)':<15}")
    print("-"*80)
    for name, res in results.items():
        print(f"{name:<15} {res['final_loss']:<15.6f} {res['time']:<15.1f}")
    print("-"*80)
    
    # ä¿å­˜å ±å‘Š
    report_path = Path('./results/audit_005_phase3/benchmarks/performance_report.txt')
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_path, 'w') as f:
        f.write("TASK-audit-005 Phase 3 æ€§èƒ½åŸºæº–æ¸¬è©¦å ±å‘Š\n")
        f.write("="*80 + "\n\n")
        f.write(f"{'é…ç½®':<15} {'æœ€çµ‚æå¤±':<15} {'è¨“ç·´æ™‚é–“ (s)':<15}\n")
        f.write("-"*80 + "\n")
        for name, res in results.items():
            f.write(f"{name:<15} {res['final_loss']:<15.6f} {res['time']:<15.1f}\n")
    
    print(f"\n    âœ… å ±å‘Šå·²ä¿å­˜: {report_path}")
    
    print("\n" + "="*80)
    print("âœ… Test 10 é€šé: æ€§èƒ½åŸºæº–æ¸¬è©¦å®Œæˆ")
    print("="*80)
    return True


# =============================================================================
# ä¸»å‡½æ•¸
# =============================================================================

if __name__ == "__main__":
    print("\n" + "="*80)
    print("TASK-audit-005 Phase 3: æ•´åˆé©—è­‰æ¸¬è©¦")
    print("="*80)
    print("é è¨ˆç¸½æ™‚é–“ï¼š30-40 åˆ†é˜")
    print("="*80)
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dirs = [
        './results/audit_005_phase3/checkpoints',
        './results/audit_005_phase3/logs',
        './results/audit_005_phase3/benchmarks'
    ]
    for dir_path in output_dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    # åŸ·è¡Œæ¸¬è©¦
    try:
        test_8_end_to_end_training_stability()
        test_9_checkpoint_reproducibility()
        test_10_performance_benchmark()
        
        print("\n" + "="*80)
        print("ğŸ‰ Phase 3 æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        print("="*80)
        
    except AssertionError as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        raise
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        raise
