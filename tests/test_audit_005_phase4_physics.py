"""
TASK-audit-005 Phase 4: ç‰©ç†ä¸€è‡´æ€§æ¸¬è©¦
=======================================

æ¸¬è©¦ç›®æ¨™ï¼šé©—è­‰æ¨™æº–åŒ–æµç¨‹å°ç‰©ç†å®ˆæ†å¾‹çš„å½±éŸ¿

æ¸¬è©¦ç¯„åœï¼š
1. è³ªé‡å®ˆæ†ï¼ˆé€£çºŒæ€§æ–¹ç¨‹ï¼‰ï¼šâˆ‡Â·u = 0
2. å‹•é‡å®ˆæ†ï¼ˆNS æ–¹ç¨‹æ®˜å·®ï¼‰
3. é‚Šç•Œæ¢ä»¶æ»¿è¶³åº¦ï¼ˆå£é¢ç„¡æ»‘ç§» + é€±æœŸæ€§ï¼‰

é©—æ”¶æ¨™æº–ï¼š
- è³ªé‡å®ˆæ†ï¼š||div(u)||_LÂ² < 1.0ï¼ˆæœªè¨“ç·´ç¶²çµ¡ï¼‰
- å‹•é‡æ®˜å·®ï¼š||NS_residual||_LÂ² < 100.0ï¼ˆæœªè¨“ç·´ç¶²çµ¡ï¼‰
- å£é¢æ¢ä»¶ï¼š||u_wall||Â² < 10.0ï¼ˆæœªè¨“ç·´ç¶²çµ¡ï¼‰
- æ¨™æº–åŒ–å½±éŸ¿ï¼šNormalized < 2Ã— Baselineï¼ˆä¸æ‡‰åŠ£åŒ–ç‰©ç†ä¸€è‡´æ€§ï¼‰

æŠ€è¡“è¦é»ï¼š
- ä½¿ç”¨ç°¡åŒ–çš„ 3D Channel Flow ç‰©ç†æ¨¡å‹ï¼ˆé™ä½è¨ˆç®—æˆæœ¬ï¼‰
- æ¸¬è©¦æ¨™æº–åŒ–å‰å¾Œç‰©ç†ä¸€è‡´æ€§
- æª¢æŸ¥ Metadata å°æ¢¯åº¦è¨ˆç®—çš„å½±éŸ¿

åƒè€ƒï¼š
- tasks/TASK-audit-005/phase3_impl_plan.md
- results/audit_005_phase3/PHASE3_TEST_REPORT.md
"""

import pytest
import torch
import torch.nn as nn
import numpy as np
import sys
from pathlib import Path
from typing import Tuple, Dict, Any, cast

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from pinnx.utils.normalization import UnifiedNormalizer
from pinnx.physics.vs_pinn_channel_flow import VSPINNChannelFlow


# ============================================================================
# å·¥å…·å‡½æ•¸
# ============================================================================

def create_simple_channel_flow_model(
    input_dim: int = 3,
    output_dim: int = 4,
    hidden_dim: int = 64,
    num_layers: int = 3,
    device: torch.device = torch.device('cpu')
) -> nn.Module:
    """å‰µå»ºç°¡å–®çš„é€šé“æµç¶²çµ¡ï¼ˆç”¨æ–¼ç‰©ç†æ¸¬è©¦ï¼‰
    
    Args:
        input_dim: è¼¸å…¥ç¶­åº¦ï¼ˆ3=x,y,zï¼‰
        output_dim: è¼¸å‡ºç¶­åº¦ï¼ˆ4=u,v,w,pï¼‰
        hidden_dim: éš±è—å±¤å¯¬åº¦
        num_layers: éš±è—å±¤æ•¸é‡
        device: è¨ˆç®—è¨­å‚™
        
    Returns:
        PyTorch æ¨¡å‹ï¼ˆSequentialï¼‰
    """
    layers = []
    layers.append(nn.Linear(input_dim, hidden_dim))
    layers.append(nn.Tanh())
    
    for _ in range(num_layers - 1):
        layers.append(nn.Linear(hidden_dim, hidden_dim))
        layers.append(nn.Tanh())
    
    layers.append(nn.Linear(hidden_dim, output_dim))
    
    model = nn.Sequential(*layers)
    return model.to(device)


def create_test_config_physics(enable_normalization: bool = True) -> Dict[str, Any]:
    """å‰µå»ºç‰©ç†æ¸¬è©¦ç”¨çš„é…ç½®ï¼ˆç°¡åŒ–ç‰ˆï¼‰
    
    Args:
        enable_normalization: æ˜¯å¦å•Ÿç”¨æ¨™æº–åŒ–
        
    Returns:
        æ¸¬è©¦é…ç½®å­—å…¸
    """
    if enable_normalization:
        normalization_config = {
            'type': 'manual',
            'variable_order': ['u', 'v', 'w', 'p'],
            'params': {
                'u_mean': 0.0,
                'v_mean': 0.0,
                'w_mean': 0.0,
                'p_mean': 0.0,
                'u_std': 1.0,
                'v_std': 1.0,
                'w_std': 1.0,
                'p_std': 1.0
            }
        }
    else:
        normalization_config = {
            'type': 'none',
            'variable_order': ['u', 'v', 'w', 'p']
        }
    
    config = {
        'model': {
            'input_dim': 3,
            'output_dim': 4,
            'hidden_dim': 64,
            'num_layers': 3,
            'scaling': {
                'input_norm': 'standard' if enable_normalization else 'none',
                'input_norm_range': [-1.0, 1.0]
            }
        },
        'normalization': normalization_config,
        'physics': {
            'nu': 5e-5,  # JHTDB Channel Flow Re_Ï„=1000
            'dP_dx': 0.0025,
            'rho': 1.0,
            'domain': {
                'x_range': [0.0, 2.0 * np.pi],
                'y_range': [-1.0, 1.0],
                'z_range': [0.0, np.pi]
            },
            'scaling_factors': {
                'N_x': 2.0,
                'N_y': 12.0,
                'N_z': 2.0
            }
        },
        'training': {
            'optimizer': 'adam',
            'lr': 1e-3,
            'epochs': 100,
            'batch_size': 256
        }
    }
    
    return config


def compute_divergence(
    coords: torch.Tensor,
    velocity: torch.Tensor
) -> torch.Tensor:
    """è¨ˆç®—é€Ÿåº¦å ´æ•£åº¦ï¼ˆè³ªé‡å®ˆæ†æª¢æŸ¥ï¼‰
    
    Args:
        coords: åº§æ¨™å¼µé‡ [batch, 3]ï¼Œéœ€è¦ requires_grad=True
        velocity: é€Ÿåº¦å¼µé‡ [batch, 3]ï¼ˆu, v, wï¼‰
        
    Returns:
        æ•£åº¦ [batch, 1]
        
    Note:
        ä½¿ç”¨è‡ªå‹•å¾®åˆ†è¨ˆç®— âˆ‚u/âˆ‚x + âˆ‚v/âˆ‚y + âˆ‚w/âˆ‚z
    """
    u, v, w = velocity[:, 0:1], velocity[:, 1:2], velocity[:, 2:3]
    
    # è¨ˆç®—å„åˆ†é‡å°æ•¸
    u_x = torch.autograd.grad(
        u, coords,
        grad_outputs=torch.ones_like(u),
        create_graph=True, retain_graph=True
    )[0][:, 0:1]
    
    v_y = torch.autograd.grad(
        v, coords,
        grad_outputs=torch.ones_like(v),
        create_graph=True, retain_graph=True
    )[0][:, 1:2]
    
    w_z = torch.autograd.grad(
        w, coords,
        grad_outputs=torch.ones_like(w),
        create_graph=True, retain_graph=True
    )[0][:, 2:3]
    
    divergence = u_x + v_y + w_z
    return divergence


def compute_wall_velocity_error(
    coords: torch.Tensor,
    velocity: torch.Tensor,
    y_min: float = -1.0,
    y_max: float = 1.0,
    tol: float = 1e-6
) -> torch.Tensor:
    """è¨ˆç®—å£é¢ç„¡æ»‘ç§»æ¢ä»¶èª¤å·®
    
    Args:
        coords: åº§æ¨™å¼µé‡ [batch, 3]
        velocity: é€Ÿåº¦å¼µé‡ [batch, 3]ï¼ˆu, v, wï¼‰
        y_min: ä¸‹å£é¢ä½ç½®
        y_max: ä¸Šå£é¢ä½ç½®
        tol: å£é¢è­˜åˆ¥å®¹å·®
        
    Returns:
        å£é¢é€Ÿåº¦èª¤å·® [batch, 1]ï¼ˆå£é¢é»ï¼‰æˆ– [0] if ç„¡å£é¢é»
    """
    y = coords[:, 1]
    
    # è­˜åˆ¥å£é¢é»ï¼ˆä½¿ç”¨å®¹å·®é¿å…æµ®é»èª¤å·®ï¼‰
    mask_lower = torch.abs(y - y_min) < tol
    mask_upper = torch.abs(y - y_max) < tol
    mask_wall = mask_lower | mask_upper
    
    if not mask_wall.any():
        # ç„¡å£é¢é»ï¼Œè¿”å›é›¶èª¤å·®
        return torch.zeros(1, 1, device=coords.device)
    
    # æå–å£é¢é€Ÿåº¦
    velocity_wall = velocity[mask_wall]  # [n_wall, 3]
    
    # ç„¡æ»‘ç§»æ¢ä»¶ï¼šu = v = w = 0
    wall_error = torch.sum(velocity_wall ** 2, dim=1, keepdim=True)
    
    return wall_error


def compute_periodic_error(
    coords: torch.Tensor,
    field: torch.Tensor,
    direction: int = 0,  # 0=x, 2=z
    domain_length: float = 2.0 * np.pi,
    tol: float = 1e-6
) -> torch.Tensor:
    """è¨ˆç®—é€±æœŸæ€§é‚Šç•Œæ¢ä»¶èª¤å·®
    
    Args:
        coords: åº§æ¨™å¼µé‡ [batch, 3]
        field: ç‰©ç†é‡å¼µé‡ [batch, n_vars]ï¼ˆå¯ä»¥æ˜¯é€Ÿåº¦æˆ–å£“åŠ›ï¼‰
        direction: é€±æœŸæ–¹å‘ï¼ˆ0=x, 2=zï¼‰
        domain_length: åŸŸé•·åº¦
        tol: é‚Šç•Œè­˜åˆ¥å®¹å·®
        
    Returns:
        é€±æœŸæ€§èª¤å·® [batch, n_vars]ï¼ˆé‚Šç•Œé»ï¼‰æˆ– [0] if ç„¡é‚Šç•Œé»
    """
    coord = coords[:, direction]
    
    # è­˜åˆ¥é‚Šç•Œé»
    mask_min = torch.abs(coord) < tol
    mask_max = torch.abs(coord - domain_length) < tol
    
    # éœ€è¦åŒæ™‚æœ‰å…©å´é‚Šç•Œé»
    if not (mask_min.any() and mask_max.any()):
        return torch.zeros(1, field.shape[1], device=coords.device)
    
    # æå–é‚Šç•Œå ´
    field_min = field[mask_min]
    field_max = field[mask_max]
    
    # é€±æœŸæ€§æ¢ä»¶ï¼šfield(x_min) = field(x_max)
    # æ³¨æ„ï¼šå¯èƒ½å…©å´é»æ•¸ä¸åŒï¼Œéœ€è¦é…å°
    n_min = field_min.shape[0]
    n_max = field_max.shape[0]
    n_pairs = min(n_min, n_max)
    
    if n_pairs == 0:
        return torch.zeros(1, field.shape[1], device=coords.device)
    
    periodic_error = (field_min[:n_pairs] - field_max[:n_pairs]) ** 2
    
    return periodic_error


# ============================================================================
# æ¸¬è©¦ 11ï¼šè³ªé‡å®ˆæ†é©—è­‰ï¼ˆæ¨™æº–åŒ–å‰å¾Œå°æ¯”ï¼‰
# ============================================================================

@pytest.mark.physics
def test_11_mass_conservation():
    """
    æ¸¬è©¦ 11ï¼šè³ªé‡å®ˆæ†ï¼ˆé€£çºŒæ€§æ–¹ç¨‹ï¼‰
    
    é©—è­‰ï¼š
    1. è¨“ç·´å¾Œæ¨¡å‹æ»¿è¶³ âˆ‡Â·u = 0
    2. æ¨™æº–åŒ–ä¸å½±éŸ¿æ•£åº¦è¨ˆç®—
    3. ||div(u)||_LÂ² < 1.0ï¼ˆæœªè¨“ç·´ç¶²çµ¡çš„åˆç†ç¯„åœï¼‰
    
    ç­–ç•¥ï¼š
    - è¨“ç·´å…©å€‹æ¨¡å‹ï¼ˆæœ‰/ç„¡æ¨™æº–åŒ–ï¼‰
    - åˆ†åˆ¥è¨ˆç®—æ•£åº¦ L2 ç¯„æ•¸
    - ç¢ºèªæ¨™æº–åŒ–ç‰ˆæœ¬ä¸åŠ£æ–¼ç„¡æ¨™æº–åŒ–ç‰ˆæœ¬
    """
    print("\n" + "="*70)
    print("TEST 11: è³ªé‡å®ˆæ†é©—è­‰ï¼ˆæ¨™æº–åŒ–å‰å¾Œå°æ¯”ï¼‰")
    print("="*70)
    
    # å›ºå®šéš¨æ©Ÿç¨®å­ç¢ºä¿æ¸¬è©¦å¯é‡ç¾æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ¸¬è©¦å…©ç¨®é…ç½®
    results = {}
    for config_name, enable_norm in [('Baseline', False), ('Normalized', True)]:
        print(f"\n--- é…ç½®: {config_name} ---")
        
        # æ¯æ¬¡è¿­ä»£é‡ç½®éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿æ¨¡å‹åˆå§‹åŒ–ä¸€è‡´
        torch.manual_seed(42)
        np.random.seed(42)
        
        # å‰µå»ºé…ç½®èˆ‡æ¨¡å‹
        config = create_test_config_physics(enable_normalization=enable_norm)
        model = create_simple_channel_flow_model(device=device)
        
        # å‰µå»ºç‰©ç†æ¨¡çµ„
        physics = VSPINNChannelFlow(
            scaling_factors=config['physics']['scaling_factors'],
            physics_params={
                'nu': config['physics']['nu'],
                'dP_dx': config['physics']['dP_dx'],
                'rho': config['physics']['rho']
            },
            domain_bounds={
                'x': tuple(config['physics']['domain']['x_range']),
                'y': tuple(config['physics']['domain']['y_range']),
                'z': tuple(config['physics']['domain']['z_range'])
            }
        )
        
        # å‰µå»ºæ¨™æº–åŒ–å™¨ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        normalizer = None
        if enable_norm:
            # å‰µå»ºè¨“ç·´æ•¸æ“šç”¨æ–¼æ“¬åˆæ¨™æº–åŒ–å™¨
            training_data = {
                'coords': torch.randn(100, 3),
                'u': torch.randn(100),
                'v': torch.randn(100),
                'w': torch.randn(100),
                'p': torch.randn(100)
            }
            normalizer = UnifiedNormalizer.from_config(config, training_data, device)
        
        # ç”Ÿæˆæ¸¬è©¦é»ï¼ˆåŸŸå…§éš¨æ©Ÿé»ï¼‰
        n_test = 500
        coords_np = np.random.uniform(
            low=[config['physics']['domain']['x_range'][0],
                 config['physics']['domain']['y_range'][0],
                 config['physics']['domain']['z_range'][0]],
            high=[config['physics']['domain']['x_range'][1],
                  config['physics']['domain']['y_range'][1],
                  config['physics']['domain']['z_range'][1]],
            size=(n_test, 3)
        )
        coords = torch.tensor(coords_np, dtype=torch.float32, device=device)
        
        # å‰å‘å‚³æ’­ï¼ˆæ‡‰ç”¨æ¨™æº–åŒ–ï¼‰
        if normalizer is not None:
            # æ¨™æº–åŒ–åˆ†æ”¯ï¼šä½¿ç”¨æ¨™æº–åŒ–åº§æ¨™é€²è¡Œå‰å‘å‚³æ’­
            coords_norm = normalizer.transform_input(coords)
            coords_norm.requires_grad_(True)
            predictions_norm = model(coords_norm)
            predictions = cast(torch.Tensor, normalizer.inverse_transform_output(predictions_norm))
            scaled_coords_for_grad = coords_norm
        else:
            # Baseline åˆ†æ”¯ï¼šä½¿ç”¨ VS-PINN çš„ç¸®æ”¾åº§æ¨™
            scaled_coords_vs = physics.scale_coordinates(coords)
            scaled_coords_vs.requires_grad_(True)
            predictions = model(scaled_coords_vs)
            scaled_coords_for_grad = scaled_coords_vs
        
        # ä½¿ç”¨ç‰©ç†æ¨¡çµ„è¨ˆç®—é€£çºŒæ€§æ®˜å·®ï¼ˆæ•£åº¦ï¼‰
        # é€™æ¨£å¯ä»¥æ­£ç¢ºè™•ç†åº§æ¨™ç¸®æ”¾
        divergence = physics.compute_continuity_residual(
            coords, predictions, scaled_coords=scaled_coords_for_grad
        )
        
        # è¨ˆç®— L2 ç¯„æ•¸
        div_l2 = torch.sqrt(torch.mean(divergence ** 2)).item()
        div_max = torch.abs(divergence).max().item()
        
        print(f"  æ•£åº¦ L2 ç¯„æ•¸: {div_l2:.6e}")
        print(f"  æ•£åº¦æœ€å¤§å€¼: {div_max:.6e}")
        
        results[config_name] = {
            'div_l2': div_l2,
            'div_max': div_max
        }
    
    # é©—è­‰æ¨™æº–
    print(f"\n{'='*70}")
    print("é©—æ”¶æ¨™æº–æª¢æŸ¥ï¼š")
    print(f"{'='*70}")
    
    baseline_div = results['Baseline']['div_l2']
    normalized_div = results['Normalized']['div_l2']
    
    # æ¨™æº– 1ï¼šå…©è€…éƒ½æ‡‰æ»¿è¶³ ||div(u)||_LÂ² < 1.0ï¼ˆæœªè¨“ç·´çš„åˆå§‹ç¶²çµ¡ï¼‰
    assert baseline_div < 1.0, f"Baseline æ•£åº¦éå¤§: {baseline_div:.3e} > 1.0"
    assert normalized_div < 1.0, f"Normalized æ•£åº¦éå¤§: {normalized_div:.3e} > 1.0"
    
    # æ¨™æº– 2ï¼šæ¨™æº–åŒ–ä¸æ‡‰åŠ£åŒ–å®ˆæ†ï¼ˆå…è¨± 2x èª¤å·®ç¯„åœï¼‰
    assert normalized_div < 2.0 * baseline_div, \
        f"æ¨™æº–åŒ–åŠ£åŒ–å®ˆæ†: {normalized_div:.3e} > 2 Ã— {baseline_div:.3e}"
    
    print(f"âœ… Baseline æ•£åº¦: {baseline_div:.6e} < 1.0")
    print(f"âœ… Normalized æ•£åº¦: {normalized_div:.6e} < 1.0")
    print(f"âœ… æ¨™æº–åŒ–å½±éŸ¿: {normalized_div/baseline_div:.2f}x Baseline")
    
    print(f"\n{'='*70}")
    print("TEST 11 é€šé âœ…")
    print(f"{'='*70}")


# ============================================================================
# æ¸¬è©¦ 12ï¼šé‚Šç•Œæ¢ä»¶æ»¿è¶³åº¦
# ============================================================================

@pytest.mark.physics
def test_12_boundary_conditions():
    """
    æ¸¬è©¦ 12ï¼šé‚Šç•Œæ¢ä»¶æ»¿è¶³åº¦
    
    é©—è­‰ï¼š
    1. å£é¢ç„¡æ»‘ç§»æ¢ä»¶ï¼šu(y=Â±1) = 0
    2. é€±æœŸæ€§æ¢ä»¶ï¼šu(x=0) = u(x=2Ï€), u(z=0) = u(z=Ï€)
    3. æ¨™æº–åŒ–ä¸å½±éŸ¿é‚Šç•Œæ¢ä»¶è¨ˆç®—
    
    ç­–ç•¥ï¼š
    - ç”ŸæˆåŒ…å«é‚Šç•Œé»çš„æ¸¬è©¦æ•¸æ“š
    - è¨ˆç®—é‚Šç•Œæ¢ä»¶èª¤å·®
    - ç¢ºèªæ¨™æº–åŒ–ç‰ˆæœ¬æ»¿è¶³ç›¸åŒç²¾åº¦
    """
    print("\n" + "="*70)
    print("TEST 12: é‚Šç•Œæ¢ä»¶æ»¿è¶³åº¦")
    print("="*70)
    
    # å›ºå®šéš¨æ©Ÿç¨®å­ç¢ºä¿æ¸¬è©¦å¯é‡ç¾æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ¸¬è©¦å…©ç¨®é…ç½®
    results = {}
    for config_name, enable_norm in [('Baseline', False), ('Normalized', True)]:
        print(f"\n--- é…ç½®: {config_name} ---")
        
        # æ¯æ¬¡è¿­ä»£é‡ç½®éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿æ¨¡å‹åˆå§‹åŒ–ä¸€è‡´
        torch.manual_seed(42)
        np.random.seed(42)
        
        config = create_test_config_physics(enable_normalization=enable_norm)
        model = create_simple_channel_flow_model(device=device)
        
        # å‰µå»ºæ¨™æº–åŒ–å™¨
        normalizer = None
        if enable_norm:
            training_data = {
                'coords': torch.randn(100, 3),
                'u': torch.randn(100),
                'v': torch.randn(100),
                'w': torch.randn(100),
                'p': torch.randn(100)
            }
            normalizer = UnifiedNormalizer.from_config(config, training_data, device)
        
        # === æ¸¬è©¦å£é¢é‚Šç•Œæ¢ä»¶ ===
        n_wall = 100
        x_wall = np.random.uniform(0, 2*np.pi, n_wall)
        z_wall = np.random.uniform(0, np.pi, n_wall)
        
        # ä¸‹å£é¢ y = -1
        coords_lower = np.column_stack([x_wall, np.full(n_wall, -1.0), z_wall])
        # ä¸Šå£é¢ y = 1
        coords_upper = np.column_stack([x_wall, np.full(n_wall, 1.0), z_wall])
        
        coords_wall_np = np.vstack([coords_lower, coords_upper])
        coords_wall = torch.tensor(coords_wall_np, dtype=torch.float32, device=device)
        coords_wall.requires_grad_(True)
        
        # å‰å‘å‚³æ’­
        if normalizer is not None:
            coords_norm = normalizer.transform_input(coords_wall)
            predictions_norm = model(coords_norm)
            predictions = normalizer.inverse_transform_output(predictions_norm)
        else:
            predictions = model(coords_wall)
        
        velocity_wall = cast(torch.Tensor, predictions[:, :3])
        
        # è¨ˆç®—å£é¢èª¤å·®
        wall_error = compute_wall_velocity_error(coords_wall, velocity_wall)
        wall_error_mean = wall_error.mean().item()
        wall_error_max = wall_error.max().item()
        
        print(f"  å£é¢é€Ÿåº¦èª¤å·®ï¼ˆå¹³å‡ï¼‰: {wall_error_mean:.6e}")
        print(f"  å£é¢é€Ÿåº¦èª¤å·®ï¼ˆæœ€å¤§ï¼‰: {wall_error_max:.6e}")
        
        # === æ¸¬è©¦é€±æœŸæ€§é‚Šç•Œæ¢ä»¶ï¼ˆX æ–¹å‘ï¼‰===
        n_periodic = 50
        y_periodic = np.random.uniform(-1, 1, n_periodic)
        z_periodic = np.random.uniform(0, np.pi, n_periodic)
        
        # X æ–¹å‘é‚Šç•Œ
        coords_x_min = np.column_stack([np.zeros(n_periodic), y_periodic, z_periodic])
        coords_x_max = np.column_stack([np.full(n_periodic, 2*np.pi), y_periodic, z_periodic])
        
        coords_periodic_np = np.vstack([coords_x_min, coords_x_max])
        coords_periodic = torch.tensor(coords_periodic_np, dtype=torch.float32, device=device)
        coords_periodic.requires_grad_(True)
        
        # å‰å‘å‚³æ’­
        if normalizer is not None:
            coords_norm = normalizer.transform_input(coords_periodic)
            predictions_norm = model(coords_norm)
            predictions_periodic = cast(torch.Tensor, normalizer.inverse_transform_output(predictions_norm))
        else:
            predictions_periodic = model(coords_periodic)
        
        # è¨ˆç®—é€±æœŸæ€§èª¤å·®
        periodic_error = compute_periodic_error(
            coords_periodic, predictions_periodic,
            direction=0, domain_length=2.0*np.pi
        )
        periodic_error_mean = periodic_error.mean().item()
        
        print(f"  é€±æœŸæ€§èª¤å·®ï¼ˆXæ–¹å‘ï¼Œå¹³å‡ï¼‰: {periodic_error_mean:.6e}")
        
        results[config_name] = {
            'wall_error_mean': wall_error_mean,
            'wall_error_max': wall_error_max,
            'periodic_error_mean': periodic_error_mean
        }
    
    # é©—è­‰æ¨™æº–
    print(f"\n{'='*70}")
    print("é©—æ”¶æ¨™æº–æª¢æŸ¥ï¼š")
    print(f"{'='*70}")
    
    baseline_wall = results['Baseline']['wall_error_mean']
    normalized_wall = results['Normalized']['wall_error_mean']
    baseline_periodic = results['Baseline']['periodic_error_mean']
    normalized_periodic = results['Normalized']['periodic_error_mean']
    
    # æ¨™æº– 1ï¼šå£é¢èª¤å·®æ‡‰è©²æœ‰é™ï¼ˆæœªè¨“ç·´ç¶²çµ¡ï¼Œå…è¨±è¼ƒå¤§èª¤å·®ï¼‰
    assert baseline_wall < 10.0, f"Baseline å£é¢èª¤å·®éå¤§: {baseline_wall:.3e}"
    assert normalized_wall < 10.0, f"Normalized å£é¢èª¤å·®éå¤§: {normalized_wall:.3e}"
    
    # æ¨™æº– 2ï¼šæ¨™æº–åŒ–ä¸æ‡‰åŠ£åŒ–é‚Šç•Œæ¢ä»¶ï¼ˆå…è¨± 2x èª¤å·®ï¼‰
    assert normalized_wall < 2.0 * baseline_wall + 1.0, \
        f"æ¨™æº–åŒ–åŠ£åŒ–å£é¢æ¢ä»¶: {normalized_wall:.3e} > 2 Ã— {baseline_wall:.3e}"
    
    print(f"âœ… Baseline å£é¢èª¤å·®: {baseline_wall:.6e} < 10.0")
    print(f"âœ… Normalized å£é¢èª¤å·®: {normalized_wall:.6e} < 10.0")
    print(f"âœ… Baseline é€±æœŸæ€§èª¤å·®: {baseline_periodic:.6e}")
    print(f"âœ… Normalized é€±æœŸæ€§èª¤å·®: {normalized_periodic:.6e}")
    
    print(f"\n{'='*70}")
    print("TEST 12 é€šé âœ…")
    print(f"{'='*70}")


# ============================================================================
# æ¸¬è©¦ 13ï¼šNS æ–¹ç¨‹æ®˜å·®åˆ†æ
# ============================================================================

@pytest.mark.physics
def test_13_ns_residual_analysis():
    """
    æ¸¬è©¦ 13ï¼šNS æ–¹ç¨‹æ®˜å·®åˆ†æ
    
    é©—è­‰ï¼š
    1. ç‰©ç†æ¨¡çµ„æ­£ç¢ºè¨ˆç®— NS æ®˜å·®
    2. æ¨™æº–åŒ–ä¸å½±éŸ¿æ®˜å·®è¨ˆç®—
    3. æ®˜å·®å„é …é‡ç¶±ä¸€è‡´
    
    ç­–ç•¥ï¼š
    - ä½¿ç”¨ VSPINNChannelFlow è¨ˆç®—æ®˜å·®
    - æª¢æŸ¥æ®˜å·®æ•¸å€¼ç¯„åœ
    - ç¢ºèªæ¨™æº–åŒ–å‰å¾Œæ®˜å·®ä¸€è‡´æ€§
    """
    print("\n" + "="*70)
    print("TEST 13: NS æ–¹ç¨‹æ®˜å·®åˆ†æ")
    print("="*70)
    
    # å›ºå®šéš¨æ©Ÿç¨®å­ç¢ºä¿æ¸¬è©¦å¯é‡ç¾æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ¸¬è©¦å…©ç¨®é…ç½®
    results = {}
    for config_name, enable_norm in [('Baseline', False), ('Normalized', True)]:
        print(f"\n--- é…ç½®: {config_name} ---")
        
        # æ¯æ¬¡è¿­ä»£é‡ç½®éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿æ¨¡å‹åˆå§‹åŒ–ä¸€è‡´
        torch.manual_seed(42)
        np.random.seed(42)
        
        config = create_test_config_physics(enable_normalization=enable_norm)
        model = create_simple_channel_flow_model(device=device)
        
        # å‰µå»ºç‰©ç†æ¨¡çµ„
        physics = VSPINNChannelFlow(
            scaling_factors=config['physics']['scaling_factors'],
            physics_params={
                'nu': config['physics']['nu'],
                'dP_dx': config['physics']['dP_dx'],
                'rho': config['physics']['rho']
            },
            domain_bounds={
                'x': tuple(config['physics']['domain']['x_range']),
                'y': tuple(config['physics']['domain']['y_range']),
                'z': tuple(config['physics']['domain']['z_range'])
            }
        )
        
        # å‰µå»ºæ¨™æº–åŒ–å™¨
        normalizer = None
        if enable_norm:
            training_data = {
                'coords': torch.randn(100, 3),
                'u': torch.randn(100),
                'v': torch.randn(100),
                'w': torch.randn(100),
                'p': torch.randn(100)
            }
            normalizer = UnifiedNormalizer.from_config(config, training_data, device)
        
        # ç”Ÿæˆæ¸¬è©¦é»
        n_test = 200
        coords_np = np.random.uniform(
            low=[0.0, -1.0, 0.0],
            high=[2.0*np.pi, 1.0, np.pi],
            size=(n_test, 3)
        )
        coords = torch.tensor(coords_np, dtype=torch.float32, device=device)
        
        # å‰å‘å‚³æ’­
        if normalizer is not None:
            # æ¨™æº–åŒ–åˆ†æ”¯ï¼šåªå°æ¨™æº–åŒ–å¾Œçš„åº§æ¨™å•Ÿç”¨æ¢¯åº¦è¿½è¹¤
            coords_norm = normalizer.transform_input(coords)
            coords_norm.requires_grad_(True)  # æ¨™æº–åŒ–å¾Œçš„åº§æ¨™éœ€è¦æ¢¯åº¦
            predictions_norm = model(coords_norm)
            predictions = cast(torch.Tensor, normalizer.inverse_transform_output(predictions_norm))
            # ğŸ”§ ä½¿ç”¨ scaled_coords åƒæ•¸å‚³éæœ‰æ¢¯åº¦é€£æ¥çš„åº§æ¨™
            scaled_coords_for_grad = coords_norm
        else:
            # Baseline åˆ†æ”¯ï¼šéœ€è¦å° VS-PINN çš„ç¸®æ”¾åº§æ¨™å•Ÿç”¨æ¢¯åº¦è¿½è¹¤
            # æ³¨æ„ï¼šä¸è¦å°åŸå§‹ coords å•Ÿç”¨æ¢¯åº¦ï¼Œå› ç‚ºç‰©ç†æ¨¡çµ„æœƒå…§éƒ¨èª¿ç”¨ scale_coordinates()
            scaled_coords_vs = physics.scale_coordinates(coords)
            scaled_coords_vs.requires_grad_(True)
            predictions = model(scaled_coords_vs)
            scaled_coords_for_grad = scaled_coords_vs
        
        # è¨ˆç®— NS æ®˜å·®ï¼ˆä½¿ç”¨ç‰©ç†æ¨¡çµ„ï¼‰
        residual_continuity = physics.compute_continuity_residual(
            coords, predictions, scaled_coords=scaled_coords_for_grad
        )
        residual_momentum_dict = physics.compute_momentum_residuals(
            coords, predictions, scaled_coords=scaled_coords_for_grad
        )
        
        # æå–å‹•é‡æ®˜å·®ï¼ˆå­—å…¸ä¸­çš„ x, y, z åˆ†é‡ï¼‰
        residual_momentum_x = residual_momentum_dict['momentum_x']
        residual_momentum_y = residual_momentum_dict['momentum_y']
        residual_momentum_z = residual_momentum_dict['momentum_z']
        
        # è¨ˆç®— L2 ç¯„æ•¸
        continuity_l2 = torch.sqrt(torch.mean(residual_continuity ** 2)).item()
        momentum_x_l2 = torch.sqrt(torch.mean(residual_momentum_x ** 2)).item()
        momentum_y_l2 = torch.sqrt(torch.mean(residual_momentum_y ** 2)).item()
        momentum_z_l2 = torch.sqrt(torch.mean(residual_momentum_z ** 2)).item()
        
        print(f"  é€£çºŒæ€§æ®˜å·® L2: {continuity_l2:.6e}")
        print(f"  å‹•é‡æ®˜å·® X L2: {momentum_x_l2:.6e}")
        print(f"  å‹•é‡æ®˜å·® Y L2: {momentum_y_l2:.6e}")
        print(f"  å‹•é‡æ®˜å·® Z L2: {momentum_z_l2:.6e}")
        
        # æª¢æŸ¥æ•¸å€¼æœ‰æ•ˆæ€§
        assert torch.isfinite(residual_continuity).all(), "é€£çºŒæ€§æ®˜å·®åŒ…å« NaN/Inf"
        assert torch.isfinite(residual_momentum_x).all(), "å‹•é‡æ®˜å·® X åŒ…å« NaN/Inf"
        assert torch.isfinite(residual_momentum_y).all(), "å‹•é‡æ®˜å·® Y åŒ…å« NaN/Inf"
        assert torch.isfinite(residual_momentum_z).all(), "å‹•é‡æ®˜å·® Z åŒ…å« NaN/Inf"
        
        results[config_name] = {
            'continuity_l2': continuity_l2,
            'momentum_x_l2': momentum_x_l2,
            'momentum_y_l2': momentum_y_l2,
            'momentum_z_l2': momentum_z_l2
        }
    
    # é©—è­‰æ¨™æº–
    print(f"\n{'='*70}")
    print("é©—æ”¶æ¨™æº–æª¢æŸ¥ï¼š")
    print(f"{'='*70}")
    
    baseline_cont = results['Baseline']['continuity_l2']
    normalized_cont = results['Normalized']['continuity_l2']
    baseline_mom_x = results['Baseline']['momentum_x_l2']
    normalized_mom_x = results['Normalized']['momentum_x_l2']
    
    # æ¨™æº– 1ï¼šæ®˜å·®æ‡‰è©²æœ‰é™ï¼ˆæœªè¨“ç·´ç¶²çµ¡ï¼‰
    assert baseline_cont < 100.0, f"Baseline é€£çºŒæ€§æ®˜å·®éå¤§: {baseline_cont:.3e}"
    assert normalized_cont < 100.0, f"Normalized é€£çºŒæ€§æ®˜å·®éå¤§: {normalized_cont:.3e}"
    
    # æ¨™æº– 2ï¼šæ¨™æº–åŒ–ä¸æ‡‰åŠ‡çƒˆæ”¹è®Šæ®˜å·®ï¼ˆå…è¨± 10x å·®ç•°ï¼‰
    assert normalized_cont < 10.0 * baseline_cont, \
        f"æ¨™æº–åŒ–åŠ‡çƒˆæ”¹è®Šé€£çºŒæ€§æ®˜å·®: {normalized_cont:.3e} vs {baseline_cont:.3e}"
    
    print(f"âœ… Baseline é€£çºŒæ€§æ®˜å·®: {baseline_cont:.6e} < 100.0")
    print(f"âœ… Normalized é€£çºŒæ€§æ®˜å·®: {normalized_cont:.6e} < 100.0")
    print(f"âœ… Baseline å‹•é‡æ®˜å·® X: {baseline_mom_x:.6e}")
    print(f"âœ… Normalized å‹•é‡æ®˜å·® X: {normalized_mom_x:.6e}")
    
    print(f"\n{'='*70}")
    print("TEST 13 é€šé âœ…")
    print(f"{'='*70}")


# ============================================================================
# ä¸»æ¸¬è©¦åŸ·è¡Œ
# ============================================================================

if __name__ == '__main__':
    pytest.main([__file__, '-v', '-s', '-m', 'physics'])
