#!/usr/bin/env python
"""
è©•ä¼°æ„Ÿæ¸¬é»ç­–ç•¥å°æ¯”å¯¦é©—çµæœ

æœ¬è…³æœ¬å°ˆç‚º ablation_sensor_qr_K50 èˆ‡ ablation_sensor_stratified_K50 å¯¦é©—è¨­è¨ˆï¼Œ
ä½¿ç”¨å·¥å» æ–¹æ³•æ­£ç¢ºè¼‰å…¥ enhanced_fourier_mlp æ¨¡å‹ï¼Œä¸¦ç”Ÿæˆå®Œæ•´çš„å°æ¯”åˆ†æã€‚

åŠŸèƒ½ï¼š
1. å¾é…ç½®æ–‡ä»¶å‹•æ…‹å‰µå»ºæ¨¡å‹ï¼ˆæ”¯æ´æ‰€æœ‰æ¨¡å‹é¡å‹ï¼‰
2. è¼‰å…¥æª¢æŸ¥é»ä¸¦è©•ä¼°æµå ´èª¤å·®ï¼ˆL2, é€é»èª¤å·®ï¼‰
3. ç”Ÿæˆè¦–è¦ºåŒ–å°æ¯”åœ–ï¼ˆé€Ÿåº¦å‰–é¢ã€èª¤å·®åˆ†å¸ƒã€èƒ½è­œï¼‰
4. è¼¸å‡ºçµæ§‹åŒ–çµæœå ±å‘Šï¼ˆJSON + Markdownï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/evaluate_sensor_ablation.py \
        --checkpoint checkpoints/ablation_sensor_qr_K50/best_model.pth \
        --config configs/ablation_sensor_qr_K50.yml \
        --output results/ablation_sensor_qr_K50
"""

import sys
import argparse
import logging
from pathlib import Path
import json

import torch
import numpy as np
import yaml
import matplotlib.pyplot as plt

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pinnx.train.factory import create_model, get_device


def compute_error_metrics(pred, true):
    """
    è¨ˆç®—èª¤å·®æŒ‡æ¨™
    
    Args:
        pred: é æ¸¬å­—å…¸ {'u': tensor, 'v': tensor, 'w': tensor, 'p': tensor}
        true: çœŸå¯¦å­—å…¸ {'u': tensor, 'v': tensor, 'w': tensor, 'p': tensor}
    
    Returns:
        metrics: èª¤å·®æŒ‡æ¨™å­—å…¸
    """
    metrics = {}
    
    for var in ['u', 'v', 'w', 'p']:
        p = pred[var]
        t = true[var]
        
        # L2 èª¤å·®
        l2_error = torch.norm(p - t, p=2).item()
        
        # ç›¸å° L2 èª¤å·®
        rel_l2_error = l2_error / (torch.norm(t, p=2).item() + 1e-12)
        
        # æœ€å¤§èª¤å·®
        max_error = torch.max(torch.abs(p - t)).item()
        
        # å¹³å‡èª¤å·®
        mean_error = torch.mean(torch.abs(p - t)).item()
        
        metrics[var] = {
            'l2_error': l2_error,
            'rel_l2_error': rel_l2_error,
            'max_error': max_error,
            'mean_error': mean_error
        }
    
    return metrics


def setup_logging(log_level="INFO"):
    """è¨­ç½®æ—¥èªŒ"""
    logging.basicConfig(
        level=getattr(logging, log_level),
        format='%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%H:%M:%S'
    )


def load_checkpoint(checkpoint_path, device):
    """è¼‰å…¥æª¢æŸ¥é»"""
    logging.info(f"ğŸ“‚ è¼‰å…¥æª¢æŸ¥é»: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # æå–è¨“ç·´è³‡è¨Š
    epoch = checkpoint.get('epoch', 'unknown')
    loss = checkpoint.get('loss', 'unknown')
    logging.info(f"   Epoch: {epoch} | Loss: {loss}")
    
    # æå–æ¨™æº–åŒ–åƒæ•¸ï¼ˆç”¨æ–¼åæ¨™æº–åŒ–ï¼‰
    if 'normalization' in checkpoint:
        norm = checkpoint['normalization']
        logging.info(f"   âœ… æ‰¾åˆ°æ¨™æº–åŒ–åƒæ•¸: {norm.get('type', 'unknown')}")
        if norm.get('type') == 'training_data_norm':
            means = norm.get('means', {})
            scales = norm.get('scales', {})
            logging.info(f"      å‡å€¼: u={means.get('u', 0):.3f}, v={means.get('v', 0):.6f}, "
                        f"w={means.get('w', 0):.6f}, p={means.get('p', 0):.3f}")
            logging.info(f"      æ¨™æº–å·®: u={scales.get('u', 1):.3f}, v={scales.get('v', 1):.6f}, "
                        f"w={scales.get('w', 1):.6f}, p={scales.get('p', 1):.3f}")
    else:
        logging.warning("   âš ï¸ æª¢æŸ¥é»ä¸­æœªæ‰¾åˆ°æ¨™æº–åŒ–åƒæ•¸ï¼Œå‡è¨­ç„¡æ¨™æº–åŒ–")
    
    return checkpoint


def load_test_data(data_path, device):
    """è¼‰å…¥æ¸¬è©¦è³‡æ–™ï¼ˆJHTDB 2D sliceï¼‰"""
    logging.info(f"ğŸ“¦ è¼‰å…¥æ¸¬è©¦è³‡æ–™: {data_path}")
    
    if not Path(data_path).exists():
        raise FileNotFoundError(
            f"æ¸¬è©¦è³‡æ–™æœªæ‰¾åˆ°: {data_path}\n"
            f"è«‹å…ˆåŸ·è¡Œ scripts/fetch_channel_flow.py ç²å– JHTDB è³‡æ–™"
        )
    
    data = np.load(data_path)
    
    # æå–åæ¨™ï¼ˆ1D é™£åˆ—ï¼‰
    x_1d = data['x']  # [Nx]
    y_1d = data['y']  # [Ny]
    
    # æå–æµå ´ï¼ˆ2D ç¶²æ ¼ï¼‰
    u_2d = data['u']  # [Nx, Ny]
    v_2d = data['v']
    w_2d = data['w']
    p_2d = data['p']
    
    logging.info(f"   ç¶²æ ¼å½¢ç‹€: {u_2d.shape}")
    logging.info(f"   x ç¯„åœ: [{x_1d.min():.3f}, {x_1d.max():.3f}]")
    logging.info(f"   y ç¯„åœ: [{y_1d.min():.3f}, {y_1d.max():.3f}]")
    
    # å»ºç«‹ç¶²æ ¼åº§æ¨™ meshgrid
    X_mesh, Y_mesh = np.meshgrid(x_1d, y_1d, indexing='ij')
    
    # å±•å¹³ç‚º 1D é™£åˆ— [Nx*Ny]
    x_flat = X_mesh.ravel()
    y_flat = Y_mesh.ravel()
    u_flat = u_2d.ravel()
    v_flat = v_2d.ravel()
    w_flat = w_2d.ravel()
    p_flat = p_2d.ravel()
    
    # æ§‹å»ºè¼¸å…¥å¼µé‡ [N, 3] (x, y, z=0)
    N = len(x_flat)
    z_flat = np.zeros_like(x_flat)
    
    X_test = torch.tensor(
        np.stack([x_flat, y_flat, z_flat], axis=1),
        dtype=torch.float32,
        device=device
    )
    
    u_true = torch.tensor(u_flat, dtype=torch.float32, device=device)
    v_true = torch.tensor(v_flat, dtype=torch.float32, device=device)
    w_true = torch.tensor(w_flat, dtype=torch.float32, device=device)
    p_true = torch.tensor(p_flat, dtype=torch.float32, device=device)
    
    logging.info(f"   è¼¸å…¥å¼µé‡å½¢ç‹€: {X_test.shape}")
    
    return {
        'X': X_test,
        'u': u_true,
        'v': v_true,
        'w': w_true,
        'p': p_true,
        'x_1d': x_1d,
        'y_1d': y_1d,
        'grid_shape': u_2d.shape
    }


def denormalize_output(pred, normalization):
    """
    åæ¨™æº–åŒ–æ¨¡å‹è¼¸å‡º
    
    Args:
        pred: æ¨™æº–åŒ–çš„é æ¸¬å€¼ [N, 4] (u, v, w, p)
        normalization: æ¨™æº–åŒ–åƒæ•¸å­—å…¸
    
    Returns:
        denorm_pred: åæ¨™æº–åŒ–çš„é æ¸¬å€¼
    """
    if normalization is None or normalization.get('type') != 'training_data_norm':
        logging.warning("âš ï¸ ç„¡æ¨™æº–åŒ–åƒæ•¸ï¼Œè·³éåæ¨™æº–åŒ–æ­¥é©Ÿ")
        return pred
    
    means = normalization.get('means', {})
    scales = normalization.get('scales', {})
    
    # åæ¨™æº–åŒ–å…¬å¼: y = y_normalized * std + mean
    denorm_pred = pred.clone()
    
    for i, var in enumerate(['u', 'v', 'w', 'p']):
        mean = means.get(var, 0.0)
        scale = scales.get(var, 1.0)
        denorm_pred[:, i] = pred[:, i] * scale + mean
    
    logging.info("âœ… è¼¸å‡ºå·²åæ¨™æº–åŒ–")
    return denorm_pred


def evaluate_model(model, test_data, checkpoint, device):
    """è©•ä¼°æ¨¡å‹é æ¸¬èª¤å·®ï¼ˆå«åæ¨™æº–åŒ–ï¼‰"""
    logging.info("ğŸ”¬ é–‹å§‹è©•ä¼°æ¨¡å‹...")
    
    model.eval()
    with torch.no_grad():
        # å‰å‘æ¨ç†
        X = test_data['X'].to(device)
        pred_normalized = model(X)  # [N, 4] (u, v, w, p) - æ¨™æº–åŒ–ç©ºé–“
        
        # â­ åæ¨™æº–åŒ–æ¨¡å‹è¼¸å‡º
        normalization = checkpoint.get('normalization', None)
        pred = denormalize_output(pred_normalized, normalization)
        
        u_pred = pred[:, 0]
        v_pred = pred[:, 1]
        w_pred = pred[:, 2]
        p_pred = pred[:, 3]
    
    # æª¢æŸ¥åæ¨™æº–åŒ–å¾Œçš„æ•¸å€¼ç¯„åœ
    logging.info("=" * 70)
    logging.info("ğŸ” é æ¸¬å€¼ç¯„åœæª¢æŸ¥ï¼ˆåæ¨™æº–åŒ–å¾Œï¼‰ï¼š")
    logging.info("-" * 70)
    for i, var in enumerate(['u', 'v', 'w', 'p']):
        pred_val = pred[:, i]
        true_val = test_data[var].to(device)
        logging.info(f"  {var}: é æ¸¬ [{pred_val.min():.3f}, {pred_val.max():.3f}] | "
                    f"çœŸå¯¦ [{true_val.min():.3f}, {true_val.max():.3f}]")
    logging.info("=" * 70)
    
    # è¨ˆç®—èª¤å·®æŒ‡æ¨™
    u_true = test_data['u'].to(device)
    v_true = test_data['v'].to(device)
    w_true = test_data['w'].to(device)
    p_true = test_data['p'].to(device)
    
    metrics = compute_error_metrics(
        pred={'u': u_pred, 'v': v_pred, 'w': w_pred, 'p': p_pred},
        true={'u': u_true, 'v': v_true, 'w': w_true, 'p': p_true}
    )
    
    logging.info("ğŸ“Š è©•ä¼°çµæœï¼š")
    logging.info("-" * 70)
    for var in ['u', 'v', 'w', 'p']:
        logging.info(
            f"  {var}: L2 Error = {metrics[var]['l2_error']:.4f}, "
            f"Rel. L2 = {metrics[var]['rel_l2_error']:.2%}"
        )
    logging.info("=" * 70)
    
    # è½‰æ›ç‚º numpy ç”¨æ–¼è¦–è¦ºåŒ–
    results = {
        'metrics': metrics,
        'predictions': {
            'u': u_pred.cpu().numpy(),
            'v': v_pred.cpu().numpy(),
            'w': w_pred.cpu().numpy(),
            'p': p_pred.cpu().numpy()
        },
        'ground_truth': {
            'u': u_true.cpu().numpy(),
            'v': v_true.cpu().numpy(),
            'w': w_true.cpu().numpy(),
            'p': p_true.cpu().numpy()
        }
    }
    
    return results


def visualize_results(results, test_data, output_dir):
    """ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    logging.info(f"ğŸ“ˆ ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨è‡³: {output_dir}")
    
    pred = results['predictions']
    true = results['ground_truth']
    x_1d = test_data['x_1d']
    y_1d = test_data['y_1d']
    grid_shape = test_data['grid_shape']  # (Nx, Ny)
    
    # Reshape å› 2D ç¶²æ ¼
    def reshape_to_grid(arr):
        return arr.reshape(grid_shape)
    
    # === 1. é€Ÿåº¦å‰–é¢å°æ¯”ï¼ˆæ²¿ y æ–¹å‘ï¼Œx å¹³å‡ï¼‰===
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    for i, var in enumerate(['u', 'v', 'w']):
        ax = axes[i]
        
        # Reshape ç‚º 2D ä¸¦æ²¿ x æ–¹å‘å¹³å‡
        pred_2d = reshape_to_grid(pred[var])
        true_2d = reshape_to_grid(true[var])
        
        pred_mean_y = pred_2d.mean(axis=0)  # [Ny]
        true_mean_y = true_2d.mean(axis=0)  # [Ny]
        
        ax.plot(y_1d, true_mean_y, 'k-', label='JHTDB Ground Truth', linewidth=2)
        ax.plot(y_1d, pred_mean_y, 'r--', label='PINN Prediction', linewidth=1.5)
        
        ax.set_xlabel('y (wall-normal)', fontsize=12)
        ax.set_ylabel(f'{var} velocity', fontsize=12)
        ax.set_title(f'{var.upper()} Profile (Rel. L2: {results["metrics"][var]["rel_l2_error"]:.2%})')
        ax.legend()
        ax.grid(alpha=0.3)
    
    plt.tight_layout()
    fig.savefig(output_dir / 'velocity_profiles.png', dpi=150, bbox_inches='tight')
    plt.close(fig)
    logging.info("   âœ… é€Ÿåº¦å‰–é¢åœ–å·²ä¿å­˜")
    
    # === 2. èª¤å·®åˆ†å¸ƒç†±åœ– ===
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    for i, var in enumerate(['u', 'v', 'w', 'p']):
        ax = axes.flat[i]
        
        pred_2d = reshape_to_grid(pred[var])
        true_2d = reshape_to_grid(true[var])
        error_2d = np.abs(pred_2d - true_2d)
        
        im = ax.imshow(error_2d.T, origin='lower', aspect='auto',
                       extent=[x_1d.min(), x_1d.max(), y_1d.min(), y_1d.max()],
                       cmap='hot')
        ax.set_xlabel('x (streamwise)')
        ax.set_ylabel('y (wall-normal)')
        ax.set_title(f'{var.upper()} Error (Rel. L2: {results["metrics"][var]["rel_l2_error"]:.2%})')
        plt.colorbar(im, ax=ax)
    
    plt.tight_layout()
    fig.savefig(output_dir / 'error_heatmap.png', dpi=150, bbox_inches='tight')
    plt.close(fig)
    logging.info("   âœ… èª¤å·®ç†±åœ–å·²ä¿å­˜")
    
    # === 3. å£“åŠ›å ´å°æ¯” ===
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    
    p_pred_2d = reshape_to_grid(pred['p'])
    p_true_2d = reshape_to_grid(true['p'])
    
    p_pred_mean_y = p_pred_2d.mean(axis=0)
    p_true_mean_y = p_true_2d.mean(axis=0)
    
    axes[0].plot(y_1d, p_true_mean_y, 'k-', label='Ground Truth', linewidth=2)
    axes[0].plot(y_1d, p_pred_mean_y, 'r--', label='Prediction', linewidth=1.5)
    axes[0].set_xlabel('y (wall-normal)')
    axes[0].set_ylabel('Pressure')
    axes[0].set_title('Pressure Profile (x-averaged)')
    axes[0].legend()
    axes[0].grid(alpha=0.3)
    
    # èª¤å·®åˆ†å¸ƒ
    p_error_mean_y = np.abs(p_pred_2d - p_true_2d).mean(axis=0)
    axes[1].plot(y_1d, p_error_mean_y, 'b-', linewidth=1.5)
    axes[1].set_xlabel('y (wall-normal)')
    axes[1].set_ylabel('Absolute Error (x-averaged)')
    axes[1].set_title(f'Pressure Error (Rel. L2: {results["metrics"]["p"]["rel_l2_error"]:.2%})')
    axes[1].grid(alpha=0.3)
    
    plt.tight_layout()
    fig.savefig(output_dir / 'pressure_comparison.png', dpi=150, bbox_inches='tight')
    plt.close(fig)
    logging.info("   âœ… å£“åŠ›å°æ¯”åœ–å·²ä¿å­˜")


def save_results(results, checkpoint_info, output_dir):
    """ä¿å­˜çµæ§‹åŒ–çµæœ"""
    output_dir = Path(output_dir)
    
    # === JSON æ ¼å¼ ===
    results_json = {
        'checkpoint': checkpoint_info,
        'metrics': {}
    }
    
    for var in ['u', 'v', 'w', 'p']:
        results_json['metrics'][var] = {
            'l2_error': float(results['metrics'][var]['l2_error']),
            'rel_l2_error': float(results['metrics'][var]['rel_l2_error']),
            'max_error': float(results['metrics'][var]['max_error']),
            'mean_error': float(results['metrics'][var]['mean_error'])
        }
    
    json_path = output_dir / 'evaluation_results.json'
    with open(json_path, 'w') as f:
        json.dump(results_json, f, indent=2)
    
    logging.info(f"ğŸ’¾ çµæœå·²ä¿å­˜è‡³: {json_path}")
    
    # === Markdown å ±å‘Š ===
    md_lines = [
        "# è©•ä¼°çµæœå ±å‘Š",
        "",
        f"**æª¢æŸ¥é»**: `{checkpoint_info['path']}`  ",
        f"**Epoch**: {checkpoint_info['epoch']}  ",
        f"**è¨“ç·´ Loss**: {checkpoint_info['loss']}",
        "",
        "## èª¤å·®æŒ‡æ¨™",
        "",
        "| è®Šé‡ | L2 Error | Relative L2 | Max Error | Mean Error |",
        "|------|----------|-------------|-----------|------------|"
    ]
    
    for var in ['u', 'v', 'w', 'p']:
        m = results['metrics'][var]
        md_lines.append(
            f"| {var} | {m['l2_error']:.4f} | {m['rel_l2_error']:.2%} | "
            f"{m['max_error']:.4f} | {m['mean_error']:.4f} |"
        )
    
    md_path = output_dir / 'evaluation_report.md'
    with open(md_path, 'w') as f:
        f.write('\n'.join(md_lines))
    
    logging.info(f"ğŸ“ Markdown å ±å‘Šå·²ä¿å­˜è‡³: {md_path}")


def main():
    parser = argparse.ArgumentParser(description='è©•ä¼°æ„Ÿæ¸¬é»ç­–ç•¥å°æ¯”å¯¦é©—')
    parser.add_argument('--checkpoint', type=str, required=True,
                        help='æª¢æŸ¥é»è·¯å¾‘ï¼ˆ.pth æ–‡ä»¶ï¼‰')
    parser.add_argument('--config', type=str, required=True,
                        help='é…ç½®æ–‡ä»¶è·¯å¾‘ï¼ˆ.yml æ–‡ä»¶ï¼‰')
    parser.add_argument('--data', type=str,
                        default='data/jhtdb/channel/2d_slice_z0_normalized.npz',
                        help='æ¸¬è©¦è³‡æ–™è·¯å¾‘')
    parser.add_argument('--output', type=str, required=True,
                        help='çµæœè¼¸å‡ºç›®éŒ„')
    parser.add_argument('--log-level', type=str, default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help='æ—¥èªŒç­‰ç´š')
    
    args = parser.parse_args()
    
    setup_logging(args.log_level)
    
    logging.info("=" * 70)
    logging.info("  æ„Ÿæ¸¬é»ç­–ç•¥è©•ä¼°è…³æœ¬")
    logging.info("=" * 70)
    
    # === 1. è¼‰å…¥é…ç½® ===
    logging.info(f"ğŸ“„ è¼‰å…¥é…ç½®: {args.config}")
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)
    
    # === 2. è¨­å‚™é¸æ“‡ ===
    device = get_device(config.get('experiment', {}).get('device', 'auto'))
    logging.info(f"ğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {device}")
    
    # === 3. å‰µå»ºæ¨¡å‹ï¼ˆä½¿ç”¨å·¥å» æ–¹æ³•ï¼‰===
    logging.info("ğŸ—ï¸  å‰µå»ºæ¨¡å‹...")
    model = create_model(config, device)
    
    # === 4. è¼‰å…¥æª¢æŸ¥é» ===
    checkpoint = load_checkpoint(args.checkpoint, device)
    
    # æå–æ¨¡å‹æ¬Šé‡
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    elif 'model' in checkpoint:
        state_dict = checkpoint['model']
    else:
        raise KeyError("æª¢æŸ¥é»ä¸­æœªæ‰¾åˆ°æ¨¡å‹æ¬Šé‡ï¼ˆ'model_state_dict' æˆ– 'model'ï¼‰")
    
    # è¼‰å…¥æ¬Šé‡
    model.load_state_dict(state_dict, strict=False)
    logging.info("âœ… æ¨¡å‹æ¬Šé‡è¼‰å…¥æˆåŠŸ")
    
    # === 5. è¼‰å…¥æ¸¬è©¦è³‡æ–™ ===
    test_data = load_test_data(args.data, device)
    
    # === 6. è©•ä¼°æ¨¡å‹ ===
    results = evaluate_model(model, test_data, checkpoint, device)
    
    # === 7. è¦–è¦ºåŒ– ===
    visualize_results(results, test_data, args.output)
    
    # === 8. ä¿å­˜çµæœ ===
    checkpoint_info = {
        'path': args.checkpoint,
        'epoch': checkpoint.get('epoch', 'unknown'),
        'loss': checkpoint.get('loss', 'unknown')
    }
    save_results(results, checkpoint_info, args.output)
    
    logging.info("=" * 70)
    logging.info("âœ… è©•ä¼°å®Œæˆï¼")
    logging.info("=" * 70)


if __name__ == '__main__':
    main()
