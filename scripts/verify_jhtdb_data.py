#!/usr/bin/env python3
"""
JHTDB Data Import Verification Script
Step-by-step verification of Channel Flow data loaded from JHTDB

Goals:
1. Load JHTDB Channel Flow data 
2. Display basic flow field statistics
3. Check physical reasonableness of data
4. Generate visualization plots to verify turbulence characteristics
"""

import sys
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
# import seaborn as sns  # Temporarily commented to avoid dependency issues

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pinnx.dataio.channel_flow_loader import ChannelFlowLoader
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def verify_jhtdb_data_step_by_step(load_mode='sensor'):
    """
    Step-by-step JHTDB data verification
    
    Args:
        load_mode: Loading mode ('sensor' for sensor points only, 'full_field' for complete field)
    """
    
    print("=" * 80)
    print("ğŸ” JHTDB Channel Flow Data Verification")
    print("=" * 80)
    
    # Step 1: Check configuration and data files
    print("\nğŸ“ Step 1: Check Configuration and Data Files")
    print("-" * 50)
    
    config_path = project_root / "configs" / "channel_flow_re1000.yml"
    cache_dir = project_root / "data" / "jhtdb" / "channel_flow_re1000"
    
    print(f"Config file path: {config_path}")
    print(f"Config file exists: {config_path.exists()}")
    print(f"Data directory path: {cache_dir}")
    print(f"Data directory exists: {cache_dir.exists()}")
    
    if cache_dir.exists():
        data_files = list(cache_dir.glob("*.npz"))
        print(f"Found {len(data_files)} data files:")
        for file in data_files:
            print(f"  - {file.name}")
    
    # Step 2: Initialize loader
    print("\nğŸ”§ Step 2: Initialize Channel Flow Loader")
    print("-" * 50)
    
    try:
        loader = ChannelFlowLoader(config_path=config_path, cache_dir=cache_dir)
        print("âœ… Loader initialization successful")
        
        # Check available datasets
        available_datasets = loader.get_available_datasets()
        print(f"Available datasets: {available_datasets}")
        
    except Exception as e:
        print(f"âŒ Loader initialization failed: {e}")
        return False
    
    # Step 3: Load data
    if load_mode == 'full_field':
        print("\nğŸ“Š Step 3: Load Complete Flow Field Data (8Ã—8Ã—8=512 points)")
        print("-" * 50)
        
        try:
            # Load complete flow field data
            channel_data = loader.load_full_field_data()
            print("âœ… Complete flow field data loaded successfully")
            
            # Display basic information
            print(f"Number of data points: {len(channel_data.sensor_points)}")
            print(f"Coordinate shape: {channel_data.sensor_points.shape}")
            print(f"Available field data: {list(channel_data.sensor_data.keys())}")
            print(f"Grid shape: {channel_data.selection_info.get('grid_shape', 'Unknown')}")
            
            # Display coordinate ranges
            coords = channel_data.sensor_points
            print(f"x coordinate range: [{coords[:, 0].min():.3f}, {coords[:, 0].max():.3f}]")
            print(f"y coordinate range: [{coords[:, 1].min():.3f}, {coords[:, 1].max():.3f}]")
            print(f"z coordinate range: [{coords[:, 2].min():.3f}, {coords[:, 2].max():.3f}]")
            
        except Exception as e:
            print(f"âŒ Complete flow field data loading failed: {e}")
            return False
    else:
        print("\nğŸ“Š Step 3: Load QR-Pivot Sensor Point Data")
        print("-" * 50)
        
        try:
            # Try to load K=8 QR-pivot data
            channel_data = loader.load_sensor_data(strategy='qr_pivot', K=8)
            print("âœ… Sensor point data loaded successfully")
            
            # Display basic information
            print(f"Number of sensor points: {len(channel_data.sensor_points)}")
            print(f"Sensor point coordinate shape: {channel_data.sensor_points.shape}")
            print(f"Available field data: {list(channel_data.sensor_data.keys())}")
            
            # Display sensor point coordinate ranges
            x_coords = channel_data.sensor_points[:, 0] 
            y_coords = channel_data.sensor_points[:, 1]
            print(f"x coordinate range: [{x_coords.min():.3f}, {x_coords.max():.3f}]")
            print(f"y coordinate range: [{y_coords.min():.3f}, {y_coords.max():.3f}]")
            
        except Exception as e:
            print(f"âŒ Sensor point data loading failed: {e}")
            return False
    
    # æ­¥é©Ÿ4ï¼šæª¢æŸ¥æµå ´æ•¸æ“š
    print("\nğŸŒŠ æ­¥é©Ÿ4ï¼šæª¢æŸ¥æµå ´æ•¸æ“šçš„ç‰©ç†ç‰¹æ€§")
    print("-" * 50)
    
    # å¦‚æœæ˜¯å®Œæ•´æµå ´ï¼Œé€²è¡Œç„¡æ•£æ¢ä»¶æª¢æŸ¥
    if load_mode == 'full_field' and 'w' in channel_data.sensor_data:
        print("\nğŸ” 3Dç„¡æ•£æ¢ä»¶æª¢æŸ¥ (âˆ‡Â·u = 0):")
        
        # é‡æ§‹3Då ´
        grid_shape = channel_data.selection_info.get('grid_shape', (8, 8, 8))
        u_3d = channel_data.sensor_data['u'].reshape(grid_shape)
        v_3d = channel_data.sensor_data['v'].reshape(grid_shape)
        w_3d = channel_data.sensor_data['w'].reshape(grid_shape)
        
        # è¨ˆç®—æ•£åº¦ (ä¸­å¿ƒå·®åˆ†) - ä¿®å¾©è»¸åº
        # meshgrid(indexing='ij'): axis=0->x, axis=1->y, axis=2->z
        du_dx = np.gradient(u_3d, axis=0)  # xæ–¹å‘ (ä¿®å¾©: axis=2 -> axis=0)
        dv_dy = np.gradient(v_3d, axis=1)  # yæ–¹å‘ (æ­£ç¢º)
        dw_dz = np.gradient(w_3d, axis=2)  # zæ–¹å‘ (ä¿®å¾©: axis=0 -> axis=2)
        
        divergence = du_dx + dv_dy + dw_dz
        
        # è¨ˆç®—æ•£åº¦çµ±è¨ˆ
        div_mean = np.mean(divergence)
        div_std = np.std(divergence)
        div_rms = np.sqrt(np.mean(divergence**2))
        div_max = np.max(np.abs(divergence))
        
        # è¨ˆç®—ç›¸å°æ•£åº¦
        velocity_rms = np.sqrt(np.mean(u_3d**2 + v_3d**2 + w_3d**2))
        relative_divergence = div_rms / velocity_rms if velocity_rms > 0 else float('inf')
        
        print(f"  æ•£åº¦çµ±è¨ˆ:")
        print(f"    å‡å€¼: {div_mean:.8f}")
        print(f"    æ¨™æº–å·®: {div_std:.8f}")
        print(f"    RMS: {div_rms:.8f}")
        print(f"    æœ€å¤§çµ•å°å€¼: {div_max:.8f}")
        print(f"    ç›¸å°æ•£åº¦: {relative_divergence:.8f}")
        
        # è©•ä¼°ç„¡æ•£ç¨‹åº¦
        if relative_divergence < 1e-6:
            print("  âœ… æ¥µä½³çš„ç„¡æ•£æ¢ä»¶æ»¿è¶³")
        elif relative_divergence < 1e-4:
            print("  âœ… è‰¯å¥½çš„ç„¡æ•£æ¢ä»¶æ»¿è¶³")
        elif relative_divergence < 1e-2:
            print("  âš ï¸  å¯æ¥å—çš„ç„¡æ•£æ¢ä»¶æ»¿è¶³")
        else:
            print("  âŒ ç„¡æ•£æ¢ä»¶ä¸æ»¿è¶³ï¼Œå¯èƒ½ä¸æ˜¯çœŸå¯¦æµå ´")
    
    # æª¢æŸ¥æ¯å€‹å ´çš„çµ±è¨ˆç‰¹æ€§
    for field_name, field_data in channel_data.sensor_data.items():
        print(f"\n{field_name.upper()} å ´çµ±è¨ˆ:")
        print(f"  å½¢ç‹€: {field_data.shape}")
        print(f"  å¹³å‡å€¼: {np.mean(field_data):.6f}")
        print(f"  æ¨™æº–å·®: {np.std(field_data):.6f}")
        print(f"  æœ€å°å€¼: {np.min(field_data):.6f}")
        print(f"  æœ€å¤§å€¼: {np.max(field_data):.6f}")
        print(f"  æ˜¯å¦æœ‰NaN: {np.isnan(field_data).any()}")
        print(f"  æ˜¯å¦æœ‰Inf: {np.isinf(field_data).any()}")
        
        # ç‰©ç†åˆç†æ€§æª¢æŸ¥
        if field_name == 'u':
            # uå ´åœ¨Channel Flowä¸­æ‡‰è©²ç‚ºæ­£å€¼ä¸”æœ‰åˆç†ç¯„åœ
            print(f"  uå ´åˆç†æ€§æª¢æŸ¥:")
            print(f"    - æ‰€æœ‰å€¼ç‚ºæ­£: {np.all(field_data >= 0)}")
            print(f"    - æœ€å¤§å€¼åˆç† (<30): {np.max(field_data) < 30}")
        elif field_name == 'v':
            # vå ´åœ¨2D channel flowä¸­æ‡‰è©²æ¥è¿‘é›¶
            print(f"  vå ´åˆç†æ€§æª¢æŸ¥:")
            print(f"    - æ¥è¿‘é›¶ (|v| < 1): {np.all(np.abs(field_data) < 1)}")
        elif field_name == 'p':
            # å£“åŠ›å ´æ‡‰è©²æœ‰æ¢¯åº¦ä½†ä¸èƒ½æœ‰æ¥µå€¼
            print(f"  på ´åˆç†æ€§æª¢æŸ¥:")
            print(f"    - æœ‰è®ŠåŒ– (std > 0): {np.std(field_data) > 0}")
    
    # æ­¥é©Ÿ5ï¼šè¼‰å…¥Enhanced Mockæ•¸æ“šé€²è¡Œå°æ¯”
    print("\nğŸ­ æ­¥é©Ÿ5ï¼šMockåŠŸèƒ½å·²ç§»é™¤")
    print("-" * 50)
    print("âŒ Enhanced Mockæ•¸æ“šç”ŸæˆåŠŸèƒ½å·²ç§»é™¤ï¼Œå°ˆæ¡ˆç¾åœ¨åƒ…ä½¿ç”¨çœŸå¯¦JHTDBæ•¸æ“š")
    mock_data = None
    
    # æ­¥é©Ÿ6ï¼šæ•¸æ“šé©—è­‰
    print("\nâœ… æ­¥é©Ÿ6ï¼šåŸ·è¡Œå®Œæ•´æ•¸æ“šé©—è­‰")
    print("-" * 50)
    
    validation_results = loader.validate_data(channel_data)
    
    print("é©—è­‰çµæœ:")
    passed_checks = 0
    total_checks = len(validation_results)
    
    for check_name, result in validation_results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {check_name}: {status}")
        if result:
            passed_checks += 1
    
    print(f"\né©—è­‰ç¸½çµ: {passed_checks}/{total_checks} æª¢æŸ¥é€šé")
    
    # æ­¥é©Ÿ7ï¼šå‰µå»ºå¯è¦–åŒ–åœ–è¡¨
    print("\nğŸ“ˆ æ­¥é©Ÿ7ï¼šå‰µå»ºæ•¸æ“šå¯è¦–åŒ–")
    print("-" * 50)
    
    try:
        create_verification_plots(channel_data, mock_data)
        print("âœ… å¯è¦–åŒ–åœ–è¡¨å‰µå»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ å¯è¦–åŒ–å‰µå»ºå¤±æ•—: {e}")
    
    # æ­¥é©Ÿ8ï¼šæª¢æŸ¥åŸŸé…ç½®
    print("\nğŸ—ï¸ æ­¥é©Ÿ8ï¼šæª¢æŸ¥åŸŸé…ç½®åƒæ•¸")
    print("-" * 50)
    
    domain_config = channel_data.domain_config
    print("åŸŸé…ç½®åƒæ•¸:")
    for key, value in domain_config.items():
        print(f"  {key}: {value}")
    
    # æª¢æŸ¥ç‰©ç†åƒæ•¸
    phys_params = channel_data.get_physical_parameters()
    print("\nç‰©ç†åƒæ•¸:")
    for key, value in phys_params.items():
        print(f"  {key}: {value}")
    
    # ç¸½çµ
    print("\n" + "=" * 80)
    print("ğŸ¯ æ•¸æ“šé©—è­‰ç¸½çµ")
    print("=" * 80)
    
    verification_score = passed_checks / total_checks * 100
    
    if verification_score >= 90:
        print(f"âœ… æ•¸æ“šè³ªé‡å„ªç§€ ({verification_score:.1f}%)")
        print("âœ… JHTDBæ•¸æ“šè¼‰å…¥é©—è­‰æˆåŠŸ")
        return True
    elif verification_score >= 70:
        print(f"âš ï¸ æ•¸æ“šè³ªé‡è‰¯å¥½ ({verification_score:.1f}%)ï¼Œä½†æœ‰è¼•å¾®å•é¡Œ")
        return True
    else:
        print(f"âŒ æ•¸æ“šè³ªé‡ä¸ä½³ ({verification_score:.1f}%)ï¼Œéœ€è¦æª¢æŸ¥")
        return False

def create_verification_plots(channel_data, mock_data=None):
    """å‰µå»ºæ•¸æ“šé©—è­‰å¯è¦–åŒ–åœ–è¡¨"""
    
    plt.style.use('default')  # ä½¿ç”¨defaultæ¨£å¼é¿å…seabornä¾è³´
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle('JHTDB Channel Flow Data Verification', fontsize=16, fontweight='bold')
    
    # å­åœ–1ï¼šæ„Ÿæ¸¬é»åˆ†ä½ˆ
    ax = axes[0, 0]
    sensor_points = channel_data.sensor_points
    scatter = ax.scatter(sensor_points[:, 0], sensor_points[:, 1], 
                        c=range(len(sensor_points)), cmap='viridis', s=100, alpha=0.8)
    ax.set_xlabel('x [Streamwise]')
    ax.set_ylabel('y [Wall-normal]')
    ax.set_title('QR-Pivot Sensor Distribution')
    ax.grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=ax, label='Sensor Index')
    
    # å­åœ–2ï¼šuå ´åˆ†ä½ˆ
    ax = axes[0, 1]
    if 'u' in channel_data.sensor_data:
        u_data = channel_data.sensor_data['u']
        scatter = ax.scatter(sensor_points[:, 0], sensor_points[:, 1], 
                           c=u_data, cmap='coolwarm', s=100, alpha=0.8)
        ax.set_xlabel('x [Streamwise]')
        ax.set_ylabel('y [Wall-normal]')
        ax.set_title(f'u Field Distribution (Mean={np.mean(u_data):.3f})')
        ax.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax, label='u [m/s]')
    
    # å­åœ–3ï¼švå ´åˆ†ä½ˆ
    ax = axes[0, 2]
    if 'v' in channel_data.sensor_data:
        v_data = channel_data.sensor_data['v']
        scatter = ax.scatter(sensor_points[:, 0], sensor_points[:, 1], 
                           c=v_data, cmap='coolwarm', s=100, alpha=0.8)
        ax.set_xlabel('x [Streamwise]')
        ax.set_ylabel('y [Wall-normal]')
        ax.set_title(f'v Field Distribution (Mean={np.mean(v_data):.3f})')
        ax.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax, label='v [m/s]')
    
    # å­åœ–4ï¼šå£“åŠ›å ´åˆ†ä½ˆ
    ax = axes[1, 0]
    if 'p' in channel_data.sensor_data:
        p_data = channel_data.sensor_data['p']
        scatter = ax.scatter(sensor_points[:, 0], sensor_points[:, 1], 
                           c=p_data, cmap='coolwarm', s=100, alpha=0.8)
        ax.set_xlabel('x [Streamwise]')
        ax.set_ylabel('y [Wall-normal]')
        ax.set_title(f'p Field Distribution (Mean={np.mean(p_data):.3f})')
        ax.grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=ax, label='p [Pa]')
    
    # å­åœ–5ï¼šå ´çµ±è¨ˆå°æ¯”
    ax = axes[1, 1]
    fields = ['u', 'v', 'p']
    means = []
    stds = []
    
    for field in fields:
        if field in channel_data.sensor_data:
            data = channel_data.sensor_data[field]
            means.append(np.mean(data))
            stds.append(np.std(data))
        else:
            means.append(0)
            stds.append(0)
    
    x_pos = np.arange(len(fields))
    bars1 = ax.bar(x_pos - 0.2, means, 0.4, label='Mean', alpha=0.7)
    bars2 = ax.bar(x_pos + 0.2, stds, 0.4, label='Std Dev', alpha=0.7)
    
    ax.set_xlabel('Field Variables')
    ax.set_ylabel('Values')
    ax.set_title('Field Statistics')
    ax.set_xticks(x_pos)
    ax.set_xticklabels(fields)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):
        height1 = bar1.get_height()
        height2 = bar2.get_height()
        ax.text(bar1.get_x() + bar1.get_width()/2., height1,
                f'{height1:.3f}', ha='center', va='bottom', fontsize=8)
        ax.text(bar2.get_x() + bar2.get_width()/2., height2,
                f'{height2:.3f}', ha='center', va='bottom', fontsize=8)
    
    # å­åœ–6ï¼šMockæ•¸æ“šå°æ¯” (å¦‚æœæœ‰)
    ax = axes[1, 2]
    if mock_data is not None:
        # å¾Mockæ•¸æ“šéš¨æ©Ÿå–æ¨£8å€‹é»é€²è¡Œå°æ¯”
        n_total = len(mock_data['u'])
        sample_indices = np.random.choice(n_total, size=8, replace=False)
        
        mock_u_sample = mock_data['u'][sample_indices]
        mock_v_sample = mock_data['v'][sample_indices]
        
        sensor_u = channel_data.sensor_data.get('u', np.zeros(8))
        sensor_v = channel_data.sensor_data.get('v', np.zeros(8))
        
        ax.scatter(sensor_u, sensor_v, c='red', s=100, alpha=0.7, label='JHTDB Sensors')
        ax.scatter(mock_u_sample, mock_v_sample, c='blue', s=100, alpha=0.7, label='Mock Samples')
        ax.set_xlabel('u [m/s]')
        ax.set_ylabel('v [m/s]')
        ax.set_title('JHTDB vs Mock Velocity Comparison')
        ax.legend()
        ax.grid(True, alpha=0.3)
    else:
        ax.text(0.5, 0.5, 'No Mock Data\nAvailable', ha='center', va='center', 
               transform=ax.transAxes, fontsize=12)
        ax.set_title('Mock Data Comparison')
    
    plt.tight_layout()
    
    # ä¿å­˜åœ–è¡¨
    output_path = project_root / 'jhtdb_verification_plots.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"Plot saved to: {output_path}")
    
    plt.show()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='é©—è­‰JHTDBæ•¸æ“š')
    parser.add_argument('--mode', choices=['sensor', 'full_field'], default='full_field',
                        help='è¼‰å…¥æ¨¡å¼ï¼šsensor (åªè¼‰å…¥æ„Ÿæ¸¬é») æˆ– full_field (è¼‰å…¥å®Œæ•´æµå ´)')
    args = parser.parse_args()
    
    print(f"é–‹å§‹JHTDBæ•¸æ“šé©—è­‰... (æ¨¡å¼: {args.mode})")
    success = verify_jhtdb_data_step_by_step(load_mode=args.mode)
    
    if success:
        print(f"\nğŸ‰ é©—è­‰å®Œæˆï¼JHTDBæ•¸æ“šè¼‰å…¥æ­£å¸¸ (æ¨¡å¼: {args.mode})")
    else:
        print(f"\nâš ï¸ é©—è­‰ç™¼ç¾å•é¡Œï¼Œè«‹æª¢æŸ¥æ•¸æ“šå’Œé…ç½® (æ¨¡å¼: {args.mode})")
        sys.exit(1)