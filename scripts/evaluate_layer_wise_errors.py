#!/usr/bin/env python
"""
åˆ†å±¤èª¤å·®è©•ä¼°è…³æœ¬ - é©—è­‰ QR-Pivot ä¸­å¿ƒå±¤ç¼ºå¤±å‡è¨­
ç›®çš„ï¼šæ¯”è¼ƒ Wall-Clustered å’Œ QR-Pivot åœ¨ä¸‰å€‹ç‰©ç†å±¤çš„é‡å»ºèª¤å·®
"""
import sys
import torch
import numpy as np
import yaml
import h5py
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, Tuple, Optional
import json

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pinnx.models.fourier_mlp import PINNNet, create_pinn_model  # ä½¿ç”¨çµ±ä¸€æ¨¡å‹èˆ‡å·¥å» å‡½æ•¸
from pinnx.utils.normalization import DataNormalizer, InputNormalizer  # æ­£ç¢ºçš„æ¨™æº–åŒ–å™¨ä½ç½®

# ============================================================================
# å¸¸æ•¸å®šç¾©
# ============================================================================
LAYER_DEFINITIONS = {
    'wall': {'range': (0.8, 1.0), 'name': 'å£é¢å±¤', 'description': 'High shear, y+ < 100'},
    'log': {'range': (0.2, 0.8), 'name': 'å°æ•¸å±¤', 'description': 'Turbulent core, 100 < y+ < 800'},
    'center': {'range': (0.0, 0.2), 'name': 'ä¸­å¿ƒå±¤', 'description': 'Low gradient, y+ > 800'}
}

# ============================================================================
# è¼‰å…¥æ¨¡å‹èˆ‡æ•¸æ“š
# ============================================================================
def load_checkpoint_and_model(checkpoint_path: Path, config_path: Path, device: torch.device) -> Tuple[torch.nn.Module, Dict, DataNormalizer]:
    """è¼‰å…¥æª¢æŸ¥é»èˆ‡æ¨¡å‹"""
    print(f"ğŸ“‚ è¼‰å…¥æª¢æŸ¥é»: {checkpoint_path.name}")
    
    # è¼‰å…¥é…ç½®
    with open(config_path, 'r') as f:
        cfg = yaml.safe_load(f)
    
    # è¼‰å…¥æª¢æŸ¥é»
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # å»ºç«‹æ¨™æº–åŒ–å™¨ï¼ˆå¾ checkpoint metadata æ¢å¾©ï¼‰
    if 'normalization' in checkpoint:
        normalizer = DataNormalizer.from_metadata(checkpoint['normalization'])
        print(f"  âœ… æ¨™æº–åŒ–å™¨å·²è¼‰å…¥: type={normalizer.norm_type}")
    else:
        print(f"  âš ï¸  æœªæ‰¾åˆ°æ¨™æº–åŒ–å™¨ç‹€æ…‹ï¼Œä½¿ç”¨é è¨­å€¼")
        normalizer = DataNormalizer(norm_type='none')
    
    # å»ºç«‹æ¨¡å‹ï¼ˆå„ªå…ˆä½¿ç”¨æª¢æŸ¥é»ä¸­çš„é…ç½®ï¼Œå› ç‚ºå®ƒåŒ…å«å®Œæ•´åƒæ•¸ï¼‰
    if 'config' in checkpoint and 'model' in checkpoint['config']:
        model_cfg = checkpoint['config']['model'].copy()
        print(f"  âœ… ä½¿ç”¨æª¢æŸ¥é»ä¸­çš„æ¨¡å‹é…ç½®")
        
        # ğŸ”§ ä¿®å¾©ï¼šå¾æ¬Šé‡æ¨æ–· use_input_projectionï¼ˆå¦‚æœé…ç½®ä¸­ç¼ºå¤±ï¼‰
        if 'use_input_projection' not in model_cfg or model_cfg['use_input_projection'] is None:
            state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', {}))
            first_layer_key = 'hidden_layers.0.linear.weight'
            if first_layer_key in state_dict:
                first_layer_shape = state_dict[first_layer_key].shape
                width = model_cfg.get('width', 256)
                fourier_m = model_cfg.get('fourier_m', 32)
                expected_dim_with_proj = width
                expected_dim_without_proj = 2 * fourier_m if model_cfg.get('use_fourier', True) else model_cfg.get('in_dim', 3)
                
                if first_layer_shape[1] == expected_dim_with_proj:
                    model_cfg['use_input_projection'] = True
                    print(f"  ğŸ”§ æ¨æ–· use_input_projection=Trueï¼ˆç¬¬ä¸€å±¤è¼¸å…¥={first_layer_shape[1]}ï¼‰")
                elif first_layer_shape[1] == expected_dim_without_proj:
                    model_cfg['use_input_projection'] = False
                    print(f"  ğŸ”§ æ¨æ–· use_input_projection=Falseï¼ˆç¬¬ä¸€å±¤è¼¸å…¥={first_layer_shape[1]}ï¼‰")
    else:
        model_cfg = cfg['model']
        print(f"  âš ï¸  æª¢æŸ¥é»ä¸­ç„¡é…ç½®ï¼Œä½¿ç”¨ YAML é…ç½®")
    
    model = create_pinn_model(model_cfg).to(device)
    
    # è¼‰å…¥æ¬Šé‡
    state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', {}))
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    
    print(f"  è¨“ç·´è¼ªæ•¸: {checkpoint.get('epoch', 'N/A')}")
    print(f"  æœ€çµ‚æå¤±: {checkpoint.get('loss', 'N/A'):.6e}" if 'loss' in checkpoint else "  æœ€çµ‚æå¤±: N/A")
    
    return model, cfg, normalizer


def load_jhtdb_ground_truth(data_path: Path, domain_bounds: Optional[Dict] = None) -> Tuple[np.ndarray, np.ndarray]:
    """
    è¼‰å…¥ JHTDB çœŸå¯¦æ•¸æ“šï¼ˆ2D/3D åˆ‡ç‰‡ï¼‰
    
    Args:
        data_path: HDF5 æ–‡ä»¶è·¯å¾‘
        domain_bounds: åŸŸç¯„åœ {'x': [min, max], 'y': [min, max], 'z': [min, max]}ï¼ˆç”¨æ–¼é‡å»ºåº§æ¨™ç¶²æ ¼ï¼‰
    
    Returns:
        coords: (N, 3) åº§æ¨™æ•¸çµ„ï¼ˆx, y, zï¼‰
        fields: (N, n_vars) å ´æ•¸æ“šï¼ˆu, v, w, pï¼‰
    """
    print(f"ğŸ“‚ è¼‰å…¥ JHTDB çœŸå¯¦æ•¸æ“š: {data_path.name}")
    
    with h5py.File(data_path, 'r') as f:
        # è®€å–é€Ÿåº¦å ´ï¼ˆä¸ä½¿ç”¨ squeeze ä»¥ä¿ç•™æ‰€æœ‰ç¶­åº¦ï¼‰
        u = np.array(f['u'])  # (nx, ny, nz)
        v = np.array(f['v'])
        w = np.array(f['w'])
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å£“åŠ›
        if 'p' in f:
            p = np.array(f['p'])
        else:
            p = None
        
        # ç¢ºå®šç¶²æ ¼ç¶­åº¦
        shape_3d = u.shape
        if len(shape_3d) == 2:
            # 2D æ•¸æ“šï¼Œæ·»åŠ  z ç¶­åº¦
            nx, ny = shape_3d
            nz = 1
            u = u[:, :, np.newaxis]
            v = v[:, :, np.newaxis]
            w = w[:, :, np.newaxis]
            if p is not None:
                p = p[:, :, np.newaxis]
        else:
            nx, ny, nz = shape_3d
        
        # å˜—è©¦è®€å–åº§æ¨™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'x' in f and 'y' in f and 'z' in f:
            x = np.array(f['x'])
            y = np.array(f['y'])
            z = np.array(f['z'])
        else:
            # å¾å ´æ•¸æ“šå½¢ç‹€æ¨æ–·ç¶²æ ¼å°ºå¯¸ï¼Œä¸¦ä½¿ç”¨é…ç½®çš„åŸŸç¯„åœ
            if domain_bounds is None:
                # ä½¿ç”¨ JHTDB Channel Flow æ¨™æº–åŸŸç¯„åœ
                domain_bounds = {
                    'x': [0.0, 8.0 * np.pi],   # 8Ï€h â‰ˆ 25.13
                    'y': [-1.0, 1.0],          # [-h, +h]
                    'z': [0.0, 3.0 * np.pi]    # 3Ï€h â‰ˆ 9.42
                }
            x = np.linspace(domain_bounds['x'][0], domain_bounds['x'][1], nx)
            y = np.linspace(domain_bounds['y'][0], domain_bounds['y'][1], ny)
            z = np.linspace(domain_bounds['z'][0], domain_bounds['z'][1], nz)
            print(f"  âš ï¸  æœªæ‰¾åˆ°åº§æ¨™ï¼Œå¾åŸŸç¯„åœé‡å»º: x=[{x[0]:.2f}, {x[-1]:.2f}], y=[{y[0]:.2f}, {y[-1]:.2f}], z=[{z[0]:.2f}, {z[-1]:.2f}]")
    
    # çµ„åˆåº§æ¨™ç¶²æ ¼ (nx, ny, nz)
    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
    coords = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)  # (N, 3)
    
    # çµ„åˆé€Ÿåº¦å ´ (N, n_vars)
    if p is not None:
        fields = np.stack([u.ravel(), v.ravel(), w.ravel(), p.ravel()], axis=1)  # (N, 4)
    else:
        fields = np.stack([u.ravel(), v.ravel(), w.ravel()], axis=1)  # (N, 3)
    
    print(f"  ç¶²æ ¼å°ºå¯¸: {u.shape}")
    print(f"  åº§æ¨™ç¯„åœ: x=[{x.min():.2f}, {x.max():.2f}], y=[{y.min():.2f}, {y.max():.2f}], z=[{z.min():.2f}, {z.max():.2f}]")
    print(f"  é€Ÿåº¦ç¯„åœ: u=[{u.min():.3f}, {u.max():.3f}], v=[{v.min():.3f}, {v.max():.3f}], w=[{w.min():.3f}, {w.max():.3f}]")
    print(f"  å ´è®Šé‡: {fields.shape[-1]} å€‹ ({'u,v,w,p' if p is not None else 'u,v,w'})")
    
    return coords, fields


def predict_full_field(model: torch.nn.Module, coords: np.ndarray, normalizer: DataNormalizer, 
                       device: torch.device, batch_size: int = 4096) -> np.ndarray:
    """é æ¸¬å…¨å ´ï¼ˆæ”¯æ´æ–°ç‰ˆ DataNormalizer APIï¼‰"""
    print(f"ğŸ”® æ¨¡å‹é æ¸¬å…¨å ´...")
    
    n_points = coords.shape[0]
    predictions = []
    
    # âš ï¸ æ³¨æ„ï¼šcoords æ˜¯ç©ºé–“åæ¨™ (x, y)ï¼Œä¸éœ€è¦ç”¨ DataNormalizer è™•ç†
    # DataNormalizer åƒ…è™•ç†è¼¸å‡ºè®Šé‡ (u, v, w, p)
    # å‡è¨­æ¨¡å‹å·²åœ¨è¨“ç·´æ™‚å°è¼¸å…¥é€²è¡Œæ­£ç¢ºè™•ç†ï¼ˆæˆ–ä¸éœ€è¦æ¨™æº–åŒ–ï¼‰
    
    with torch.no_grad():
        for i in range(0, n_points, batch_size):
            batch_coords = coords[i:i+batch_size]
            
            # è½‰æ›ç‚º Tensorï¼ˆè¼¸å…¥åæ¨™é€šå¸¸ä¸éœ€è¦æ¨™æº–åŒ–ï¼Œæˆ–å·²åœ¨æ¨¡å‹å…§éƒ¨è™•ç†ï¼‰
            batch_coords_tensor = torch.tensor(batch_coords, dtype=torch.float32).to(device)
            
            # é æ¸¬ï¼ˆæ¨¡å‹è¼¸å‡ºæ˜¯æ¨™æº–åŒ–ç©ºé–“ï¼‰
            batch_pred_norm = model(batch_coords_tensor)
            
            # åæ¨™æº–åŒ–è¼¸å‡ºï¼ˆä½¿ç”¨æ‰¹æ¬¡ APIï¼‰
            var_order = ['u', 'v', 'w', 'p'][:batch_pred_norm.shape[-1]]  # è‡ªå‹•é©é…è¼¸å‡ºç¶­åº¦
            batch_pred = normalizer.denormalize_batch(batch_pred_norm.cpu(), var_order=var_order)
            
            # è½‰æ›ç‚º numpyï¼ˆå¦‚æœæ˜¯ Tensorï¼‰
            if isinstance(batch_pred, torch.Tensor):
                batch_pred = batch_pred.numpy()
            
            predictions.append(batch_pred)
    
    predictions = np.vstack(predictions)
    print(f"  é æ¸¬å®Œæˆ: {predictions.shape}")
    
    return predictions


# ============================================================================
# åˆ†å±¤èª¤å·®è¨ˆç®—
# ============================================================================
def compute_layer_wise_errors(coords: np.ndarray, predictions: np.ndarray, 
                              ground_truth: np.ndarray) -> Dict:
    """è¨ˆç®—åˆ†å±¤èª¤å·®"""
    print(f"\nğŸ“Š è¨ˆç®—åˆ†å±¤èª¤å·®...")
    
    # æå– y åº§æ¨™ï¼ˆæ­¸ä¸€åŒ–åˆ° [0, 1]ï¼‰
    y_coords = np.abs(coords[:, 1])  # å–çµ•å°å€¼ï¼ˆå°ç¨±é€šé“æµï¼‰
    
    results = {}
    
    for layer_name, layer_info in LAYER_DEFINITIONS.items():
        y_min, y_max = layer_info['range']
        
        # é¸æ“‡è©²å±¤çš„é»
        mask = (y_coords >= y_min) & (y_coords < y_max)
        n_points = mask.sum()
        
        if n_points == 0:
            print(f"  âš ï¸  {layer_info['name']} ({layer_name}): ç„¡æ•¸æ“šé»")
            results[layer_name] = {
                'n_points': 0,
                'l2_error': np.nan,
                'relative_l2': np.nan,
                'u_error': np.nan,
                'v_error': np.nan,
                'w_error': np.nan
            }
            continue
        
        # æå–è©²å±¤æ•¸æ“š
        pred_layer = predictions[mask]
        gt_layer = ground_truth[mask]
        
        # è™•ç†è®Šé‡æ•¸é‡ä¸åŒ¹é…ï¼ˆé æ¸¬å¯èƒ½æœ‰ pï¼ŒçœŸå¯¦æ•¸æ“šå¯èƒ½æ²’æœ‰ï¼‰
        n_vars = min(pred_layer.shape[1], gt_layer.shape[1])
        pred_layer = pred_layer[:, :n_vars]
        gt_layer = gt_layer[:, :n_vars]
        
        # è¨ˆç®— L2 èª¤å·®
        diff = pred_layer - gt_layer
        l2_error = np.linalg.norm(diff, axis=0)  # æ¯å€‹è®Šé‡
        gt_norm = np.linalg.norm(gt_layer, axis=0)
        relative_l2 = l2_error / (gt_norm + 1e-10)
        
        # ç¸½é«”ç›¸å° L2
        total_l2 = np.linalg.norm(diff)
        total_gt = np.linalg.norm(gt_layer)
        total_relative = total_l2 / (total_gt + 1e-10)
        
        # æ§‹å»ºçµæœå­—å…¸ï¼ˆå‹•æ…‹æ”¯æ´ 2/3/4 å€‹è®Šé‡ï¼‰
        result_dict = {
            'n_points': int(n_points),
            'y_range': layer_info['range'],
            'l2_error': float(total_l2),
            'relative_l2': float(total_relative),
            'u_error': float(relative_l2[0]),
            'v_error': float(relative_l2[1]) if n_vars > 1 else np.nan,
            'w_error': float(relative_l2[2]) if n_vars > 2 else np.nan,
            'p_error': float(relative_l2[3]) if n_vars > 3 else np.nan,
            'name': layer_info['name'],
            'description': layer_info['description']
        }
        results[layer_name] = result_dict
        
        # å‹•æ…‹ç”Ÿæˆèª¤å·®è¼¸å‡ºå­—ç¬¦ä¸²
        var_names = ['u', 'v', 'w', 'p'][:n_vars]
        error_str = ' / '.join([f"{relative_l2[i]:.4f}" for i in range(n_vars)])
        var_label = ' / '.join(var_names)
        
        print(f"  {layer_info['name']} ({layer_name}):")
        print(f"    é»æ•¸: {n_points:,} ({n_points/len(y_coords)*100:.1f}%)")
        print(f"    ç›¸å° L2: {total_relative:.4f}")
        print(f"    {var_label} èª¤å·®: {error_str}")
    
    return results


def compare_strategies(results_wall: Dict, results_qr: Dict) -> Dict:
    """æ¯”è¼ƒå…©ç¨®ç­–ç•¥"""
    print(f"\nğŸ” ç­–ç•¥æ¯”è¼ƒåˆ†æ...")
    
    comparison = {}
    
    for layer_name in LAYER_DEFINITIONS.keys():
        wall_error = results_wall[layer_name]['relative_l2']
        qr_error = results_qr[layer_name]['relative_l2']
        
        if np.isnan(wall_error) or np.isnan(qr_error):
            ratio = np.nan
            advantage = "N/A"
        else:
            ratio = qr_error / wall_error
            if ratio < 0.95:
                advantage = "QR-Pivot å„ªå‹¢"
            elif ratio > 1.05:
                advantage = "Wall-Clustered å„ªå‹¢"
            else:
                advantage = "ç›¸ç•¶"
        
        comparison[layer_name] = {
            'wall_error': float(wall_error) if not np.isnan(wall_error) else None,
            'qr_error': float(qr_error) if not np.isnan(qr_error) else None,
            'ratio': float(ratio) if not np.isnan(ratio) else None,
            'advantage': advantage,
            'name': LAYER_DEFINITIONS[layer_name]['name']
        }
        
        print(f"  {LAYER_DEFINITIONS[layer_name]['name']}:")
        print(f"    Wall-Clustered: {wall_error:.4f}")
        print(f"    QR-Pivot: {qr_error:.4f}")
        print(f"    æ¯”å€¼ (QR/Wall): {ratio:.4f} ({advantage})")
    
    return comparison


# ============================================================================
# è¦–è¦ºåŒ–
# ============================================================================
def plot_layer_wise_errors(results_wall: Dict, results_qr: Dict, output_dir: Path):
    """ç¹ªè£½åˆ†å±¤èª¤å·®å°æ¯”åœ–"""
    print(f"\nğŸ“ˆ ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
    
    # æº–å‚™æ•¸æ“š
    layers = list(LAYER_DEFINITIONS.keys())
    layer_names = [LAYER_DEFINITIONS[l]['name'] for l in layers]
    
    wall_errors = [results_wall[l]['relative_l2'] for l in layers]
    qr_errors = [results_qr[l]['relative_l2'] for l in layers]
    
    # å‰µå»ºåœ–è¡¨
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # === åœ– 1: åˆ†å±¤èª¤å·®å°æ¯” ===
    ax = axes[0]
    x = np.arange(len(layers))
    width = 0.35
    
    ax.bar(x - width/2, wall_errors, width, label='Wall-Clustered', alpha=0.8, color='#3498db')
    ax.bar(x + width/2, qr_errors, width, label='QR-Pivot', alpha=0.8, color='#e74c3c')
    
    ax.set_xlabel('Physical Layer', fontsize=12, fontweight='bold')
    ax.set_ylabel('Relative L2 Error', fontsize=12, fontweight='bold')
    ax.set_title('Layer-wise Reconstruction Error Comparison', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(layer_names)
    ax.legend()
    ax.grid(axis='y', alpha=0.3)
    
    # === åœ– 2: èª¤å·®æ¯”å€¼ ===
    ax = axes[1]
    ratios = [qr_errors[i] / wall_errors[i] if wall_errors[i] > 0 else np.nan for i in range(len(layers))]
    colors = ['#27ae60' if r < 1.0 else '#e67e22' if r > 1.0 else '#95a5a6' for r in ratios]
    
    ax.bar(x, ratios, color=colors, alpha=0.8)
    ax.axhline(y=1.0, color='black', linestyle='--', linewidth=2, label='Equal Performance')
    
    ax.set_xlabel('Physical Layer', fontsize=12, fontweight='bold')
    ax.set_ylabel('Error Ratio (QR / Wall)', fontsize=12, fontweight='bold')
    ax.set_title('QR-Pivot vs Wall-Clustered Error Ratio', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(layer_names)
    ax.legend()
    ax.grid(axis='y', alpha=0.3)
    
    # æ¨™è¨»æ•¸å€¼
    for i, ratio in enumerate(ratios):
        if not np.isnan(ratio):
            ax.text(i, ratio + 0.05, f'{ratio:.2f}x', ha='center', fontsize=10, fontweight='bold')
    
    # === åœ– 3: é€Ÿåº¦åˆ†é‡èª¤å·® ===
    ax = axes[2]
    
    # Wall-Clustered
    wall_u = [results_wall[l]['u_error'] for l in layers]
    wall_v = [results_wall[l]['v_error'] for l in layers]
    wall_w = [results_wall[l]['w_error'] for l in layers]
    
    # QR-Pivot
    qr_u = [results_qr[l]['u_error'] for l in layers]
    qr_v = [results_qr[l]['v_error'] for l in layers]
    qr_w = [results_qr[l]['w_error'] for l in layers]
    
    width = 0.12
    x_pos = np.arange(len(layers))
    
    ax.bar(x_pos - 1.5*width, wall_u, width, label='Wall u', alpha=0.8, color='#3498db')
    ax.bar(x_pos - 0.5*width, wall_v, width, label='Wall v', alpha=0.8, color='#2ecc71')
    ax.bar(x_pos + 0.5*width, wall_w, width, label='Wall w', alpha=0.8, color='#9b59b6')
    
    ax.bar(x_pos + 1.5*width, qr_u, width, label='QR u', alpha=0.8, color='#e74c3c', hatch='//')
    ax.bar(x_pos + 2.5*width, qr_v, width, label='QR v', alpha=0.8, color='#f39c12', hatch='//')
    ax.bar(x_pos + 3.5*width, qr_w, width, label='QR w', alpha=0.8, color='#e67e22', hatch='//')
    
    ax.set_xlabel('Physical Layer', fontsize=12, fontweight='bold')
    ax.set_ylabel('Relative L2 Error', fontsize=12, fontweight='bold')
    ax.set_title('Velocity Component Errors by Layer', fontsize=14, fontweight='bold')
    ax.set_xticks(x_pos)
    ax.set_xticklabels(layer_names)
    ax.legend(ncol=2, fontsize=9)
    ax.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    output_path = output_dir / 'layer_wise_error_comparison.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  âœ… å·²å„²å­˜: {output_path}")
    
    plt.close()


def plot_spatial_error_distribution(coords: np.ndarray, predictions_wall: np.ndarray, 
                                    predictions_qr: np.ndarray, ground_truth: np.ndarray, 
                                    output_dir: Path):
    """ç¹ªè£½ç©ºé–“èª¤å·®åˆ†ä½ˆç†±åœ–"""
    print(f"  ç”Ÿæˆç©ºé–“èª¤å·®åˆ†ä½ˆåœ–...")
    
    # è™•ç†è®Šé‡æ•¸é‡ä¸åŒ¹é…
    n_vars = min(predictions_wall.shape[1], ground_truth.shape[1])
    pred_wall_aligned = predictions_wall[:, :n_vars]
    pred_qr_aligned = predictions_qr[:, :n_vars]
    gt_aligned = ground_truth[:, :n_vars]
    
    # è¨ˆç®—èª¤å·®
    error_wall = np.linalg.norm(pred_wall_aligned - gt_aligned, axis=1)
    error_qr = np.linalg.norm(pred_qr_aligned - gt_aligned, axis=1)
    
    # é‡å¡‘ç‚º 2D ç¶²æ ¼ï¼ˆå‡è¨­ coords ä¾†è‡ª meshgridï¼‰
    x_unique = np.unique(coords[:, 0])
    y_unique = np.unique(coords[:, 1])
    nx, ny = len(x_unique), len(y_unique)
    
    error_wall_2d = error_wall.reshape(nx, ny)
    error_qr_2d = error_qr.reshape(nx, ny)
    
    # å‰µå»ºåœ–è¡¨
    fig, axes = plt.subplots(1, 3, figsize=(20, 6))
    
    # === Wall-Clustered èª¤å·® ===
    ax = axes[0]
    im1 = ax.imshow(error_wall_2d.T, origin='lower', extent=[x_unique.min(), x_unique.max(), 
                                                              y_unique.min(), y_unique.max()],
                   cmap='viridis', aspect='auto')
    ax.set_title('Wall-Clustered: Spatial Error Distribution', fontsize=14, fontweight='bold')
    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    plt.colorbar(im1, ax=ax, label='L2 Error')
    
    # æ¨™è¨»ç‰©ç†å±¤
    ax.axhline(y=0.8, color='white', linestyle='--', linewidth=1.5, label='Log Layer')
    ax.axhline(y=0.2, color='white', linestyle='--', linewidth=1.5)
    ax.axhline(y=-0.8, color='white', linestyle='--', linewidth=1.5)
    ax.axhline(y=-0.2, color='white', linestyle='--', linewidth=1.5)
    
    # === QR-Pivot èª¤å·® ===
    ax = axes[1]
    im2 = ax.imshow(error_qr_2d.T, origin='lower', extent=[x_unique.min(), x_unique.max(), 
                                                            y_unique.min(), y_unique.max()],
                   cmap='viridis', aspect='auto')
    ax.set_title('QR-Pivot: Spatial Error Distribution', fontsize=14, fontweight='bold')
    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    plt.colorbar(im2, ax=ax, label='L2 Error')
    
    # æ¨™è¨»ç‰©ç†å±¤
    ax.axhline(y=0.8, color='white', linestyle='--', linewidth=1.5)
    ax.axhline(y=0.2, color='white', linestyle='--', linewidth=1.5)
    ax.axhline(y=-0.8, color='white', linestyle='--', linewidth=1.5)
    ax.axhline(y=-0.2, color='white', linestyle='--', linewidth=1.5)
    
    # === èª¤å·®å·®ç•° (QR - Wall) ===
    ax = axes[2]
    error_diff = error_qr_2d - error_wall_2d
    vmax = np.abs(error_diff).max()
    im3 = ax.imshow(error_diff.T, origin='lower', extent=[x_unique.min(), x_unique.max(), 
                                                          y_unique.min(), y_unique.max()],
                   cmap='RdBu_r', vmin=-vmax, vmax=vmax, aspect='auto')
    ax.set_title('Error Difference (QR - Wall)\nRed = QR worse, Blue = QR better', 
                fontsize=14, fontweight='bold')
    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    plt.colorbar(im3, ax=ax, label='Error Difference')
    
    # æ¨™è¨»ç‰©ç†å±¤
    ax.axhline(y=0.8, color='black', linestyle='--', linewidth=1.5)
    ax.axhline(y=0.2, color='black', linestyle='--', linewidth=1.5)
    ax.axhline(y=-0.8, color='black', linestyle='--', linewidth=1.5)
    ax.axhline(y=-0.2, color='black', linestyle='--', linewidth=1.5)
    
    plt.tight_layout()
    output_path = output_dir / 'spatial_error_distribution.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  âœ… å·²å„²å­˜: {output_path}")
    
    plt.close()


# ============================================================================
# ä¸»å‡½æ•¸
# ============================================================================
def main():
    import argparse
    parser = argparse.ArgumentParser(description='åˆ†å±¤èª¤å·®è©•ä¼°')
    parser.add_argument('--wall-checkpoint', type=str, required=True, help='Wall-Clustered æª¢æŸ¥é»è·¯å¾‘')
    parser.add_argument('--wall-config', type=str, required=True, help='Wall-Clustered é…ç½®æ–‡ä»¶')
    parser.add_argument('--qr-checkpoint', type=str, required=True, help='QR-Pivot æª¢æŸ¥é»è·¯å¾‘')
    parser.add_argument('--qr-config', type=str, required=True, help='QR-Pivot é…ç½®æ–‡ä»¶')
    parser.add_argument('--jhtdb-data', type=str, required=True, help='JHTDB çœŸå¯¦æ•¸æ“š (HDF5)')
    parser.add_argument('--output', type=str, default='./results/layer_wise_analysis', help='è¼¸å‡ºç›®éŒ„')
    args = parser.parse_args()
    
    # è·¯å¾‘è™•ç†
    wall_ckpt = Path(args.wall_checkpoint)
    wall_cfg = Path(args.wall_config)
    qr_ckpt = Path(args.qr_checkpoint)
    qr_cfg = Path(args.qr_config)
    jhtdb_data = Path(args.jhtdb_data)
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 80)
    print("  åˆ†å±¤èª¤å·®è©•ä¼° - é©—è­‰ QR-Pivot ä¸­å¿ƒå±¤ç¼ºå¤±å‡è¨­")
    print("=" * 80)
    
    # è¨­å‚™
    device = torch.device('mps' if torch.backends.mps.is_available() else 
                         'cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {device}")
    
    # === 1. è¼‰å…¥çœŸå¯¦æ•¸æ“š ===
    print(f"\n{'='*80}")
    print("æ­¥é©Ÿ 1: è¼‰å…¥ JHTDB çœŸå¯¦æ•¸æ“š")
    print("="*80)
    coords, ground_truth = load_jhtdb_ground_truth(jhtdb_data)
    
    # === 2. è¼‰å…¥ Wall-Clustered æ¨¡å‹ä¸¦é æ¸¬ ===
    print(f"\n{'='*80}")
    print("æ­¥é©Ÿ 2: è¼‰å…¥ Wall-Clustered æ¨¡å‹")
    print("="*80)
    model_wall, cfg_wall, norm_wall = load_checkpoint_and_model(wall_ckpt, wall_cfg, device)
    predictions_wall = predict_full_field(model_wall, coords, norm_wall, device)
    
    # === 3. è¼‰å…¥ QR-Pivot æ¨¡å‹ä¸¦é æ¸¬ ===
    print(f"\n{'='*80}")
    print("æ­¥é©Ÿ 3: è¼‰å…¥ QR-Pivot æ¨¡å‹")
    print("="*80)
    model_qr, cfg_qr, norm_qr = load_checkpoint_and_model(qr_ckpt, qr_cfg, device)
    predictions_qr = predict_full_field(model_qr, coords, norm_qr, device)
    
    # === 4. è¨ˆç®—åˆ†å±¤èª¤å·® ===
    print(f"\n{'='*80}")
    print("æ­¥é©Ÿ 4: è¨ˆç®—åˆ†å±¤èª¤å·®")
    print("="*80)
    
    print(f"\n--- Wall-Clustered ---")
    results_wall = compute_layer_wise_errors(coords, predictions_wall, ground_truth)
    
    print(f"\n--- QR-Pivot ---")
    results_qr = compute_layer_wise_errors(coords, predictions_qr, ground_truth)
    
    # === 5. æ¯”è¼ƒåˆ†æ ===
    print(f"\n{'='*80}")
    print("æ­¥é©Ÿ 5: ç­–ç•¥æ¯”è¼ƒ")
    print("="*80)
    comparison = compare_strategies(results_wall, results_qr)
    
    # === 6. è¦–è¦ºåŒ– ===
    print(f"\n{'='*80}")
    print("æ­¥é©Ÿ 6: è¦–è¦ºåŒ–")
    print("="*80)
    plot_layer_wise_errors(results_wall, results_qr, output_dir)
    plot_spatial_error_distribution(coords, predictions_wall, predictions_qr, ground_truth, output_dir)
    
    # === 7. å„²å­˜çµæœ ===
    print(f"\n{'='*80}")
    print("æ­¥é©Ÿ 7: å„²å­˜çµæœ")
    print("="*80)
    
    results = {
        'wall_clustered': results_wall,
        'qr_pivot': results_qr,
        'comparison': comparison,
        'metadata': {
            'wall_checkpoint': str(wall_ckpt),
            'qr_checkpoint': str(qr_ckpt),
            'jhtdb_data': str(jhtdb_data),
            'n_points': int(coords.shape[0]),
            'device': str(device)
        }
    }
    
    json_path = output_dir / 'layer_wise_error_analysis.json'
    with open(json_path, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"  âœ… JSON å ±å‘Šå·²å„²å­˜: {json_path}")
    
    # ç”Ÿæˆ Markdown å ±å‘Š
    md_path = output_dir / 'layer_wise_error_report.md'
    with open(md_path, 'w') as f:
        f.write("# åˆ†å±¤èª¤å·®åˆ†æå ±å‘Š\n\n")
        f.write("## åŸ·è¡Œæ‘˜è¦\n\n")
        f.write("æœ¬å ±å‘Šé©—è­‰ **QR-Pivot ä¸­å¿ƒå±¤ç¼ºå¤±å‡è¨­**ï¼Œæ¯”è¼ƒå…©ç¨®æ„Ÿæ¸¬é»ç­–ç•¥åœ¨ä¸‰å€‹ç‰©ç†å±¤çš„é‡å»ºèª¤å·®ã€‚\n\n")
        
        f.write("## é—œéµç™¼ç¾\n\n")
        f.write("| ç‰©ç†å±¤ | Wall-Clustered | QR-Pivot | èª¤å·®æ¯”å€¼ (QR/Wall) | å„ªå‹¢ |\n")
        f.write("|--------|----------------|----------|-------------------|------|\n")
        for layer_name, comp in comparison.items():
            f.write(f"| {comp['name']} | {comp['wall_error']:.4f} | {comp['qr_error']:.4f} | "
                   f"{comp['ratio']:.2f}Ã— | {comp['advantage']} |\n")
        
        f.write("\n## è©³ç´°åˆ†æ\n\n")
        for layer_name, layer_info in LAYER_DEFINITIONS.items():
            f.write(f"### {layer_info['name']} ({layer_info['description']})\n\n")
            f.write(f"**Wall-Clustered**:\n")
            f.write(f"- é»æ•¸: {results_wall[layer_name]['n_points']:,}\n")
            f.write(f"- ç›¸å° L2: {results_wall[layer_name]['relative_l2']:.4f}\n")
            f.write(f"- u/v/w èª¤å·®: {results_wall[layer_name]['u_error']:.4f} / "
                   f"{results_wall[layer_name]['v_error']:.4f} / {results_wall[layer_name]['w_error']:.4f}\n\n")
            
            f.write(f"**QR-Pivot**:\n")
            f.write(f"- é»æ•¸: {results_qr[layer_name]['n_points']:,}\n")
            f.write(f"- ç›¸å° L2: {results_qr[layer_name]['relative_l2']:.4f}\n")
            f.write(f"- u/v/w èª¤å·®: {results_qr[layer_name]['u_error']:.4f} / "
                   f"{results_qr[layer_name]['v_error']:.4f} / {results_qr[layer_name]['w_error']:.4f}\n\n")
        
        f.write("## çµè«–\n\n")
        f.write("æ ¹æ“šåˆ†å±¤èª¤å·®åˆ†æï¼Œ")
        center_comp = comparison['center']
        if center_comp['ratio'] and center_comp['ratio'] > 1.05:
            f.write(f"**ä¸­å¿ƒå±¤å‡è¨­å¾—åˆ°é©—è­‰**ï¼šQR-Pivot çš„ä¸­å¿ƒå±¤èª¤å·®æ¯” Wall-Clustered é«˜ "
                   f"{(center_comp['ratio']-1)*100:.1f}%ï¼Œè­‰å¯¦äº†å› ç¼ºä¹æ„Ÿæ¸¬é»å°è‡´çš„èª¤å·®ç´¯ç©ã€‚\n")
        else:
            f.write(f"**ä¸­å¿ƒå±¤å‡è¨­æœªå¾—åˆ°é©—è­‰**ï¼šQR-Pivot çš„ä¸­å¿ƒå±¤èª¤å·®èˆ‡ Wall-Clustered ç›¸ç•¶æˆ–æ›´ä½ï¼Œ"
                   f"è¡¨æ˜å…¶ä»–æ©Ÿåˆ¶ï¼ˆå¦‚ PDE ç´„æŸï¼‰æœ‰æ•ˆè£œå„Ÿäº†æ„Ÿæ¸¬é»ç¼ºå¤±ã€‚\n")
    
    print(f"  âœ… Markdown å ±å‘Šå·²å„²å­˜: {md_path}")
    
    print(f"\n{'='*80}")
    print("âœ… åˆ†å±¤èª¤å·®è©•ä¼°å®Œæˆï¼")
    print(f"è¼¸å‡ºç›®éŒ„: {output_dir}")
    print("="*80)


if __name__ == '__main__':
    main()
