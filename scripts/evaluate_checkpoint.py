#!/usr/bin/env python
"""å¿«é€Ÿè©•ä¼°æª¢æŸ¥é»çš„æµå ´èª¤å·®"""
import sys
import torch
import numpy as np
import yaml
from pathlib import Path

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pinnx.models.fourier_mlp import PINNNet
from pinnx.models.wrappers import ManualScalingWrapper

def load_checkpoint(ckpt_path):
    """è¼‰å…¥æª¢æŸ¥é»"""
    print(f"ğŸ“‚ è¼‰å…¥æª¢æŸ¥é»: {ckpt_path}")
    checkpoint = torch.load(ckpt_path, map_location='cpu')
    return checkpoint

def evaluate_model(checkpoint_path, config_path, data_path=None):
    """è©•ä¼°æ¨¡å‹"""
    print("=" * 70)
    print("  PINNs Checkpoint å¿«é€Ÿè©•ä¼°")
    print("=" * 70)
    
    # è¼‰å…¥é…ç½®
    with open(config_path, 'r') as f:
        cfg = yaml.safe_load(f)
    
    # è¼‰å…¥æª¢æŸ¥é»
    ckpt = load_checkpoint(checkpoint_path)
    
    # æå–è¨“ç·´è³‡è¨Š
    print("\nğŸ“Š è¨“ç·´è³‡è¨Šï¼š")
    print("-" * 70)
    if 'epoch' in ckpt:
        print(f"  è¨“ç·´è¼ªæ•¸: {ckpt['epoch']}")
    if 'loss' in ckpt:
        print(f"  æœ€çµ‚æå¤±: {ckpt['loss']:.6f}")
    if 'config' in ckpt:
        print(f"  é…ç½®å·²åµŒå…¥: âœ…")
    
    # å»ºç«‹æ¨¡å‹
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    
    # å¾é…ç½®æˆ–æª¢æŸ¥é»ä¸­ç²å–æ¨¡å‹åƒæ•¸
    model_cfg = ckpt.get('config', {}).get('model', cfg.get('model', {}))
    
    model = PINNNet(
        in_dim=model_cfg.get('in_dim', 2),
        out_dim=model_cfg.get('out_dim', 3),
        width=model_cfg.get('width', 128),
        depth=model_cfg.get('depth', 6),
        fourier_m=model_cfg.get('fourier_m', 32),
        fourier_sigma=model_cfg.get('fourier_sigma', 1.0)
    ).to(device)
    
    # è¼‰å…¥æ¬Šé‡
    if 'model_state_dict' in ckpt:
        state_dict = ckpt['model_state_dict']
    elif 'model' in ckpt:
        state_dict = ckpt['model']
    else:
        print("âš ï¸  ç„¡æ³•æ‰¾åˆ°æ¨¡å‹æ¬Šé‡")
        return
    
    # æª¢æ¸¬æ˜¯å¦åŒ…å« ManualScalingWrapper çš„ç·©è¡å€
    has_scaling_buffers = any(k in state_dict for k in ['input_min', 'input_max', 'output_min', 'output_max'])
    has_base_prefix = any(k.startswith('base_model.') for k in state_dict.keys())
    
    if has_scaling_buffers:
        print("  æª¢æ¸¬åˆ°å°ºåº¦åŒ–ç·©è¡å€ï¼Œä½¿ç”¨ ManualScalingWrapper...")
        # å»ºç«‹ä½”ä½ç¯„åœï¼ˆæœƒè¢« state_dict è¦†è“‹ï¼‰
        in_dim = model_cfg.get('in_dim', 2)
        out_dim = model_cfg.get('out_dim', 3)
        in_ranges = {f'in_{i}': (0.0, 1.0) for i in range(in_dim)}
        out_ranges = {f'out_{i}': (0.0, 1.0) for i in range(out_dim)}
        
        wrapper = ManualScalingWrapper(base_model=model, input_ranges=in_ranges, output_ranges=out_ranges).to(device)
        
        # è™•ç†éµæ˜ å°„
        if not has_base_prefix:
            mapped_state = {}
            for k, v in state_dict.items():
                if k in ['input_min', 'input_max', 'output_min', 'output_max']:
                    mapped_state[k] = v
                else:
                    mapped_state[f'base_model.{k}'] = v
            state_dict = mapped_state
        
        wrapper.load_state_dict(state_dict, strict=False)
        model = wrapper
        print("  âœ… ManualScalingWrapper è¼‰å…¥æˆåŠŸ")
    else:
        # è™•ç†å¯èƒ½çš„ base_model å‰ç¶´
        if has_base_prefix:
            state_dict = {k.replace('base_model.', ''): v for k, v in state_dict.items() 
                         if k not in ['input_min', 'input_max', 'output_min', 'output_max']}
        
        model.load_state_dict(state_dict, strict=False)
    model.eval()
    print(f"âœ… æ¨¡å‹å·²è¼‰å…¥ï¼ˆè¨­å‚™: {device}ï¼‰")
    
    # è¼‰å…¥æ¸¬è©¦æ•¸æ“š
    if data_path is None:
        data_path = cfg.get('data', {}).get('sensors_cache', 'data/jhtdb/channel_qr_K80_sensors.npz')
    
    print("\nğŸ“ è¼‰å…¥æ¸¬è©¦æ•¸æ“š...")
    print("-" * 70)
    
    try:
        data = np.load(data_path, allow_pickle=True)
        
        # æå–åº§æ¨™å’Œå ´å€¼ï¼ˆæ”¯æŒå¤šç¨®æ ¼å¼ï¼‰
        if 'coords' in data:
            # æ ¼å¼1: ç›´æ¥çš„ coords, u, v, p
            coords = data['coords']
            u_true = data['u'].reshape(-1, 1)
            v_true = data['v'].reshape(-1, 1)
            w_true = data['w'].reshape(-1, 1) if 'w' in data else None
            p_true = data['p'].reshape(-1, 1)
        elif 'sensor_points' in data:
            # æ ¼å¼2: æ„Ÿæ¸¬é»æ ¼å¼
            coords = data['sensor_points']
            u_true = data['sensor_u'].reshape(-1, 1)
            v_true = data['sensor_v'].reshape(-1, 1)
            w_true = data['sensor_w'].reshape(-1, 1) if 'sensor_w' in data else None
            p_true = data['sensor_p'].reshape(-1, 1)
        elif 'x' in data and 'y' in data:
            # æ ¼å¼3: ç¶²æ ¼æ ¼å¼ (æ”¯æŒ 2D å’Œ 3D)
            x = data['x']  # (Nx,)
            y = data['y']  # (Ny,)
            
            # æª¢æ¸¬æ˜¯å¦ç‚º 3D æ•¸æ“š
            if 'z' in data and data['z'].ndim == 1:
                # 3D ç¶²æ ¼æ ¼å¼
                z = data['z']  # (Nz,)
                u = data['u']  # (Nx, Ny, Nz)
                v = data['v']
                w = data.get('w', None)  # å¯èƒ½æ²’æœ‰ w
                p = data['p']
                
                # å»ºç«‹ç¶²æ ¼åº§æ¨™
                X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
                coords = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=1)
                u_true = u.ravel().reshape(-1, 1)
                v_true = v.ravel().reshape(-1, 1)
                w_true = w.ravel().reshape(-1, 1) if w is not None else None
                p_true = p.ravel().reshape(-1, 1)
            else:
                # 2D ç¶²æ ¼æ ¼å¼
                u = data['u']  # (Nx, Ny)
                v = data['v']
                p = data['p']
                
                # å»ºç«‹ç¶²æ ¼åº§æ¨™
                X, Y = np.meshgrid(x, y, indexing='ij')
                coords = np.stack([X.ravel(), Y.ravel()], axis=1)
                u_true = u.ravel().reshape(-1, 1)
                v_true = v.ravel().reshape(-1, 1)
                w_true = None
                p_true = p.ravel().reshape(-1, 1)
        else:
            print(f"âŒ ç„¡æ³•è­˜åˆ¥çš„æ•¸æ“šæ ¼å¼ã€‚å¯ç”¨éµ: {list(data.keys())}")
            return
        
        print(f"  æ•¸æ“šé»æ•¸: {len(coords)}")
        print(f"  åº§æ¨™ç¶­åº¦: {coords.shape}")
        print(f"  åº§æ¨™ç¯„åœ:")
        for i, name in enumerate(['x', 'y', 'z'][:coords.shape[1]]):
            print(f"    {name} âˆˆ [{coords[:, i].min():.3f}, {coords[:, i].max():.3f}]")
        
    except FileNotFoundError:
        print(f"âŒ æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return
    except Exception as e:
        print(f"âŒ è¼‰å…¥æ•¸æ“šå¤±æ•—: {e}")
        return
    
    # é æ¸¬
    print("\nğŸ”® æ¨¡å‹é æ¸¬...")
    print("-" * 70)
    with torch.no_grad():
        # ç¢ºä¿åº§æ¨™ç¶­åº¦èˆ‡æ¨¡å‹è¼¸å…¥ä¸€è‡´
        if coords.shape[1] < model_cfg.get('in_dim', 2):
            print(f"âš ï¸  åº§æ¨™ç¶­åº¦ ({coords.shape[1]}) å°æ–¼æ¨¡å‹è¼¸å…¥ç¶­åº¦ ({model_cfg.get('in_dim', 2)})")
            # è£œé›¶æˆ–ä½¿ç”¨é»˜èªå€¼
            coords_input = np.pad(coords, ((0, 0), (0, model_cfg.get('in_dim', 2) - coords.shape[1])), 
                                 mode='constant', constant_values=0)
        else:
            coords_input = coords[:, :model_cfg.get('in_dim', 2)]
        
        coords_tensor = torch.FloatTensor(coords_input).to(device)
        pred = model(coords_tensor)
        u_pred = pred[:, 0:1].cpu().numpy()
        v_pred = pred[:, 1:2].cpu().numpy()
        
        # æ ¹æ“šè¼¸å‡ºç¶­åº¦æ±ºå®š w å’Œ p çš„ä½ç½®
        if pred.shape[1] == 4:  # 3D: (u, v, w, p)
            w_pred = pred[:, 2:3].cpu().numpy()
            p_pred = pred[:, 3:4].cpu().numpy()
        elif pred.shape[1] == 3:  # 2D: (u, v, p)
            w_pred = None
            p_pred = pred[:, 2:3].cpu().numpy()
        else:
            w_pred = None
            p_pred = np.zeros_like(u_pred)
    
    # è¨ˆç®—èª¤å·®
    def relative_l2_error(pred, true):
        """ç›¸å° L2 èª¤å·®"""
        return np.linalg.norm(pred - true) / np.linalg.norm(true)
    
    def mean_absolute_error(pred, true):
        """å¹³å‡çµ•å°èª¤å·®"""
        return np.mean(np.abs(pred - true))
    
    u_error = relative_l2_error(u_pred, u_true) * 100
    v_error = relative_l2_error(v_pred, v_true) * 100
    p_error = relative_l2_error(p_pred, p_true) * 100
    
    u_mae = mean_absolute_error(u_pred, u_true)
    v_mae = mean_absolute_error(v_pred, v_true)
    p_mae = mean_absolute_error(p_pred, p_true)
    
    # å¦‚æœæœ‰ w é€Ÿåº¦ï¼Œä¹Ÿè¨ˆç®—èª¤å·®
    if w_true is not None and w_pred is not None:
        w_error = relative_l2_error(w_pred, w_true) * 100
        w_mae = mean_absolute_error(w_pred, w_true)
    else:
        w_error = None
        w_mae = None
    
    print("\nğŸ¯ è©•ä¼°çµæœï¼š")
    print("=" * 70)
    print(f"  U é€Ÿåº¦å ´ï¼š")
    print(f"    - ç›¸å° L2 èª¤å·®: {u_error:.2f}%")
    print(f"    - å¹³å‡çµ•å°èª¤å·®: {u_mae:.6f}")
    print(f"    - é æ¸¬ç¯„åœ: [{u_pred.min():.3f}, {u_pred.max():.3f}]")
    print(f"    - çœŸå¯¦ç¯„åœ: [{u_true.min():.3f}, {u_true.max():.3f}]")
    print()
    print(f"  V é€Ÿåº¦å ´ï¼š")
    print(f"    - ç›¸å° L2 èª¤å·®: {v_error:.2f}%")
    print(f"    - å¹³å‡çµ•å°èª¤å·®: {v_mae:.6f}")
    print(f"    - é æ¸¬ç¯„åœ: [{v_pred.min():.3f}, {v_pred.max():.3f}]")
    print(f"    - çœŸå¯¦ç¯„åœ: [{v_true.min():.3f}, {v_true.max():.3f}]")
    print()
    
    # å¦‚æœæœ‰ W é€Ÿåº¦ï¼Œé¡¯ç¤ºå…¶èª¤å·®
    if w_error is not None and w_pred is not None and w_true is not None:
        print(f"  W é€Ÿåº¦å ´ï¼š")
        print(f"    - ç›¸å° L2 èª¤å·®: {w_error:.2f}%")
        print(f"    - å¹³å‡çµ•å°èª¤å·®: {w_mae:.6f}")
        print(f"    - é æ¸¬ç¯„åœ: [{w_pred.min():.3f}, {w_pred.max():.3f}]")
        print(f"    - çœŸå¯¦ç¯„åœ: [{w_true.min():.3f}, {w_true.max():.3f}]")
        print()
    
    print(f"  å£“åŠ›å ´ï¼š")
    print(f"    - ç›¸å° L2 èª¤å·®: {p_error:.2f}%")
    print(f"    - å¹³å‡çµ•å°èª¤å·®: {p_mae:.6f}")
    print(f"    - é æ¸¬ç¯„åœ: [{p_pred.min():.3f}, {p_pred.max():.3f}]")
    print(f"    - çœŸå¯¦ç¯„åœ: [{p_true.min():.3f}, {p_true.max():.3f}]")
    
    print("\n" + "=" * 70)
    print("ğŸ† æˆåŠŸæŒ‡æ¨™æª¢æŸ¥ï¼ˆç›®æ¨™: < 15%ï¼‰ï¼š")
    print("=" * 70)
    
    success_count = 0
    total_metrics = 3  # åŸºæœ¬: u, v, p
    
    if u_error < 15.0:
        print(f"  âœ… U é€Ÿåº¦å ´: {u_error:.2f}% < 15%")
        success_count += 1
    else:
        print(f"  âŒ U é€Ÿåº¦å ´: {u_error:.2f}% >= 15%")
    
    if v_error < 15.0:
        print(f"  âœ… V é€Ÿåº¦å ´: {v_error:.2f}% < 15%")
        success_count += 1
    else:
        print(f"  âŒ V é€Ÿåº¦å ´: {v_error:.2f}% >= 15%")
    
    # å¦‚æœæœ‰ W é€Ÿåº¦ï¼Œä¹Ÿæª¢æŸ¥
    if w_error is not None:
        total_metrics = 4
        if w_error < 15.0:
            print(f"  âœ… W é€Ÿåº¦å ´: {w_error:.2f}% < 15%")
            success_count += 1
        else:
            print(f"  âŒ W é€Ÿåº¦å ´: {w_error:.2f}% >= 15%")
    
    if p_error < 15.0:
        print(f"  âœ… å£“åŠ›å ´: {p_error:.2f}% < 15%")
        success_count += 1
    else:
        print(f"  âŒ å£“åŠ›å ´: {p_error:.2f}% >= 15%")
    
    print("\n" + "=" * 70)
    if success_count == total_metrics:
        print("  ğŸ‰ æ‰€æœ‰æŒ‡æ¨™å‡é”æ¨™ï¼")
    elif success_count >= total_metrics * 0.67:
        print(f"  âš ï¸  éƒ¨åˆ†æŒ‡æ¨™é”æ¨™ ({success_count}/{total_metrics})ï¼Œéœ€é€²ä¸€æ­¥å„ªåŒ–")
    else:
        print(f"  âŒ å¤§éƒ¨åˆ†æŒ‡æ¨™æœªé”æ¨™ ({success_count}/{total_metrics})ï¼Œéœ€é‡æ–°è¨“ç·´")
    print("=" * 70)
    
    result = {
        'u_error': u_error,
        'v_error': v_error,
        'p_error': p_error,
        'success_count': success_count,
        'total_metrics': total_metrics
    }
    
    if w_error is not None:
        result['w_error'] = w_error
    
    return result

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='å¿«é€Ÿè©•ä¼° PINNs æª¢æŸ¥é»')
    parser.add_argument('--checkpoint', type=str, 
                       default='checkpoints/curriculum_adam_baseline_latest.pth',
                       help='æª¢æŸ¥é»è·¯å¾‘')
    parser.add_argument('--config', type=str,
                       default='configs/curriculum_adam_vs_soap_adam.yml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--data', type=str, default=None,
                       help='æ¸¬è©¦æ•¸æ“šè·¯å¾‘ï¼ˆé»˜èªä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾‘ï¼‰')
    
    args = parser.parse_args()
    
    evaluate_model(args.checkpoint, args.config, args.data)
