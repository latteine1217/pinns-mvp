#!/usr/bin/env python3
"""
å¢å¼·è¦–è¦ºåŒ–è©•ä¼°è…³æœ¬
Enhanced Evaluation and Visualization Script

æœ¬è…³æœ¬æä¾›å°ˆæ¥­ç´šçš„ PINNs çµæœè¦–è¦ºåŒ–ï¼ŒåŒ…æ‹¬ï¼š
- ä¸‰è¡Œå°æ¯”åœ–ï¼šPINNsé æ¸¬ | JHTDBçœŸå¯¦ | èª¤å·®åˆ†å¸ƒ
- 2Dæµå ´åˆ‡ç‰‡å¯è¦–åŒ–ï¼šu, v, p å ´åˆ†å¸ƒ
- è‡ªå‹•ç”Ÿæˆé«˜å“è³ªmatplotlibåœ–è¡¨
- æ•´åˆmetrics.pyçš„å®Œæ•´è©•ä¼°æŒ‡æ¨™

ä½œè€…: PINNs-MVP å°ˆæ¡ˆåœ˜éšŠ
æ—¥æœŸ: 2025-10-07
"""

import os
import sys
import argparse
import logging
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime

import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from matplotlib.gridspec import GridSpec
import seaborn as sns

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))

# å°ˆæ¡ˆæ¨¡çµ„
from pinnx.evals.metrics import (
    relative_L2, rmse_metrics, conservation_error,
    energy_spectrum_1d, wall_shear_stress, k_error_curve,
    uncertainty_correlation, comprehensive_evaluation
)

# è¨­å®šè­¦å‘Šèˆ‡æ—¥èªŒ
warnings.filterwarnings('ignore', category=UserWarning)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å…¨åŸŸè¨­å®š
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class EnhancedVisualizer:
    """å¢å¼·è¦–è¦ºåŒ–é¡åˆ¥"""
    
    def __init__(self, output_dir: str = "results/enhanced_plots"):
        """
        åˆå§‹åŒ–è¦–è¦ºåŒ–å™¨
        
        Args:
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è¨­å®šmatplotlibåƒæ•¸
        plt.rcParams.update({
            'figure.figsize': (15, 10),
            'font.size': 12,
            'axes.titlesize': 14,
            'axes.labelsize': 12,
            'xtick.labelsize': 10,
            'ytick.labelsize': 10,
            'legend.fontsize': 11,
            'figure.dpi': 150,
            'savefig.dpi': 300,
            'savefig.bbox': 'tight',
            'savefig.pad_inches': 0.1
        })
        
        logger.info(f"å¢å¼·è¦–è¦ºåŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œè¼¸å‡ºç›®éŒ„: {self.output_dir}")
    
    def create_three_panel_comparison(self, 
                                    pred_data: Dict[str, torch.Tensor],
                                    ref_data: Dict[str, torch.Tensor],
                                    coords: torch.Tensor,
                                    field_name: str = "u",
                                    save_name: str = "comparison_3panel") -> str:
        """
        å‰µå»ºä¸‰è¡Œå°æ¯”åœ–ï¼šé æ¸¬ | çœŸå¯¦ | èª¤å·®
        
        Args:
            pred_data: é æ¸¬æ•¸æ“š {"u": tensor, "v": tensor, "p": tensor}
            ref_data: åƒè€ƒæ•¸æ“š {"u": tensor, "v": tensor, "p": tensor}
            coords: åº§æ¨™ [N, 2] æˆ– [N, 3] (t, x, y)
            field_name: å ´åç¨± ("u", "v", "p")
            save_name: å„²å­˜æª”å
            
        Returns:
            å„²å­˜çš„åœ–ç‰‡è·¯å¾‘
        """
        fig = plt.figure(figsize=(18, 6))
        gs = GridSpec(1, 4, width_ratios=[1, 1, 1, 0.05], hspace=0.3, wspace=0.4)
        
        # å–å¾—å°æ‡‰å ´æ•¸æ“š
        pred_field = pred_data[field_name].detach().cpu().numpy()
        ref_field = ref_data[field_name].detach().cpu().numpy()
        error_field = np.abs(pred_field - ref_field)
        
        # åº§æ¨™è™•ç†
        if coords.shape[1] == 3:  # [t, x, y]
            x_coords = coords[:, 1].detach().cpu().numpy()
            y_coords = coords[:, 2].detach().cpu().numpy()
        else:  # [x, y]
            x_coords = coords[:, 0].detach().cpu().numpy()
            y_coords = coords[:, 1].detach().cpu().numpy()
        
        # çµ±ä¸€è‰²éšç¯„åœ
        vmin = min(pred_field.min(), ref_field.min())
        vmax = max(pred_field.max(), ref_field.max())
        
        # å­åœ–1: PINNsé æ¸¬
        ax1 = fig.add_subplot(gs[0, 0])
        scatter1 = ax1.scatter(x_coords, y_coords, c=pred_field, 
                              vmin=vmin, vmax=vmax, cmap='RdBu_r', s=20)
        ax1.set_title(f'PINNs Prediction\n{field_name}')
        ax1.set_xlabel('x')
        ax1.set_ylabel('y')
        ax1.grid(True, alpha=0.3)
        
        # å­åœ–2: JHTDBçœŸå¯¦
        ax2 = fig.add_subplot(gs[0, 1])
        scatter2 = ax2.scatter(x_coords, y_coords, c=ref_field, 
                              vmin=vmin, vmax=vmax, cmap='RdBu_r', s=20)
        ax2.set_title(f'JHTDB Reference\n{field_name}')
        ax2.set_xlabel('x')
        ax2.set_ylabel('y')
        ax2.grid(True, alpha=0.3)
        
        # å­åœ–3: çµ•å°èª¤å·®
        ax3 = fig.add_subplot(gs[0, 2])
        scatter3 = ax3.scatter(x_coords, y_coords, c=error_field, 
                              cmap='Reds', s=20)
        ax3.set_title(f'Absolute Error\n{field_name}')
        ax3.set_xlabel('x')
        ax3.set_ylabel('y')
        ax3.grid(True, alpha=0.3)
        
        # è‰²éšæ¢
        cbar_ax1 = fig.add_subplot(gs[0, 3])
        cbar1 = plt.colorbar(scatter1, cax=cbar_ax1)
        cbar1.set_label(f'{field_name} Value')
        
        # æ·»åŠ çµ±è¨ˆè³‡è¨Š
        rel_l2 = relative_L2(pred_data[field_name], ref_data[field_name]).item()
        rmse_result = rmse_metrics(pred_data[field_name], ref_data[field_name])
        
        # æ ¹æ“šå ´åé¸æ“‡æ­£ç¢ºçš„ç›¸å°RMSEéµ
        rmse_key_map = {'u': 'relative_rmse_u', 'v': 'relative_rmse_v', 'p': 'relative_rmse_p'}
        rel_rmse = rmse_result[rmse_key_map[field_name]]
        
        fig.suptitle(f'Field Comparison: {field_name}\n'
                    f'Relative L2: {rel_l2:.4f} | Relative RMSE: {rel_rmse:.4f}', 
                    fontsize=16, y=0.95)
        
        # å„²å­˜
        save_path = self.output_dir / f"{save_name}_{field_name}.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ä¸‰è¡Œå°æ¯”åœ–å·²å„²å­˜: {save_path}")
        return str(save_path)
    
    def create_flow_field_overview(self, 
                                 pred_data: Dict[str, torch.Tensor],
                                 ref_data: Dict[str, torch.Tensor],
                                 coords: torch.Tensor,
                                 save_name: str = "flow_field_overview") -> str:
        """
        å‰µå»ºæµå ´ç¸½è¦½åœ–ï¼šu, v, p å ´çš„ç¶œåˆå±•ç¤º
        """
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Flow Field Overview: PINNs vs JHTDB', fontsize=16)
        
        fields = ['u', 'v', 'p']
        field_names = ['Velocity U', 'Velocity V', 'Pressure']
        
        # åº§æ¨™è™•ç†
        if coords.shape[1] == 3:
            x_coords = coords[:, 1].detach().cpu().numpy()
            y_coords = coords[:, 2].detach().cpu().numpy()
        else:
            x_coords = coords[:, 0].detach().cpu().numpy()
            y_coords = coords[:, 1].detach().cpu().numpy()
        
        for i, (field, field_name) in enumerate(zip(fields, field_names)):
            pred_field = pred_data[field].detach().cpu().numpy()
            ref_field = ref_data[field].detach().cpu().numpy()
            
            # çµ±ä¸€è‰²éš
            vmin = min(pred_field.min(), ref_field.min())
            vmax = max(pred_field.max(), ref_field.max())
            
            # PINNsé æ¸¬ (ä¸Šæ’)
            im1 = axes[0, i].scatter(x_coords, y_coords, c=pred_field, 
                                   vmin=vmin, vmax=vmax, cmap='RdBu_r', s=15)
            axes[0, i].set_title(f'PINNs: {field_name}')
            axes[0, i].grid(True, alpha=0.3)
            plt.colorbar(im1, ax=axes[0, i])
            
            # JHTDBåƒè€ƒ (ä¸‹æ’)
            im2 = axes[1, i].scatter(x_coords, y_coords, c=ref_field, 
                                   vmin=vmin, vmax=vmax, cmap='RdBu_r', s=15)
            axes[1, i].set_title(f'JHTDB: {field_name}')
            axes[1, i].grid(True, alpha=0.3)
            plt.colorbar(im2, ax=axes[1, i])
            
            # è¨­å®šè»¸æ¨™ç±¤
            if i == 0:
                axes[0, i].set_ylabel('y (PINNs)')
                axes[1, i].set_ylabel('y (JHTDB)')
            axes[1, i].set_xlabel('x')
        
        plt.tight_layout()
        
        # å„²å­˜
        save_path = self.output_dir / f"{save_name}.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"æµå ´ç¸½è¦½åœ–å·²å„²å­˜: {save_path}")
        return str(save_path)
    
    def create_error_analysis_plot(self, 
                                 pred_data: Dict[str, torch.Tensor],
                                 ref_data: Dict[str, torch.Tensor],
                                 coords: torch.Tensor,
                                 save_name: str = "error_analysis") -> str:
        """
        å‰µå»ºèª¤å·®åˆ†æåœ–
        """
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Error Analysis', fontsize=16)
        
        # è¨ˆç®—å„å ´èª¤å·®
        fields = ['u', 'v', 'p']
        field_names = ['Velocity U', 'Velocity V', 'Pressure']
        colors = ['red', 'blue', 'green']
        
        errors = {}
        rel_errors = {}
        
        for field in fields:
            pred_field = pred_data[field].detach().cpu().numpy()
            ref_field = ref_data[field].detach().cpu().numpy()
            
            errors[field] = np.abs(pred_field - ref_field)
            rel_errors[field] = errors[field] / (np.abs(ref_field) + 1e-8)
        
        # å­åœ–1: çµ•å°èª¤å·®åˆ†ä½ˆ
        for i, (field, field_name, color) in enumerate(zip(fields, field_names, colors)):
            axes[0, 0].hist(errors[field], bins=50, alpha=0.7, 
                           label=f'{field_name}', color=color, density=True)
        axes[0, 0].set_xlabel('Absolute Error')
        axes[0, 0].set_ylabel('Density')
        axes[0, 0].set_title('Absolute Error Distribution')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # å­åœ–2: ç›¸å°èª¤å·®åˆ†ä½ˆ
        for i, (field, field_name, color) in enumerate(zip(fields, field_names, colors)):
            axes[0, 1].hist(rel_errors[field], bins=50, alpha=0.7, 
                           label=f'{field_name}', color=color, density=True)
        axes[0, 1].set_xlabel('Relative Error')
        axes[0, 1].set_ylabel('Density')
        axes[0, 1].set_title('Relative Error Distribution')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # å­åœ–3: èª¤å·® vs é æ¸¬å€¼æ•£é»åœ–
        all_pred = np.concatenate([pred_data[f].detach().cpu().numpy() for f in fields])
        all_error = np.concatenate([errors[f] for f in fields])
        
        axes[1, 0].scatter(all_pred, all_error, alpha=0.5, s=10)
        axes[1, 0].set_xlabel('Predicted Value')
        axes[1, 0].set_ylabel('Absolute Error')
        axes[1, 0].set_title('Error vs Prediction')
        axes[1, 0].grid(True, alpha=0.3)
        
        # å­åœ–4: çµ±è¨ˆæŒ‡æ¨™è¡¨æ ¼
        axes[1, 1].axis('off')
        
        # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
        stats_data = []
        for field, field_name in zip(fields, field_names):
            rel_l2 = relative_L2(pred_data[field], ref_data[field]).item()
            rmse_result = rmse_metrics(pred_data[field], ref_data[field])
            
            # æ ¹æ“šå ´åé¸æ“‡æ­£ç¢ºçš„ç›¸å°RMSEéµ
            rmse_key_map = {'u': 'relative_rmse_u', 'v': 'relative_rmse_v', 'p': 'relative_rmse_p'}
            rel_rmse = rmse_result[rmse_key_map[field]]
            
            max_error = errors[field].max()
            mean_error = errors[field].mean()
            
            stats_data.append([field_name, f'{rel_l2:.4f}', f'{rel_rmse:.4f}', 
                              f'{max_error:.4f}', f'{mean_error:.4f}'])
        
        # å‰µå»ºè¡¨æ ¼
        table = axes[1, 1].table(cellText=stats_data,
                                colLabels=['Field', 'Rel L2', 'Rel RMSE', 'Max Error', 'Mean Error'],
                                cellLoc='center',
                                loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 2)
        axes[1, 1].set_title('Error Statistics')
        
        plt.tight_layout()
        
        # å„²å­˜
        save_path = self.output_dir / f"{save_name}.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"èª¤å·®åˆ†æåœ–å·²å„²å­˜: {save_path}")
        return str(save_path)
    
    def create_physics_consistency_plot(self, 
                                      pred_data: Dict[str, torch.Tensor],
                                      coords: torch.Tensor,
                                      save_name: str = "physics_consistency") -> str:
        """
        å‰µå»ºç‰©ç†ä¸€è‡´æ€§æª¢æŸ¥åœ–
        """
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle('Physics Consistency Check', fontsize=16)
        
        # è¨ˆç®—å®ˆæ†å¾‹èª¤å·®
        try:
            mass_error = conservation_error(pred_data['u'], pred_data['v'], coords)
            
            # è™•ç†ä¸åŒçš„è¿”å›é¡å‹
            if isinstance(mass_error, torch.Tensor):
                if mass_error.numel() == 1:  # æ¨™é‡å¼µé‡
                    mass_error_val = mass_error.item()
                    mass_error_np = np.full(coords.shape[0], mass_error_val)
                else:  # å‘é‡å¼µé‡
                    mass_error_np = mass_error.detach().cpu().numpy()
            else:  # æ¨™é‡æ•¸å€¼
                mass_error_val = float(mass_error)
                mass_error_np = np.full(coords.shape[0], mass_error_val)
            
            # åº§æ¨™è™•ç†
            if coords.shape[1] == 3:
                x_coords = coords[:, 1].detach().cpu().numpy()
                y_coords = coords[:, 2].detach().cpu().numpy()
            else:
                x_coords = coords[:, 0].detach().cpu().numpy()
                y_coords = coords[:, 1].detach().cpu().numpy()
            
            # å­åœ–1: è³ªé‡å®ˆæ†èª¤å·®ç©ºé–“åˆ†ä½ˆ
            scatter = axes[0].scatter(x_coords, y_coords, c=mass_error_np, 
                                     cmap='Reds', s=20)
            axes[0].set_title('Mass Conservation Error')
            axes[0].set_xlabel('x')
            axes[0].set_ylabel('y')
            axes[0].grid(True, alpha=0.3)
            plt.colorbar(scatter, ax=axes[0])
            
            # å­åœ–2: å®ˆæ†èª¤å·®çµ±è¨ˆ
            axes[1].hist(mass_error_np, bins=50, alpha=0.7, color='red', density=True)
            axes[1].set_xlabel('Conservation Error')
            axes[1].set_ylabel('Density')
            axes[1].set_title(f'Conservation Error Distribution\n'
                             f'Mean: {mass_error_np.mean():.2e}, '
                             f'Max: {mass_error_np.max():.2e}')
            axes[1].grid(True, alpha=0.3)
            
        except Exception as e:
            logger.warning(f"ç‰©ç†ä¸€è‡´æ€§è¨ˆç®—å¤±æ•—: {e}")
            # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
            for ax in axes:
                ax.text(0.5, 0.5, f'Physics consistency check failed:\n{str(e)}', 
                       ha='center', va='center', transform=ax.transAxes)
                ax.set_title('Error in Physics Check')
        
        plt.tight_layout()
        
        # å„²å­˜
        save_path = self.output_dir / f"{save_name}.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ç‰©ç†ä¸€è‡´æ€§åœ–å·²å„²å­˜: {save_path}")
        return str(save_path)
    
    def generate_comprehensive_report(self, 
                                    pred_data: Dict[str, torch.Tensor],
                                    ref_data: Dict[str, torch.Tensor],
                                    coords: torch.Tensor,
                                    model_info: Optional[Dict] = None) -> str:
        """
        ç”Ÿæˆç¶œåˆè©•ä¼°å ±å‘Š
        """
        logger.info("é–‹å§‹ç”Ÿæˆç¶œåˆè©•ä¼°å ±å‘Š...")
        
        # ç”Ÿæˆæ‰€æœ‰åœ–è¡¨
        plots_generated = []
        
        # 1. ä¸‰è¡Œå°æ¯”åœ– (æ‰€æœ‰å ´)
        for field in ['u', 'v', 'p']:
            plot_path = self.create_three_panel_comparison(
                pred_data, ref_data, coords, field, f"comparison_3panel"
            )
            plots_generated.append(plot_path)
        
        # 2. æµå ´ç¸½è¦½
        overview_path = self.create_flow_field_overview(pred_data, ref_data, coords)
        plots_generated.append(overview_path)
        
        # 3. èª¤å·®åˆ†æ
        error_path = self.create_error_analysis_plot(pred_data, ref_data, coords)
        plots_generated.append(error_path)
        
        # 4. ç‰©ç†ä¸€è‡´æ€§
        physics_path = self.create_physics_consistency_plot(pred_data, coords)
        plots_generated.append(physics_path)
        
        # 5. ç”Ÿæˆæ–‡å­—å ±å‘Š
        report_path = self._generate_text_report(pred_data, ref_data, coords, 
                                                model_info or {}, plots_generated)
        
        logger.info(f"ç¶œåˆè©•ä¼°å ±å‘Šç”Ÿæˆå®Œæˆ: {report_path}")
        return report_path
    
    def _generate_text_report(self, 
                             pred_data: Dict[str, torch.Tensor],
                             ref_data: Dict[str, torch.Tensor],
                             coords: torch.Tensor,
                             model_info: Dict,
                             plots_generated: List[str]) -> str:
        """ç”Ÿæˆæ–‡å­—å ±å‘Š"""
        
        report_path = self.output_dir / "evaluation_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("PINNs å¢å¼·è©•ä¼°å ±å‘Š\n")
            f.write("Enhanced PINNs Evaluation Report\n") 
            f.write("=" * 80 + "\n\n")
            
            # åŸºæœ¬è³‡è¨Š
            f.write("ğŸ“Š åŸºæœ¬è³‡è¨Š / Basic Information\n")
            f.write("-" * 40 + "\n")
            f.write(f"è©•ä¼°æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ•¸æ“šé»æ•¸: {coords.shape[0]}\n")
            f.write(f"ç©ºé–“ç¶­åº¦: {coords.shape[1]}\n")
            
            if model_info:
                f.write(f"æ¨¡å‹è³‡è¨Š: {model_info}\n")
            f.write("\n")
            
            # æ•¸å€¼ç²¾åº¦æŒ‡æ¨™
            f.write("ğŸ¯ æ•¸å€¼ç²¾åº¦æŒ‡æ¨™ / Numerical Accuracy Metrics\n")
            f.write("-" * 40 + "\n")
            
            for field in ['u', 'v', 'p']:
                rel_l2 = relative_L2(pred_data[field], ref_data[field]).item()
                rmse_result = rmse_metrics(pred_data[field], ref_data[field])
                
                # æ ¹æ“šå ´åé¸æ“‡æ­£ç¢ºçš„ç›¸å°RMSEéµ
                rmse_key_map = {'u': 'relative_rmse_u', 'v': 'relative_rmse_v', 'p': 'relative_rmse_p'}
                rel_rmse = rmse_result[rmse_key_map[field]]
                
                f.write(f"{field.upper()} å ´:\n")
                f.write(f"  ç›¸å° L2 èª¤å·®:   {rel_l2:.6f}\n")
                f.write(f"  ç›¸å° RMSE èª¤å·®: {rel_rmse:.6f}\n")
                
                # åˆ¤æ–·æ˜¯å¦é”æ¨™ (10-15%é–€æª»)
                status = "âœ… é”æ¨™" if rel_l2 <= 0.15 else "âŒ æœªé”æ¨™"
                f.write(f"  é”æ¨™ç‹€æ³ (15%): {status}\n\n")
            
            # ç‰©ç†ä¸€è‡´æ€§
            f.write("âš–ï¸ ç‰©ç†ä¸€è‡´æ€§ / Physics Consistency\n")
            f.write("-" * 40 + "\n")
            try:
                mass_error = conservation_error(pred_data['u'], pred_data['v'], coords)
                if isinstance(mass_error, torch.Tensor):
                    mass_error_val = mass_error.mean().item() if mass_error.numel() > 1 else mass_error.item()
                else:
                    mass_error_val = float(mass_error)
                f.write(f"è³ªé‡å®ˆæ†èª¤å·®: {mass_error_val:.2e}\n\n")
                
            except Exception as e:
                f.write(f"ç‰©ç†ä¸€è‡´æ€§è¨ˆç®—å¤±æ•—: {e}\n\n")
            
            # ç”Ÿæˆçš„åœ–è¡¨æ¸…å–®
            f.write("ğŸ“ˆ ç”Ÿæˆåœ–è¡¨ / Generated Plots\n")
            f.write("-" * 40 + "\n")
            for i, plot_path in enumerate(plots_generated, 1):
                f.write(f"{i}. {Path(plot_path).name}\n")
            f.write("\n")
            
            # çµè«–èˆ‡å»ºè­°
            f.write("ğŸ“‹ çµè«–èˆ‡å»ºè­° / Conclusions and Recommendations\n")
            f.write("-" * 40 + "\n")
            
            # è‡ªå‹•ç”Ÿæˆçµè«–
            avg_rel_l2 = np.mean([relative_L2(pred_data[f], ref_data[f]).item() 
                                 for f in ['u', 'v', 'p']])
            
            if avg_rel_l2 <= 0.10:
                f.write("ğŸ‰ æ¨¡å‹è¡¨ç¾å„ªç•°ï¼Œå¹³å‡ç›¸å°èª¤å·® â‰¤ 10%\n")
            elif avg_rel_l2 <= 0.15:
                f.write("âœ… æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼Œé”åˆ°é è¨­é–€æª» (15%)\n")
            else:
                f.write("âš ï¸ æ¨¡å‹éœ€è¦æ”¹é€²ï¼Œæœªé”é è¨­é–€æª» (15%)\n")
                f.write("å»ºè­°: æª¢æŸ¥è¨“ç·´åƒæ•¸ã€å¢åŠ è¨“ç·´è¼ªæ•¸æˆ–èª¿æ•´ç¶²è·¯æ¶æ§‹\n")
            
            f.write(f"\nå¹³å‡ç›¸å° L2 èª¤å·®: {avg_rel_l2:.4f}\n")
            f.write("\n" + "=" * 80 + "\n")
        
        return str(report_path)


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='å¢å¼·è¦–è¦ºåŒ–è©•ä¼°è…³æœ¬')
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='è¨“ç·´å¥½çš„æ¨¡å‹æª¢æŸ¥é»è·¯å¾‘')
    parser.add_argument('--config', type=str, default=None,
                       help='é…ç½®æ–‡ä»¶è·¯å¾‘ï¼ˆå¦‚æœä¸åœ¨checkpointä¸­ï¼‰')
    parser.add_argument('--output_dir', type=str, default='evaluation_results',
                       help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--device', type=str, default='auto',
                       help='è¨ˆç®—è¨­å‚™: auto, cuda, cpu, mps')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è¦–è¦ºåŒ–å™¨
    visualizer = EnhancedVisualizer(args.output_dir)
    
    # === è¼‰å…¥æ¨¡å‹å’Œé…ç½® ===
    logger.info(f"è¼‰å…¥æª¢æŸ¥é»: {args.checkpoint}")
    
    from scripts.train import create_model, get_device
    from pinnx.dataio.channel_flow_loader import ChannelFlowLoader
    
    device = get_device(args.device)
    checkpoint = torch.load(args.checkpoint, map_location=device)
    
    # å–å¾—é…ç½®
    if 'config' in checkpoint:
        config = checkpoint['config']
        logger.info("å¾ checkpoint è¼‰å…¥é…ç½®")
    elif args.config:
        import yaml
        with open(args.config, 'r') as f:
            config = yaml.safe_load(f)
        logger.info(f"å¾æ–‡ä»¶è¼‰å…¥é…ç½®: {args.config}")
    else:
        raise ValueError("éœ€è¦æä¾›é…ç½®æ–‡ä»¶æˆ–åœ¨ checkpoint ä¸­åŒ…å«é…ç½®")
    
    # å»ºç«‹ä¸¦è¼‰å…¥æ¨¡å‹
    logger.info("å»ºç«‹æ¨¡å‹...")
    model = create_model(config, device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # === è¼‰å…¥åƒè€ƒæ•¸æ“šï¼ˆå®Œæ•´å ´ï¼‰ ===
    logger.info("è¼‰å…¥ JHTDB Channel Flow å®Œæ•´å ´æ•¸æ“š...")
    loader = ChannelFlowLoader(config_path=args.config)
    channel_data = loader.load_full_field_data()
    
    # å–å¾—å®Œæ•´å ´åº§æ¨™å’Œæ•¸æ“š
    coords_full = torch.from_numpy(channel_data.sensor_points).float().to(device)
    ref_u = torch.from_numpy(channel_data.sensor_data['u']).float().to(device)
    ref_v = torch.from_numpy(channel_data.sensor_data['v']).float().to(device)
    ref_p = torch.from_numpy(channel_data.sensor_data['p']).float().to(device)
    
    logger.info(f"å®Œæ•´å ´æ•¸æ“šå½¢ç‹€: coords={coords_full.shape}, u={ref_u.shape}")
    
    # === æ¨¡å‹æ¨è«–ï¼ˆå»ºç«‹æ¢¯åº¦åœ–ï¼‰ ===
    logger.info("åŸ·è¡Œæ¨¡å‹æ¨è«–...")
    
    # ğŸ”‘ é—œéµï¼šå¿…é ˆåœ¨å•Ÿç”¨æ¢¯åº¦çš„æƒ…æ³ä¸‹æ¨è«–ï¼Œæ‰èƒ½è¨ˆç®—è³ªé‡å®ˆæ†
    coords_eval = coords_full.clone().detach().requires_grad_(True)
    predictions_with_grad = model(coords_eval)
    
    # ä¸è¦ detachï¼Œä¿æŒæ¢¯åº¦é€£æ¥
    pred_u = predictions_with_grad[:, 0]
    pred_v = predictions_with_grad[:, 1]
    pred_p = predictions_with_grad[:, 2] if predictions_with_grad.shape[1] > 2 else predictions_with_grad[:, 1]
    
    pred_data = {
        'u': pred_u,
        'v': pred_v,
        'p': pred_p
    }
    
    # === åƒè€ƒæ•¸æ“š ===
    ref_data = {
        'u': ref_u,
        'v': ref_v,
        'p': ref_p
    }
    
    # === æ¨¡å‹è³‡è¨Š ===
    model_info = {
        'checkpoint': args.checkpoint,
        'epoch': checkpoint.get('epoch', 'Unknown'),
        'loss': checkpoint.get('loss', 'Unknown'),
        'architecture': config.get('model', {}).get('architecture', 'Unknown'),
        'device': str(device)
    }
    
    # === ç”Ÿæˆç¶œåˆå ±å‘Š ===
    logger.info("ç”Ÿæˆç¶œåˆè©•ä¼°å ±å‘Š...")
    report_path = visualizer.generate_comprehensive_report(
        pred_data, ref_data, coords_eval, model_info
    )
    
    print(f"\n{'='*60}")
    print("ğŸ‰ å¢å¼·è¦–è¦ºåŒ–è©•ä¼°å®Œæˆ!")
    print(f"ğŸ“Š å ±å‘Šè·¯å¾‘: {report_path}")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {args.output_dir}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()