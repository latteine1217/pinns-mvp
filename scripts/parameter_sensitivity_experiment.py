#!/usr/bin/env python3
"""
åƒæ•¸æ•æ„Ÿåº¦å¯¦é©—è…³æœ¬ - è‡ªé©æ‡‰æ®˜å·®é»æ¡æ¨£ç³»çµ±æ€§è©•ä¼°

åŠŸèƒ½ï¼š
1. ç¶²æ ¼æœç´¢é—œéµåƒæ•¸ï¼ˆkeep_ratio, initial_weight, epoch_intervalï¼‰
2. è‡ªå‹•ç”Ÿæˆé…ç½®è®Šé«”ä¸¦æ‰¹æ¬¡è¨“ç·´
3. æ”¶é›†ä¸¦æ¯”è¼ƒè¨“ç·´æŒ‡æ¨™ï¼ˆæ”¶æ–‚é€Ÿåº¦ã€æœ€çµ‚èª¤å·®ã€é‡æ¡æ¨£æ•ˆç‡ï¼‰
4. å¯è¦–åŒ–åƒæ•¸å½±éŸ¿ï¼ˆç†±åœ–ã€ä¸¦è¡Œåº§æ¨™åœ–ã€æ”¶æ–‚æ›²ç·šç–ŠåŠ ï¼‰

ç”¨æ³•ï¼š
    # å®Œæ•´åƒæ•¸æƒæï¼ˆè­¦å‘Šï¼šè¨ˆç®—é‡å¤§ï¼‰
    python scripts/parameter_sensitivity_experiment.py \
        --base-config configs/inverse_reconstruction_main.yml \
        --output results/sensitivity_analysis/

    # å¿«é€Ÿæ¸¬è©¦ï¼ˆå°åƒæ•¸ç©ºé–“ï¼‰
    python scripts/parameter_sensitivity_experiment.py \
        --base-config configs/inverse_reconstruction_main.yml \
        --mode quick \
        --output results/sensitivity_quick/
"""

import argparse
import copy
import json
import logging
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from itertools import product
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed

import yaml
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.gridspec import GridSpec

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è¨­ç½®ç¹ªåœ–æ¨£å¼
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 150


class SensitivityExperiment:
    """åƒæ•¸æ•æ„Ÿåº¦å¯¦é©—ç®¡ç†å™¨"""
    
    def __init__(self,
                 base_config_path: str,
                 output_dir: str,
                 mode: str = "full"):
        """
        Args:
            base_config_path: åŸºç¤é…ç½®æ–‡ä»¶è·¯å¾‘
            output_dir: è¼¸å‡ºç›®éŒ„
            mode: å¯¦é©—æ¨¡å¼ - "full"ï¼ˆå®Œæ•´ï¼‰ã€"quick"ï¼ˆå¿«é€Ÿæ¸¬è©¦ï¼‰ã€"custom"ï¼ˆè‡ªå®šç¾©ï¼‰
        """
        self.base_config_path = Path(base_config_path)
        self.output_dir = Path(output_dir)
        self.mode = mode
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„çµæ§‹
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "configs").mkdir(exist_ok=True)
        (self.output_dir / "results").mkdir(exist_ok=True)
        (self.output_dir / "plots").mkdir(exist_ok=True)
        (self.output_dir / "logs").mkdir(exist_ok=True)
        
        # è¼‰å…¥åŸºç¤é…ç½®
        with open(self.base_config_path, 'r') as f:
            self.base_config = yaml.safe_load(f)
        
        # å®šç¾©åƒæ•¸ç©ºé–“
        self.param_space = self._define_parameter_space()
        
        # å¯¦é©—çµæœæ”¶é›†å™¨
        self.results: List[Dict[str, Any]] = []
        
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š åƒæ•¸æ•æ„Ÿåº¦å¯¦é©—åˆå§‹åŒ–")
        logger.info(f"   åŸºç¤é…ç½®: {self.base_config_path}")
        logger.info(f"   è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        logger.info(f"   å¯¦é©—æ¨¡å¼: {mode}")
        logger.info("=" * 80)
    
    def _define_parameter_space(self) -> Dict[str, List]:
        """å®šç¾©åƒæ•¸æœç´¢ç©ºé–“"""
        if self.mode == "full":
            # å®Œæ•´åƒæ•¸ç©ºé–“ï¼ˆè¨ˆç®—å¯†é›†ï¼‰
            param_space = {
                "keep_ratio": [0.5, 0.6, 0.7, 0.8],
                "initial_weight": [1.5, 2.0, 2.5, 3.0],
                "epoch_interval": [500, 1000, 1500, 2000],
                "energy_threshold": [0.95, 0.99],  # SVD èƒ½é‡é–¾å€¼
            }
        elif self.mode == "quick":
            # å¿«é€Ÿæ¸¬è©¦ï¼ˆå°åƒæ•¸ç©ºé–“ï¼‰
            param_space = {
                "keep_ratio": [0.6, 0.7],
                "initial_weight": [2.0, 2.5],
                "epoch_interval": [1000, 1500],
                "energy_threshold": [0.99],
            }
        else:
            raise ValueError(f"æœªçŸ¥æ¨¡å¼: {self.mode}")
        
        # è¨ˆç®—ç¸½å¯¦é©—æ•¸
        total_runs = np.prod([len(v) for v in param_space.values()])
        logger.info(f"   åƒæ•¸ç©ºé–“: {param_space}")
        logger.info(f"   ç¸½å¯¦é©—æ•¸: {total_runs}")
        
        return param_space
    
    def generate_config_variants(self) -> List[Tuple[Dict, str, Dict]]:
        """
        ç”Ÿæˆæ‰€æœ‰é…ç½®è®Šé«”
        
        Returns:
            [(config_dict, config_name, params_dict), ...]
        """
        variants = []
        
        # ç¬›å¡çˆ¾ç©ç”Ÿæˆæ‰€æœ‰åƒæ•¸çµ„åˆ
        param_names = list(self.param_space.keys())
        param_values = list(self.param_space.values())
        
        for idx, combination in enumerate(product(*param_values)):
            # å‰µå»ºåƒæ•¸å­—å…¸
            params = dict(zip(param_names, combination))
            
            # è¤‡è£½åŸºç¤é…ç½®
            config = copy.deepcopy(self.base_config)
            
            # ä¿®æ”¹é…ç½®ä¸­çš„åƒæ•¸
            self._update_config_with_params(config, params)
            
            # ç”Ÿæˆé…ç½®åç¨±
            config_name = self._generate_config_name(params, idx)
            
            variants.append((config, config_name, params))
        
        logger.info(f"âœ… ç”Ÿæˆ {len(variants)} å€‹é…ç½®è®Šé«”")
        return variants
    
    def _update_config_with_params(self, config: Dict, params: Dict) -> None:
        """æ›´æ–°é…ç½®ä¸­çš„åƒæ•¸"""
        # å…¼å®¹æ€§ä¿®æ­£ï¼šç¢ºä¿ fourier åƒæ•¸æ ¼å¼æ­£ç¢ºï¼ˆtrain.py æœŸæœ›æ‰å¹³æ ¼å¼ï¼‰
        if 'fourier' in config['model'] and isinstance(config['model']['fourier'], dict):
            fourier_cfg = config['model']['fourier']
            if 'm' in fourier_cfg:
                config['model']['fourier_m'] = fourier_cfg['m']
            if 'sigma' in fourier_cfg:
                config['model']['fourier_sigma'] = fourier_cfg['sigma']
            if 'enabled' in fourier_cfg:
                config['model']['use_fourier'] = fourier_cfg['enabled']
        
        # å…¼å®¹æ€§ä¿®æ­£ï¼šå°‡ output_norm å­—ç¬¦ä¸²æ ¼å¼è½‰ç‚ºå­—å…¸æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if 'output_norm' in config['model'] and isinstance(config['model']['output_norm'], str):
            # ä½¿ç”¨ output_scales ä½œç‚ºè¼¸å‡ºç¯„åœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'output_scales' in config['model']:
                scales = config['model']['output_scales']
                config['model']['output_norm'] = {
                    'u': [0.0, scales.get('u', 1.0) * 20.0],  # å‡è¨­æœ€å¤§ç‚º 20 * scale
                    'v': [-scales.get('v', 0.1) * 5.0, scales.get('v', 0.1) * 5.0],
                    'p': [-scales.get('p', 1.0) * 100.0, scales.get('p', 1.0) * 10.0]
                }
            else:
                # ä½¿ç”¨é»˜èªå€¼
                config['model']['output_norm'] = {
                    'u': [0.0, 20.0],
                    'v': [-0.5, 0.5],
                    'p': [-100.0, 10.0]
                }
        
        # è‡ªé©æ‡‰æ¡æ¨£åƒæ•¸
        adaptive = config["training"]["sampling"]["adaptive_collocation"]
        
        # æ›´æ–° keep_ratio
        adaptive["incremental_replace"]["keep_ratio"] = params["keep_ratio"]
        adaptive["incremental_replace"]["replace_ratio"] = 1.0 - params["keep_ratio"]
        
        # æ›´æ–°é‡æ–°è¨ˆç®—çš„ k_newï¼ˆåŸºæ–¼ keep_ratioï¼‰
        pde_points: int = config["training"]["sampling"]["pde_points"]  # type: ignore
        k_new = int(pde_points * (1.0 - params["keep_ratio"]))
        adaptive["incremental_replace"]["k_new"] = k_new  # type: ignore
        
        # æ›´æ–° epoch_interval
        adaptive["trigger"]["epoch_interval"] = params["epoch_interval"]
        
        # æ›´æ–°æ–°é»æ¬Šé‡
        adaptive["new_point_weighting"]["initial_weight_multiplier"] = params["initial_weight"]
        
        # æ›´æ–° SVD èƒ½é‡é–¾å€¼
        adaptive["residual_qr"]["svd"]["energy_threshold"] = params["energy_threshold"]
        
        # èª¿æ•´è¨“ç·´ epoch æ•¸ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
        if self.mode == "quick":
            config["training"]["max_epochs"] = 5000
            config["training"]["validation_freq"] = 200
            config["training"]["checkpoint_freq"] = 1000
            
            # ğŸ”¥ é‡è¦ï¼šèª¿æ•´ early stopping patienceï¼Œç¢ºä¿è‡ªé©æ‡‰æ¡æ¨£æœ‰æ©Ÿæœƒè§¸ç™¼
            # è‡ªé©æ‡‰æ¡æ¨£æœ€æ—©åœ¨ epoch_interval (1000 æˆ– 1500) æ™‚è§¸ç™¼
            # æ‰€ä»¥ patience éœ€è¦ > epoch_interval æ‰æœ‰æ„ç¾©
            if "early_stopping" in config["training"]:
                current_epoch_interval = params["epoch_interval"]
                min_patience = current_epoch_interval + 500  # è‡³å°‘ç­‰å¾…ä¸€æ¬¡é‡æ¡æ¨£å¾Œ 500 epochs
                config["training"]["early_stopping"]["patience"] = max(
                    min_patience,
                    config["training"]["early_stopping"].get("patience", 400)
                )
                logger.info(f"ğŸ”§ Adjusted early_stopping patience to {config['training']['early_stopping']['patience']} (epoch_interval={current_epoch_interval})")
        
        
        # å…¼å®¹æ€§ä¿®æ­£ï¼šå°‡å¤šéšæ®µå„ªåŒ–å™¨é…ç½®è½‰æ›ç‚º train.py æœŸæœ›çš„æ‰å¹³æ ¼å¼
        if "optimizer_stage1" in config["training"]:
            stage1 = config["training"]["optimizer_stage1"]
            config["training"]["lr"] = stage1.get("lr", 1e-3)
            config["training"]["weight_decay"] = stage1.get("weight_decay", 1e-6)
            config["training"]["optimizer"] = stage1.get("type", "adam")
        
        # ç¢ºä¿å¿…è¦çš„è¨“ç·´åƒæ•¸å­˜åœ¨
        if "lr_scheduler" not in config["training"]:
            config["training"]["lr_scheduler"] = "cosine"
        if "warmup_epochs" not in config["training"]:
            config["training"]["warmup_epochs"] = 0
    
    def _generate_config_name(self, params: Dict, idx: int) -> str:
        """ç”Ÿæˆé…ç½®åç¨±"""
        name_parts = [f"run{idx:03d}"]
        
        for key, value in params.items():
            if key == "keep_ratio":
                name_parts.append(f"kr{value:.1f}".replace('.', 'p'))
            elif key == "initial_weight":
                name_parts.append(f"iw{value:.1f}".replace('.', 'p'))
            elif key == "epoch_interval":
                name_parts.append(f"ei{value}")
            elif key == "energy_threshold":
                name_parts.append(f"et{value:.2f}".replace('.', 'p'))
        
        return "_".join(name_parts)
    
    def save_config(self, config: Dict, config_name: str) -> Path:
        """ä¿å­˜é…ç½®æ–‡ä»¶ï¼ˆä¸¦è¨­å®šè¼¸å‡ºè·¯å¾‘ï¼‰"""
        # è¨­å®šå¯¦é©—è¼¸å‡ºè·¯å¾‘
        exp_output = self.output_dir / "results" / config_name
        config["training"]["checkpoint_dir"] = str(exp_output)
        
        config_path = self.output_dir / "configs" / f"{config_name}.yml"
        
        with open(config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False)
        
        return config_path
    
    def run_single_experiment(self, 
                              config_path: Path,
                              config_name: str,
                              params: Dict) -> Dict[str, Any]:
        """
        åŸ·è¡Œå–®æ¬¡å¯¦é©—
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘
            config_name: é…ç½®åç¨±
            params: åƒæ•¸å­—å…¸
            
        Returns:
            result_dict: å¯¦é©—çµæœ
        """
        logger.info(f"â–¶ é–‹å§‹å¯¦é©—: {config_name}")
        logger.info(f"   åƒæ•¸: {params}")
        
        # å®šç¾©è¼¸å‡ºè·¯å¾‘
        exp_output = self.output_dir / "results" / config_name
        exp_output.mkdir(exist_ok=True)
        
        # å®šç¾©æ—¥èªŒè·¯å¾‘
        log_file = self.output_dir / "logs" / f"{config_name}.log"
        
        # æ§‹å»ºè¨“ç·´å‘½ä»¤
        train_script = Path(__file__).parent / "train.py"
        cmd = [
            sys.executable,
            str(train_script),
            "--cfg", str(config_path)
        ]
        
        # åŸ·è¡Œè¨“ç·´
        start_time = datetime.now()
        
        try:
            with open(log_file, 'w') as log_f:
                process = subprocess.run(
                    cmd,
                    stdout=log_f,
                    stderr=subprocess.STDOUT,
                    timeout=3600 * 2  # 2å°æ™‚è¶…æ™‚
                )
            
            success = (process.returncode == 0)
            
        except subprocess.TimeoutExpired:
            logger.warning(f"âš  å¯¦é©—è¶…æ™‚: {config_name}")
            success = False
        except Exception as e:
            logger.error(f"âŒ å¯¦é©—å¤±æ•—: {config_name} - {e}")
            success = False
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # æå–çµæœï¼ˆå¾æª¢æŸ¥é»æˆ–æ—¥èªŒï¼‰
        metrics = self._extract_metrics(exp_output, log_file, success)
        
        # çµ„åˆçµæœ
        result = {
            "config_name": config_name,
            "params": params,
            "success": success,
            "duration_sec": duration,
            **metrics
        }
        
        logger.info(f"âœ… å®Œæˆå¯¦é©—: {config_name} ({duration:.1f}s)")
        logger.info(f"   æœ€çµ‚æå¤±: {metrics.get('final_loss', 'N/A')}")
        logger.info(f"   é‡æ¡æ¨£æ¬¡æ•¸: {metrics.get('resample_count', 'N/A')}")
        
        return result
    
    def _extract_metrics(self, 
                         exp_output: Path,
                         log_file: Path,
                         success: bool) -> Dict[str, Any]:
        """å¾è¼¸å‡ºä¸­æå–é—œéµæŒ‡æ¨™"""
        metrics = {
            "final_loss": None,
            "min_loss": None,
            "resample_count": None,
            "convergence_epoch": None,
            "l2_error_u": None,
            "l2_error_v": None,
            "l2_error_p": None,
        }
        
        if not success:
            return metrics
        
        # 1. å˜—è©¦å¾æª¢æŸ¥é»æå–
        checkpoint_files = list(exp_output.glob("checkpoint_*.pth"))
        if checkpoint_files:
            import torch
            latest_checkpoint = max(checkpoint_files, key=lambda p: p.stat().st_mtime)
            
            try:
                ckpt = torch.load(latest_checkpoint, map_location='cpu')
                
                # è¨“ç·´æ­·å²
                history = ckpt.get('training_history', {})
                if history and 'total_loss' in history:
                    losses = history['total_loss']
                    metrics['final_loss'] = losses[-1] if losses else None
                    metrics['min_loss'] = min(losses) if losses else None
                
                # é‡æ¡æ¨£çµ±è¨ˆ
                sampling_stats = ckpt.get('sampling_stats', {})
                metrics['resample_count'] = sampling_stats.get('resample_count', 0)
                
                # L2 èª¤å·®ï¼ˆå¦‚æœæœ‰è©•ä¼°çµæœï¼‰
                eval_metrics = ckpt.get('eval_metrics', {})
                metrics['l2_error_u'] = eval_metrics.get('l2_error_u')
                metrics['l2_error_v'] = eval_metrics.get('l2_error_v')
                metrics['l2_error_p'] = eval_metrics.get('l2_error_p')
                
            except Exception as e:
                logger.warning(f"âš  ç„¡æ³•è®€å–æª¢æŸ¥é» {latest_checkpoint}: {e}")
        
        # 2. å˜—è©¦å¾æ—¥èªŒæå–ï¼ˆå‚™é¸ï¼‰
        if metrics['final_loss'] is None and log_file.exists():
            try:
                with open(log_file, 'r') as f:
                    lines = f.readlines()
                
                # è§£ææ—¥èªŒä¸­çš„æå¤±ï¼ˆç°¡å–®æ­£å‰‡åŒ¹é…ï¼‰
                import re
                loss_pattern = re.compile(r"Total Loss:\s*([\d.e+-]+)")
                resample_pattern = re.compile(r"Resampling triggered")
                
                losses = []
                resample_count = 0
                
                for line in lines:
                    loss_match = loss_pattern.search(line)
                    if loss_match:
                        losses.append(float(loss_match.group(1)))
                    
                    if resample_pattern.search(line):
                        resample_count += 1
                
                if losses:
                    metrics['final_loss'] = losses[-1]
                    metrics['min_loss'] = min(losses)
                
                metrics['resample_count'] = resample_count
                
            except Exception as e:
                logger.warning(f"âš  ç„¡æ³•è§£ææ—¥èªŒ {log_file}: {e}")
        
        return metrics
    
    def run_all_experiments(self, parallel: bool = False, max_workers: int = 4) -> None:
        """
        åŸ·è¡Œæ‰€æœ‰å¯¦é©—
        
        Args:
            parallel: æ˜¯å¦ä¸¦è¡ŒåŸ·è¡Œ
            max_workers: æœ€å¤§ä¸¦è¡Œå·¥ä½œæ•¸
        """
        variants = self.generate_config_variants()
        
        logger.info("=" * 80)
        logger.info(f"ğŸš€ é–‹å§‹æ‰¹æ¬¡å¯¦é©—ï¼ˆå…± {len(variants)} å€‹ï¼‰")
        logger.info(f"   ä¸¦è¡Œæ¨¡å¼: {parallel}")
        if parallel:
            logger.info(f"   å·¥ä½œæ•¸: {max_workers}")
        logger.info("=" * 80)
        
        # ä¿å­˜æ‰€æœ‰é…ç½®
        config_paths = []
        for config, name, params in variants:
            config_path = self.save_config(config, name)
            config_paths.append((config_path, name, params))
        
        # åŸ·è¡Œå¯¦é©—
        if parallel:
            # ä¸¦è¡ŒåŸ·è¡Œ
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                futures = {
                    executor.submit(
                        self.run_single_experiment, 
                        config_path, 
                        name, 
                        params
                    ): name
                    for config_path, name, params in config_paths
                }
                
                for future in as_completed(futures):
                    name = futures[future]
                    try:
                        result = future.result()
                        self.results.append(result)
                    except Exception as e:
                        logger.error(f"âŒ å¯¦é©—å¤±æ•— {name}: {e}")
        else:
            # é †åºåŸ·è¡Œ
            for config_path, name, params in config_paths:
                result = self.run_single_experiment(config_path, name, params)
                self.results.append(result)
        
        # ä¿å­˜çµæœåŒ¯ç¸½
        self._save_results_summary()
        
        logger.info("=" * 80)
        logger.info(f"âœ… æ‰€æœ‰å¯¦é©—å®Œæˆï¼")
        logger.info(f"   æˆåŠŸ: {sum(r['success'] for r in self.results)}/{len(self.results)}")
        logger.info("=" * 80)
    
    def _save_results_summary(self) -> None:
        """ä¿å­˜çµæœåŒ¯ç¸½"""
        # è½‰ç‚º DataFrame
        df = pd.DataFrame(self.results)
        
        # å±•é–‹ params åˆ—
        params_df = pd.json_normalize(df['params'])
        df = pd.concat([df.drop('params', axis=1), params_df], axis=1)
        
        # ä¿å­˜ CSV
        csv_path = self.output_dir / "results_summary.csv"
        df.to_csv(csv_path, index=False)
        
        # ä¿å­˜ JSON
        json_path = self.output_dir / "results_summary.json"
        with open(json_path, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        logger.info(f"ğŸ“„ çµæœåŒ¯ç¸½å·²ä¿å­˜:")
        logger.info(f"   CSV: {csv_path}")
        logger.info(f"   JSON: {json_path}")
    
    def analyze_and_visualize(self) -> None:
        """åˆ†æçµæœä¸¦ç”Ÿæˆå¯è¦–åŒ–"""
        logger.info("=" * 80)
        logger.info("ğŸ“Š é–‹å§‹çµæœåˆ†æèˆ‡å¯è¦–åŒ–...")
        logger.info("=" * 80)
        
        # è¼‰å…¥çµæœ
        df = pd.DataFrame(self.results)
        params_df = pd.json_normalize(df['params'])
        df = pd.concat([df.drop('params', axis=1), params_df], axis=1)
        
        # éæ¿¾æˆåŠŸçš„å¯¦é©—
        df_success = df[df['success'] == True].copy()
        
        if df_success.empty:
            logger.warning("âš  æ²’æœ‰æˆåŠŸçš„å¯¦é©—ï¼Œç„¡æ³•ç”Ÿæˆå¯è¦–åŒ–")
            return
        
        # 1. åƒæ•¸ç†±åœ–ï¼ˆåƒæ•¸ vs æŒ‡æ¨™ï¼‰
        self._plot_parameter_heatmaps(df_success)
        
        # 2. ä¸¦è¡Œåº§æ¨™åœ–
        self._plot_parallel_coordinates(df_success)
        
        # 3. æ”¶æ–‚æ›²ç·šæ¯”è¼ƒï¼ˆéœ€è¦é¡å¤–æ•¸æ“šï¼‰
        # self._plot_convergence_comparison(df_success)
        
        # 4. çµ±è¨ˆæ‘˜è¦
        self._print_statistical_summary(df_success)
        
        logger.info("=" * 80)
        logger.info("âœ… åˆ†æèˆ‡å¯è¦–åŒ–å®Œæˆï¼")
        logger.info(f"   åœ–è¡¨ä¿å­˜è‡³: {self.output_dir / 'plots'}")
        logger.info("=" * 80)
    
    def _plot_parameter_heatmaps(self, df: pd.DataFrame) -> None:
        """ç¹ªè£½åƒæ•¸ç†±åœ–"""
        param_cols = ["keep_ratio", "initial_weight", "epoch_interval", "energy_threshold"]
        metric_cols = ["final_loss", "min_loss", "resample_count", "duration_sec"]
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 14))
        axes = axes.flatten()
        
        for idx, metric in enumerate(metric_cols):
            ax = axes[idx]
            
            # é‡å°æ¯å°åƒæ•¸å‰µå»ºç†±åœ–
            # é€™è£¡ç°¡åŒ–ç‚º keep_ratio vs initial_weight
            pivot = df.pivot_table(
                values=metric,
                index='keep_ratio',
                columns='initial_weight',
                aggfunc='mean'
            )
            
            sns.heatmap(pivot, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax)
            ax.set_title(f'{metric} vs (keep_ratio, initial_weight)', fontweight='bold')
            ax.set_xlabel('Initial Weight Multiplier')
            ax.set_ylabel('Keep Ratio')
        
        fig.suptitle('Parameter Sensitivity Heatmaps', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        save_path = self.output_dir / "plots" / "parameter_heatmaps.png"
        fig.savefig(save_path, dpi=200, bbox_inches='tight')
        logger.info(f"âœ… ä¿å­˜ç†±åœ–: {save_path}")
        plt.close(fig)
    
    def _plot_parallel_coordinates(self, df: pd.DataFrame) -> None:
        """ç¹ªè£½ä¸¦è¡Œåº§æ¨™åœ–"""
        from pandas.plotting import parallel_coordinates
        
        # é¸æ“‡è®Šé‡
        plot_cols = ["keep_ratio", "initial_weight", "epoch_interval", 
                     "energy_threshold", "final_loss"]
        
        # æ¨™æº–åŒ–æ•¸å€¼ï¼ˆä¾¿æ–¼å¯è¦–åŒ–ï¼‰
        df_norm = df[plot_cols].copy()
        for col in plot_cols:
            df_norm[col] = (df_norm[col] - df_norm[col].min()) / (df_norm[col].max() - df_norm[col].min() + 1e-8)
        
        # æ ¹æ“š final_loss åˆ†çµ„ï¼ˆé«˜/ä¸­/ä½ï¼‰
        df_norm['loss_category'] = pd.qcut(df['final_loss'], q=3, labels=['Low', 'Medium', 'High'])
        
        fig, ax = plt.subplots(figsize=(14, 8))
        
        parallel_coordinates(
            df_norm, 
            'loss_category', 
            cols=plot_cols[:-1],
            color=['green', 'orange', 'red'],
            alpha=0.5,
            ax=ax
        )
        
        ax.set_title('Parallel Coordinates Plot: Parameter Impact on Final Loss', 
                     fontsize=14, fontweight='bold')
        ax.set_ylabel('Normalized Value')
        ax.legend(title='Loss Category', loc='upper right')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        save_path = self.output_dir / "plots" / "parallel_coordinates.png"
        fig.savefig(save_path, dpi=200, bbox_inches='tight')
        logger.info(f"âœ… ä¿å­˜ä¸¦è¡Œåº§æ¨™åœ–: {save_path}")
        plt.close(fig)
    
    def _print_statistical_summary(self, df: pd.DataFrame) -> None:
        """æ‰“å°çµ±è¨ˆæ‘˜è¦"""
        logger.info("=" * 80)
        logger.info("ğŸ“ˆ çµ±è¨ˆæ‘˜è¦")
        logger.info("=" * 80)
        
        # æœ€ä½³é…ç½®
        best_idx = df['final_loss'].idxmin()
        best_config = df.loc[best_idx]
        
        logger.info("ğŸ† æœ€ä½³é…ç½®:")
        logger.info(f"   é…ç½®åç¨±: {best_config['config_name']}")
        logger.info(f"   keep_ratio: {best_config['keep_ratio']}")
        logger.info(f"   initial_weight: {best_config['initial_weight']}")
        logger.info(f"   epoch_interval: {best_config['epoch_interval']}")
        logger.info(f"   energy_threshold: {best_config['energy_threshold']}")
        logger.info(f"   æœ€çµ‚æå¤±: {best_config['final_loss']:.6e}")
        logger.info(f"   é‡æ¡æ¨£æ¬¡æ•¸: {best_config['resample_count']}")
        logger.info(f"   è¨“ç·´æ™‚é•·: {best_config['duration_sec']:.1f}s")
        
        # ç›¸é—œæ€§åˆ†æ
        logger.info("=" * 80)
        logger.info("ğŸ“Š åƒæ•¸èˆ‡æœ€çµ‚æå¤±çš„ç›¸é—œæ€§:")
        
        param_cols = ["keep_ratio", "initial_weight", "epoch_interval", "energy_threshold"]
        for param in param_cols:
            corr = df[param].corr(df['final_loss'])
            logger.info(f"   {param:20s}: {corr:+.3f}")
        
        logger.info("=" * 80)


def main():
    parser = argparse.ArgumentParser(description='åƒæ•¸æ•æ„Ÿåº¦å¯¦é©—')
    parser.add_argument('--base-config', type=str, required=True,
                       help='åŸºç¤é…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--output', type=str, default='results/sensitivity_analysis/',
                       help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--mode', type=str, default='quick', 
                       choices=['full', 'quick'],
                       help='å¯¦é©—æ¨¡å¼ï¼ˆfull: å®Œæ•´åƒæ•¸ç©ºé–“ï¼Œquick: å¿«é€Ÿæ¸¬è©¦ï¼‰')
    parser.add_argument('--parallel', action='store_true',
                       help='ä¸¦è¡ŒåŸ·è¡Œå¯¦é©—')
    parser.add_argument('--max-workers', type=int, default=4,
                       help='æœ€å¤§ä¸¦è¡Œå·¥ä½œæ•¸')
    parser.add_argument('--analyze-only', action='store_true',
                       help='åƒ…åˆ†æç¾æœ‰çµæœï¼ˆä¸åŸ·è¡Œå¯¦é©—ï¼‰')
    
    args = parser.parse_args()
    
    # å‰µå»ºå¯¦é©—ç®¡ç†å™¨
    experiment = SensitivityExperiment(
        base_config_path=args.base_config,
        output_dir=args.output,
        mode=args.mode
    )
    
    # åŸ·è¡Œå¯¦é©—
    if not args.analyze_only:
        experiment.run_all_experiments(
            parallel=args.parallel,
            max_workers=args.max_workers
        )
    
    # åˆ†æèˆ‡å¯è¦–åŒ–
    if experiment.results or (experiment.output_dir / "results_summary.json").exists():
        # å¦‚æœæ˜¯ analyze_only æ¨¡å¼ï¼Œå¾æ–‡ä»¶è¼‰å…¥çµæœ
        if args.analyze_only and not experiment.results:
            json_path = experiment.output_dir / "results_summary.json"
            with open(json_path, 'r') as f:
                experiment.results = json.load(f)
            logger.info(f"ğŸ“‚ è¼‰å…¥ç¾æœ‰çµæœ: {json_path}")
        
        experiment.analyze_and_visualize()
    
    logger.info("âœ… åƒæ•¸æ•æ„Ÿåº¦å¯¦é©—å®Œæˆï¼")


if __name__ == "__main__":
    main()
