"""
PirateNet è¨“ç·´å¤±æ•—è¨ºæ–·è…³æœ¬

è¨ºæ–·é‡é»ï¼š
1. æª¢æŸ¥é»å®Œæ•´æ€§ï¼ˆloss history, æ¨¡å‹æ¬Šé‡ï¼‰
2. è¨“ç·´éç¨‹åˆ†æï¼ˆNaN å‡ºç¾æ™‚æ©Ÿã€æå¤±æ›²ç·šï¼‰
3. æ¨¡å‹è¼¸å‡ºç¯„åœæª¢æŸ¥ï¼ˆæ•¸å€¼ç©©å®šæ€§ï¼‰
4. é…ç½®æª”æ¡ˆé©—è­‰ï¼ˆç‰©ç†åƒæ•¸ã€æ¬Šé‡è¨­å®šï¼‰
"""

import torch
import numpy as np
import yaml
import json
from pathlib import Path
import sys
import matplotlib.pyplot as plt

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def diagnose_checkpoint(checkpoint_path: str):
    """è¨ºæ–·æª¢æŸ¥é»æª”æ¡ˆ"""
    print("=" * 80)
    print("ğŸ” æª¢æŸ¥é»è¨ºæ–·")
    print("=" * 80)
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # 1. åŸºæœ¬è³‡è¨Š
    print(f"\nğŸ“¦ æª¢æŸ¥é»è³‡è¨Š:")
    print(f"  - Epoch: {checkpoint.get('epoch', 'N/A')}")
    print(f"  - Loss: {checkpoint.get('loss', 'N/A')}")
    
    # 2. æª¢æŸ¥æ¨¡å‹æ¬Šé‡
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
        print(f"\nğŸ§  æ¨¡å‹æ¬Šé‡çµ±è¨ˆ:")
        
        all_params = []
        has_nan = False
        has_inf = False
        
        for name, param in state_dict.items():
            if isinstance(param, torch.Tensor):
                param_np = param.cpu().numpy()
                all_params.extend(param_np.flatten())
                
                if np.isnan(param_np).any():
                    print(f"  âš ï¸  {name}: åŒ…å« NaN")
                    has_nan = True
                if np.isinf(param_np).any():
                    print(f"  âš ï¸  {name}: åŒ…å« Inf")
                    has_inf = True
                
                print(f"  - {name:40s} | shape: {str(param.shape):20s} | "
                      f"mean: {param_np.mean():10.4e} | std: {param_np.std():10.4e} | "
                      f"min: {param_np.min():10.4e} | max: {param_np.max():10.4e}")
        
        all_params = np.array(all_params)
        print(f"\n  ğŸ“Š å…¨å±€çµ±è¨ˆ:")
        print(f"    - ç¸½åƒæ•¸æ•¸é‡: {len(all_params):,}")
        print(f"    - å‡å€¼: {all_params.mean():.6e}")
        print(f"    - æ¨™æº–å·®: {all_params.std():.6e}")
        print(f"    - ç¯„åœ: [{all_params.min():.6e}, {all_params.max():.6e}]")
        print(f"    - åŒ…å« NaN: {'âŒ æ˜¯' if has_nan else 'âœ… å¦'}")
        print(f"    - åŒ…å« Inf: {'âŒ æ˜¯' if has_inf else 'âœ… å¦'}")
    
    # 3. æå¤±æ­·å²
    if 'loss_history' in checkpoint:
        loss_hist = checkpoint['loss_history']
        print(f"\nğŸ“ˆ æå¤±æ­·å²åˆ†æ (å…± {len(loss_hist)} ç­†è¨˜éŒ„):")
        
        if len(loss_hist) > 0:
            # æ‰¾å‡º NaN å‡ºç¾æ™‚æ©Ÿ
            nan_epochs = []
            for i, entry in enumerate(loss_hist):
                total_loss = entry.get('total', 0)
                if np.isnan(total_loss) or np.isinf(total_loss):
                    nan_epochs.append(i)
            
            if nan_epochs:
                print(f"  âš ï¸  NaN/Inf å‡ºç¾æ–¼ epoch: {nan_epochs[:10]}...")
                print(f"     é¦–æ¬¡å‡ºç¾: epoch {nan_epochs[0]}")
            else:
                print(f"  âœ… ç„¡ NaN/Inf")
            
            # å‰ 10 epochs
            print(f"\n  ğŸ“‹ å‰ 10 epochs:")
            print(f"  {'Epoch':>6} {'Total':>12} {'Data':>12} {'PDE':>12} {'Wall':>12}")
            print(f"  {'-'*60}")
            for i in range(min(10, len(loss_hist))):
                entry = loss_hist[i]
                print(f"  {entry.get('epoch', i):>6} "
                      f"{entry.get('total', 0):>12.4e} "
                      f"{entry.get('data', 0):>12.4e} "
                      f"{entry.get('pde', 0):>12.4e} "
                      f"{entry.get('wall', 0):>12.4e}")
            
            # æœ€å¾Œ 10 epochs
            if len(loss_hist) > 10:
                print(f"\n  ğŸ“‹ æœ€å¾Œ 10 epochs:")
                print(f"  {'Epoch':>6} {'Total':>12} {'Data':>12} {'PDE':>12} {'Wall':>12}")
                print(f"  {'-'*60}")
                for i in range(max(0, len(loss_hist)-10), len(loss_hist)):
                    entry = loss_hist[i]
                    print(f"  {entry.get('epoch', i):>6} "
                          f"{entry.get('total', 0):>12.4e} "
                          f"{entry.get('data', 0):>12.4e} "
                          f"{entry.get('pde', 0):>12.4e} "
                          f"{entry.get('wall', 0):>12.4e}")
    
    # 4. å„ªåŒ–å™¨ç‹€æ…‹
    if 'optimizer_state_dict' in checkpoint:
        opt_state = checkpoint['optimizer_state_dict']
        print(f"\nâš™ï¸  å„ªåŒ–å™¨ç‹€æ…‹:")
        if 'param_groups' in opt_state:
            for i, group in enumerate(opt_state['param_groups']):
                print(f"  - Group {i}: lr={group.get('lr', 'N/A')}")
    
    # 5. é…ç½®è³‡è¨Š
    if 'config' in checkpoint:
        cfg = checkpoint['config']
        print(f"\nğŸ“ é…ç½®æ‘˜è¦:")
        if 'model' in cfg:
            print(f"  - æ¨¡å‹: {cfg['model'].get('type', 'N/A')}")
            print(f"  - å¯¬åº¦: {cfg['model'].get('width', 'N/A')}")
            print(f"  - æ·±åº¦: {cfg['model'].get('depth', 'N/A')}")
        if 'training' in cfg:
            print(f"  - Batch size: {cfg['training'].get('batch_size', 'N/A')}")
            # å­¸ç¿’ç‡å¾å„ªåŒ–å™¨ç‹€æ…‹æˆ–é…ç½®ä¸­ç²å–
            lr = 'N/A'
            if 'optimizer_state_dict' in checkpoint and 'param_groups' in checkpoint['optimizer_state_dict']:
                lr = checkpoint['optimizer_state_dict']['param_groups'][0].get('lr', 'N/A')
            elif isinstance(cfg['training'].get('lr'), (int, float)):
                lr = cfg['training'].get('lr')
            print(f"  - å­¸ç¿’ç‡: {lr}")
    
    return checkpoint

def visualize_loss_history(loss_history, output_dir):
    """è¦–è¦ºåŒ–æå¤±æ›²ç·š"""
    if not loss_history or len(loss_history) == 0:
        print("âš ï¸  ç„¡æå¤±æ­·å²è³‡æ–™ï¼Œè·³éè¦–è¦ºåŒ–")
        return
    
    print(f"\nğŸ“Š ç”Ÿæˆæå¤±æ›²ç·šåœ–...")
    
    epochs = [entry.get('epoch', i) for i, entry in enumerate(loss_history)]
    total_loss = [entry.get('total', np.nan) for entry in loss_history]
    data_loss = [entry.get('data', np.nan) for entry in loss_history]
    pde_loss = [entry.get('pde', np.nan) for entry in loss_history]
    wall_loss = [entry.get('wall', np.nan) for entry in loss_history]
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # Total Loss
    axes[0, 0].semilogy(epochs, total_loss, 'k-', linewidth=2)
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Total Loss')
    axes[0, 0].set_title('Total Loss')
    axes[0, 0].grid(True, alpha=0.3)
    
    # Data Loss
    axes[0, 1].semilogy(epochs, data_loss, 'b-', linewidth=2)
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Data Loss')
    axes[0, 1].set_title('Data Loss')
    axes[0, 1].grid(True, alpha=0.3)
    
    # PDE Loss
    axes[1, 0].semilogy(epochs, pde_loss, 'r-', linewidth=2)
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('PDE Loss')
    axes[1, 0].set_title('PDE Residual Loss')
    axes[1, 0].grid(True, alpha=0.3)
    
    # Wall Loss
    axes[1, 1].semilogy(epochs, wall_loss, 'g-', linewidth=2)
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Wall Loss')
    axes[1, 1].set_title('Wall BC Loss')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    output_path = Path(output_dir) / 'loss_history.png'
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"  âœ… å·²ä¿å­˜: {output_path}")
    
    plt.close()

def check_config(config_path):
    """æª¢æŸ¥é…ç½®æª”æ¡ˆ"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ é…ç½®æª”æ¡ˆæª¢æŸ¥")
    print("=" * 80)
    
    with open(config_path, 'r') as f:
        cfg = yaml.safe_load(f)
    
    issues = []
    
    # 1. æª¢æŸ¥ç‰©ç†åƒæ•¸
    if 'physics' in cfg:
        phys = cfg['physics']
        nu = phys.get('nu', None)
        re_tau = phys.get('re_tau', None)
        
        print(f"\nâš›ï¸  ç‰©ç†åƒæ•¸:")
        print(f"  - é¡å‹: {phys.get('type', 'N/A')}")
        print(f"  - Î½: {nu}")
        print(f"  - Re_Ï„: {re_tau}")
        
        # æª¢æŸ¥åŸŸç¯„åœ
        if 'domain' in phys:
            domain = phys['domain']
            y_min = domain.get('y_min', None)
            y_max = domain.get('y_max', None)
            print(f"  - y ç¯„åœ: [{y_min}, {y_max}]")
            
            if y_min != -1.0 or y_max != 1.0:
                issues.append(f"âš ï¸  å£é¢ä½ç½®ä¸å°ç¨±: y âˆˆ [{y_min}, {y_max}]ï¼ˆæ‡‰ç‚º [-1, 1]ï¼‰")
        
        # æª¢æŸ¥ VS-PINN ç¸®æ”¾
        if 'scaling' in phys:
            scaling = phys['scaling']
            N_x = scaling.get('N_x', 1.0)
            N_y = scaling.get('N_y', 1.0)
            N_z = scaling.get('N_z', 1.0)
            print(f"  - VS-PINN ç¸®æ”¾: N_x={N_x}, N_y={N_y}, N_z={N_z}")
            
            if N_x == 1.0 and N_y == 1.0 and N_z == 1.0:
                issues.append("âš ï¸  VS-PINN ç¸®æ”¾æœªå•Ÿç”¨ï¼ˆæ‰€æœ‰ç¸®æ”¾å› å­=1ï¼‰")
    
    # 2. æª¢æŸ¥æå¤±æ¬Šé‡
    if 'losses' in cfg:
        losses = cfg['losses']
        print(f"\nâš–ï¸  æå¤±æ¬Šé‡:")
        print(f"  - Data: {losses.get('data_loss_weight', 'N/A')}")
        print(f"  - PDE: {losses.get('pde_loss_weight', 'N/A')}")
        print(f"  - Wall: {losses.get('wall_loss_weight', 'N/A')}")
        print(f"  - Initial: {losses.get('initial_loss_weight', 'N/A')}")
        
        # æª¢æŸ¥è‡ªé©æ‡‰æ¬Šé‡
        if 'adaptive_weights' in losses:
            adp = losses['adaptive_weights']
            print(f"  - è‡ªé©æ‡‰æ¬Šé‡: {adp.get('enabled', False)}")
            if adp.get('enabled'):
                print(f"    - æ–¹æ³•: {adp.get('method', 'N/A')}")
                print(f"    - Î±: {adp.get('alpha', 'N/A')}")
                print(f"    - æ›´æ–°é »ç‡: {adp.get('update_frequency', 'N/A')}")
    
    # 3. æª¢æŸ¥è¨“ç·´é…ç½®
    if 'training' in cfg:
        train = cfg['training']
        print(f"\nğŸ‹ï¸  è¨“ç·´é…ç½®:")
        print(f"  - Epochs: {train.get('epochs', 'N/A')}")
        print(f"  - Batch size: {train.get('batch_size', 'N/A')}")
        
        if 'optimizer' in train:
            opt = train['optimizer']
            # optimizer å¯èƒ½æ˜¯å­—ä¸²æˆ–å­—å…¸
            if isinstance(opt, dict):
                lr = opt.get('lr', train.get('lr'))
                opt_type = opt.get('type', 'N/A')
            else:
                lr = train.get('lr', None)
                opt_type = opt
            
            print(f"  - å„ªåŒ–å™¨: {opt_type}")
            print(f"  - å­¸ç¿’ç‡: {lr}")
            
            if lr and lr > 1e-2:
                issues.append(f"âš ï¸  å­¸ç¿’ç‡éé«˜: {lr}ï¼ˆå»ºè­° â‰¤ 1e-3ï¼‰")
        
        # æª¢æŸ¥æ¢¯åº¦è£å‰ª
        grad_clip = train.get('gradient_clip', None)
        if grad_clip:
            print(f"  - æ¢¯åº¦è£å‰ª: {grad_clip}")
        else:
            issues.append("âš ï¸  æœªå•Ÿç”¨æ¢¯åº¦è£å‰ªï¼ˆå»ºè­°è¨­ç‚º 1.0ï¼‰")
    
    # 4. æª¢æŸ¥æ¨¡å‹é…ç½®
    if 'model' in cfg:
        model = cfg['model']
        print(f"\nğŸ§  æ¨¡å‹é…ç½®:")
        print(f"  - é¡å‹: {model.get('type', 'N/A')}")
        print(f"  - å¯¬åº¦: {model.get('width', 'N/A')}")
        print(f"  - æ·±åº¦: {model.get('depth', 'N/A')}")
        print(f"  - æ¿€æ´»å‡½æ•¸: {model.get('activation', 'N/A')}")
        
        if model.get('use_fourier'):
            print(f"  - Fourier M: {model.get('fourier_m', 'N/A')}")
            print(f"  - Fourier Ïƒ: {model.get('fourier_sigma', 'N/A')}")
        
        if model.get('use_rwf'):
            print(f"  - RWF: å·²å•Ÿç”¨")
    
    # è¼¸å‡ºå•é¡Œç¸½çµ
    if issues:
        print(f"\nâŒ ç™¼ç¾ {len(issues)} å€‹æ½›åœ¨å•é¡Œ:")
        for i, issue in enumerate(issues, 1):
            print(f"  {i}. {issue}")
    else:
        print(f"\nâœ… é…ç½®æª”æ¡ˆçœ‹èµ·ä¾†æ­£å¸¸")
    
    return cfg, issues

def main():
    import argparse
    parser = argparse.ArgumentParser(description='PirateNet è¨“ç·´å¤±æ•—è¨ºæ–·')
    parser.add_argument('--checkpoint', type=str, required=True, help='æª¢æŸ¥é»è·¯å¾‘')
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--output-dir', type=str, default='results/piratenet_diagnosis',
                        help='è¨ºæ–·çµæœè¼¸å‡ºç›®éŒ„')
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ”¬ PirateNet è¨“ç·´å¤±æ•—è¨ºæ–·å·¥å…·")
    print("=" * 80)
    print(f"\næª¢æŸ¥é»: {args.checkpoint}")
    print(f"é…ç½®: {args.config}")
    print(f"è¼¸å‡º: {args.output_dir}")
    
    # 1. è¨ºæ–·æª¢æŸ¥é»
    checkpoint = diagnose_checkpoint(args.checkpoint)
    
    # 2. è¦–è¦ºåŒ–æå¤±æ­·å²
    if 'loss_history' in checkpoint:
        visualize_loss_history(checkpoint['loss_history'], args.output_dir)
    
    # 3. æª¢æŸ¥é…ç½®
    config, issues = check_config(args.config)
    
    # 4. ç”Ÿæˆè¨ºæ–·å ±å‘Š
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    report_path = output_dir / 'diagnosis_report.json'
    report = {
        'checkpoint': args.checkpoint,
        'config': args.config,
        'epoch': checkpoint.get('epoch', None),
        'final_loss': float(checkpoint.get('loss', np.nan)),
        'issues': issues,
        'has_nan_weights': False,  # æœƒåœ¨ä¸Šé¢æ›´æ–°
        'has_nan_loss': False,      # æœƒåœ¨ä¸Šé¢æ›´æ–°
    }
    
    # æª¢æŸ¥ NaN
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
        for name, param in state_dict.items():
            if isinstance(param, torch.Tensor):
                if torch.isnan(param).any():
                    report['has_nan_weights'] = True
                    break
    
    if 'loss_history' in checkpoint and len(checkpoint['loss_history']) > 0:
        for entry in checkpoint['loss_history']:
            if np.isnan(entry.get('total', 0)):
                report['has_nan_loss'] = True
                break
    
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"\nğŸ’¾ è¨ºæ–·å ±å‘Šå·²ä¿å­˜: {report_path}")
    
    # 5. ç¸½çµèˆ‡å»ºè­°
    print("\n" + "=" * 80)
    print("ğŸ“ è¨ºæ–·ç¸½çµèˆ‡å»ºè­°")
    print("=" * 80)
    
    if report['has_nan_loss']:
        print("\nâŒ è¨“ç·´éç¨‹ä¸­å‡ºç¾ NaN æå¤±")
        print("   å»ºè­°:")
        print("   1. é™ä½å­¸ç¿’ç‡ (ç›®å‰å¯èƒ½éé«˜)")
        print("   2. å•Ÿç”¨æ¢¯åº¦è£å‰ª (gradient_clip: 1.0)")
        print("   3. æª¢æŸ¥è³‡æ–™æ­¸ä¸€åŒ–")
        print("   4. æ¸›å° batch size")
    
    if report['has_nan_weights']:
        print("\nâŒ æ¨¡å‹æ¬Šé‡åŒ…å« NaN")
        print("   å»ºè­°:")
        print("   1. é‡æ–°åˆå§‹åŒ–æ¨¡å‹")
        print("   2. æª¢æŸ¥æ¬Šé‡åˆå§‹åŒ–æ–¹æ³•")
        print("   3. ä½¿ç”¨æ›´ç©©å®šçš„æ¿€æ´»å‡½æ•¸ (å¦‚ tanh)")
    
    if issues:
        print(f"\nâš ï¸  é…ç½®å•é¡Œéœ€è¦ä¿®æ­£:")
        for issue in issues:
            print(f"   - {issue}")
    
    print("\n" + "=" * 80)
    print("âœ… è¨ºæ–·å®Œæˆ")
    print("=" * 80)

if __name__ == '__main__':
    main()
