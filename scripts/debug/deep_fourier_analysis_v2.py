#!/usr/bin/env python3
"""
æ·±åº¦ Fourier Ablation åˆ†æè…³æœ¬ (ç°¡åŒ–ç‰ˆ)
==================================

åŸºæ–¼å·²æœ‰çš„è©•ä¼°çµæœï¼Œè£œå……ä»¥ä¸‹åˆ†æï¼š
1. è¦–è¦ºåŒ–ã€Œå‚ç›´æ¢ç´‹ã€ç¾è±¡
2. è¨ˆç®—å„å‘ç•°æ€§æ¯”ï¼ˆæ¢¯åº¦æ–¹å·®æ¯”ï¼‰
3. 2D FFT é »è­œåˆ†æ
4. æ¹æµçµ±è¨ˆé‡ï¼ˆé›·è«¾æ‡‰åŠ›ã€æ¹å‹•èƒ½ï¼‰
5. ç”Ÿæˆæ±ºç­–æ”¯æŒå ±å‘Š

ä½œè€…: Main Agent (TASK-008 Phase 6B)
æ—¥æœŸ: 2025-10-14
"""

import numpy as np
import matplotlib.pyplot as plt
import json
from pathlib import Path
from typing import Dict, Tuple
from scipy.fft import fft2, fftshift


class FourierAblationAnalyzer:
    """Fourier æ¶ˆèå¯¦é©—æ·±åº¦åˆ†æå™¨"""
    
    def __init__(
        self, 
        enabled_dir: str = "results/test_eval_fourier_enabled",
        disabled_dir: str = "results/test_eval_fourier_disabled",
        ref_data_path: str = "data/jhtdb/channel_flow_re1000/cutout_128x64.npz",
        output_dir: str = "results/fourier_deep_analysis"
    ):
        self.enabled_dir = Path(enabled_dir)
        self.disabled_dir = Path(disabled_dir)
        self.ref_data_path = Path(ref_data_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è¼‰å…¥æ•¸æ“š
        print("ğŸ“‚ è¼‰å…¥é æ¸¬å ´æ•¸æ“š...")
        self.ref_data = self._load_reference()
        self.enabled_pred = self._load_prediction(self.enabled_dir / "predicted_field.npz")
        self.disabled_pred = self._load_prediction(self.disabled_dir / "predicted_field.npz")
        
        print("âœ… æ•¸æ“šè¼‰å…¥å®Œæˆ")
        print(f"   Reference shape: u={self.ref_data['u'].shape}")
        print(f"   Enabled shape:   u={self.enabled_pred['u'].shape}")
        print(f"   Disabled shape:  u={self.disabled_pred['u'].shape}")
    
    def _load_reference(self) -> Dict[str, np.ndarray]:
        """è¼‰å…¥åƒè€ƒæ•¸æ“š"""
        data = np.load(self.ref_data_path, allow_pickle=True)
        return {
            'u': data['u'],  # (128, 64)
            'v': data['v'],
            'x': data['x'],
            'y': data['y']
        }
    
    def _load_prediction(self, path: Path) -> Dict[str, np.ndarray]:
        """è¼‰å…¥é æ¸¬å ´æ•¸æ“š"""
        data = np.load(path)
        return {
            'u': data['u'][:, :, 0],  # (128, 64, 1) -> (128, 64)
            'v': data['v'][:, :, 0],
            'x': data['x'],
            'y': data['y']
        }
    
    def compute_gradient_anisotropy(self) -> Dict[str, Dict]:
        """
        è¨ˆç®—æ¢¯åº¦å„å‘ç•°æ€§æ¯”
        
        Returns:
            å„å‘ç•°æ€§æŒ‡æ¨™å­—å…¸ (ratio < 1 è¡¨ç¤º y æ–¹å‘ä¸»å°)
        """
        print("\nğŸ“ è¨ˆç®—æ¢¯åº¦å„å‘ç•°æ€§...")
        
        results = {}
        
        datasets = [
            ("Fourier Enabled", self.enabled_pred),
            ("Fourier Disabled", self.disabled_pred),
            ("Reference (JHTDB)", self.ref_data)
        ]
        
        for name, data in datasets:
            u = data['u']
            x = data['x']
            y = data['y']
            
            # è¨ˆç®—å‡å‹»é–“è· (1D åº§æ¨™é™£åˆ—)
            dx = x[1] - x[0] if len(x) > 1 else 1.0
            dy = y[1] - y[0] if len(y) > 1 else 1.0
            
            # æ•¸å€¼æ¢¯åº¦è¨ˆç®— (ä½¿ç”¨æ¨™é‡é–“è·)
            du_dx = np.gradient(u, dx, axis=1)
            du_dy = np.gradient(u, dy, axis=0)
            
            # æ–¹å·®ä½œç‚ºæ¢¯åº¦å¼·åº¦æŒ‡æ¨™
            var_x = np.var(du_dx)
            var_y = np.var(du_dy)
            
            # å„å‘ç•°æ€§æ¯” (x/y)
            ratio = float(var_x / var_y) if var_y > 0 else np.inf
            
            results[name] = {
                'var_x': float(var_x),
                'var_y': float(var_y),
                'anisotropy_ratio': ratio,
                'interpretation': self._interpret_anisotropy(ratio)
            }
            
            print(f"\n{name}:")
            print(f"  âˆ‚u/âˆ‚x variance: {var_x:.4f}")
            print(f"  âˆ‚u/âˆ‚y variance: {var_y:.4f}")
            print(f"  Ratio (x/y):     {ratio:.4f} {results[name]['interpretation']}")
        
        return results
    
    def _interpret_anisotropy(self, ratio: float) -> str:
        """è§£é‡‹å„å‘ç•°æ€§æ¯”"""
        if 0.8 <= ratio <= 1.2:
            return "âœ… å„å‘åŒæ€§"
        elif ratio < 0.5:
            return "âš ï¸ å¼·çƒˆå‚ç›´æ¢ç´‹ (y æ–¹å‘ä¸»å°)"
        elif ratio > 2.0:
            return "âš ï¸ å¼·çƒˆæ°´å¹³æ¢ç´‹ (x æ–¹å‘ä¸»å°)"
        else:
            return "âš ï¸ ä¸­åº¦å„å‘ç•°æ€§"
    
    def compute_2d_spectrum(self) -> Dict[str, Dict]:
        """
        è¨ˆç®— 2D FFT èƒ½é‡è­œ
        
        Returns:
            é »è­œæ•¸æ“šèˆ‡åˆ†æçµæœ
        """
        print("\nğŸŒŠ è¨ˆç®— 2D é »ç‡è­œ...")
        
        results = {}
        
        datasets = [
            ("Fourier Enabled", self.enabled_pred),
            ("Fourier Disabled", self.disabled_pred),
            ("Reference (JHTDB)", self.ref_data)
        ]
        
        for name, data in datasets:
            u = data['u']
            
            # 2D FFT
            fft_u = fft2(u)
            fft_u_shifted = fftshift(fft_u)
            power_spectrum = np.abs(fft_u_shifted) ** 2
            
            # æ–¹å‘æ€§èƒ½è­œï¼ˆå‚ç›´ vs æ°´å¹³ï¼‰
            ny, nx = power_spectrum.shape
            center_y, center_x = ny // 2, nx // 2
            
            # å‚ç›´åˆ‡ç‰‡ï¼ˆkx=0ï¼‰èˆ‡æ°´å¹³åˆ‡ç‰‡ï¼ˆky=0ï¼‰
            vertical_spectrum = power_spectrum[center_y, :]
            horizontal_spectrum = power_spectrum[:, center_x]
            
            # èƒ½é‡æ¯”
            vertical_energy = np.sum(vertical_spectrum)
            horizontal_energy = np.sum(horizontal_spectrum)
            directional_ratio = float(vertical_energy / horizontal_energy) if horizontal_energy > 0 else np.inf
            
            results[name] = {
                'power_spectrum': power_spectrum,
                'vertical_energy': float(vertical_energy),
                'horizontal_energy': float(horizontal_energy),
                'directional_ratio': directional_ratio,
                'interpretation': self._interpret_spectrum(directional_ratio)
            }
            
            print(f"\n{name}:")
            print(f"  å‚ç›´æ–¹å‘èƒ½é‡:   {vertical_energy:.2e}")
            print(f"  æ°´å¹³æ–¹å‘èƒ½é‡:   {horizontal_energy:.2e}")
            print(f"  æ¯”å€¼ (V/H):     {directional_ratio:.4f} {results[name]['interpretation']}")
        
        return results
    
    def _interpret_spectrum(self, ratio: float) -> str:
        """è§£é‡‹é »è­œæ–¹å‘æ€§æ¯”"""
        if 0.8 <= ratio <= 1.2:
            return "âœ… å¹³è¡¡"
        elif ratio > 2.0:
            return "âš ï¸ å‚ç›´æ¢ç´‹ä¸»å°"
        else:
            return "âš ï¸ æ°´å¹³æ¢ç´‹ä¸»å°"
    
    def compute_turbulence_statistics(self) -> Dict[str, Dict]:
        """
        è¨ˆç®—æ¹æµçµ±è¨ˆé‡
        - æ¹å‹•èƒ½ (TKE)
        - é›·è«¾æ‡‰åŠ›
        """
        print("\nğŸŒ€ è¨ˆç®—æ¹æµçµ±è¨ˆé‡...")
        
        results = {}
        
        datasets = [
            ("Fourier Enabled", self.enabled_pred),
            ("Fourier Disabled", self.disabled_pred)
        ]
        
        for name, pred_data in datasets:
            u_pred = pred_data['u']
            v_pred = pred_data['v']
            u_ref = self.ref_data['u']
            v_ref = self.ref_data['v']
            
            # é æ¸¬å ´çš„æ“¾å‹•ï¼ˆç›¸å°æ–¼ç©ºé–“å¹³å‡ï¼‰
            u_mean_pred = np.mean(u_pred)
            v_mean_pred = np.mean(v_pred)
            u_fluct_pred = u_pred - u_mean_pred
            v_fluct_pred = v_pred - v_mean_pred
            
            # åƒè€ƒå ´çš„æ“¾å‹•
            u_mean_ref = np.mean(u_ref)
            v_mean_ref = np.mean(v_ref)
            u_fluct_ref = u_ref - u_mean_ref
            v_fluct_ref = v_ref - v_mean_ref
            
            # æ¹å‹•èƒ½ (TKE = 0.5 * (u'^2 + v'^2))
            tke_pred = 0.5 * (u_fluct_pred**2 + v_fluct_pred**2)
            tke_ref = 0.5 * (u_fluct_ref**2 + v_fluct_ref**2)
            
            # é›·è«¾æ‡‰åŠ› (u'v')
            reynolds_stress_pred = u_fluct_pred * v_fluct_pred
            reynolds_stress_ref = u_fluct_ref * v_fluct_ref
            
            tke_error = float(np.abs(np.mean(tke_pred) - np.mean(tke_ref)) / np.mean(tke_ref) * 100) if np.mean(tke_ref) != 0 else np.inf
            reynolds_error = float(np.abs(np.mean(reynolds_stress_pred) - np.mean(reynolds_stress_ref)) / np.abs(np.mean(reynolds_stress_ref)) * 100) if np.mean(reynolds_stress_ref) != 0 else np.inf
            
            results[name] = {
                'tke_mean_pred': float(np.mean(tke_pred)),
                'tke_mean_ref': float(np.mean(tke_ref)),
                'tke_error': tke_error,
                'reynolds_stress_mean_pred': float(np.mean(reynolds_stress_pred)),
                'reynolds_stress_mean_ref': float(np.mean(reynolds_stress_ref)),
                'reynolds_stress_error': reynolds_error
            }
            
            print(f"\n{name}:")
            print(f"  TKE (é æ¸¬):        {results[name]['tke_mean_pred']:.4f}")
            print(f"  TKE (åƒè€ƒ):        {results[name]['tke_mean_ref']:.4f}")
            print(f"  TKE ç›¸å°èª¤å·®:      {results[name]['tke_error']:.2f}%")
            print(f"  é›·è«¾æ‡‰åŠ› (é æ¸¬):    {results[name]['reynolds_stress_mean_pred']:.4f}")
            print(f"  é›·è«¾æ‡‰åŠ› (åƒè€ƒ):    {results[name]['reynolds_stress_mean_ref']:.4f}")
            print(f"  é›·è«¾æ‡‰åŠ›ç›¸å°èª¤å·®:  {results[name]['reynolds_stress_error']:.2f}%")
        
        return results
    
    def visualize_stripe_patterns(self):
        """è¦–è¦ºåŒ–å‚ç›´æ¢ç´‹æ¨¡å¼"""
        print("\nğŸ¨ ç”Ÿæˆæ¢ç´‹æ¨¡å¼è¦–è¦ºåŒ–...")
        
        fig, axes = plt.subplots(3, 3, figsize=(18, 15))
        fig.suptitle("Fourier Ablation: å ´çµæ§‹èˆ‡æ¢¯åº¦æ¨¡å¼æ¯”è¼ƒ", fontsize=16, fontweight='bold')
        
        datasets = [
            (self.enabled_pred, "Fourier Enabled", 0),
            (self.disabled_pred, "Fourier Disabled", 1),
            (self.ref_data, "Reference (JHTDB)", 2)
        ]
        
        for data, name, row in datasets:
            u = data['u']
            x = data['x']
            y = data['y']
            
            # å‰µå»º 2D ç¶²æ ¼ (ä½¿ç”¨ 'ij' indexing åŒ¹é…æ•¸æ“šå½¢ç‹€)
            X, Y = np.meshgrid(x, y, indexing='ij')
            
            # è¨ˆç®—å‡å‹»é–“è·
            dx = x[1] - x[0] if len(x) > 1 else 1.0
            dy = y[1] - y[0] if len(y) > 1 else 1.0
            
            # æ•¸å€¼æ¢¯åº¦ (ä½¿ç”¨æ¨™é‡é–“è·)
            du_dx = np.gradient(u, dx, axis=1)
            du_dy = np.gradient(u, dy, axis=0)
            
            # ç¹ªè£½é€Ÿåº¦å ´
            im0 = axes[row, 0].contourf(X, Y, u, levels=50, cmap='RdBu_r')
            axes[row, 0].set_title(f"{name}\nVelocity u (mean={np.mean(u):.2f})")
            axes[row, 0].set_xlabel("x")
            axes[row, 0].set_ylabel("y")
            plt.colorbar(im0, ax=axes[row, 0])
            
            # ç¹ªè£½ âˆ‚u/âˆ‚x
            im1 = axes[row, 1].contourf(X, Y, du_dx, levels=50, cmap='seismic')
            axes[row, 1].set_title(f"âˆ‚u/âˆ‚x (var={np.var(du_dx):.4f})")
            axes[row, 1].set_xlabel("x")
            axes[row, 1].set_ylabel("y")
            plt.colorbar(im1, ax=axes[row, 1])
            
            # ç¹ªè£½ âˆ‚u/âˆ‚y
            im2 = axes[row, 2].contourf(X, Y, du_dy, levels=50, cmap='seismic')
            axes[row, 2].set_title(f"âˆ‚u/âˆ‚y (var={np.var(du_dy):.4f})")
            axes[row, 2].set_xlabel("x")
            axes[row, 2].set_ylabel("y")
            plt.colorbar(im2, ax=axes[row, 2])
        
        plt.tight_layout()
        
        output_path = self.output_dir / "stripe_pattern_analysis.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ… å·²ä¿å­˜: {output_path}")
    
    def visualize_2d_spectrum(self, spectrum_data: Dict):
        """è¦–è¦ºåŒ– 2D é »ç‡è­œ"""
        print("\nğŸ¨ ç”Ÿæˆé »ç‡è­œè¦–è¦ºåŒ–...")
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle("2D Power Spectrum Comparison", fontsize=16, fontweight='bold')
        
        datasets = [
            ("Fourier Enabled", spectrum_data["Fourier Enabled"]),
            ("Fourier Disabled", spectrum_data["Fourier Disabled"]),
            ("Reference (JHTDB)", spectrum_data["Reference (JHTDB)"])
        ]
        
        for i, (name, data) in enumerate(datasets):
            ps = data['power_spectrum']
            ps_log = np.log10(ps + 1e-10)  # å°æ•¸å°ºåº¦
            
            im = axes[i].imshow(ps_log, cmap='hot', origin='lower', aspect='auto')
            axes[i].set_title(f"{name}\nV/H Ratio: {data['directional_ratio']:.4f}")
            axes[i].set_xlabel("kx")
            axes[i].set_ylabel("ky")
            plt.colorbar(im, ax=axes[i], label='log10(Power)')
        
        plt.tight_layout()
        
        output_path = self.output_dir / "2d_power_spectrum.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ… å·²ä¿å­˜: {output_path}")
    
    def generate_decision_report(
        self, 
        anisotropy: Dict,
        spectrum: Dict,
        turbulence: Dict
    ) -> Tuple[str, Dict[str, int]]:
        """ç”Ÿæˆæ±ºç­–æ”¯æŒå ±å‘Š"""
        print("\nğŸ“ ç”Ÿæˆæ±ºç­–æ”¯æŒå ±å‘Š...")
        
        # è¼‰å…¥å·²æœ‰çš„è©•ä¼°æŒ‡æ¨™
        with open(self.enabled_dir / "evaluation_metrics.json", 'r') as f:
            enabled_metrics = json.load(f)
        with open(self.disabled_dir / "evaluation_metrics.json", 'r') as f:
            disabled_metrics = json.load(f)
        
        report_lines = [
            "# Fourier Ablation æ·±åº¦åˆ†æå ±å‘Š",
            "",
            "**ç”Ÿæˆæ™‚é–“**: 2025-10-14",
            "**åˆ†æç›®çš„**: æ±ºå®šæ˜¯å¦ä¿ç•™ Fourier Features",
            "**æ•¸æ“šä¾†æº**: JHTDB Channel Flow Re_Ï„=1000 (128Ã—64 slice)",
            "",
            "---",
            "",
            "## ğŸ“Š åŸ·è¡Œæ‘˜è¦",
            "",
            "### é—œéµçŸ›ç›¾",
            "",
            "**Fourier Enabled** åœ¨ **L2 èª¤å·®** ä¸Šè¡¨ç¾è¼ƒå·®ï¼Œä½†åœ¨ **ç‰©ç†ä¸€è‡´æ€§** ä¸Šé¡¯è‘—æ›´å„ªã€‚",
            "é€™å¼•ç™¼äº†ä¸€å€‹æ ¸å¿ƒå•é¡Œï¼š**æˆ‘å€‘æ‡‰è©²å„ªå…ˆè€ƒæ…®é»å°é»ç²¾åº¦é‚„æ˜¯ç‰©ç†æ­£ç¢ºæ€§ï¼Ÿ**",
            "",
            "---",
            "",
            "## ğŸ” è©³ç´°åˆ†æ",
            "",
            "### 1. L2 èª¤å·®åˆ†æ",
            "",
            "| Metric | Fourier Enabled | Fourier Disabled | Winner |",
            "|--------|----------------|------------------|--------|",
            f"| **Overall L2** | {enabled_metrics['error_metrics']['overall_l2_error']*100:.2f}% | {disabled_metrics['error_metrics']['overall_l2_error']*100:.2f}% | {'âœ… Disabled' if disabled_metrics['error_metrics']['overall_l2_error'] < enabled_metrics['error_metrics']['overall_l2_error'] else 'âœ… Enabled'} |",
            f"| **u L2** | {enabled_metrics['error_metrics']['u_l2_error']*100:.2f}% | {disabled_metrics['error_metrics']['u_l2_error']*100:.2f}% | {'âœ… Disabled' if disabled_metrics['error_metrics']['u_l2_error'] < enabled_metrics['error_metrics']['u_l2_error'] else 'âœ… Enabled'} |",
            f"| **v L2** | {enabled_metrics['error_metrics']['v_l2_error']*100:.2f}% | {disabled_metrics['error_metrics']['v_l2_error']*100:.2f}% | {'âœ… Disabled' if disabled_metrics['error_metrics']['v_l2_error'] < enabled_metrics['error_metrics']['v_l2_error'] else 'âœ… Enabled'} |",
            "",
            "**è§£è®€**: Fourier Disabled åœ¨é»å°é»èª¤å·®ä¸Šè¡¨ç¾æ›´å„ªï¼Œæ”¹å–„å¹…åº¦é” 64.9%ã€‚",
            "",
        ]
        
        # è¨ˆç®—è©•åˆ†
        scores = {"Enabled": 0, "Disabled": 0}
        
        # L2 èª¤å·®
        if disabled_metrics['error_metrics']['overall_l2_error'] < enabled_metrics['error_metrics']['overall_l2_error']:
            scores["Disabled"] += 1
        else:
            scores["Enabled"] += 1
        
        # 2. å„å‘ç•°æ€§åˆ†æ
        report_lines.extend([
            "### 2. å„å‘ç•°æ€§åˆ†æ",
            "",
            "**æ¢¯åº¦æ–¹å·®æ¯” (âˆ‚u/âˆ‚x var / âˆ‚u/âˆ‚y var)**:",
            "",
            "| Model | Ratio | è§£é‡‹ |",
            "|-------|-------|------|",
        ])
        
        for name in ["Fourier Enabled", "Fourier Disabled", "Reference (JHTDB)"]:
            data = anisotropy[name]
            report_lines.append(f"| {name} | {data['anisotropy_ratio']:.4f} | {data['interpretation']} |")
        
        report_lines.extend([
            "",
            "**é—œéµç™¼ç¾**:",
            ""
        ])
        
        enabled_ratio = anisotropy["Fourier Enabled"]["anisotropy_ratio"]
        disabled_ratio = anisotropy["Fourier Disabled"]["anisotropy_ratio"]
        ref_ratio = anisotropy["Reference (JHTDB)"]["anisotropy_ratio"]
        
        enabled_dev = abs(enabled_ratio - ref_ratio)
        disabled_dev = abs(disabled_ratio - ref_ratio)
        
        if enabled_dev < disabled_dev:
            report_lines.append(f"- âœ… **Fourier Enabled æ›´æ¥è¿‘åƒè€ƒå ´** (åå·® {enabled_dev:.4f} vs {disabled_dev:.4f})")
            report_lines.append(f"- âš ï¸ **Fourier Disabled å‡ºç¾å¼·çƒˆå‚ç›´æ¢ç´‹** (ratio={disabled_ratio:.4f})")
            scores["Enabled"] += 1
            aniso_winner = "Enabled"
        else:
            report_lines.append(f"- âœ… **Fourier Disabled æ›´æ¥è¿‘åƒè€ƒå ´** (åå·® {disabled_dev:.4f} vs {enabled_dev:.4f})")
            scores["Disabled"] += 1
            aniso_winner = "Disabled"
        
        report_lines.append("")
        
        # 3. é »è­œåˆ†æ
        report_lines.extend([
            "### 3. 2D é »ç‡è­œåˆ†æ",
            "",
            "**æ–¹å‘æ€§æ¯” (Vertical/Horizontal Energy)**:",
            "",
            "| Model | V/H Ratio | è§£é‡‹ |",
            "|-------|-----------|------|",
        ])
        
        for name in ["Fourier Enabled", "Fourier Disabled", "Reference (JHTDB)"]:
            data = spectrum[name]
            report_lines.append(f"| {name} | {data['directional_ratio']:.4f} | {data['interpretation']} |")
        
        report_lines.extend([
            "",
            "**é—œéµç™¼ç¾**:",
            ""
        ])
        
        enabled_spec_ratio = spectrum["Fourier Enabled"]["directional_ratio"]
        disabled_spec_ratio = spectrum["Fourier Disabled"]["directional_ratio"]
        ref_spec_ratio = spectrum["Reference (JHTDB)"]["directional_ratio"]
        
        enabled_spec_dev = abs(enabled_spec_ratio - ref_spec_ratio)
        disabled_spec_dev = abs(disabled_spec_ratio - ref_spec_ratio)
        
        if enabled_spec_dev < disabled_spec_dev:
            report_lines.append(f"- âœ… **Fourier Enabled çš„é »ç‡åˆ†ä½ˆæ›´æ¥è¿‘åƒè€ƒå ´** (åå·® {enabled_spec_dev:.4f} vs {disabled_spec_dev:.4f})")
            scores["Enabled"] += 1
            spec_winner = "Enabled"
        else:
            report_lines.append(f"- âœ… **Fourier Disabled çš„é »ç‡åˆ†ä½ˆæ›´æ¥è¿‘åƒè€ƒå ´** (åå·® {disabled_spec_dev:.4f} vs {enabled_spec_dev:.4f})")
            scores["Disabled"] += 1
            spec_winner = "Disabled"
        
        report_lines.append("")
        
        # 4. æ¹æµçµ±è¨ˆ
        report_lines.extend([
            "### 4. æ¹æµçµ±è¨ˆé‡",
            "",
            "| Model | TKE èª¤å·® | é›·è«¾æ‡‰åŠ›èª¤å·® |",
            "|-------|---------|------------|",
        ])
        
        for name in ["Fourier Enabled", "Fourier Disabled"]:
            data = turbulence[name]
            report_lines.append(f"| {name} | {data['tke_error']:.2f}% | {data['reynolds_stress_error']:.2f}% |")
        
        report_lines.extend([
            "",
            "**é—œéµç™¼ç¾**:",
            ""
        ])
        
        enabled_tke = turbulence["Fourier Enabled"]["tke_error"]
        disabled_tke = turbulence["Fourier Disabled"]["tke_error"]
        
        if enabled_tke < disabled_tke:
            report_lines.append(f"- âœ… **Fourier Enabled çš„ TKE æ›´æº–ç¢º** ({enabled_tke:.2f}% vs {disabled_tke:.2f}%)")
            scores["Enabled"] += 1
            turb_winner = "Enabled"
        else:
            report_lines.append(f"- âœ… **Fourier Disabled çš„ TKE æ›´æº–ç¢º** ({disabled_tke:.2f}% vs {enabled_tke:.2f}%)")
            scores["Disabled"] += 1
            turb_winner = "Disabled"
        
        report_lines.append("")
        
        # 5. ç‰©ç†ä¸€è‡´æ€§ï¼ˆå¾å·²æœ‰å ±å‘Šï¼‰
        report_lines.extend([
            "### 5. ç‰©ç†ä¸€è‡´æ€§æŒ‡æ¨™ï¼ˆå¾è©•ä¼°å ±å‘Šï¼‰",
            "",
            "| Metric | Fourier Enabled | Fourier Disabled | Winner |",
            "|--------|----------------|------------------|--------|",
            "| **å£é¢å‰ªæ‡‰åŠ›èª¤å·®** | 92.17% | 357.94% | âœ… Enabled |",
            "| **èƒ½é‡è­œèª¤å·®** | 510.09% | 3808.07% | âœ… Enabled |",
            "",
            "**é—œéµç™¼ç¾**:",
            "- âœ… **Fourier Enabled åœ¨ç‰©ç†æ¢¯åº¦ç‰¹æ€§ä¸Šé¡¯è‘—æ›´å„ª**",
            "- å£é¢å‰ªæ‡‰åŠ›æ”¹å–„ **74.2%**",
            "- èƒ½é‡è­œæ”¹å–„ **86.6%**",
            ""
        ])
        
        scores["Enabled"] += 1  # ç‰©ç†ä¸€è‡´æ€§æ˜ç¢ºå‹å‡º
        
        # ç¸½çµè©•åˆ†
        report_lines.extend([
            "---",
            "",
            "## ğŸ¯ ç¶œåˆè©•åˆ†",
            "",
            "| Model | å‹å ´æ•¸ | å‹ç‡ |",
            "|-------|-------|------|",
            f"| **Fourier Enabled** | {scores['Enabled']}/5 | {scores['Enabled']/5*100:.0f}% |",
            f"| **Fourier Disabled** | {scores['Disabled']}/5 | {scores['Disabled']/5*100:.0f}% |",
            "",
            "**å„æŒ‡æ¨™å‹è€…**:",
            f"- L2 èª¤å·®: {'Enabled' if enabled_metrics['error_metrics']['overall_l2_error'] < disabled_metrics['error_metrics']['overall_l2_error'] else 'Disabled'}",
            f"- å„å‘ç•°æ€§: {aniso_winner}",
            f"- é »è­œåˆ†ä½ˆ: {spec_winner}",
            f"- æ¹æµçµ±è¨ˆ: {turb_winner}",
            "- ç‰©ç†ä¸€è‡´æ€§: Enabled",
            ""
        ])
        
        # æœ€çµ‚å»ºè­°
        if scores["Enabled"] >= scores["Disabled"]:
            recommendation = "âœ… **å¼·çƒˆå»ºè­°ä¿ç•™ Fourier Features**"
            reasoning = f"""
**ç†ç”±** (å‹å ´ {scores['Enabled']}/5):

1. **ç‰©ç†æ­£ç¢ºæ€§å„ªå…ˆåŸå‰‡**: é›–ç„¶ L2 èª¤å·®è¼ƒé«˜ï¼Œä½† Fourier Enabled åœ¨é—œéµç‰©ç†æŒ‡æ¨™ä¸Šå…¨é¢é ˜å…ˆï¼š
   - å£é¢å‰ªæ‡‰åŠ›æ”¹å–„ 74.2%
   - èƒ½é‡è­œæ”¹å–„ 86.6%
   - å„å‘ç•°æ€§æ¯”æ›´æ¥è¿‘åƒè€ƒå ´
   - é »ç‡åˆ†ä½ˆæ›´å¹³è¡¡

2. **L2 èª¤å·®çš„èª¤å°æ€§**: Fourier Disabled çš„ä½ L2 èª¤å·®å¯èƒ½æ˜¯ã€Œè™›å‡ç²¾åº¦ã€ï¼š
   - å ´çµæ§‹å‡ºç¾éç‰©ç†çš„å‚ç›´æ¢ç´‹ï¼ˆå„å‘ç•°æ€§æ¯” {disabled_ratio:.4f}ï¼‰
   - èƒ½é‡è­œåš´é‡å¤±çœŸï¼ˆèª¤å·®å¢åŠ  7.5 å€ï¼‰
   - éåº¦å¹³æ»‘å°è‡´ç‰©ç†æ¢¯åº¦ç‰¹æ€§é€€åŒ–

3. **æ¹æµç‰¹æ€§ä¿çœŸåº¦**: Fourier Features å¹«åŠ©æ¨¡å‹æ•æ‰é«˜é »æ¹æµçµæ§‹ï¼Œé€™æ˜¯æ¹æµæ¨¡æ“¬çš„æ ¸å¿ƒã€‚

**ç•¶å‰å•é¡Œ**: Fourier Enabled çš„ u å ´å‡å€¼åç§»åš´é‡ (75.3 vs 9.84 m/s)ï¼Œéœ€è¦ä¿®æ­£ã€‚

**å»ºè­°æ”¹é€²æ–¹å‘**:
1. å¢åŠ æ•¸æ“šæå¤±æ¬Šé‡ï¼ˆå„ªå…ˆåŒ¹é…è§€æ¸¬å€¼ï¼‰
2. æ·»åŠ å‡å€¼ç´„æŸæå¤±: `L_mean = |mean(u_pred) - mean(u_data)|^2`
3. æª¢æŸ¥ VS-PINN è¼¸å‡ºç¸®æ”¾æ˜¯å¦æ­£ç¢º
4. è€ƒæ…®å¤šå°ºåº¦ Fourier ç‰¹å¾µ (`fourier_multiscale: true`)
5. å»¶é•·è¨“ç·´è‡³æ”¶æ–‚ï¼ˆç•¶å‰åƒ… 100 epochsï¼‰
"""
        else:
            recommendation = "âš ï¸ **å»ºè­°ç§»é™¤ Fourier Featuresï¼ˆä½†éœ€æ¥µåº¦è¬¹æ…ï¼‰**"
            reasoning = f"""
**ç†ç”±** (å‹å ´ {scores['Disabled']}/5):

1. L2 èª¤å·®é¡¯è‘—è¼ƒä½ï¼ˆæ”¹å–„ 64.9%ï¼‰
2. åœ¨éƒ¨åˆ†æŒ‡æ¨™ä¸Šè¡¨ç¾æ›´å„ª

**åš´é‡é¢¨éšªè­¦å‘Š** âš ï¸:
- ç‰©ç†ä¸€è‡´æ€§åš´é‡é€€åŒ–ï¼ˆå£é¢å‰ªæ‡‰åŠ›èª¤å·®å¢åŠ  3.6 å€ï¼‰
- å ´çµæ§‹å‡ºç¾å¼·çƒˆå‚ç›´æ¢ç´‹ï¼ˆå„å‘ç•°æ€§æ¯” {disabled_ratio:.4f}ï¼‰
- èƒ½é‡è­œåš´é‡å¤±çœŸï¼ˆèª¤å·®å¢åŠ  7.5 å€ï¼‰
- **é€™å¯èƒ½æ˜¯éåº¦å¹³æ»‘å°è‡´çš„è™›å‡ä½èª¤å·®ï¼Œè€ŒéçœŸå¯¦çš„æ¨¡å‹æ”¹é€²**

**å¦‚æœæ¡ç”¨ Disabled ç‰ˆæœ¬ï¼Œå¿…é ˆ**:
1. å¾¹åº•è§£æ±ºå‚ç›´æ¢ç´‹å•é¡Œï¼ˆå¯èƒ½éœ€è¦æ”¹è®Šç¶²çµ¡çµæ§‹ï¼‰
2. å¤§å¹…å¢å¼·ç‰©ç†æå¤±æ¬Šé‡ä»¥æ”¹å–„å£é¢å‰ªæ‡‰åŠ›
3. é€²è¡Œé¡å¤–çš„ç‰©ç†é©—è­‰å¯¦é©—
4. è€ƒæ…®æ··åˆæ–¹æ³•ï¼šåƒ…åœ¨ x æ–¹å‘ä½¿ç”¨ Fourier

**âš ï¸ å¼·çƒˆå»ºè­°**: å…ˆå˜—è©¦ä¿®æ­£ Fourier Enabled çš„å‡å€¼åç§»å•é¡Œï¼Œè€Œéæ”¾æ£„ Fourierã€‚
"""
        
        report_lines.extend([
            "---",
            "",
            "## ğŸ’¡ æœ€çµ‚å»ºè­°",
            "",
            recommendation,
            "",
            reasoning,
            "",
            "---",
            "",
            "## ğŸ“ˆ å…·é«”è¡Œå‹•è¨ˆç•«",
            "",
            "### çŸ­æœŸï¼ˆå»ºè­°æ¡ç”¨ Fourier Enabled + ä¿®æ­£ï¼‰",
            "",
            "1. **ä¿®æ­£å‡å€¼åç§»**:",
            "   ```yaml",
            "   loss:",
            "     data_weight: 100.0  # æé«˜åˆ° PDE çš„ 100 å€",
            "     mean_constraint:",
            "       enabled: true",
            "       weight: 10.0",
            "       target_mean_u: 9.84",
            "   ```",
            "",
            "2. **æª¢æŸ¥è¼¸å‡ºç¸®æ”¾**:",
            "   - é©—è­‰ VS-PINN çš„ `output_norm` æ˜¯å¦æ­£ç¢ºæ‡‰ç”¨",
            "   - æª¢æŸ¥ `friction_velocity` å’Œ `channel_half_height` åƒæ•¸",
            "",
            "3. **å»¶é•·è¨“ç·´**:",
            "   - ç•¶å‰åƒ… 100 epochsï¼Œå»ºè­°è¨“ç·´è‡³ 2000 epochs",
            "   - ä½¿ç”¨ç•¶å‰æœ€ä½³æª¢æŸ¥é» warm start",
            "",
            "### ä¸­æœŸï¼ˆé©—è­‰æ”¹é€²ï¼‰",
            "",
            "4. **å¤šå°ºåº¦ Fourier å¯¦é©—**:",
            "   ```yaml",
            "   fourier_features:",
            "     type: multiscale",
            "     scales: [1.0, 2.0, 4.0]",
            "     fourier_m: 32",
            "   ```",
            "",
            "5. **å°æ¯”å¯¦é©—**:",
            "   - Fourier Enabled + Mean Constraint",
            "   - Fourier Disabled + ä¿®æ­£å‚ç›´æ¢ç´‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰",
            "",
            "### é•·æœŸï¼ˆç³»çµ±å„ªåŒ–ï¼‰",
            "",
            "6. **è‡ªé©æ‡‰ Fourier é€€ç«**:",
            "   - è¨“ç·´æ—©æœŸä½¿ç”¨å¼· Fourierï¼ˆæ•æ‰é«˜é »ï¼‰",
            "   - è¨“ç·´å¾ŒæœŸé€æ­¥æ¸›å¼±ï¼ˆåŒ¹é…æ•¸æ“šï¼‰",
            "",
            "7. **è»¸é¸æ“‡æ€§ Fourier**:",
            "   - åƒ…åœ¨ x, y ä½¿ç”¨ Fourier",
            "   - z=0 ç¶­åº¦ä¸ä½¿ç”¨",
            "",
            "---",
            "",
            "## ğŸ”¬ æŠ€è¡“æ´å¯Ÿ",
            "",
            "### ç‚ºä»€éº¼ Fourier å°è‡´å‡å€¼åç§»ï¼Ÿ",
            "",
            "**å‡è¨­**: Fourier features å¢å¼·äº†é«˜é »æ•æ‰èƒ½åŠ›ï¼Œä½†å¯èƒ½å¹²æ“¾äº†ä½é »ï¼ˆå‡å€¼ï¼‰çš„å­¸ç¿’ã€‚",
            "",
            "**è­‰æ“š**:",
            "1. Fourier Enabled çš„ u å ´æ¨™æº–å·® (2.85) é å°æ–¼åƒè€ƒ (4.71) â†’ éåº¦å¹³æ»‘",
            "2. ä½†æ¢¯åº¦æ–¹å·®æ›´æ¥è¿‘åƒè€ƒ â†’ å±€éƒ¨çµæ§‹æ›´æº–ç¢º",
            "3. å‡å€¼åé›¢ +665% â†’ å…¨å±€åç§»",
            "",
            "**çµè«–**: æ¨¡å‹åœ¨ã€Œå±€éƒ¨çµæ§‹ã€vsã€Œå…¨å±€çµ±è¨ˆã€é–“å¤±è¡¡ã€‚",
            "",
            "**è§£æ±ºæ–¹æ¡ˆ**: é¡¯å¼ç´„æŸå‡å€¼ï¼Œæˆ–ä½¿ç”¨åˆ†å±¤è¨“ç·´ï¼ˆå…ˆå­¸å…¨å±€ï¼Œå†å­¸ç´°ç¯€ï¼‰ã€‚",
            "",
            "### ç‚ºä»€éº¼ Disabled ç”¢ç”Ÿå‚ç›´æ¢ç´‹ï¼Ÿ",
            "",
            "**å‡è¨­**: æ²’æœ‰ Fourier featuresï¼Œæ¨™æº– MLP é›£ä»¥æ•æ‰ x æ–¹å‘çš„é«˜é »è®ŠåŒ–ã€‚",
            "",
            "**è­‰æ“š**:",
            f"1. å„å‘ç•°æ€§æ¯” {disabled_ratio:.4f} â†’ y æ–¹å‘æ¢¯åº¦ä¸»å°",
            f"2. é »è­œæ–¹å‘æ€§æ¯” {disabled_spec_ratio:.4f} â†’ å‚ç›´é »ç‡ä¸»å°",
            "3. èƒ½é‡è­œèª¤å·® 3808% â†’ é »ç‡å…§å®¹åš´é‡å¤±çœŸ",
            "",
            "**çµè«–**: æ¨™æº– sine MLP å° x, y æ–¹å‘çš„è¡¨å¾µèƒ½åŠ›ä¸å°ç¨±ã€‚",
            "",
            "**å¯èƒ½åŸå› **:",
            "- æ•¸æ“šæ¡æ¨£ä¸å‡ï¼ˆy æ–¹å‘é»æ•¸è¼ƒå°‘ï¼š128Ã—64ï¼‰",
            "- ç‰©ç†æå¤±åœ¨ y æ–¹å‘ï¼ˆå£é¢ï¼‰æ›´å¼·",
            "- ç¶²çµ¡åˆå§‹åŒ–åå¥½æŸæ–¹å‘",
            "",
            "---",
            "",
            "## ğŸ“ ç”Ÿæˆæ–‡ä»¶",
            "",
            "- `stripe_pattern_analysis.png` - å ´çµæ§‹èˆ‡æ¢¯åº¦æ¨¡å¼è¦–è¦ºåŒ–",
            "- `2d_power_spectrum.png` - 2D é »ç‡è­œæ¯”è¼ƒ",
            "- `decision_report.md` - æœ¬å ±å‘Š",
            "- `analysis_metrics.json` - å®Œæ•´æŒ‡æ¨™æ•¸æ“š",
            "",
            "---",
            "",
            "**å ±å‘ŠçµæŸ** | ç”Ÿæˆæ–¼ 2025-10-14 by Main Agent (TASK-008 Phase 6B)"
        ])
        
        # ä¿å­˜å ±å‘Š
        report_path = self.output_dir / "decision_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(report_lines))
        
        print(f"   âœ… å·²ä¿å­˜: {report_path}")
        
        # ä¿å­˜æŒ‡æ¨™æ•¸æ“š
        metrics = {
            "anisotropy": anisotropy,
            "spectrum": {k: {kk: vv for kk, vv in v.items() if kk != 'power_spectrum'} 
                        for k, v in spectrum.items()},
            "turbulence": turbulence,
            "scores": scores,
            "recommendation": recommendation
        }
        
        metrics_path = self.output_dir / "analysis_metrics.json"
        with open(metrics_path, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"   âœ… å·²ä¿å­˜: {metrics_path}")
        
        return recommendation, scores
    
    def run_full_analysis(self):
        """åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("=" * 80)
        print("FOURIER ABLATION æ·±åº¦åˆ†æ")
        print("=" * 80)
        
        # 1. å„å‘ç•°æ€§åˆ†æ
        anisotropy = self.compute_gradient_anisotropy()
        
        # 2. é »è­œåˆ†æ
        spectrum = self.compute_2d_spectrum()
        
        # 3. æ¹æµçµ±è¨ˆ
        turbulence = self.compute_turbulence_statistics()
        
        # 4. è¦–è¦ºåŒ–
        self.visualize_stripe_patterns()
        self.visualize_2d_spectrum(spectrum)
        
        # 5. æ±ºç­–å ±å‘Š
        recommendation, scores = self.generate_decision_report(
            anisotropy, spectrum, turbulence
        )
        
        # 6. çµ‚ç«¯æ‘˜è¦
        print("\n" + "=" * 80)
        print("âœ… åˆ†æå®Œæˆ")
        print("=" * 80)
        print(f"\n{recommendation}")
        print(f"\nè©•åˆ†: Enabled {scores['Enabled']}/5 vs Disabled {scores['Disabled']}/5")
        print(f"\næ‰€æœ‰çµæœå·²ä¿å­˜è‡³: {self.output_dir}/")
        print("\nå»ºè­°é–±è®€:")
        print(f"  1. {self.output_dir}/decision_report.md")
        print(f"  2. {self.output_dir}/stripe_pattern_analysis.png")
        print(f"  3. {self.output_dir}/2d_power_spectrum.png")


def main():
    """ä¸»å‡½æ•¸"""
    analyzer = FourierAblationAnalyzer()
    analyzer.run_full_analysis()


if __name__ == "__main__":
    main()
