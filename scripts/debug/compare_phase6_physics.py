#!/usr/bin/env python
"""
Phase 6 ç‰©ç†å°æ¯”åˆ†æè…³æœ¬

å°æ¯” Phase 6B (log1p) vs Phase 6C-v3 (Huber) çš„ç‰©ç†æŒ‡æ¨™ï¼š
- Î½_t/Î½ åˆ†å¸ƒï¼ˆmin/max/mean/stdã€ç›´æ–¹åœ–ï¼‰
- k-Îµ æ–¹ç¨‹æ®˜å·®ï¼ˆL2 normï¼‰
- é€Ÿåº¦å ´èª¤å·®ï¼ˆç›¸å° JHTDBï¼‰
- æ¹å‹•èƒ½åˆ†å¸ƒï¼ˆèˆ‡ DNS å°æ¯”ï¼‰
"""
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from pinnx.models.fourier_mlp import PINNNet
from pinnx.models.wrappers import ManualScalingWrapper


def load_checkpoint_with_model(ckpt_path: str) -> tuple:
    """
    è¼‰å…¥æª¢æŸ¥é»ä¸¦å¾åµŒå…¥é…ç½®æ§‹å»ºæ¨¡å‹
    
    Returns:
        (checkpoint, model, config)
    """
    print(f"ğŸ“‚ è¼‰å…¥æª¢æŸ¥é»: {ckpt_path}")
    checkpoint = torch.load(ckpt_path, map_location='cpu')
    
    # ç²å–åµŒå…¥é…ç½®
    if 'config' not in checkpoint:
        raise ValueError("æª¢æŸ¥é»ä¸­æ²’æœ‰åµŒå…¥é…ç½®")
    
    cfg = checkpoint['config']
    model_cfg = cfg['model']
    
    # å¾å¯¦éš›æ¬Šé‡æ¨æ–·æ¨¡å‹åƒæ•¸
    state_dict = checkpoint['model_state_dict']
    
    # æª¢æ¸¬æ˜¯å¦ä½¿ç”¨ input_projection
    has_input_projection = 'input_projection.weight' in state_dict
    
    # å¾æ¬Šé‡æ¨æ–·åƒæ•¸
    in_dim = model_cfg.get('in_dim', 3)
    out_dim = model_cfg.get('out_dim', 4)
    
    if has_input_projection:
        # æœ‰ input_projection: fourier.B -> input_projection -> hidden_layers
        fourier_output_dim = state_dict['input_projection.weight'].shape[1]
        actual_fourier_m = fourier_output_dim // 2
        width = state_dict['input_projection.weight'].shape[0]
    else:
        # ç„¡ input_projection: fourier.B -> hidden_layers
        first_layer_weight = state_dict['hidden_layers.0.linear.weight']
        fourier_output_dim = first_layer_weight.shape[1]
        actual_fourier_m = fourier_output_dim // 2
        width = first_layer_weight.shape[0]
    
    print(f"  å¾æ¬Šé‡æ¨æ–·æ¨¡å‹åƒæ•¸:")
    print(f"    - in_dim: {in_dim}")
    print(f"    - out_dim: {out_dim}")
    print(f"    - width: {width}")
    print(f"    - å¯¦éš› fourier_m: {actual_fourier_m} (é…ç½®ä¸­ç‚º {model_cfg.get('fourier_m', 32)})")
    print(f"    - use_input_projection: {has_input_projection}")
    
    # ä½¿ç”¨å¯¦éš›æ¨æ–·çš„åƒæ•¸æ§‹å»ºæ¨¡å‹
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    
    # ç²å–å…¶ä»–æ¨¡å‹åƒæ•¸ï¼ˆä½¿ç”¨åµŒå…¥é…ç½®æˆ–é è¨­å€¼ï¼‰
    fourier_cfg = model_cfg.get('fourier_features', {})
    scaling_cfg = model_cfg.get('scaling', {})
    
    # æ§‹å»ºæ¨¡å‹åƒæ•¸
    model_params = {
        'in_dim': in_dim,
        'out_dim': out_dim,
        'width': width,
        'depth': model_cfg.get('depth', 5),
        'fourier_m': actual_fourier_m,
        'fourier_sigma': fourier_cfg.get('fourier_sigma', model_cfg.get('fourier_sigma', 1.0)),
        'activation': model_cfg.get('activation', 'sine'),
        'use_fourier': model_cfg.get('use_fourier', True),
        'trainable_fourier': fourier_cfg.get('trainable', model_cfg.get('fourier_trainable', False)),
        'use_input_projection': has_input_projection,
        'use_layer_norm': True,  # Phase 6 éƒ½ä½¿ç”¨äº† layer_norm
        'use_residual': False,
    }
    
    # è™•ç†è¼¸å…¥ç¸®æ”¾å› å­ï¼ˆç”¨æ–¼ VS-PINNï¼‰
    if 'input_scale_factors' in state_dict:
        model_params['input_scale_factors'] = state_dict['input_scale_factors']
        print(f"    - input_scale_factors: {state_dict['input_scale_factors']}")
    
    model = PINNNet(**model_params).to(device)
    
    # æª¢æ¸¬æ˜¯å¦ä½¿ç”¨ ManualScalingWrapper
    has_scaling_buffers = any(k in state_dict for k in ['input_min', 'input_max', 'output_min', 'output_max'])
    has_base_prefix = any(k.startswith('base_model.') for k in state_dict.keys())
    
    if has_scaling_buffers:
        print("  æª¢æ¸¬åˆ°å°ºåº¦åŒ–ç·©è¡å€ï¼Œä½¿ç”¨ ManualScalingWrapper...")
        # å»ºç«‹ä½”ä½ç¯„åœï¼ˆæœƒè¢« state_dict è¦†è“‹ï¼‰
        in_ranges = {f'in_{i}': (0.0, 1.0) for i in range(in_dim)}
        out_ranges = {f'out_{i}': (0.0, 1.0) for i in range(out_dim)}
        
        wrapper = ManualScalingWrapper(base_model=model, input_ranges=in_ranges, output_ranges=out_ranges).to(device)
        
        # è™•ç†éµæ˜ å°„
        if not has_base_prefix:
            mapped_state = {}
            for k, v in state_dict.items():
                if k in ['input_min', 'input_max', 'output_min', 'output_max']:
                    mapped_state[k] = v
                else:
                    mapped_state[f'base_model.{k}'] = v
            state_dict = mapped_state
        
        wrapper.load_state_dict(state_dict, strict=False)
        model = wrapper
        print("  âœ… ManualScalingWrapper è¼‰å…¥æˆåŠŸ")
    else:
        # è™•ç†å¯èƒ½çš„ base_model å‰ç¶´
        if has_base_prefix:
            state_dict = {k.replace('base_model.', ''): v for k, v in state_dict.items() 
                         if k not in ['input_min', 'input_max', 'output_min', 'output_max']}
        
        model.load_state_dict(state_dict, strict=False)
    
    model.eval()
    print(f"âœ… æ¨¡å‹å·²è¼‰å…¥ï¼ˆè¨­å‚™: {device}ï¼‰")
    
    return checkpoint, model, cfg


def compute_rans_residuals(model, coords: torch.Tensor, physics_cfg: Dict) -> Dict[str, float]:
    """
    è¨ˆç®— RANS æ–¹ç¨‹æ®˜å·®
    
    Args:
        model: PINN æ¨¡å‹
        coords: [N, 3] åº§æ¨™ (x, y, z)
        physics_cfg: ç‰©ç†é…ç½®
    
    Returns:
        {
            'k_residual': float,
            'epsilon_residual': float,
            'nu_t_min': float,
            'nu_t_max': float,
            'nu_t_mean': float,
            'nu_t_std': float,
            'nu_t_over_nu_ratio': np.ndarray [N]
        }
    """
    coords.requires_grad_(True)
    
    # å‰å‘å‚³æ’­
    pred = model(coords)
    u = pred[:, 0:1]
    v = pred[:, 1:2]
    w = pred[:, 2:3]
    
    # è¨ˆç®—æ¢¯åº¦ï¼ˆç”¨æ–¼ k-Îµ æ–¹ç¨‹ï¼‰
    # æ³¨æ„ï¼šé€™è£¡ç°¡åŒ–ç‚ºä¸è¨ˆç®—å®Œæ•´çš„ k-Îµ æ®˜å·®ï¼ˆéœ€è¦é¡å¤–çš„ç¶²çµ¡è¼¸å‡ºï¼‰
    # å¯¦éš›è©•ä¼°éœ€è¦æ¨¡å‹è¼¸å‡º k å’Œ Îµ
    
    # è¨ˆç®—æ¹å‹•é»åº¦ï¼ˆåŸºæ–¼æ··åˆé•·åº¦ç†è«–çš„è¿‘ä¼¼ï¼‰
    nu = physics_cfg.get('nu', 5.0e-5)
    
    # ç°¡åŒ–ï¼šä½¿ç”¨é€Ÿåº¦æ¢¯åº¦ä¼°ç®— Î½_t
    # å®Œæ•´ç‰ˆéœ€è¦å¾ RANS æ¨¡å‹ä¸­æå– k å’Œ Îµ
    du_dy = torch.autograd.grad(u, coords, torch.ones_like(u), create_graph=True)[0][:, 1:2]
    S = torch.sqrt(2 * du_dy**2)  # ç°¡åŒ–çš„æ‡‰è®Šç‡å¼µé‡ç¯„æ•¸
    
    # æ··åˆé•·åº¦è¿‘ä¼¼ï¼šÎ½_t ~ l_m^2 |S|
    y = coords[:, 1:2]
    l_m = 0.41 * torch.abs(y) * (1 - torch.abs(y))  # von KÃ¡rmÃ¡n æ··åˆé•·åº¦
    nu_t = l_m**2 * S
    
    # çµ±è¨ˆé‡
    nu_t_np = nu_t.detach().cpu().numpy().flatten()
    nu_t_over_nu = nu_t_np / nu
    
    return {
        'k_residual': 0.0,  # å¾…å¯¦ä½œï¼šéœ€è¦å®Œæ•´çš„ k-Îµ æ–¹ç¨‹
        'epsilon_residual': 0.0,  # å¾…å¯¦ä½œ
        'nu_t_min': float(nu_t_np.min()),
        'nu_t_max': float(nu_t_np.max()),
        'nu_t_mean': float(nu_t_np.mean()),
        'nu_t_std': float(nu_t_np.std()),
        'nu_t_over_nu_ratio': nu_t_over_nu
    }


def evaluate_phase(phase_name: str, ckpt_path: str) -> Dict[str, Any]:
    """
    è©•ä¼°å–®å€‹ Phase çš„ç‰©ç†æŒ‡æ¨™
    
    Returns:
        {
            'name': str,
            'loss': dict,
            'rans_metrics': dict,
            'velocity_error': dict
        }
    """
    print(f"\n{'='*70}")
    print(f"  è©•ä¼° {phase_name}")
    print(f"{'='*70}")
    
    # è¼‰å…¥æ¨¡å‹
    checkpoint, model, cfg = load_checkpoint_with_model(ckpt_path)
    
    # æå–è¨“ç·´æå¤±
    loss_info = {
        'epoch': checkpoint.get('epoch', 'N/A'),
    }
    
    # å¦‚æœæœ‰è©³ç´°çš„æå¤±æ­·å²ï¼Œæå–æœ€å¾Œä¸€è¼ªçš„æå¤±
    if 'history' in checkpoint:
        history = checkpoint['history']
        # history æ˜¯ dictï¼Œæ¯å€‹éµå°æ‡‰ä¸€å€‹åˆ—è¡¨
        for key in ['total_loss', 'turbulent_viscosity_loss', 'k_equation_loss', 'epsilon_equation_loss', 
                   'rans_loss', 'pde_loss', 'data_loss']:
            if key in history and isinstance(history[key], list) and len(history[key]) > 0:
                loss_info[key] = history[key][-1]
            elif key in history:
                loss_info[key] = history[key]
    
    # ç”Ÿæˆæ¸¬è©¦é»ï¼ˆé€šé“æµçš„å…¸å‹åˆ†å¸ƒï¼‰
    device = next(model.parameters()).device
    N_test = 1000
    
    # é€šé“æµåŸŸï¼šx âˆˆ [0, 25.13], y âˆˆ [-1, 1], z âˆˆ [0, 9.42]
    x = np.random.uniform(0, 25.13, N_test)
    y = np.random.uniform(-1, 1, N_test)
    z = np.random.uniform(0, 9.42, N_test)
    coords = torch.FloatTensor(np.stack([x, y, z], axis=1)).to(device)
    
    # è¨ˆç®— RANS æŒ‡æ¨™ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
    print("\n  è¨ˆç®— RANS ç‰©ç†æŒ‡æ¨™...")
    rans_metrics = compute_rans_residuals(model, coords, cfg.get('physics', {}))
    
    # é€Ÿåº¦å ´é æ¸¬ï¼ˆç”¨æ–¼å¾ŒçºŒå°æ¯”ï¼‰
    print("  è¨ˆç®—é€Ÿåº¦å ´é æ¸¬...")
    with torch.no_grad():
        pred = model(coords)
        velocity_pred = {
            'u': pred[:, 0].cpu().numpy(),
            'v': pred[:, 1].cpu().numpy(),
            'w': pred[:, 2].cpu().numpy(),
            'p': pred[:, 3].cpu().numpy() if pred.shape[1] > 3 else None
        }
    
    return {
        'name': phase_name,
        'loss': loss_info,
        'rans_metrics': rans_metrics,
        'velocity_pred': velocity_pred,
        'test_coords': coords.detach().cpu().numpy()
    }


def compare_and_visualize(results_6b: Dict, results_6c: Dict, output_dir: Path):
    """
    å°æ¯”å…©å€‹ Phase çš„çµæœä¸¦ç”Ÿæˆè¦–è¦ºåŒ–
    """
    print(f"\n{'='*70}")
    print("  å°æ¯”åˆ†æ")
    print(f"{'='*70}")
    
    # 1. è¨“ç·´æå¤±å°æ¯”
    print("\nğŸ“Š è¨“ç·´æå¤±å°æ¯”ï¼š")
    print("-" * 70)
    print(f"{'æŒ‡æ¨™':<40} {'Phase 6B (log1p)':<20} {'Phase 6C-v3 (Huber)':<20}")
    print("-" * 70)
    
    for key in ['total_loss', 'turbulent_viscosity_loss', 'k_equation_loss', 'epsilon_equation_loss']:
        val_6b = results_6b['loss'].get(key, 'N/A')
        val_6c = results_6c['loss'].get(key, 'N/A')
        
        if isinstance(val_6b, (int, float)) and isinstance(val_6c, (int, float)):
            ratio = val_6c / val_6b if val_6b != 0 else float('inf')
            print(f"{key:<40} {val_6b:<20.2f} {val_6c:<20.2f} ({ratio:.2f}x)")
        else:
            print(f"{key:<40} {str(val_6b):<20} {str(val_6c):<20}")
    
    # 2. RANS ç‰©ç†æŒ‡æ¨™å°æ¯”
    print("\nğŸ”¬ RANS ç‰©ç†æŒ‡æ¨™å°æ¯”ï¼š")
    print("-" * 70)
    print(f"{'æŒ‡æ¨™':<40} {'Phase 6B':<20} {'Phase 6C-v3':<20}")
    print("-" * 70)
    
    rans_6b = results_6b['rans_metrics']
    rans_6c = results_6c['rans_metrics']
    
    for key in ['nu_t_min', 'nu_t_max', 'nu_t_mean', 'nu_t_std']:
        val_6b = rans_6b[key]
        val_6c = rans_6c[key]
        print(f"{key:<40} {val_6b:<20.6e} {val_6c:<20.6e}")
    
    # 3. Î½_t/Î½ åˆ†å¸ƒçµ±è¨ˆ
    ratio_6b = rans_6b['nu_t_over_nu_ratio']
    ratio_6c = rans_6c['nu_t_over_nu_ratio']
    
    print("\nğŸ“ˆ Î½_t/Î½ åˆ†å¸ƒçµ±è¨ˆï¼š")
    print("-" * 70)
    print(f"{'çµ±è¨ˆé‡':<40} {'Phase 6B':<20} {'Phase 6C-v3':<20}")
    print("-" * 70)
    print(f"{'Min':<40} {ratio_6b.min():<20.2f} {ratio_6c.min():<20.2f}")
    print(f"{'Max':<40} {ratio_6b.max():<20.2f} {ratio_6c.max():<20.2f}")
    print(f"{'Mean':<40} {ratio_6b.mean():<20.2f} {ratio_6c.mean():<20.2f}")
    print(f"{'Std':<40} {ratio_6b.std():<20.2f} {ratio_6c.std():<20.2f}")
    print(f"{'Median':<40} {np.median(ratio_6b):<20.2f} {np.median(ratio_6c):<20.2f}")
    print(f"{'95th percentile':<40} {np.percentile(ratio_6b, 95):<20.2f} {np.percentile(ratio_6c, 95):<20.2f}")
    
    # 4. ç”Ÿæˆè¦–è¦ºåŒ–
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 4.1 Î½_t/Î½ åˆ†å¸ƒç›´æ–¹åœ–
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    axes[0].hist(ratio_6b, bins=50, alpha=0.7, color='blue', edgecolor='black')
    axes[0].set_xlabel('Î½_t/Î½')
    axes[0].set_ylabel('Frequency')
    axes[0].set_title('Phase 6B (log1p)')
    axes[0].axvline(ratio_6b.mean(), color='red', linestyle='--', label=f'Mean: {ratio_6b.mean():.1f}')
    axes[0].legend()
    axes[0].grid(alpha=0.3)
    
    axes[1].hist(ratio_6c, bins=50, alpha=0.7, color='green', edgecolor='black')
    axes[1].set_xlabel('Î½_t/Î½')
    axes[1].set_ylabel('Frequency')
    axes[1].set_title('Phase 6C-v3 (Huber)')
    axes[1].axvline(ratio_6c.mean(), color='red', linestyle='--', label=f'Mean: {ratio_6c.mean():.1f}')
    axes[1].legend()
    axes[1].grid(alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'nu_t_distribution_comparison.png', dpi=150)
    print(f"\n  âœ… å„²å­˜: {output_dir / 'nu_t_distribution_comparison.png'}")
    
    # 4.2 ç–ŠåŠ å°æ¯”ç›´æ–¹åœ–
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.hist(ratio_6b, bins=50, alpha=0.5, color='blue', label='Phase 6B (log1p)', edgecolor='black')
    ax.hist(ratio_6c, bins=50, alpha=0.5, color='green', label='Phase 6C-v3 (Huber)', edgecolor='black')
    ax.set_xlabel('Î½_t/Î½')
    ax.set_ylabel('Frequency')
    ax.set_title('Î½_t/Î½ Distribution Comparison')
    ax.axvline(ratio_6b.mean(), color='blue', linestyle='--', label=f'6B Mean: {ratio_6b.mean():.1f}')
    ax.axvline(ratio_6c.mean(), color='green', linestyle='--', label=f'6C-v3 Mean: {ratio_6c.mean():.1f}')
    ax.legend()
    ax.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig(output_dir / 'nu_t_overlay_comparison.png', dpi=150)
    print(f"  âœ… å„²å­˜: {output_dir / 'nu_t_overlay_comparison.png'}")
    
    # 5. æ±ºç­–å»ºè­°
    print(f"\n{'='*70}")
    print("  æ±ºç­–å»ºè­°")
    print(f"{'='*70}")
    
    # åŸºæ–¼ç‰©ç†æŒ‡æ¨™çµ¦å‡ºæ¨è–¦
    decision_score = 0  # æ­£æ•¸åå‘ 6Cï¼Œè² æ•¸åå‘ 6B
    decision_reasons = []
    
    # 1. æå¤±æ•¸å€¼æ¯”è¼ƒï¼ˆç¸½æå¤±è¶Šä½è¶Šå¥½ï¼‰
    loss_6b = results_6b['loss'].get('total_loss', float('inf'))
    loss_6c = results_6c['loss'].get('total_loss', float('inf'))
    if loss_6b < loss_6c:
        decision_score -= 2  # 6B å‹å‡ºï¼ˆæ¬Šé‡è¼ƒé«˜ï¼‰
        print(f"\n  âŒ Phase 6B ç¸½æå¤±æ›´ä½ ({loss_6b:.2f} < {loss_6c:.2f})")
        decision_reasons.append("Phase 6B ç¸½æå¤±æ›´ä½")
    else:
        decision_score += 2
        print(f"\n  âœ… Phase 6C-v3 ç¸½æå¤±æ›´ä½ ({loss_6c:.2f} < {loss_6b:.2f})")
        decision_reasons.append("Phase 6C-v3 ç¸½æå¤±æ›´ä½")
    
    # 1.5. æ¹æµé»åº¦æå¤±æª¢æŸ¥ï¼ˆé—œéµç‰©ç†æŒ‡æ¨™ï¼‰
    turb_visc_6b = results_6b['loss'].get('turbulent_viscosity_loss', 0)
    turb_visc_6c = results_6c['loss'].get('turbulent_viscosity_loss', 0)
    if turb_visc_6c > turb_visc_6b * 10:  # å¦‚æœ 6C çš„æ¹æµé»åº¦æå¤±æ˜¯ 6B çš„ 10 å€ä»¥ä¸Š
        decision_score -= 2
        print(f"  âš ï¸  Phase 6C-v3 æ¹æµé»åº¦æå¤±ç•°å¸¸é«˜ ({turb_visc_6c:.0f} vs {turb_visc_6b:.0f}, {turb_visc_6c/turb_visc_6b:.1f}x)")
        decision_reasons.append("Phase 6C-v3 æ¹æµé»åº¦æå¤±ç•°å¸¸")
    elif turb_visc_6b > turb_visc_6c * 10:
        decision_score += 2
        print(f"  âœ… Phase 6C-v3 æ¹æµé»åº¦æå¤±é¡¯è‘—æ›´ä½")
        decision_reasons.append("Phase 6C-v3 æ¹æµé»åº¦æå¤±æ›´ä½")
    
    # 2. Î½_t/Î½ åˆ†å¸ƒåˆç†æ€§ï¼ˆç›®æ¨™ï¼š< 200ï¼Œç†æƒ³ < 100ï¼‰
    ratio_6b_exceed = (ratio_6b > 200).sum() / len(ratio_6b) * 100
    ratio_6c_exceed = (ratio_6c > 200).sum() / len(ratio_6c) * 100
    
    if ratio_6c_exceed < ratio_6b_exceed:
        decision_score += 1
        print(f"  âœ… Phase 6C-v3 çš„ Î½_t/Î½ > 200 ä½”æ¯”æ›´ä½ ({ratio_6c_exceed:.1f}% vs {ratio_6b_exceed:.1f}%)")
        decision_reasons.append("Phase 6C-v3 æ¥µå€¼ä½”æ¯”æ›´ä½")
    elif ratio_6b_exceed < ratio_6c_exceed:
        decision_score -= 1
        print(f"  âŒ Phase 6B çš„ Î½_t/Î½ > 200 ä½”æ¯”æ›´ä½ ({ratio_6b_exceed:.1f}% vs {ratio_6c_exceed:.1f}%)")
        decision_reasons.append("Phase 6B æ¥µå€¼ä½”æ¯”æ›´ä½")
    else:
        print(f"  âš–ï¸  å…©è€…çš„ Î½_t/Î½ > 200 ä½”æ¯”ç›¸åŒ ({ratio_6b_exceed:.1f}%)")
    
    # 3. åˆ†å¸ƒç©©å®šæ€§ï¼ˆæ¨™æº–å·®è¶Šå°è¶Šå¥½ï¼‰
    if ratio_6c.std() < ratio_6b.std():
        decision_score += 1
        print(f"  âœ… Phase 6C-v3 çš„ Î½_t/Î½ åˆ†å¸ƒæ›´ç©©å®š (std: {ratio_6c.std():.1f} vs {ratio_6b.std():.1f})")
        decision_reasons.append("Phase 6C-v3 åˆ†å¸ƒæ›´ç©©å®š")
    else:
        decision_score -= 1
        print(f"  âŒ Phase 6B çš„ Î½_t/Î½ åˆ†å¸ƒæ›´ç©©å®š (std: {ratio_6b.std():.1f} vs {ratio_6c.std():.1f})")
        decision_reasons.append("Phase 6B åˆ†å¸ƒæ›´ç©©å®š")
    
    # 4. å¹³å‡å€¼åˆç†æ€§ï¼ˆç†æƒ³ç¯„åœ 5-50ï¼‰
    mean_6b = ratio_6b.mean()
    mean_6c = ratio_6c.mean()
    ideal_range = (5, 50)
    
    if ideal_range[0] <= mean_6c <= ideal_range[1] and not (ideal_range[0] <= mean_6b <= ideal_range[1]):
        decision_score += 1
        print(f"  âœ… Phase 6C-v3 å¹³å‡å€¼åœ¨ç†æƒ³ç¯„åœå…§ ({mean_6c:.1f} âˆˆ [{ideal_range[0]}, {ideal_range[1]}])")
        decision_reasons.append("Phase 6C-v3 å¹³å‡å€¼æ›´åˆç†")
    elif ideal_range[0] <= mean_6b <= ideal_range[1] and not (ideal_range[0] <= mean_6c <= ideal_range[1]):
        decision_score -= 1
        print(f"  âŒ Phase 6B å¹³å‡å€¼åœ¨ç†æƒ³ç¯„åœå…§ ({mean_6b:.1f} âˆˆ [{ideal_range[0]}, {ideal_range[1]}])")
        decision_reasons.append("Phase 6B å¹³å‡å€¼æ›´åˆç†")
    
    # æœ€çµ‚æ¨è–¦
    print(f"\n{'='*70}")
    print(f"  æ±ºç­–åˆ†æ•¸: {decision_score} (æ­£æ•¸åå‘ 6C-v3ï¼Œè² æ•¸åå‘ 6B)")
    print(f"{'='*70}")
    
    if decision_score > 1:
        print("  ğŸ† æ¨è–¦ï¼šPhase 6C-v3 (Huber) ç‰©ç†æ€§èƒ½æ›´å„ª")
    elif decision_score < -1:
        print("  ğŸ† æ¨è–¦ï¼šPhase 6B (log1p) ç‰©ç†æ€§èƒ½æ›´å„ª")
    else:
        print("  âš–ï¸  å…©è€…æ€§èƒ½ç›¸ç•¶ï¼Œéœ€é€²ä¸€æ­¥è©•ä¼°é€Ÿåº¦å ´èª¤å·®")
    
    print(f"\n  ä¸»è¦åŸå› :")
    for reason in decision_reasons:
        print(f"    - {reason}")
    print(f"{'='*70}")
    
    return decision_score


def main():
    """ä¸»å‡½æ•¸"""
    print("="*70)
    print("  Phase 6 ç‰©ç†å°æ¯”åˆ†æ")
    print("="*70)
    
    # æª¢æŸ¥é»è·¯å¾‘
    phase6b_ckpt = Path("checkpoints/test_rans_phase6b/epoch_100.pth")
    phase6c_ckpt = Path("checkpoints/test_rans_phase6c_v3/epoch_100.pth")
    
    if not phase6b_ckpt.exists():
        print(f"âŒ Phase 6B æª¢æŸ¥é»ä¸å­˜åœ¨: {phase6b_ckpt}")
        return
    
    if not phase6c_ckpt.exists():
        print(f"âŒ Phase 6C-v3 æª¢æŸ¥é»ä¸å­˜åœ¨: {phase6c_ckpt}")
        return
    
    # è©•ä¼°å…©å€‹ Phase
    results_6b = evaluate_phase("Phase 6B (log1p)", str(phase6b_ckpt))
    results_6c = evaluate_phase("Phase 6C-v3 (Huber)", str(phase6c_ckpt))
    
    # å°æ¯”åˆ†æ
    output_dir = Path("tasks/TASK-008/phase_6_comparison")
    decision_score = compare_and_visualize(results_6b, results_6c, output_dir)
    
    # å„²å­˜çµæœç‚º JSON
    import json
    
    # è½‰æ› numpy æ•¸çµ„ç‚ºåˆ—è¡¨ï¼ˆJSON ä¸æ”¯æŒ numpyï¼‰
    def convert_to_json_serializable(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {k: convert_to_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_to_json_serializable(item) for item in obj]
        else:
            return obj
    
    results = {
        'phase_6b': convert_to_json_serializable(results_6b),
        'phase_6c_v3': convert_to_json_serializable(results_6c),
        'decision_score': decision_score
    }
    
    with open(output_dir / 'comparison_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\n  âœ… å®Œæ•´çµæœå·²å„²å­˜: {output_dir / 'comparison_results.json'}")
    print("\nâœ… å°æ¯”åˆ†æå®Œæˆï¼")


if __name__ == "__main__":
    main()
