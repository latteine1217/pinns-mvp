#!/usr/bin/env python3
"""
QR-Pivot æ„Ÿæ¸¬é»åˆ†ä½ˆè¦–è¦ºåŒ–å·¥å…·

åŠŸèƒ½ï¼š
  1. è¼‰å…¥ QR-pivot é¸æ“‡çš„æ„Ÿæ¸¬é»è³‡æ–™
  2. ç¹ªè£½æ„Ÿæ¸¬é»çš„ç©ºé–“åˆ†ä½ˆåœ–ï¼ˆ2D/3Dï¼‰
  3. é¡¯ç¤ºæ„Ÿæ¸¬é»çš„åº§æ¨™èˆ‡æ•¸å€¼å¤§å°
  4. åˆ†ææ„Ÿæ¸¬é»çš„å¹¾ä½•åˆ†ä½ˆç‰¹æ€§
  5. æ¯”è¼ƒä¸åŒé¸é»ç­–ç•¥çš„å·®ç•°

ä½¿ç”¨æ–¹å¼ï¼š
  # å¾ npz æª”æ¡ˆè¼‰å…¥
  python scripts/visualize_qr_sensors.py \
    --input data/jhtdb/sensors_K50.npz \
    --output results/sensor_analysis

  # å¾ JHTDB è³‡æ–™é‡æ–°è¨ˆç®—
  python scripts/visualize_qr_sensors.py \
    --jhtdb-data data/jhtdb/channel_flow_re1000.h5 \
    --n-sensors 50 \
    --output results/sensor_analysis

  # æ¯”è¼ƒå¤šç¨®ç­–ç•¥
  python scripts/visualize_qr_sensors.py \
    --jhtdb-data data/jhtdb/channel_flow_re1000.h5 \
    --n-sensors 50 \
    --compare-strategies \
    --output results/sensor_comparison
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D
import argparse
import sys
from pathlib import Path
from typing import Dict, Any, List, Optional
import json
import h5py

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pinnx.sensors.qr_pivot import (
    QRPivotSelector, 
    PODBasedSelector, 
    GreedySelector,
    evaluate_sensor_placement
)


def load_sensor_data(input_path: str) -> Dict[str, Any]:
    """è¼‰å…¥æ„Ÿæ¸¬é»è³‡æ–™
    
    æ”¯æ´æ ¼å¼ï¼š
      1. æ¨™æº– QR-Pivot: sensor_indices, sensor_coords, sensor_values
      2. åˆ†å±¤ QR-Pivot: indices, coords, pressure_values, layer_info, metadata
      3. å®Œæ•´ JHTDB: x, y, z, u, v, w, p + indices
    """
    print(f"ğŸ“‚ è¼‰å…¥æ„Ÿæ¸¬é»è³‡æ–™: {input_path}")
    
    input_path_obj = Path(input_path)
    
    if input_path_obj.suffix == '.npz':
        data = np.load(str(input_path_obj), allow_pickle=True)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºåˆ†å±¤ QR-Pivot æ ¼å¼
        is_stratified = 'layer_info' in data and 'metadata' in data
        
        if is_stratified:
            print("  âœ… æª¢æ¸¬åˆ°åˆ†å±¤ QR-Pivot æ ¼å¼")
            result: Dict[str, Any] = {}
            
            # æå–åŸºæœ¬è³‡æ–™
            result['indices'] = data['indices']
            result['coordinates'] = data['coords']
            result['values'] = data['pressure_values'].reshape(-1, 1)  # [N, 1] å£“åŠ›å€¼
            
            # æå–åˆ†å±¤è³‡è¨Š
            layer_info = data['layer_info'].item()
            result['layer_info'] = layer_info
            
            # æå–å…ƒæ•¸æ“š
            metadata = data['metadata'].item()
            result['metadata'] = metadata
            
            # è¨ˆç®—æ¯å€‹æ„Ÿæ¸¬é»çš„åˆ†å±¤æ¨™ç±¤
            layer_labels = []
            for i in range(len(result['indices'])):
                if i < layer_info['wall']['n_selected']:
                    layer_labels.append('wall')
                elif i < layer_info['wall']['n_selected'] + layer_info['log']['n_selected']:
                    layer_labels.append('log')
                else:
                    layer_labels.append('center')
            result['layer_labels'] = np.array(layer_labels)
            
            print(f"     åˆ†å±¤è³‡è¨Š: wall={layer_info['wall']['n_selected']}, "
                  f"log={layer_info['log']['n_selected']}, "
                  f"center={layer_info['center']['n_selected']}")
            print(f"     ç¸½æ„Ÿæ¸¬é»æ•¸: {len(result['indices'])}")
            
            return result
        
        # æ¨™æº–æ ¼å¼ï¼šå˜—è©¦ä¸åŒçš„éµå
        possible_keys = {
            'indices': ['sensor_indices', 'indices', 'selected_indices'],
            'coordinates': ['sensor_points', 'sensor_coords', 'coordinates', 'coords', 'positions'],
            'values': ['sensor_data', 'sensor_values', 'values', 'u', 'velocity', 'pressure_values']
        }
        
        result: Dict[str, Any] = {}
        
        # æå–ç´¢å¼•
        for key in possible_keys['indices']:
            if key in data:
                result['indices'] = data[key]
                break
        
        # æå–åº§æ¨™
        for key in possible_keys['coordinates']:
            if key in data:
                result['coordinates'] = data[key]
                break
        
        # æå–æ•¸å€¼ï¼ˆè™•ç† object arrayï¼‰
        for key in possible_keys['values']:
            if key in data:
                val = data[key]
                # è™•ç† numpy object array (éœ€è¦ .item() æå–)
                if val.dtype == np.object_ and val.shape == ():
                    val = val.item()
                
                # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–é€Ÿåº¦å ´
                if isinstance(val, dict):
                    # å‡è¨­æœ‰ u, v, w, p éµ
                    if 'u' in val:
                        u = val['u']
                        v = val.get('v', np.zeros_like(u))
                        w = val.get('w', np.zeros_like(u))
                        # å †ç–Šç‚º (N, 3) æˆ– (N, 4) åŒ…å«å£“åŠ›
                        if 'p' in val:
                            result['values'] = np.stack([u, v, w, val['p']], axis=1)
                        else:
                            result['values'] = np.stack([u, v, w], axis=1)
                    result['velocity_magnitude'] = np.linalg.norm(
                        np.stack([val.get('u', 0), val.get('v', 0), val.get('w', 0)], axis=1), axis=1
                    ) if 'u' in val else None
                else:
                    result['values'] = val
                break
        
        # å¦‚æœæœ‰å®Œæ•´çš„ JHTDB è³‡æ–™ï¼Œæå–å…¶ä»–è³‡è¨Š
        if 'x' in data and 'y' in data and 'z' in data:
            # é€™æ˜¯å®Œæ•´çš„ JHTDB è³‡æ–™
            x, y, z = data['x'], data['y'], data['z']
            
            if 'indices' in result:
                indices = result['indices']
                # æå–é¸å®šé»çš„åº§æ¨™
                if len(x.shape) == 1:
                    # 1D åº§æ¨™é™£åˆ—
                    n_total = len(x) * len(y) * len(z)
                    X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
                    X_flat = X.flatten()
                    Y_flat = Y.flatten()
                    Z_flat = Z.flatten()
                    result['coordinates'] = np.stack([
                        X_flat[indices],
                        Y_flat[indices],
                        Z_flat[indices]
                    ], axis=1)
                else:
                    # å·²ç¶“æ˜¯ç¶²æ ¼å½¢å¼
                    result['coordinates'] = np.stack([
                        x.flatten()[indices],
                        y.flatten()[indices],
                        z.flatten()[indices]
                    ], axis=1)
                
                # æå–é€Ÿåº¦å ´
                if 'u' in data:
                    u = data['u'].flatten()[indices]
                    v = data['v'].flatten()[indices] if 'v' in data else np.zeros_like(u)
                    w = data['w'].flatten()[indices] if 'w' in data else np.zeros_like(u)
                    result['values'] = np.stack([u, v, w], axis=1)
        
        print(f"  âœ… è¼‰å…¥æˆåŠŸ")
        print(f"     åŒ…å«éµ: {list(data.keys())}")
        
        return result
    
    elif input_path_obj.suffix in ['.h5', '.hdf5']:
        # HDF5 æ ¼å¼
        with h5py.File(str(input_path_obj), 'r') as f:
            result: Dict[str, Any] = {}
            
            # åˆ—å‡ºæ‰€æœ‰è³‡æ–™é›†
            print(f"  HDF5 è³‡æ–™é›†: {list(f.keys())}")
            
            if 'sensor_indices' in f:
                result['indices'] = np.array(f['sensor_indices'])
            if 'sensor_coords' in f:
                result['coordinates'] = np.array(f['sensor_coords'])
            if 'sensor_values' in f:
                result['values'] = np.array(f['sensor_values'])
        
        return result
    
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {input_path_obj.suffix}")


def compute_sensors_from_jhtdb(jhtdb_path: str, n_sensors: int, strategy: str = 'qr_pivot', temporal_data_path: Optional[str] = None) -> Dict[str, Any]:
    """å¾ JHTDB è³‡æ–™è¨ˆç®—æ„Ÿæ¸¬é»
    
    Args:
        jhtdb_path: JHTDB è³‡æ–™æª”æ¡ˆè·¯å¾‘ï¼ˆå–®æ™‚é–“æ­¥æˆ–ç©ºé–“è³‡æ–™ï¼‰
        n_sensors: æ„Ÿæ¸¬é»æ•¸é‡
        strategy: é¸é»ç­–ç•¥ï¼ˆ'qr_pivot', 'pod_based', 'greedy'ï¼‰
        temporal_data_path: å¤šæ™‚é–“æ­¥å¿«ç…§è³‡æ–™è·¯å¾‘ï¼ˆå„ªå…ˆä½¿ç”¨ï¼Œæ ¼å¼ï¼š[n_time, nx, ny]ï¼‰
    
    Returns:
        åŒ…å« indices, coordinates, values, metrics çš„å­—å…¸
    
    Notes:
        - è‹¥æä¾› temporal_data_pathï¼Œå°‡ä½¿ç”¨å¤šæ™‚é–“æ­¥è³‡æ–™çŸ©é™£ [n_locations, n_time]
        - å¦å‰‡å›é€€åˆ°ç©ºé–“åˆ‡ç‰‡ç­–ç•¥ï¼ˆå¯èƒ½å°è‡´ç§©ä¸è¶³èˆ‡é«˜æ¢ä»¶æ•¸ï¼‰
    """
    print(f"\nğŸ§® å¾ JHTDB è³‡æ–™è¨ˆç®—æ„Ÿæ¸¬é»...")
    print(f"   ç­–ç•¥: {strategy}")
    print(f"   æ„Ÿæ¸¬é»æ•¸é‡: {n_sensors}")
    
    # ==== å„ªå…ˆä½¿ç”¨å¤šæ™‚é–“æ­¥è³‡æ–™ ====
    if temporal_data_path is not None:
        print(f"   â±ï¸  ä½¿ç”¨å¤šæ™‚é–“æ­¥å¿«ç…§è³‡æ–™: {temporal_data_path}")
        temp_data = np.load(temporal_data_path)
        
        # æå–æ™‚é–“å¿«ç…§ [n_time, nx, ny] æˆ– [n_time, nx, ny, nz]
        u_snapshots = temp_data['u']
        v_snapshots = temp_data.get('v', np.zeros_like(u_snapshots))
        w_snapshots = temp_data.get('w', np.zeros_like(u_snapshots))
        
        n_time = u_snapshots.shape[0]
        spatial_shape = u_snapshots.shape[1:]
        n_locations = np.prod(spatial_shape)
        
        print(f"   æ™‚é–“æ­¥æ•¸: {n_time}")
        print(f"   ç©ºé–“å½¢ç‹€: {spatial_shape}")
        print(f"   ç©ºé–“é»æ•¸: {n_locations}")
        
        # é‡çµ„ç‚ºè³‡æ–™çŸ©é™£ [n_locations, n_time]
        # ç­–ç•¥ï¼šæ¯å€‹æ™‚é–“æ­¥ä½œç‚ºä¸€å€‹ç‰¹å¾µï¼ˆsnapshotï¼‰
        u_matrix = u_snapshots.reshape(n_time, -1).T  # [n_locations, n_time]
        v_matrix = v_snapshots.reshape(n_time, -1).T
        w_matrix = w_snapshots.reshape(n_time, -1).T
        
        # çµ„åˆä¸‰å€‹ç‰©ç†é‡çš„æ™‚é–“æ¼”åŒ–
        # é¸é … 1: åƒ…ä½¿ç”¨ u åˆ†é‡ï¼ˆé™ä½å…§å­˜ï¼Œä¿ç•™æ™‚é–“å‹•æ…‹ï¼‰
        data_matrix = u_matrix  # [n_locations, n_time]
        
        # é¸é … 2: çµ„åˆ u, v, wï¼ˆå¢åŠ ç‰¹å¾µï¼Œä½†å¯èƒ½å°è‡´éå¤§çŸ©é™£ï¼‰
        # data_matrix = np.hstack([u_matrix, v_matrix, w_matrix])  # [n_locations, 3*n_time]
        
        print(f"   âœ… è³‡æ–™çŸ©é™£å½¢ç‹€: {data_matrix.shape} [n_locations, n_features]")
        print(f"      çŸ©é™£ç§©ï¼ˆä¼°è¨ˆï¼‰: min({n_locations}, {n_time}) = {min(n_locations, n_time)}")
        
        # æå–åº§æ¨™ï¼ˆå¾ temporal dataï¼‰
        x = temp_data['x']
        y = temp_data['y']
        z = temp_data.get('z', None)
        
        # å¦‚æœæ²’æœ‰ zï¼Œå˜—è©¦å¾ metadata ç²å–åˆ‡ç‰‡ä½ç½®
        if z is None and 'metadata' in temp_data:
            import json
            metadata = temp_data['metadata']
            if isinstance(metadata, np.ndarray):
                metadata = metadata.item()
            if isinstance(metadata, str):
                metadata = json.loads(metadata)
            
            if 'slice_position' in metadata:
                z_pos = metadata['slice_position']
            else:
                z_pos = 0.0
            z = np.array([z_pos])
        
        # å»ºç«‹ç¶²æ ¼
        if len(spatial_shape) == 2:
            # 2D è³‡æ–™
            X, Y = np.meshgrid(x, y, indexing='ij')
            coords = np.stack([X.flatten(), Y.flatten(), np.zeros(n_locations)], axis=1)
        else:
            # 3D è³‡æ–™
            X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
            coords = np.stack([X.flatten(), Y.flatten(), Z.flatten()], axis=1)
        
        # é€Ÿåº¦å€¼ï¼šä½¿ç”¨ç¬¬ä¸€å€‹æ™‚é–“æ­¥
        velocities = np.stack([
            u_snapshots[0].flatten(),
            v_snapshots[0].flatten(),
            w_snapshots[0].flatten()
        ], axis=1)
    
    # ==== å›é€€åˆ°å–®æ™‚é–“æ­¥è³‡æ–™ ====
    else:
        jhtdb_path_obj = Path(jhtdb_path)
        
        if jhtdb_path_obj.suffix == '.npz':
            data = np.load(str(jhtdb_path_obj))
            
            # æå–åº§æ¨™
            # æ”¯æ´ 2D (x, y) å’Œ 3D (x, y, z) è³‡æ–™
            if 'x' in data and 'y' in data:
                x, y = data['x'], data['y']
                z = data.get('z', None)
                
                # å»ºç«‹ç¶²æ ¼
                if z is not None:
                    # 3D è³‡æ–™
                    if len(x.shape) == 1:
                        X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
                    else:
                        X, Y, Z = x, y, z
                else:
                    # 2D è³‡æ–™ï¼šå¾åˆ‡ç‰‡ä½ç½®æ¢å¾© Z åº§æ¨™
                    if len(x.shape) == 1:
                        X, Y = np.meshgrid(x, y, indexing='ij')
                    else:
                        X, Y = x, y
                    
                    # å˜—è©¦å¾ metadata ç²å–åˆ‡ç‰‡ä½ç½®
                    if 'slice_position' in data:
                        z_pos = float(data['slice_position'])
                    else:
                        z_pos = 0.0  # é è¨­å€¼
                    
                    Z = np.full_like(X, z_pos)
                
                # æå–é€Ÿåº¦å ´
                if 'u' in data:
                    u = data['u']
                    v = data.get('v', np.zeros_like(u))
                    w = data.get('w', np.zeros_like(u))
                    
                    # å±•å¹³
                    coords = np.stack([X.flatten(), Y.flatten(), Z.flatten()], axis=1)
                    velocities = np.stack([u.flatten(), v.flatten(), w.flatten()], axis=1)
                    
                    # å»ºç«‹è³‡æ–™çŸ©é™£ [n_locations, n_features]
                    # æ–¹æ³•ï¼šä½¿ç”¨ç©ºé–“åˆ‡ç‰‡ä½œç‚ºã€Œè™›æ“¬å¿«ç…§ã€+ å¤šç‰©ç†é‡çµ„åˆ
                    # âš ï¸ è­¦å‘Šï¼šé€™ç¨®æ–¹æ³•çš„ç§©å—é™æ–¼ç‰©ç†é‡æ•¸é‡ï¼Œå¯èƒ½å°è‡´é«˜æ¢ä»¶æ•¸
                    print(f"   âš ï¸  ä½¿ç”¨å–®æ™‚é–“æ­¥è³‡æ–™ï¼ˆå›é€€ç­–ç•¥ï¼‰")
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚º 3D è³‡æ–™ï¼ˆæœ‰å¤šå€‹å±¤å¯ä½œç‚ºå¿«ç…§ï¼‰
                    if u.ndim == 3 and min(u.shape) > 3:
                        # 3D è³‡æ–™ï¼šä½¿ç”¨å¤šæ–¹å‘åˆ‡ç‰‡çµ„åˆ
                        # u.shape = (nx, ny, nz)
                        nx, ny, nz = u.shape
                    
                        # ç­–ç•¥ï¼šçµ„åˆä¸‰å€‹ç‰©ç†é‡ Ã— ä¸‰å€‹æ–¹å‘çš„åˆ‡ç‰‡
                        # 1. Z æ–¹å‘åˆ‡ç‰‡ï¼ˆXY å¹³é¢ï¼‰ï¼š[nx*ny, nz]
                        u_xy = u.transpose(2, 0, 1).reshape(nz, -1).T  # [nx*ny, nz]
                        v_xy = v.transpose(2, 0, 1).reshape(nz, -1).T
                        w_xy = w.transpose(2, 0, 1).reshape(nz, -1).T
                        
                        # 2. Y æ–¹å‘åˆ‡ç‰‡ï¼ˆXZ å¹³é¢ï¼‰ï¼š[nx*nz, ny]
                        u_xz = u.transpose(1, 0, 2).reshape(ny, -1).T  # [nx*nz, ny]
                        v_xz = v.transpose(1, 0, 2).reshape(ny, -1).T
                        w_xz = w.transpose(1, 0, 2).reshape(ny, -1).T
                        
                        # 3. X æ–¹å‘åˆ‡ç‰‡ï¼ˆYZ å¹³é¢ï¼‰ï¼š[ny*nz, nx]
                        u_yz = u.transpose(0, 1, 2).reshape(nx, -1).T  # [ny*nz, nx]
                        v_yz = v.transpose(0, 1, 2).reshape(nx, -1).T
                        w_yz = w.transpose(0, 1, 2).reshape(nx, -1).T
                        
                        # çµ„åˆç­–ç•¥ï¼šä½¿ç”¨ XY å¹³é¢ï¼ˆé€šå¸¸ç©ºé–“é»æœ€å¤šï¼‰+ ä¸‰å€‹ç‰©ç†é‡
                        # é€™æ¨£å¾—åˆ° [nx*ny, 3*nz] çš„è³‡æ–™çŸ©é™£
                        data_matrix = np.hstack([u_xy, v_xy, w_xy])  # [16384, 96]
                        
                        # æ›´æ–°åº§æ¨™ï¼ˆåƒ…ä½¿ç”¨ XY å¹³é¢ï¼‰
                        coords = np.stack([
                            X[:, :, 0].flatten(),
                            Y[:, :, 0].flatten(),
                            np.full(nx*ny, z[nz//2])  # Z åº§æ¨™è¨­ç‚ºä¸­é–“å±¤çš„å¯¦éš›å€¼
                        ], axis=1)
                        
                        # å°æ‡‰çš„é€Ÿåº¦å€¼ï¼ˆå–ä¸­é–“ Z å±¤ï¼‰
                        velocities = np.stack([
                            u[:, :, nz//2].flatten(),
                            v[:, :, nz//2].flatten(),
                            w[:, :, nz//2].flatten()
                        ], axis=1)
                        
                        print(f"  âœ… ä½¿ç”¨ 3D å¤šæ–¹å‘åˆ‡ç‰‡ï¼š")
                        print(f"     - u/v/w Ã— {nz} å€‹ Z å±¤ = {3*nz} å€‹ç‰¹å¾µ")
                        print(f"     - ç©ºé–“é»æ•¸: {nx*ny} (XY å¹³é¢)")
                        print(f"  è³‡æ–™çŸ©é™£å½¢ç‹€: {data_matrix.shape} [n_locations, n_features]")
                    
                    else:
                        # 2D è³‡æ–™æˆ– Z å±¤æ•¸å¤ªå°‘ï¼šå›é€€åˆ°åŸå§‹æ–¹æ³•
                        # âš ï¸ è­¦å‘Šï¼šåƒ… 3 å€‹ç‰¹å¾µï¼Œå“è³ªæŒ‡æ¨™æœƒåä½
                        data_matrix = velocities  # [n_locations, 3]
                        print(f"  âš ï¸  ä½¿ç”¨ 2D è³‡æ–™æˆ–å–®å±¤ 3Dï¼šåƒ… 3 å€‹ç‰¹å¾µï¼ˆu,v,wï¼‰")
                        print(f"  å»ºè­°ä½¿ç”¨ POD-based é¸é»ç­–ç•¥ä»¥æå‡å“è³ª")
                    
                else:
                    raise ValueError("JHTDB è³‡æ–™ä¸­æœªæ‰¾åˆ°é€Ÿåº¦å ´ 'u'")
            else:
                raise ValueError("JHTDB è³‡æ–™ä¸­æœªæ‰¾åˆ°åº§æ¨™ 'x', 'y'")
        
        elif jhtdb_path_obj.suffix in ['.h5', '.hdf5']:
            with h5py.File(str(jhtdb_path_obj), 'r') as f:
                # æ ¹æ“šå¯¦éš› HDF5 çµæ§‹èª¿æ•´
                x = np.array(f['x'])
                y = np.array(f['y'])
                z = np.array(f['z'])
                u = np.array(f['u'])
                v = np.array(f['v'])
                w = np.array(f['w'])
                
                X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
                coords = np.stack([X.flatten(), Y.flatten(), Z.flatten()], axis=1)
                velocities = np.stack([u.flatten(), v.flatten(), w.flatten()], axis=1)
                data_matrix = velocities
        
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {jhtdb_path_obj.suffix}")
    
    print(f"   è³‡æ–™çŸ©é™£å½¢ç‹€: {data_matrix.shape}")
    print(f"   åº§æ¨™å½¢ç‹€: {coords.shape}")
    
    # â­ æ•¸æ“šæ¨™æº–åŒ–ï¼ˆæ”¹å–„æ¢ä»¶æ•¸ï¼‰
    # å°æ¯å€‹ç‰¹å¾µï¼ˆåˆ—ï¼‰é€²è¡Œ Z-score æ¨™æº–åŒ–
    data_matrix_normalized = (data_matrix - data_matrix.mean(axis=0)) / (data_matrix.std(axis=0) + 1e-10)
    print(f"   âœ… å·²é€²è¡Œæ•¸æ“šæ¨™æº–åŒ–ï¼ˆZ-scoreï¼‰")
    
    # é¸æ“‡æ„Ÿæ¸¬é»
    if strategy == 'qr_pivot':
        selector = QRPivotSelector(mode='row', pivoting=True)
    elif strategy == 'pod_based':
        selector = PODBasedSelector(n_modes=min(10, data_matrix.shape[1]))
    elif strategy == 'greedy':
        selector = GreedySelector(objective='info_gain')
    else:
        raise ValueError(f"æœªçŸ¥çš„ç­–ç•¥: {strategy}")
    
    print(f"   åŸ·è¡Œ {strategy} é¸é»...")
    selected_indices, metrics = selector.select_sensors(data_matrix_normalized, n_sensors)
    
    print(f"   âœ… é¸æ“‡å®Œæˆ: {len(selected_indices)} å€‹é»")
    print(f"      æ¢ä»¶æ•¸: {metrics.get('condition_number', 'N/A'):.2f}")
    print(f"      èƒ½é‡æ¯”ä¾‹: {metrics.get('energy_ratio', 0.0):.3f}")
    
    result = {
        'indices': selected_indices,
        'coordinates': coords[selected_indices],
        'values': velocities[selected_indices],
        'metrics': metrics,
        'strategy': strategy
    }
    
    return result


def plot_sensor_distribution_2d(sensor_data: Dict[str, Any], output_dir: Path, view: str = 'xy'):
    """ç¹ªè£½æ„Ÿæ¸¬é»çš„ 2D åˆ†ä½ˆåœ–"""
    print(f"\nğŸ“Š ç¹ªè£½ 2D åˆ†ä½ˆåœ– ({view} å¹³é¢)...")
    
    coords = sensor_data['coordinates']
    values = sensor_data.get('values', None)
    
    # æª¢æŸ¥åº§æ¨™ç¶­åº¦
    ndim = coords.shape[1]
    
    # å¦‚æœæ˜¯ 2D è³‡æ–™ä¸”è©¦åœ–ç¹ªè£½ xz/yz å¹³é¢ï¼Œè·³é
    if ndim == 2 and view != 'xy':
        print(f"  âš ï¸  è·³é {view} å¹³é¢ï¼ˆè³‡æ–™ç‚º 2Dï¼‰")
        return
    
    # ç¢ºå®šç¹ªåœ–è»¸
    if view == 'xy':
        x_idx, y_idx = 0, 1
        z_idx = 2 if ndim >= 3 else None
        x_label, y_label = 'x', 'y'
    elif view == 'xz':
        x_idx, y_idx = 0, 2
        z_idx = 1
        x_label, y_label = 'x', 'z'
    elif view == 'yz':
        x_idx, y_idx = 1, 2
        z_idx = 0
        x_label, y_label = 'y', 'z'
    else:
        raise ValueError(f"æœªçŸ¥çš„è¦–è§’: {view}")
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # å­åœ– 1: æŒ‰ç´¢å¼•é¡è‰²ç·¨ç¢¼
    ax = axes[0]
    scatter = ax.scatter(
        coords[:, x_idx], 
        coords[:, y_idx],
        c=np.arange(len(coords)),
        cmap='viridis',
        s=100,
        alpha=0.7,
        edgecolors='black',
        linewidth=1.5
    )
    
    # æ¨™è¨»æ„Ÿæ¸¬é»ç·¨è™Ÿ
    for i, (x, y) in enumerate(zip(coords[:, x_idx], coords[:, y_idx])):
        ax.annotate(
            f'{i}',
            (x, y),
            fontsize=8,
            ha='center',
            va='center',
            color='white',
            weight='bold'
        )
    
    ax.set_xlabel(x_label, fontsize=12)
    ax.set_ylabel(y_label, fontsize=12)
    ax.set_title(f'Sensor Distribution ({view.upper()} plane) - Indexed', fontsize=14)
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal', adjustable='box')
    
    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('Sensor Index', fontsize=10)
    
    # å­åœ– 2: æŒ‰æ•¸å€¼å¤§å°é¡è‰²ç·¨ç¢¼
    ax = axes[1]
    
    if values is not None:
        # ä½¿ç”¨é€Ÿåº¦å¤§å°
        if len(values.shape) == 2 and values.shape[1] >= 3:
            magnitude = np.linalg.norm(values[:, :3], axis=1)
        else:
            magnitude = np.abs(values.flatten())
        
        scatter = ax.scatter(
            coords[:, x_idx], 
            coords[:, y_idx],
            c=magnitude,
            cmap='jet',
            s=100,
            alpha=0.7,
            edgecolors='black',
            linewidth=1.5
        )
        
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('Velocity Magnitude', fontsize=10)
        title_suffix = '- Velocity Magnitude'
    else:
        # ç„¡æ•¸å€¼è³‡æ–™
        if z_idx is not None:
            # 3D è³‡æ–™ï¼šä½¿ç”¨ z åº§æ¨™é¡è‰²ç·¨ç¢¼
            scatter = ax.scatter(
                coords[:, x_idx], 
                coords[:, y_idx],
                c=coords[:, z_idx],
                cmap='coolwarm',
                s=100,
                alpha=0.7,
                edgecolors='black',
                linewidth=1.5
            )
            
            cbar = plt.colorbar(scatter, ax=ax)
            cbar.set_label(f'{["x", "y", "z"][z_idx]} coordinate', fontsize=10)
            title_suffix = f'- {["x", "y", "z"][z_idx].upper()} Position'
        else:
            # 2D è³‡æ–™ï¼šä½¿ç”¨ç´¢å¼•é¡è‰²ç·¨ç¢¼
            scatter = ax.scatter(
                coords[:, x_idx], 
                coords[:, y_idx],
                c=np.arange(len(coords)),
                cmap='viridis',
                s=100,
                alpha=0.7,
                edgecolors='black',
                linewidth=1.5
            )
            
            cbar = plt.colorbar(scatter, ax=ax)
            cbar.set_label('Sensor Index', fontsize=10)
            title_suffix = '- Indexed'
    
    ax.set_xlabel(x_label, fontsize=12)
    ax.set_ylabel(y_label, fontsize=12)
    ax.set_title(f'Sensor Distribution ({view.upper()} plane) {title_suffix}', fontsize=14)
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal', adjustable='box')
    
    plt.tight_layout()
    
    output_path = output_dir / f'sensor_distribution_2d_{view}.png'
    plt.savefig(str(output_path), dpi=150, bbox_inches='tight')
    print(f"  âœ… å·²ä¿å­˜: {output_path}")
    
    plt.close()


def plot_sensor_distribution_3d(sensor_data: Dict[str, Any], output_dir: Path):
    """ç¹ªè£½æ„Ÿæ¸¬é»çš„ 3D åˆ†ä½ˆåœ–"""
    print(f"\nğŸ“Š ç¹ªè£½ 3D åˆ†ä½ˆåœ–...")
    
    coords = sensor_data['coordinates']
    values = sensor_data.get('values', None)
    
    # æª¢æŸ¥åº§æ¨™ç¶­åº¦
    if coords.shape[1] < 3:
        print(f"  âš ï¸  è·³é 3D ç¹ªåœ–ï¼ˆè³‡æ–™ç‚º {coords.shape[1]}Dï¼‰")
        return
    
    fig = plt.figure(figsize=(14, 10))
    ax = fig.add_subplot(111, projection='3d')
    
    # ç¢ºå®šé¡è‰²ç·¨ç¢¼
    if values is not None and len(values.shape) == 2 and values.shape[1] >= 3:
        # ä½¿ç”¨é€Ÿåº¦å¤§å°
        magnitude = np.linalg.norm(values[:, :3], axis=1)
        color_data = magnitude
        color_label = 'Velocity Magnitude'
    else:
        # ä½¿ç”¨ç´¢å¼•
        color_data = np.arange(len(coords))
        color_label = 'Sensor Index'
    
    # ç¹ªè£½æ•£é»
    scatter = ax.scatter(
        coords[:, 0],  # x
        coords[:, 1],  # y
        coords[:, 2],  # z
        c=color_data,
        cmap='viridis',
        s=100,
        alpha=0.7,
        edgecolors='black',
        linewidth=1.5
    )
    
    # æ¨™è¨»éƒ¨åˆ†æ„Ÿæ¸¬é»ç·¨è™Ÿï¼ˆé¿å…éæ–¼æ“æ“ ï¼‰
    n_annotate = min(20, len(coords))
    for i in range(n_annotate):
        ax.text(
            coords[i, 0],
            coords[i, 1],
            coords[i, 2],
            f'{i}',  # 3D text çš„ç¬¬å››å€‹ä½ç½®åƒæ•¸
            fontsize=8,
            color='red',
            fontweight='bold'
        )
    
    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.set_zlabel('z', fontsize=12)  # type: ignore
    ax.set_title(f'3D Sensor Distribution\n({len(coords)} sensors)', fontsize=14)
    
    cbar = plt.colorbar(scatter, ax=ax, shrink=0.5, aspect=10)
    cbar.set_label(color_label, fontsize=10)
    
    # è¨­å®šè¦–è§’
    ax.view_init(elev=20, azim=45)  # type: ignore
    
    plt.tight_layout()
    
    output_path = output_dir / 'sensor_distribution_3d.png'
    plt.savefig(str(output_path), dpi=150, bbox_inches='tight')
    print(f"  âœ… å·²ä¿å­˜: {output_path}")
    
    plt.close()


def plot_sensor_statistics(sensor_data: Dict[str, Any], output_dir: Path):
    """ç¹ªè£½æ„Ÿæ¸¬é»çµ±è¨ˆè³‡è¨Š"""
    print(f"\nğŸ“Š ç¹ªè£½çµ±è¨ˆè³‡è¨Š...")
    
    coords = sensor_data['coordinates']
    values = sensor_data.get('values', None)
    ndim = coords.shape[1]
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # å­åœ– 1: åº§æ¨™åˆ†ä½ˆç›´æ–¹åœ–
    ax = axes[0, 0]
    ax.hist(coords[:, 0], bins=20, alpha=0.7, label='x', color='red')
    ax.hist(coords[:, 1], bins=20, alpha=0.7, label='y', color='green')
    if ndim >= 3:
        ax.hist(coords[:, 2], bins=20, alpha=0.7, label='z', color='blue')
    ax.set_xlabel('Coordinate Value', fontsize=12)
    ax.set_ylabel('Frequency', fontsize=12)
    ax.set_title('Coordinate Distribution', fontsize=14)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # å­åœ– 2: æ„Ÿæ¸¬é»é–“è·é›¢åˆ†ä½ˆ
    ax = axes[0, 1]
    distances = []
    for i in range(len(coords)):
        for j in range(i+1, len(coords)):
            dist = np.linalg.norm(coords[i] - coords[j])
            distances.append(dist)
    
    distances = np.array(distances)
    ax.hist(distances, bins=30, alpha=0.7, color='purple', edgecolor='black')
    ax.axvline(np.mean(distances), color='red', linestyle='--', 
               linewidth=2, label=f'Mean: {np.mean(distances):.3f}')
    ax.axvline(np.median(distances), color='green', linestyle='--', 
               linewidth=2, label=f'Median: {np.median(distances):.3f}')
    ax.set_xlabel('Distance', fontsize=12)
    ax.set_ylabel('Frequency', fontsize=12)
    ax.set_title('Pairwise Distance Distribution', fontsize=14)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # å­åœ– 3: æ•¸å€¼å¤§å°åˆ†ä½ˆï¼ˆå¦‚æœæœ‰ï¼‰
    ax = axes[1, 0]
    if values is not None:
        if len(values.shape) == 2 and values.shape[1] >= 3:
            # é€Ÿåº¦åˆ†é‡
            ax.hist(values[:, 0], bins=20, alpha=0.7, label='u', color='red')
            ax.hist(values[:, 1], bins=20, alpha=0.7, label='v', color='green')
            ax.hist(values[:, 2], bins=20, alpha=0.7, label='w', color='blue')
            ax.set_xlabel('Velocity Component', fontsize=12)
            ax.set_title('Velocity Component Distribution', fontsize=14)
        else:
            ax.hist(values.flatten(), bins=30, alpha=0.7, color='orange', edgecolor='black')
            ax.set_xlabel('Value', fontsize=12)
            ax.set_title('Value Distribution', fontsize=14)
        
        ax.set_ylabel('Frequency', fontsize=12)
        ax.legend()
        ax.grid(True, alpha=0.3)
    else:
        ax.text(0.5, 0.5, 'No value data available', 
                ha='center', va='center', fontsize=14, transform=ax.transAxes)
        ax.set_xticks([])
        ax.set_yticks([])
    
    # å­åœ– 4: ç´¯ç©çµ±è¨ˆè³‡è¨Šæ–‡å­—
    ax = axes[1, 1]
    ax.axis('off')
    
    # å»ºç«‹çµ±è¨ˆæ–‡å­—ï¼ˆè™•ç† 2D/3D æƒ…æ³ï¼‰
    stats_text = f"""
    æ„Ÿæ¸¬é»çµ±è¨ˆè³‡è¨Š
    {'='*40}
    
    ç¸½æ„Ÿæ¸¬é»æ•¸é‡: {len(coords)}
    
    åº§æ¨™ç¯„åœ:
      x: [{coords[:, 0].min():.3f}, {coords[:, 0].max():.3f}]
      y: [{coords[:, 1].min():.3f}, {coords[:, 1].max():.3f}]"""
    
    if ndim >= 3:
        stats_text += f"""
      z: [{coords[:, 2].min():.3f}, {coords[:, 2].max():.3f}]"""
    
    stats_text += f"""
    
    æ„Ÿæ¸¬é»é–“è·é›¢:
      æœ€å°è·é›¢: {distances.min():.4f}
      æœ€å¤§è·é›¢: {distances.max():.4f}
      å¹³å‡è·é›¢: {np.mean(distances):.4f}
      æ¨™æº–å·®: {np.std(distances):.4f}
    """
    
    if values is not None and len(values.shape) == 2 and values.shape[1] >= 3:
        magnitude = np.linalg.norm(values[:, :3], axis=1)
        stats_text += f"""
    é€Ÿåº¦å ´çµ±è¨ˆ:
      |U| ç¯„åœ: [{magnitude.min():.3f}, {magnitude.max():.3f}]
      |U| å¹³å‡: {magnitude.mean():.3f}
      u å¹³å‡: {values[:, 0].mean():.3f}
      v å¹³å‡: {values[:, 1].mean():.3f}
      w å¹³å‡: {values[:, 2].mean():.3f}
        """
    
    if 'metrics' in sensor_data:
        metrics = sensor_data['metrics']
        stats_text += f"""
    QR-Pivot æŒ‡æ¨™:
      æ¢ä»¶æ•¸: {metrics.get('condition_number', 'N/A'):.2f}
      èƒ½é‡æ¯”ä¾‹: {metrics.get('energy_ratio', 0.0):.3f}
      å­ç©ºé–“è¦†è“‹ç‡: {metrics.get('subspace_coverage', 0.0):.3f}
        """
    
    ax.text(0.05, 0.95, stats_text, 
            fontsize=10, 
            verticalalignment='top',
            family='monospace',
            transform=ax.transAxes)
    
    plt.tight_layout()
    
    output_path = output_dir / 'sensor_statistics.png'
    plt.savefig(str(output_path), dpi=150, bbox_inches='tight')
    print(f"  âœ… å·²ä¿å­˜: {output_path}")
    
    plt.close()


def save_sensor_table(sensor_data: Dict[str, Any], output_dir: Path):
    """ä¿å­˜æ„Ÿæ¸¬é»åº§æ¨™èˆ‡æ•¸å€¼è¡¨æ ¼"""
    print(f"\nğŸ’¾ ä¿å­˜æ„Ÿæ¸¬é»è³‡æ–™è¡¨æ ¼...")
    
    coords = sensor_data['coordinates']
    values = sensor_data.get('values', None)
    indices = sensor_data.get('indices', np.arange(len(coords)))
    ndim = coords.shape[1]
    
    # å»ºç«‹è¡¨æ ¼
    output_path = output_dir / 'sensor_table.txt'
    
    with open(str(output_path), 'w') as f:
        f.write("=" * 100 + "\n")
        f.write("QR-Pivot æ„Ÿæ¸¬é»åº§æ¨™èˆ‡æ•¸å€¼è¡¨æ ¼\n")
        f.write("=" * 100 + "\n\n")
        
        if values is not None and len(values.shape) == 2 and values.shape[1] >= 3:
            # é€Ÿåº¦å ´è³‡æ–™
            if ndim >= 3:
                f.write(f"{'Index':>6} {'Global_ID':>10} {'x':>12} {'y':>12} {'z':>12} "
                        f"{'u':>12} {'v':>12} {'w':>12} {'|U|':>12}\n")
                f.write("-" * 100 + "\n")
                
                for i, (idx, coord, vel) in enumerate(zip(indices, coords, values)):
                    magnitude = np.linalg.norm(vel[:3])
                    f.write(f"{i:6d} {idx:10d} {coord[0]:12.6f} {coord[1]:12.6f} {coord[2]:12.6f} "
                            f"{vel[0]:12.6f} {vel[1]:12.6f} {vel[2]:12.6f} {magnitude:12.6f}\n")
            else:
                # 2D è³‡æ–™
                f.write(f"{'Index':>6} {'Global_ID':>10} {'x':>12} {'y':>12} "
                        f"{'u':>12} {'v':>12} {'|U|':>12}\n")
                f.write("-" * 80 + "\n")
                
                for i, (idx, coord, vel) in enumerate(zip(indices, coords, values)):
                    magnitude = np.linalg.norm(vel[:2])
                    f.write(f"{i:6d} {idx:10d} {coord[0]:12.6f} {coord[1]:12.6f} "
                            f"{vel[0]:12.6f} {vel[1]:12.6f} {magnitude:12.6f}\n")
        else:
            # åƒ…åº§æ¨™
            if ndim >= 3:
                f.write(f"{'Index':>6} {'Global_ID':>10} {'x':>12} {'y':>12} {'z':>12}\n")
                f.write("-" * 70 + "\n")
                
                for i, (idx, coord) in enumerate(zip(indices, coords)):
                    f.write(f"{i:6d} {idx:10d} {coord[0]:12.6f} {coord[1]:12.6f} {coord[2]:12.6f}\n")
            else:
                # 2D è³‡æ–™
                f.write(f"{'Index':>6} {'Global_ID':>10} {'x':>12} {'y':>12}\n")
                f.write("-" * 50 + "\n")
                
                for i, (idx, coord) in enumerate(zip(indices, coords)):
                    f.write(f"{i:6d} {idx:10d} {coord[0]:12.6f} {coord[1]:12.6f}\n")
        
        f.write("\n" + "=" * 100 + "\n")
        
        # çµ±è¨ˆæ‘˜è¦
        f.write("\nçµ±è¨ˆæ‘˜è¦:\n")
        f.write(f"  ç¸½æ„Ÿæ¸¬é»æ•¸é‡: {len(coords)}\n")
        f.write(f"  x ç¯„åœ: [{coords[:, 0].min():.6f}, {coords[:, 0].max():.6f}]\n")
        f.write(f"  y ç¯„åœ: [{coords[:, 1].min():.6f}, {coords[:, 1].max():.6f}]\n")
        if ndim >= 3:
            f.write(f"  z ç¯„åœ: [{coords[:, 2].min():.6f}, {coords[:, 2].max():.6f}]\n")
        
        if values is not None and len(values.shape) == 2 and values.shape[1] >= 3:
            magnitude = np.linalg.norm(values[:, :3], axis=1)
            f.write(f"\n  é€Ÿåº¦å¤§å°ç¯„åœ: [{magnitude.min():.6f}, {magnitude.max():.6f}]\n")
            f.write(f"  å¹³å‡é€Ÿåº¦å¤§å°: {magnitude.mean():.6f}\n")
    
    print(f"  âœ… å·²ä¿å­˜: {output_path}")
    
    # åŒæ™‚ä¿å­˜ç‚º JSON
    json_path = output_dir / 'sensor_data.json'
    
    json_data: Dict[str, Any] = {
        'n_sensors': int(len(coords)),
        'indices': indices.tolist(),
        'coordinates': coords.tolist(),
    }
    
    if values is not None:
        json_data['values'] = values.tolist()
    
    # ä¿å­˜åˆ†å±¤è³‡è¨Šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'layer_info' in sensor_data:
        layer_info = sensor_data['layer_info']
        json_data['layer_info'] = {
            layer: {
                'n_selected': int(info['n_selected']),
                'y_range': [float(info['y_range'][0]), float(info['y_range'][1])],
                'indices': info['indices'].tolist()
            }
            for layer, info in layer_info.items()
        }
    
    if 'layer_labels' in sensor_data:
        json_data['layer_labels'] = sensor_data['layer_labels'].tolist()
    
    if 'metadata' in sensor_data:
        metadata = sensor_data['metadata']
        json_data['metadata'] = {
            k: (v.tolist() if isinstance(v, np.ndarray) else v)
            for k, v in metadata.items()
        }
    
    if 'metrics' in sensor_data:
        json_data['metrics'] = {
            k: float(v) if isinstance(v, (int, float, np.number)) else v
            for k, v in sensor_data['metrics'].items()
        }
    
    with open(str(json_path), 'w') as f:
        json.dump(json_data, f, indent=2)
    
    print(f"  âœ… å·²ä¿å­˜: {json_path}")


def compare_strategies(jhtdb_path: str, n_sensors: int, output_dir: Path):
    """æ¯”è¼ƒä¸åŒé¸é»ç­–ç•¥"""
    print(f"\nğŸ” æ¯”è¼ƒä¸åŒé¸é»ç­–ç•¥...")
    
    strategies = {
        'QR-Pivot': 'qr_pivot',
        'POD-based': 'pod_based',
        'Greedy': 'greedy'
    }
    
    results: Dict[str, Dict[str, Any]] = {}
    
    for name, strategy in strategies.items():
        print(f"\n  è¨ˆç®— {name} ç­–ç•¥...")
        try:
            sensor_data = compute_sensors_from_jhtdb(jhtdb_path, n_sensors, strategy)
            results[name] = sensor_data
        except Exception as e:
            print(f"    âŒ å¤±æ•—: {e}")
    
    # ç¹ªè£½æ¯”è¼ƒåœ–
    if len(results) > 0:
        print(f"\n  ç¹ªè£½ç­–ç•¥æ¯”è¼ƒåœ–...")
        
        fig, axes = plt.subplots(1, len(results), figsize=(6*len(results), 5))
        
        if len(results) == 1:
            axes = [axes]
        
        for ax, (name, data) in zip(axes, results.items()):
            coords = data['coordinates']
            
            # 2D æŠ•å½± (xy å¹³é¢)
            scatter = ax.scatter(
                coords[:, 0],
                coords[:, 1],
                c=np.arange(len(coords)),
                cmap='viridis',
                s=80,
                alpha=0.7,
                edgecolors='black',
                linewidth=1.5
            )
            
            ax.set_xlabel('x', fontsize=12)
            ax.set_ylabel('y', fontsize=12)
            ax.set_title(f'{name}\n({len(coords)} sensors)', fontsize=14)
            ax.grid(True, alpha=0.3)
            ax.set_aspect('equal', adjustable='box')
            
            # é¡¯ç¤ºæŒ‡æ¨™
            metrics = data.get('metrics', {})
            cond = metrics.get('condition_number', np.inf)
            energy = metrics.get('energy_ratio', 0.0)
            
            ax.text(0.05, 0.95, 
                    f'Cond: {cond:.1f}\nEnergy: {energy:.2f}',
                    transform=ax.transAxes,
                    fontsize=10,
                    verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        plt.tight_layout()
        
        output_path = output_dir / 'strategy_comparison.png'
        plt.savefig(str(output_path), dpi=150, bbox_inches='tight')
        print(f"  âœ… å·²ä¿å­˜: {output_path}")
        
        plt.close()


def main():
    parser = argparse.ArgumentParser(
        description='QR-Pivot æ„Ÿæ¸¬é»åˆ†ä½ˆè¦–è¦ºåŒ–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    # è¼¸å…¥é¸é …ï¼ˆäºŒé¸ä¸€ï¼‰
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument('--input', type=str,
                            help='æ„Ÿæ¸¬é»è³‡æ–™æª”æ¡ˆè·¯å¾‘ (.npz, .h5)')
    input_group.add_argument('--jhtdb-data', type=str,
                            help='JHTDB è³‡æ–™æª”æ¡ˆè·¯å¾‘ï¼ˆé‡æ–°è¨ˆç®—æ„Ÿæ¸¬é»ï¼‰')
    
    # åƒæ•¸é¸é …
    parser.add_argument('--n-sensors', type=int, default=50,
                        help='æ„Ÿæ¸¬é»æ•¸é‡ï¼ˆä½¿ç”¨ --jhtdb-data æ™‚ï¼‰')
    parser.add_argument('--strategy', type=str, default='qr_pivot',
                        choices=['qr_pivot', 'pod_based', 'greedy'],
                        help='æ„Ÿæ¸¬é»é¸æ“‡ç­–ç•¥')
    parser.add_argument('--compare-strategies', action='store_true',
                        help='æ¯”è¼ƒå¤šç¨®ç­–ç•¥')
    
    # å¤šæ™‚é–“æ­¥è³‡æ–™æ”¯æ´ï¼ˆæ–°å¢ï¼‰â­
    parser.add_argument('--temporal-data', type=str, default=None,
                        help='å¤šæ™‚é–“æ­¥å¿«ç…§è³‡æ–™æª”æ¡ˆè·¯å¾‘ï¼ˆ.npz æ ¼å¼ï¼Œå„ªå…ˆæ–¼ --jhtdb-dataï¼‰')
    
    # è¼¸å‡ºé¸é …
    parser.add_argument('--output', type=str, default='results/sensor_analysis',
                        help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--views', type=str, nargs='+', 
                        default=['xy', 'xz', 'yz'],
                        help='2D è¦–è§’åˆ—è¡¨')
    
    args = parser.parse_args()
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 80)
    print("  ğŸ¯ QR-Pivot æ„Ÿæ¸¬é»åˆ†ä½ˆè¦–è¦ºåŒ–å·¥å…·")
    print("=" * 80)
    
    # è¼‰å…¥æˆ–è¨ˆç®—æ„Ÿæ¸¬é»è³‡æ–™
    if args.input:
        sensor_data = load_sensor_data(args.input)
    else:
        sensor_data = compute_sensors_from_jhtdb(
            args.jhtdb_data, 
            args.n_sensors, 
            args.strategy,
            temporal_data_path=args.temporal_data  # â­ å‚³éå¤šæ™‚é–“æ­¥è³‡æ–™
        )
    
    # è¦–è¦ºåŒ–
    print(f"\n{'='*80}")
    print("  ğŸ“Š ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨")
    print(f"{'='*80}")
    
    # 2D åˆ†ä½ˆåœ–
    for view in args.views:
        plot_sensor_distribution_2d(sensor_data, output_dir, view)
    
    # 3D åˆ†ä½ˆåœ–
    plot_sensor_distribution_3d(sensor_data, output_dir)
    
    # çµ±è¨ˆè³‡è¨Š
    plot_sensor_statistics(sensor_data, output_dir)
    
    # ä¿å­˜è¡¨æ ¼
    save_sensor_table(sensor_data, output_dir)
    
    # ç­–ç•¥æ¯”è¼ƒï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
    if args.compare_strategies and args.jhtdb_data:
        compare_strategies(args.jhtdb_data, args.n_sensors, output_dir)
    
    print(f"\n{'='*80}")
    print("  âœ… å®Œæˆ")
    print(f"{'='*80}")
    print(f"\nçµæœå·²ä¿å­˜è‡³: {output_dir.absolute()}")
    print(f"\nåŒ…å«æª”æ¡ˆ:")
    for file in sorted(output_dir.glob('*')):
        print(f"  - {file.name}")


if __name__ == '__main__':
    main()
