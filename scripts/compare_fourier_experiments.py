#!/usr/bin/env python3
"""
Fourier Features å°æ¯”å¯¦é©—è©•ä¼°è…³æœ¬

æ¯”è¼ƒ Baseline (ç„¡ Fourier) èˆ‡ Fourier (æœ‰ Fourier) çš„è¨“ç·´çµæœï¼š
1. è¼‰å…¥å…©å€‹æ¨¡å‹çš„æœ€çµ‚æª¢æŸ¥é»
2. åœ¨ç›¸åŒæ¸¬è©¦é›†ä¸Šè©•ä¼°
3. ç”Ÿæˆå°æ¯”åˆ†æå ±å‘Š

ä½¿ç”¨æ–¹å¼:
    python scripts/compare_fourier_experiments.py
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
import torch
import yaml
import matplotlib.pyplot as plt
from datetime import datetime
import re
import logging

# åæ¨™æº–åŒ–å·¥å…·
from pinnx.utils.denormalization import denormalize_output

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(message)s')

# ============================================================
# é…ç½®
# ============================================================

BASELINE_CONFIG = "configs/vs_pinn_baseline_1k.yml"
FOURIER_CONFIG = "configs/vs_pinn_fourier_1k.yml"

BASELINE_CHECKPOINT = "checkpoints/vs_pinn_baseline_1k_latest.pth"
FOURIER_CHECKPOINT = "checkpoints/vs_pinn_fourier_1k_latest.pth"

TEST_DATA = "data/jhtdb/channel_flow_re1000/cutout3d_128x128x32.npz"

BASELINE_LOG = "log/baseline_1k_training.log"
FOURIER_LOG = "log/fourier_1k_training.log"

OUTPUT_DIR = Path("results/fourier_comparison")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

REPORT_FILE = OUTPUT_DIR / "comparison_report.md"

# ============================================================
# å·¥å…·å‡½æ•¸
# ============================================================

def load_config(config_path):
    """è¼‰å…¥ YAML é…ç½®"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def load_test_data(data_path):
    """è¼‰å…¥æ¸¬è©¦è³‡æ–™"""
    print(f"\nğŸ“‚ è¼‰å…¥æ¸¬è©¦è³‡æ–™: {data_path}")
    data = np.load(data_path)
    
    # æª¢æŸ¥è³‡æ–™æ ¼å¼
    if 'coords' in data and 'u' in data:
        # æ ¼å¼ 1: coords, u, v, w, p
        coords = data['coords']
        u_true = data['u']
        v_true = data['v']
        w_true = data['w'] if 'w' in data else None
        p_true = data['p']
    elif 'x' in data and 'y' in data:
        # æ ¼å¼ 2: x, y, z (ç¶²æ ¼)
        x = data['x']
        y = data['y']
        z = data['z'] if 'z' in data else None
        
        if z is not None:
            # 3D ç¶²æ ¼
            X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
            coords = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=-1)
        else:
            # 2D ç¶²æ ¼
            X, Y = np.meshgrid(x, y, indexing='ij')
            coords = np.stack([X.ravel(), Y.ravel()], axis=-1)
        
        u_true = data['u'].ravel()
        v_true = data['v'].ravel()
        w_true = data['w'].ravel() if 'w' in data else None
        p_true = data['p'].ravel()
    else:
        raise ValueError(f"ç„¡æ³•è­˜åˆ¥è³‡æ–™æ ¼å¼: {list(data.keys())}")
    
    n_points = coords.shape[0]
    n_vars = 4 if w_true is not None else 3
    
    print(f"  âœ… åº§æ¨™å½¢ç‹€: {coords.shape}")
    print(f"  âœ… æ¸¬è©¦é»æ•¸: {n_points}")
    print(f"  âœ… è®Šæ•¸æ•¸é‡: {n_vars} {'(u,v,w,p)' if w_true is not None else '(u,v,p)'}")
    
    # è¨ˆç®—çœŸå¯¦å€¼ç¯„åœï¼ˆç”¨æ–¼å¾Œè™•ç†ç¸®æ”¾ï¼‰
    true_ranges = {
        'u': (float(u_true.min()), float(u_true.max())),
        'v': (float(v_true.min()), float(v_true.max())),
    }
    if w_true is not None:
        true_ranges['w'] = (float(w_true.min()), float(w_true.max()))
    true_ranges['p'] = (float(p_true.min()), float(p_true.max()))
    
    return {
        'coords': coords,
        'u': u_true,
        'v': v_true,
        'w': w_true,
        'p': p_true,
        'n_points': n_points,
        'is_3d': w_true is not None,
        'true_ranges': true_ranges  # æ–°å¢
    }

def load_model(config_path, checkpoint_path, device):
    """è¼‰å…¥æ¨¡å‹ï¼ˆç°¡åŒ–ç‰ˆï¼Œé©ç”¨æ–¼è©•ä¼°ï¼‰"""
    from pinnx.models.fourier_mlp import PINNNet
    
    print(f"\nğŸ”§ è¼‰å…¥æ¨¡å‹: {checkpoint_path}")
    
    # è¼‰å…¥é…ç½®
    config = load_config(config_path)
    model_cfg = config['model']
    
    # å‰µå»ºæ¨¡å‹
    model = PINNNet(
        in_dim=model_cfg['in_dim'],
        out_dim=model_cfg['out_dim'],
        width=model_cfg['width'],
        depth=model_cfg['depth'],
        activation=model_cfg.get('activation', 'sine'),
        use_fourier=model_cfg.get('use_fourier', False),
        fourier_m=model_cfg.get('fourier_m', 0),
        fourier_sigma=model_cfg.get('fourier_sigma', 1.0),
    ).to(device)
    
    # è¼‰å…¥æ¬Šé‡
    checkpoint = torch.load(checkpoint_path, map_location=device)
    if 'model_state_dict' in checkpoint:
        # ä½¿ç”¨ strict=False å…è¨±é¡å¤–çš„ VS-PINN åƒæ•¸ï¼ˆå¦‚ input_scale_factorsï¼‰
        missing_keys, unexpected_keys = model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        if unexpected_keys:
            print(f"  â„¹ï¸  è·³éçš„é¡å¤–åƒæ•¸: {unexpected_keys}")
    else:
        model.load_state_dict(checkpoint, strict=False)
    
    model.eval()
    
    n_params = sum(p.numel() for p in model.parameters())
    print(f"  âœ… æ¨¡å‹åƒæ•¸: {n_params:,}")
    print(f"  âœ… Fourier Features: {'å•Ÿç”¨' if model_cfg.get('use_fourier', False) else 'ç¦ç”¨'}")
    
    return model, config

def predict(model, coords, device, batch_size=4096):
    """æ‰¹æ¬¡é æ¸¬"""
    n_points = coords.shape[0]
    n_batches = (n_points + batch_size - 1) // batch_size
    
    predictions = []
    
    with torch.no_grad():
        for i in range(n_batches):
            start_idx = i * batch_size
            end_idx = min((i + 1) * batch_size, n_points)
            
            batch_coords = torch.tensor(coords[start_idx:end_idx], dtype=torch.float32, device=device)
            batch_pred = model(batch_coords)
            predictions.append(batch_pred.cpu().numpy())
    
    return np.vstack(predictions)

def compute_metrics(pred, true, var_name):
    """è¨ˆç®—è©•ä¼°æŒ‡æ¨™"""
    # ç›¸å° L2 èª¤å·®
    rel_l2 = np.linalg.norm(pred - true) / (np.linalg.norm(true) + 1e-10)
    
    # RMSE
    rmse = np.sqrt(np.mean((pred - true) ** 2))
    
    # æœ€å¤§èª¤å·®
    max_error = np.max(np.abs(pred - true))
    
    # å¹³å‡çµ•å°èª¤å·®
    mae = np.mean(np.abs(pred - true))
    
    return {
        'rel_l2': rel_l2 * 100,  # è½‰ç‚ºç™¾åˆ†æ¯”
        'rmse': rmse,
        'max_error': max_error,
        'mae': mae
    }

def parse_training_log(log_path):
    """è§£æè¨“ç·´æ—¥èªŒï¼Œæå–æå¤±æ›²ç·š"""
    epochs = []
    total_losses = []
    residual_losses = []
    data_losses = []
    conservation_errors = []
    
    with open(log_path, 'r') as f:
        for line in f:
            # è§£æ epoch æå¤±
            epoch_match = re.search(r'Epoch\s+(\d+)\s+\|\s+Total:\s+([\d.]+)\s+\|\s+Residual:\s+([\d.]+)\s+.*Data:\s+([\d.]+)', line)
            if epoch_match:
                epochs.append(int(epoch_match.group(1)))
                total_losses.append(float(epoch_match.group(2)))
                residual_losses.append(float(epoch_match.group(3)))
                data_losses.append(float(epoch_match.group(4)))
            
            # è§£ææœ€ä½³å®ˆæ†èª¤å·®
            cons_match = re.search(r'New best conservation_error:\s+([\d.]+)\s+at epoch\s+(\d+)', line)
            if cons_match:
                error = float(cons_match.group(1))
                epoch = int(cons_match.group(2))
                conservation_errors.append((epoch, error))
    
    return {
        'epochs': np.array(epochs),
        'total_loss': np.array(total_losses),
        'residual_loss': np.array(residual_losses),
        'data_loss': np.array(data_losses),
        'conservation_errors': conservation_errors
    }

# ============================================================
# ä¸»è©•ä¼°å‡½æ•¸
# ============================================================

def main():
    print("=" * 60)
    print("ğŸ“Š Fourier Features å°æ¯”å¯¦é©—è©•ä¼°")
    print("=" * 60)
    
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {device}")
    
    # ----------------------------------------
    # 1. è¼‰å…¥æ¸¬è©¦è³‡æ–™
    # ----------------------------------------
    test_data = load_test_data(TEST_DATA)
    
    # ----------------------------------------
    # 2. è¼‰å…¥æ¨¡å‹
    # ----------------------------------------
    baseline_model, baseline_config = load_model(BASELINE_CONFIG, BASELINE_CHECKPOINT, device)
    fourier_model, fourier_config = load_model(FOURIER_CONFIG, FOURIER_CHECKPOINT, device)
    
    # ----------------------------------------
    # 3. é æ¸¬
    # ----------------------------------------
    print("\n" + "=" * 60)
    print("ğŸ”® é–‹å§‹é æ¸¬...")
    print("=" * 60)
    
    print("\nğŸ“Š Baseline é æ¸¬ä¸­...")
    baseline_pred = predict(baseline_model, test_data['coords'], device)
    
    # ğŸ”§ å¾Œè™•ç†ç¸®æ”¾ Baseline é æ¸¬ï¼ˆè‡ªå‹•ç¯„åœæ˜ å°„ï¼‰
    print("  ğŸ”„ åŸ·è¡Œå¾Œè™•ç†ç¸®æ”¾ (post_scaling)...")
    baseline_pred = denormalize_output(
        baseline_pred, 
        baseline_config, 
        output_norm_type='post_scaling',
        true_ranges=test_data['true_ranges'],
        verbose=False
    )
    print(f"  ğŸ“Š Baseline ç¸®æ”¾å¾Œç¯„åœ: u=[{baseline_pred[:, 0].min():.2f}, {baseline_pred[:, 0].max():.2f}], "
          f"p=[{baseline_pred[:, 3].min():.2f}, {baseline_pred[:, 3].max():.2f}]")
    
    print("\nğŸ“Š Fourier é æ¸¬ä¸­...")
    fourier_pred = predict(fourier_model, test_data['coords'], device)
    
    # ğŸ”§ å¾Œè™•ç†ç¸®æ”¾ Fourier é æ¸¬ï¼ˆè‡ªå‹•ç¯„åœæ˜ å°„ï¼‰
    print("  ğŸ”„ åŸ·è¡Œå¾Œè™•ç†ç¸®æ”¾ (post_scaling)...")
    fourier_pred = denormalize_output(
        fourier_pred, 
        fourier_config, 
        output_norm_type='post_scaling',
        true_ranges=test_data['true_ranges'],
        verbose=False
    )
    print(f"  ğŸ“Š Fourier ç¸®æ”¾å¾Œç¯„åœ: u=[{fourier_pred[:, 0].min():.2f}, {fourier_pred[:, 0].max():.2f}], "
          f"p=[{fourier_pred[:, 3].min():.2f}, {fourier_pred[:, 3].max():.2f}]")
    
    # ğŸ“Š çœŸå¯¦å€¼ç¯„åœï¼ˆé©—è­‰ï¼‰
    print(f"\n  ğŸ“Š çœŸå¯¦å€¼ç¯„åœ: u=[{test_data['u'].min():.2f}, {test_data['u'].max():.2f}], "
          f"p=[{test_data['p'].min():.2f}, {test_data['p'].max():.2f}]")
    
    # ----------------------------------------
    # 4. è¨ˆç®—æŒ‡æ¨™
    # ----------------------------------------
    print("\n" + "=" * 60)
    print("ğŸ“ˆ è¨ˆç®—è©•ä¼°æŒ‡æ¨™...")
    print("=" * 60)
    
    results = {
        'baseline': {},
        'fourier': {}
    }
    
    var_names = ['u', 'v', 'w', 'p'] if test_data['is_3d'] else ['u', 'v', 'p']
    
    for i, var in enumerate(var_names):
        if var == 'w' and test_data['w'] is None:
            continue
        
        true_data = test_data[var]
        
        baseline_metrics = compute_metrics(baseline_pred[:, i], true_data, var)
        fourier_metrics = compute_metrics(fourier_pred[:, i], true_data, var)
        
        results['baseline'][var] = baseline_metrics
        results['fourier'][var] = fourier_metrics
        
        print(f"\n{var.upper()} é€Ÿåº¦:" if var != 'p' else f"\nå£“åŠ›:")
        print(f"  Baseline - ç›¸å° L2: {baseline_metrics['rel_l2']:.2f}%")
        print(f"  Fourier  - ç›¸å° L2: {fourier_metrics['rel_l2']:.2f}%")
    
    # ----------------------------------------
    # 5. è§£æè¨“ç·´æ—¥èªŒ
    # ----------------------------------------
    print("\n" + "=" * 60)
    print("ğŸ“œ è§£æè¨“ç·´æ—¥èªŒ...")
    print("=" * 60)
    
    baseline_log = parse_training_log(BASELINE_LOG)
    fourier_log = parse_training_log(FOURIER_LOG)
    
    print(f"\n  Baseline è¨“ç·´ epochs: {len(baseline_log['epochs'])}")
    print(f"  Fourier è¨“ç·´ epochs: {len(fourier_log['epochs'])}")
    
    # ----------------------------------------
    # 6. ç”Ÿæˆå°æ¯”åœ–è¡¨
    # ----------------------------------------
    print("\n" + "=" * 60)
    print("ğŸ“Š ç”Ÿæˆå°æ¯”åœ–è¡¨...")
    print("=" * 60)
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 6.1 Total Loss
    ax = axes[0, 0]
    ax.plot(baseline_log['epochs'], baseline_log['total_loss'], label='Baseline', linewidth=2)
    ax.plot(fourier_log['epochs'], fourier_log['total_loss'], label='Fourier', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Total Loss')
    ax.set_title('Total Loss Comparison')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_yscale('log')
    
    # 6.2 Residual Loss
    ax = axes[0, 1]
    ax.plot(baseline_log['epochs'], baseline_log['residual_loss'], label='Baseline', linewidth=2)
    ax.plot(fourier_log['epochs'], fourier_log['residual_loss'], label='Fourier', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Residual Loss')
    ax.set_title('Physics Residual Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_yscale('log')
    
    # 6.3 Data Loss
    ax = axes[1, 0]
    ax.plot(baseline_log['epochs'], baseline_log['data_loss'], label='Baseline', linewidth=2)
    ax.plot(fourier_log['epochs'], fourier_log['data_loss'], label='Fourier', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Data Loss')
    ax.set_title('Data Fitting Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 6.4 ç›¸å° L2 èª¤å·®å°æ¯”ï¼ˆbar chartï¼‰
    ax = axes[1, 1]
    x_pos = np.arange(len(var_names))
    baseline_errors = [results['baseline'][v]['rel_l2'] for v in var_names]
    fourier_errors = [results['fourier'][v]['rel_l2'] for v in var_names]
    
    width = 0.35
    ax.bar(x_pos - width/2, baseline_errors, width, label='Baseline', alpha=0.8)
    ax.bar(x_pos + width/2, fourier_errors, width, label='Fourier', alpha=0.8)
    ax.set_xlabel('Variable')
    ax.set_ylabel('Relative L2 Error (%)')
    ax.set_title('Final Prediction Error')
    ax.set_xticks(x_pos)
    ax.set_xticklabels(var_names)
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    
    plot_path = OUTPUT_DIR / "training_comparison.png"
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    print(f"  âœ… åœ–è¡¨å·²ä¿å­˜: {plot_path}")
    
    # ----------------------------------------
    # 7. ç”Ÿæˆ Markdown å ±å‘Š
    # ----------------------------------------
    print("\n" + "=" * 60)
    print("ğŸ“ ç”Ÿæˆè©•ä¼°å ±å‘Š...")
    print("=" * 60)
    
    with open(REPORT_FILE, 'w') as f:
        f.write("# Fourier Features å°æ¯”å¯¦é©—å ±å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        f.write("## ğŸ“‹ å¯¦é©—é…ç½®\n\n")
        f.write("| é …ç›® | Baseline | Fourier |\n")
        f.write("|------|----------|----------|\n")
        f.write(f"| **Fourier Features** | ç¦ç”¨ | å•Ÿç”¨ |\n")
        f.write(f"| **Fourier M** | 0 | 64 |\n")
        f.write(f"| **Fourier Sigma** | - | 5.0 |\n")
        f.write(f"| **æ¨¡å‹æ¶æ§‹** | {baseline_config['model']['depth']}Ã—{baseline_config['model']['width']} | {fourier_config['model']['depth']}Ã—{fourier_config['model']['width']} |\n")
        f.write(f"| **æ¿€æ´»å‡½æ•¸** | {baseline_config['model']['activation']} | {fourier_config['model']['activation']} |\n")
        f.write(f"| **è¨“ç·´ Epochs** | {len(baseline_log['epochs'])} | {len(fourier_log['epochs'])} |\n")
        f.write(f"| **æ„Ÿæ¸¬é»æ•¸ (K)** | 30 | 30 |\n\n")
        
        f.write("## ğŸ“Š é æ¸¬èª¤å·®å°æ¯”\n\n")
        f.write("**æ¸¬è©¦é›†**: 3D Cutout (128Ã—128Ã—32 = 524,288 é»)\n\n")
        f.write("| è®Šæ•¸ | Baseline L2 (%) | Fourier L2 (%) | æ”¹å–„ |\n")
        f.write("|------|----------------|---------------|------|\n")
        
        for var in var_names:
            baseline_l2 = results['baseline'][var]['rel_l2']
            fourier_l2 = results['fourier'][var]['rel_l2']
            improvement = ((baseline_l2 - fourier_l2) / baseline_l2) * 100 if baseline_l2 > 0 else 0
            improvement_str = f"{'â†“' if improvement > 0 else 'â†‘'} {abs(improvement):.1f}%"
            
            f.write(f"| **{var.upper()}** | {baseline_l2:.2f} | {fourier_l2:.2f} | {improvement_str} |\n")
        
        f.write("\n## ğŸ“ˆ è¨“ç·´æ•ˆç‡å°æ¯”\n\n")
        
        baseline_final_loss = baseline_log['total_loss'][-1] if len(baseline_log['total_loss']) > 0 else 0
        fourier_final_loss = fourier_log['total_loss'][-1] if len(fourier_log['total_loss']) > 0 else 0
        
        baseline_best_cons = min([e[1] for e in baseline_log['conservation_errors']]) if baseline_log['conservation_errors'] else 0
        fourier_best_cons = min([e[1] for e in fourier_log['conservation_errors']]) if fourier_log['conservation_errors'] else 0
        
        f.write("| æŒ‡æ¨™ | Baseline | Fourier |\n")
        f.write("|------|----------|----------|\n")
        f.write(f"| **æœ€çµ‚ Total Loss** | {baseline_final_loss:.4f} | {fourier_final_loss:.4f} |\n")
        f.write(f"| **æœ€ä½³ Conservation Error** | {baseline_best_cons:.6f} | {fourier_best_cons:.6f} |\n")
        f.write(f"| **è¨“ç·´ Epochs** | {len(baseline_log['epochs'])} | {len(fourier_log['epochs'])} |\n")
        
        f.write("\n## ğŸ“Š å¯è¦–åŒ–\n\n")
        f.write(f"![è¨“ç·´å°æ¯”]({plot_path.name})\n\n")
        
        f.write("## ğŸ¯ çµè«–\n\n")
        
        # è¨ˆç®—å¹³å‡æ”¹å–„
        avg_improvement = np.mean([
            ((results['baseline'][v]['rel_l2'] - results['fourier'][v]['rel_l2']) / results['baseline'][v]['rel_l2']) * 100
            for v in var_names
        ])
        
        if avg_improvement > 0:
            f.write(f"âœ… **Fourier Features å¸¶ä¾†é¡¯è‘—æ”¹å–„**ï¼šå¹³å‡ç›¸å° L2 èª¤å·®ä¸‹é™ **{avg_improvement:.1f}%**\n\n")
        elif avg_improvement < -5:
            f.write(f"âŒ **Fourier Features æ•ˆæœä¸ä½³**ï¼šå¹³å‡ç›¸å° L2 èª¤å·®ä¸Šå‡ **{abs(avg_improvement):.1f}%**\n\n")
        else:
            f.write(f"âš–ï¸ **Fourier Features å½±éŸ¿ä¸å¤§**ï¼šå¹³å‡ç›¸å° L2 èª¤å·®è®ŠåŒ– **{avg_improvement:.1f}%**\n\n")
        
        f.write("---\n\n")
        f.write("**å ±å‘ŠçµæŸ**\n")
    
    print(f"  âœ… å ±å‘Šå·²ä¿å­˜: {REPORT_FILE}")
    
    print("\n" + "=" * 60)
    print("âœ… è©•ä¼°å®Œæˆï¼")
    print("=" * 60)
    print(f"\nğŸ“ çµæœä½ç½®: {OUTPUT_DIR}")
    print(f"   - å ±å‘Š: {REPORT_FILE.name}")
    print(f"   - åœ–è¡¨: training_comparison.png")

if __name__ == "__main__":
    main()
