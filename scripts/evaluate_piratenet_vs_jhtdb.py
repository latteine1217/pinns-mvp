"""
PirateNet vs JHTDB çœŸå¯¦æ•¸æ“šå°æ¯”è©•ä¼°
=====================================

è©•ä¼°é …ç›®ï¼š
1. ç›¸å° L2 èª¤å·®ï¼ˆu, v, w, pï¼‰
2. çµ±è¨ˆé‡å°æ¯”ï¼ˆå‡å€¼ã€æ¨™æº–å·®ã€Reynolds æ‡‰åŠ›ï¼‰
3. ç‰©ç†æ®˜å·®ï¼ˆNS æ–¹ç¨‹æ»¿è¶³åº¦ï¼‰
"""

import torch
import numpy as np
from pathlib import Path
import json
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from pinnx.models import create_pinn_model
from pinnx.train.config_loader import load_config


def load_checkpoint(checkpoint_path, device='mps'):
    """è¼‰å…¥è¨“ç·´æª¢æŸ¥é»"""
    checkpoint = torch.load(checkpoint_path, map_location=device)
    epoch = checkpoint.get('epoch', 'N/A')
    loss = checkpoint.get('loss', float('nan'))
    print(f"âœ… è¼‰å…¥æª¢æŸ¥é»: epoch {epoch}")
    if isinstance(loss, (int, float)):
        print(f"   è¨“ç·´æå¤±: {loss:.4e}")
    else:
        print(f"   è¨“ç·´æå¤±: {loss}")
    return checkpoint


def load_jhtdb_ground_truth(jhtdb_path):
    """è¼‰å…¥ JHTDB çœŸå¯¦æ•¸æ“š"""
    data = np.load(jhtdb_path)
    
    # åº§æ¨™æ˜¯ 1D æ•¸çµ„ï¼Œéœ€è¦å»ºç«‹ç¶²æ ¼
    x_1d = data['x']  # (128,)
    y_1d = data['y']  # (128,)
    z_1d = data['z']  # (32,)
    
    # å»ºç«‹ 3D ç¶²æ ¼
    X, Y, Z = np.meshgrid(x_1d, y_1d, z_1d, indexing='ij')
    
    # åº§æ¨™çŸ©é™£
    coords = np.stack([
        X.flatten(),
        Y.flatten(),
        Z.flatten()
    ], axis=1)
    
    # å ´è®Šé‡
    fields = {
        'u': data['u'].flatten(),
        'v': data['v'].flatten(),
        'w': data['w'].flatten(),
        'p': data['p'].flatten() if 'p' in data else None
    }
    
    print(f"âœ… JHTDB æ•¸æ“š: {coords.shape[0]} å€‹é»")
    print(f"   ç¶²æ ¼å½¢ç‹€: {data['u'].shape}")
    print(f"   åŸŸç¯„åœ: x=[{x_1d.min():.2f}, {x_1d.max():.2f}]")
    print(f"           y=[{y_1d.min():.2f}, {y_1d.max():.2f}]")
    print(f"           z=[{z_1d.min():.2f}, {z_1d.max():.2f}]")
    
    return coords, fields, data


def create_model_from_checkpoint(checkpoint, config_path, device='mps'):
    """å¾æª¢æŸ¥é»å‰µå»ºæ¨¡å‹"""
    # ğŸ”§ å„ªå…ˆä½¿ç”¨æª¢æŸ¥é»ä¸­ä¿å­˜çš„é…ç½®ï¼ˆæ›´æº–ç¢ºï¼‰
    ckpt_cfg = checkpoint.get('config', {})
    file_cfg = load_config(config_path)
    
    # åˆä½µé…ç½®ï¼šæª¢æŸ¥é»å„ªå…ˆï¼Œæ–‡ä»¶é…ç½®è£œå……
    cfg = {**file_cfg, **ckpt_cfg} if ckpt_cfg else file_cfg
    model_cfg = cfg.get('model', {})
    physics_cfg = cfg.get('physics', {})
    
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®ä¾†æº: {'æª¢æŸ¥é»' if ckpt_cfg else 'é…ç½®æ–‡ä»¶'}")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ VS-PINN ç¸®æ”¾å› å­
    input_scale_factors = None
    
    # ğŸ”§ ä¿®å¾©ï¼šæ”¯æ´å…©ç¨®é…ç½®è·¯å¾‘
    # è·¯å¾‘ 1: physics.vs_pinn.scaling_factors.* (æ¨™æº–è·¯å¾‘)
    # è·¯å¾‘ 2: physics.scaling.* (èˆŠç‰ˆè·¯å¾‘)
    if 'vs_pinn' in physics_cfg and 'scaling_factors' in physics_cfg['vs_pinn']:
        vs_pinn_cfg = physics_cfg['vs_pinn']['scaling_factors']
        scale_factors = [
            vs_pinn_cfg.get('N_x', 1.0),
            vs_pinn_cfg.get('N_y', 1.0),
            vs_pinn_cfg.get('N_z', 1.0)
        ]
        input_scale_factors = scale_factors
        print(f"ğŸ”§ VS-PINN ç¸®æ”¾å› å­ (vs_pinn.scaling_factors): {scale_factors}")
    elif 'scaling' in physics_cfg and physics_cfg['scaling'].get('use_scaling', False):
        scale_factors = [
            physics_cfg['scaling'].get('N_x', 1.0),
            physics_cfg['scaling'].get('N_y', 1.0),
            physics_cfg['scaling'].get('N_z', 1.0)
        ]
        input_scale_factors = scale_factors
        print(f"ğŸ”§ VS-PINN ç¸®æ”¾å› å­ (scaling.*): {scale_factors}")
    
    # ğŸ”§ è™•ç† Fourier ç‰¹å¾µé…ç½®ï¼ˆæ”¯æ´å¤šç¨®æ ¼å¼ï¼‰
    # å„ªå…ˆç´šï¼šmodel.fourier_m > model.fourier_features.fourier_m
    fourier_m = model_cfg.get('fourier_m', 32)
    fourier_sigma = model_cfg.get('fourier_sigma', 1.0)
    
    # å¾ fourier_features é…ç½®ä¸­è®€å–ï¼ˆä½œç‚ºå‚™é¸ï¼‰
    if 'fourier_features' in model_cfg and fourier_m == 32:  # åƒ…ç•¶æœªæ˜ç¢ºè¨­å®šæ™‚ä½¿ç”¨
        ff_cfg = model_cfg['fourier_features']
        # æ³¨æ„ï¼šä¸è¦†è“‹å·²å­˜åœ¨çš„ fourier_m
        if 'fourier_m' not in model_cfg:
            fourier_m = ff_cfg.get('fourier_m', fourier_m)
        if 'fourier_sigma' not in model_cfg:
            fourier_sigma = ff_cfg.get('fourier_sigma', fourier_sigma)
    
    print(f"ğŸ“ æ¨¡å‹æ¶æ§‹: {model_cfg.get('width')}Ã—{model_cfg.get('depth')}")
    print(f"ğŸŒŠ Fourier ç‰¹å¾µ: M={fourier_m}, Ïƒ={fourier_sigma}")
    print(f"ğŸ­ æ¿€æ´»å‡½æ•¸: {model_cfg.get('activation')}")
    
    model_config = {
        'type': model_cfg.get('type', 'fourier_vs_mlp'),
        'in_dim': model_cfg.get('in_dim', 3),
        'out_dim': model_cfg.get('out_dim', 4),
        'width': model_cfg.get('width', model_cfg.get('hidden_dim', 256)),
        'depth': model_cfg.get('depth', model_cfg.get('num_layers', 4)),
        'activation': model_cfg.get('activation', 'swish'),
        'fourier_m': fourier_m,
        'fourier_sigma': fourier_sigma,
        'use_fourier': model_cfg.get('use_fourier', True),
        'use_rwf': model_cfg.get('use_rwf', False),
        'rwf_scale_std': model_cfg.get('rwf_scale_std', 0.1),
        'rwf_scale_mean': model_cfg.get('rwf_scale_mean', 0.0),
    }

    if input_scale_factors is not None:
        model_config['input_scale_factors'] = input_scale_factors

    model = create_pinn_model(model_config)
    
    # ğŸ”§ é˜²ç¦¦æ€§è¼‰å…¥ï¼šéæ¿¾ä¸ç›¸å®¹çš„éµ
    state_dict = checkpoint['model_state_dict']
    model_keys = set(model.state_dict().keys())
    ckpt_keys = set(state_dict.keys())
    
    unexpected = ckpt_keys - model_keys
    missing = model_keys - ckpt_keys
    
    if unexpected:
        print(f"âš ï¸  éæ¿¾æª¢æŸ¥é»ä¸­çš„ä¸ç›¸å®¹éµ: {unexpected}")
        state_dict = {k: v for k, v in state_dict.items() if k in model_keys}
    
    if missing:
        print(f"âš ï¸  æ¨¡å‹ç¼ºå°‘çš„éµï¼ˆå°‡ä½¿ç”¨åˆå§‹åŒ–å€¼ï¼‰: {missing}")
    
    # éåš´æ ¼æ¨¡å¼è¼‰å…¥ï¼ˆå…è¨±éƒ¨åˆ†éµç¼ºå¤±ï¼‰
    model.load_state_dict(state_dict, strict=False)
    model = model.to(device)
    model.eval()
    
    num_layers = model_cfg.get('depth', model_cfg.get('num_layers', 4))
    hidden_dim = model_cfg.get('width', model_cfg.get('hidden_dim', 256))
    print(f"âœ… æ¨¡å‹å·²è¼‰å…¥: {num_layers}Ã—{hidden_dim}")
    print(f"   Fourier: M={model_cfg.get('fourier_m', 32)}, Ïƒ={model_cfg.get('fourier_sigma', 2.0)}")
    print(f"   RWF: {model_cfg.get('use_rwf', True)}")
    
    return model


def predict_full_field(model, coords, batch_size=4096, device='mps'):
    """åœ¨å®Œæ•´ç¶²æ ¼ä¸Šé æ¸¬"""
    n_points = len(coords)
    predictions = []
    
    print(f"\nğŸ”® é æ¸¬å®Œæ•´å ´ ({n_points} å€‹é»)...")
    
    with torch.no_grad():
        for i in range(0, n_points, batch_size):
            batch = coords[i:i+batch_size]
            coords_tensor = torch.tensor(batch, dtype=torch.float32, device=device)
            
            output = model(coords_tensor)
            predictions.append(output.cpu().numpy())
    
    predictions = np.concatenate(predictions, axis=0)
    
    pred_fields = {
        'u': predictions[:, 0],
        'v': predictions[:, 1],
        'w': predictions[:, 2],
        'p': predictions[:, 3]
    }
    
    return pred_fields


def compute_relative_l2_error(pred, true):
    """è¨ˆç®—ç›¸å° L2 èª¤å·®"""
    numerator = np.linalg.norm(pred - true)
    denominator = np.linalg.norm(true)
    
    if denominator < 1e-12:
        return float('nan')
    
    return numerator / denominator


def compute_field_statistics(pred_fields, true_fields):
    """è¨ˆç®—å ´çµ±è¨ˆé‡"""
    stats = {}
    
    for field_name in ['u', 'v', 'w', 'p']:
        if true_fields[field_name] is None:
            continue
        
        pred = pred_fields[field_name]
        true = true_fields[field_name]
        
        # ç›¸å° L2 èª¤å·®
        rel_l2 = compute_relative_l2_error(pred, true)
        
        # çµ•å°èª¤å·®çµ±è¨ˆ
        abs_error = np.abs(pred - true)
        
        # çµ±è¨ˆé‡
        stats[field_name] = {
            'relative_l2': float(rel_l2),
            'mae': float(np.mean(abs_error)),
            'rmse': float(np.sqrt(np.mean((pred - true)**2))),
            'max_error': float(np.max(abs_error)),
            'pred_mean': float(np.mean(pred)),
            'true_mean': float(np.mean(true)),
            'pred_std': float(np.std(pred)),
            'true_std': float(np.std(true))
        }
    
    return stats


def print_comparison_table(stats):
    """æ‰“å°å°æ¯”è¡¨æ ¼"""
    print("\n" + "="*90)
    print("ğŸ“Š å ´è®Šé‡èª¤å·®åˆ†æ")
    print("="*90)
    
    print(f"\n{'å ´è®Šé‡':<10} {'ç›¸å°L2èª¤å·®':<15} {'RMSE':<15} {'MAE':<15} {'æœ€å¤§èª¤å·®':<15}")
    print("-"*90)
    
    for field_name, s in stats.items():
        rel_l2_pct = s['relative_l2'] * 100
        print(f"{field_name:<10} {rel_l2_pct:>13.2f}% {s['rmse']:>14.4e} {s['mae']:>14.4e} {s['max_error']:>14.4e}")
    
    print("\n" + "="*90)
    print("ğŸ“ˆ çµ±è¨ˆé‡å°æ¯”")
    print("="*90)
    
    print(f"\n{'å ´è®Šé‡':<10} {'é æ¸¬å‡å€¼':<15} {'çœŸå¯¦å‡å€¼':<15} {'é æ¸¬æ¨™æº–å·®':<15} {'çœŸå¯¦æ¨™æº–å·®':<15}")
    print("-"*90)
    
    for field_name, s in stats.items():
        print(f"{field_name:<10} {s['pred_mean']:>14.4e} {s['true_mean']:>14.4e} {s['pred_std']:>14.4e} {s['true_std']:>14.4e}")
    
    print("="*90)


def evaluate_success_criteria(stats):
    """è©•ä¼°æˆåŠŸæ¨™æº–"""
    print("\n" + "="*90)
    print("ğŸ¯ å°ˆæ¡ˆæˆåŠŸæ¨™æº–æª¢é©—")
    print("="*90)
    
    # æ¨™æº– 1: é€Ÿåº¦å ´ç›¸å° L2 èª¤å·® â‰¤ 10-15%
    velocity_errors = [
        stats.get('u', {}).get('relative_l2', 1.0),
        stats.get('v', {}).get('relative_l2', 1.0),
        stats.get('w', {}).get('relative_l2', 1.0)
    ]
    avg_velocity_error = np.mean(velocity_errors) * 100
    
    print(f"\n1. é€Ÿåº¦å ´ç›¸å° L2 èª¤å·®:")
    print(f"   - u: {stats.get('u', {}).get('relative_l2', 0)*100:.2f}%")
    print(f"   - v: {stats.get('v', {}).get('relative_l2', 0)*100:.2f}%")
    print(f"   - w: {stats.get('w', {}).get('relative_l2', 0)*100:.2f}%")
    print(f"   - å¹³å‡: {avg_velocity_error:.2f}%")
    
    if avg_velocity_error <= 15.0:
        print(f"   âœ… é€šéï¼ï¼ˆç›®æ¨™ï¼šâ‰¤ 15%ï¼‰")
        success_velocity = True
    else:
        print(f"   âŒ æœªé€šéï¼ˆç›®æ¨™ï¼šâ‰¤ 15%ï¼‰")
        success_velocity = False
    
    # æ¨™æº– 2: å£“åŠ›å ´ç›¸å° L2 èª¤å·® â‰¤ 15%
    if 'p' in stats:
        pressure_error = stats['p']['relative_l2'] * 100
        print(f"\n2. å£“åŠ›å ´ç›¸å° L2 èª¤å·®: {pressure_error:.2f}%")
        
        if pressure_error <= 15.0:
            print(f"   âœ… é€šéï¼ï¼ˆç›®æ¨™ï¼šâ‰¤ 15%ï¼‰")
            success_pressure = True
        else:
            print(f"   âŒ æœªé€šéï¼ˆç›®æ¨™ï¼šâ‰¤ 15%ï¼‰")
            success_pressure = False
    else:
        print(f"\n2. å£“åŠ›å ´: âš ï¸  ç„¡çœŸå¯¦æ•¸æ“šå°æ¯”")
        success_pressure = None
    
    print("\n" + "="*90)
    
    overall_success = success_velocity and (success_pressure if success_pressure is not None else True)
    
    if overall_success:
        print("ğŸ‰ æ•´é«”è©•ä¼°ï¼šæˆåŠŸï¼é”åˆ°å°ˆæ¡ˆç›®æ¨™")
    else:
        print("âš ï¸  æ•´é«”è©•ä¼°ï¼šéœ€è¦æ”¹é€²")
    
    print("="*90)
    
    return {
        'velocity_success': success_velocity,
        'pressure_success': success_pressure,
        'overall_success': overall_success
    }


def main():
    import argparse
    parser = argparse.ArgumentParser(description='PirateNet vs JHTDB çœŸå¯¦æ•¸æ“šå°æ¯”')
    parser.add_argument('--checkpoint', type=str, required=True, help='æª¢æŸ¥é»è·¯å¾‘')
    parser.add_argument('--config', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--jhtdb', type=str, default='data/jhtdb/channel_flow_re1000/cutout3d_128x128x32.npz',
                       help='JHTDB æ•¸æ“šè·¯å¾‘')
    parser.add_argument('--device', type=str, default='mps', help='è¨ˆç®—è¨­å‚™')
    parser.add_argument('--batch-size', type=int, default=4096, help='æ‰¹æ¬¡å¤§å°')
    args = parser.parse_args()
    
    print("="*90)
    print("  PirateNet vs JHTDB çœŸå¯¦æ•¸æ“šå°æ¯”è©•ä¼°")
    print("="*90)
    
    # 1. è¼‰å…¥æª¢æŸ¥é»
    checkpoint = load_checkpoint(args.checkpoint, device=args.device)
    
    # 2. è¼‰å…¥ JHTDB çœŸå¯¦æ•¸æ“š
    coords, true_fields, jhtdb_data = load_jhtdb_ground_truth(args.jhtdb)
    
    # 3. å‰µå»ºæ¨¡å‹
    model = create_model_from_checkpoint(checkpoint, args.config, device=args.device)
    
    # 4. é æ¸¬å®Œæ•´å ´
    pred_fields = predict_full_field(model, coords, batch_size=args.batch_size, device=args.device)
    
    # 5. è¨ˆç®—çµ±è¨ˆ
    stats = compute_field_statistics(pred_fields, true_fields)
    
    # 6. æ‰“å°å°æ¯”è¡¨æ ¼
    print_comparison_table(stats)
    
    # 7. è©•ä¼°æˆåŠŸæ¨™æº–
    success_criteria = evaluate_success_criteria(stats)
    
    # 8. ä¿å­˜çµæœ
    output_dir = Path('results/piratenet_quick_test')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜çµ±è¨ˆæ•¸æ“š
    stats_file = output_dir / 'vs_jhtdb_statistics.json'
    with open(stats_file, 'w') as f:
        json.dump({
            'statistics': stats,
            'success_criteria': success_criteria,
            'checkpoint_epoch': checkpoint.get('epoch', 'N/A'),
            'checkpoint_loss': float(checkpoint.get('loss', 0))
        }, f, indent=2)
    
    print(f"\nğŸ’¾ çµ±è¨ˆæ•¸æ“šå·²ä¿å­˜: {stats_file}")
    
    # ä¿å­˜é æ¸¬å ´
    pred_file = output_dir / 'vs_jhtdb_predictions.npz'
    np.savez(
        pred_file,
        coords=coords,
        u_pred=pred_fields['u'],
        v_pred=pred_fields['v'],
        w_pred=pred_fields['w'],
        p_pred=pred_fields['p'],
        u_true=true_fields['u'],
        v_true=true_fields['v'],
        w_true=true_fields['w'],
        p_true=true_fields['p'] if true_fields['p'] is not None else np.zeros_like(pred_fields['p']),
        grid_shape=jhtdb_data['u'].shape
    )
    
    print(f"ğŸ’¾ é æ¸¬å ´å·²ä¿å­˜: {pred_file}")
    print("="*90)


if __name__ == '__main__':
    main()
