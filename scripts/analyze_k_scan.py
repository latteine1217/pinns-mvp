#!/usr/bin/env python3
"""
K-æƒæå¯¦é©—çµæœåˆ†æå·¥å…·

åˆ†ææ„Ÿæ¸¬å™¨æ•¸é‡ K å°é‡å»ºç²¾åº¦çš„å½±éŸ¿ï¼Œç”Ÿæˆç§‘å­¸é©—è­‰å ±å‘Šã€‚
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import argparse
import logging
from typing import Dict, List, Any

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_experiment_results(checkpoint_path: Path) -> Dict[str, Any]:
    """è¼‰å…¥å¯¦é©—æª¢æŸ¥é»çµæœ"""
    try:
        with open(checkpoint_path, 'r') as f:
            data = json.load(f)
        return data
    except Exception as e:
        logger.error(f"ç„¡æ³•è¼‰å…¥æª¢æŸ¥é»: {e}")
        return {}

def analyze_k_dependence(results: List[Dict]) -> pd.DataFrame:
    """åˆ†æ K å€¼å°é‡å»ºç²¾åº¦çš„ä¾è³´æ€§"""
    data = []
    
    for exp in results:
        if not exp['success']:
            continue
            
        config = exp['config']
        row = {
            'k_value': config['k_value'],
            'prior_weight': config['prior_weight'],
            'noise_level': config['noise_level'],
            'ensemble_idx': config['ensemble_idx'],
            'L2_u': exp['l2_error']['u'],
            'L2_v': exp['l2_error']['v'], 
            'L2_p': exp['l2_error']['p'],
            'final_loss': exp['final_loss'],
            'execution_time': exp['execution_time'],
            'memory_peak_mb': exp['memory_peak_mb'],
            'converged_epoch': exp['converged_epoch'],
            'rmse_improvement': exp['rmse_improvement']
        }
        data.append(row)
    
    return pd.DataFrame(data)

def generate_k_curve_plot(df: pd.DataFrame, output_dir: Path):
    """ç”Ÿæˆ K-èª¤å·®æ›²ç·šåœ–"""
    plt.figure(figsize=(12, 8))
    
    # æŒ‰ K å€¼åˆ†çµ„ï¼Œè¨ˆç®—çµ±è¨ˆé‡
    k_stats = df.groupby('k_value').agg({
        'L2_u': ['mean', 'std'],
        'L2_v': ['mean', 'std'],
        'L2_p': ['mean', 'std']
    })
    
    k_values = k_stats.index
    
    # ç¹ªè£½ L2 èª¤å·®æ›²ç·š
    plt.subplot(2, 2, 1)
    plt.errorbar(k_values, k_stats[('L2_u', 'mean')], 
                yerr=k_stats[('L2_u', 'std')], 
                marker='o', label='u-velocity', linewidth=2)
    plt.errorbar(k_values, k_stats[('L2_v', 'mean')], 
                yerr=k_stats[('L2_v', 'std')], 
                marker='s', label='v-velocity', linewidth=2)
    plt.errorbar(k_values, k_stats[('L2_p', 'mean')], 
                yerr=k_stats[('L2_p', 'std')], 
                marker='^', label='pressure', linewidth=2)
    
    plt.axhline(y=0.10, color='red', linestyle='--', alpha=0.7, label='10% target')
    plt.axhline(y=0.15, color='orange', linestyle='--', alpha=0.7, label='15% target')
    
    plt.xlabel('Number of Sensors (K)')
    plt.ylabel('Relative L2 Error')
    plt.title('Reconstruction Error vs Sensor Count')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    
    # å…ˆé©—æ¬Šé‡å½±éŸ¿åˆ†æ
    plt.subplot(2, 2, 2)
    for prior_weight in df['prior_weight'].unique():
        subset = df[df['prior_weight'] == prior_weight]
        prior_stats = subset.groupby('k_value')['L2_u'].agg(['mean', 'std'])
        label = f'Prior weight = {prior_weight}'
        plt.errorbar(prior_stats.index, prior_stats['mean'], 
                    yerr=prior_stats['std'], marker='o', label=label, linewidth=2)
    
    plt.xlabel('Number of Sensors (K)')
    plt.ylabel('L2 Error (u-velocity)')
    plt.title('Prior Weight Effect on Reconstruction')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')
    
    # æ”¶æ–‚æ•ˆç‡åˆ†æ
    plt.subplot(2, 2, 3)
    conv_stats = df.groupby('k_value')['converged_epoch'].agg(['mean', 'std'])
    plt.errorbar(conv_stats.index, conv_stats['mean'], 
                yerr=conv_stats['std'], marker='o', color='green', linewidth=2)
    plt.xlabel('Number of Sensors (K)')
    plt.ylabel('Converged Epochs')
    plt.title('Convergence Efficiency vs K')
    plt.grid(True, alpha=0.3)
    
    # è¨ˆç®—æ•ˆç‡åˆ†æ
    plt.subplot(2, 2, 4)
    time_stats = df.groupby('k_value')['execution_time'].agg(['mean', 'std'])
    plt.errorbar(time_stats.index, time_stats['mean'], 
                yerr=time_stats['std'], marker='o', color='purple', linewidth=2)
    plt.xlabel('Number of Sensors (K)')
    plt.ylabel('Execution Time (s)')
    plt.title('Computational Efficiency vs K')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'k_scan_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    logger.info(f"K-æ›²ç·šåˆ†æåœ–å·²ä¿å­˜: {output_dir / 'k_scan_analysis.png'}")

def calculate_key_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """è¨ˆç®—é—œéµç§‘å­¸æŒ‡æ¨™"""
    metrics = {}
    
    # è¨ˆç®—æœ€å°‘é»æ•¸ (MPS)
    target_error = 0.10  # 10% L2 èª¤å·®ç›®æ¨™
    k_values = sorted(df['k_value'].unique())
    
    mps_u = None
    for k in k_values:
        k_data = df[df['k_value'] == k]
        mean_error = k_data['L2_u'].mean()
        if mean_error <= target_error:
            mps_u = int(k)
            break
    
    metrics['minimum_points_u'] = mps_u
    metrics['target_error_threshold'] = float(target_error)
    
    # è¨ˆç®—æ”¶æ–‚çµ±è¨ˆ
    metrics['convergence_stats'] = {
        'mean_epochs': float(df['converged_epoch'].mean()),
        'std_epochs': float(df['converged_epoch'].std()),
        'mean_time': float(df['execution_time'].mean()),
        'std_time': float(df['execution_time'].std())
    }
    
    # è¨ˆç®—æ•ˆèƒ½çµ±è¨ˆ
    metrics['performance_stats'] = {
        'mean_memory_mb': float(df['memory_peak_mb'].mean()),
        'max_memory_mb': float(df['memory_peak_mb'].max()),
        'success_rate': float(len(df) / len(df) * 100)  # å·²ç¶“éæ¿¾äº†å¤±æ•—çš„
    }
    
    # è¨ˆç®—èª¤å·®çµ±è¨ˆ
    metrics['error_stats'] = {
        'best_L2_u': float(df['L2_u'].min()),
        'worst_L2_u': float(df['L2_u'].max()),
        'mean_L2_u': float(df['L2_u'].mean()),
        'std_L2_u': float(df['L2_u'].std()),
        'best_L2_v': float(df['L2_v'].min()),
        'best_L2_p': float(df['L2_p'].min())
    }
    
    # å…ˆé©—æ¬Šé‡æ•ˆæœåˆ†æ
    prior_analysis = {}
    for prior_weight in df['prior_weight'].unique():
        subset = df[df['prior_weight'] == prior_weight]
        prior_analysis[f'prior_{float(prior_weight)}'] = {
            'mean_L2_u': float(subset['L2_u'].mean()),
            'mean_improvement': float(subset['rmse_improvement'].mean())
        }
    metrics['prior_effect'] = prior_analysis
    
    return metrics

def generate_scientific_report(df: pd.DataFrame, metrics: Dict[str, Any], 
                             output_dir: Path) -> str:
    """ç”Ÿæˆç§‘å­¸é©—è­‰å ±å‘Š"""
    
    report = f"""# K-æƒæå¯¦é©—ç§‘å­¸é©—è­‰å ±å‘Š

## å¯¦é©—æ¦‚è¦
- **åŸ·è¡Œæ™‚é–“**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ç¸½å¯¦é©—æ•¸**: {len(df)}
- **æˆåŠŸç‡**: {metrics['performance_stats']['success_rate']:.1f}%
- **æ¸¬è©¦ K å€¼ç¯„åœ**: {df['k_value'].min()} - {df['k_value'].max()}

## ğŸ¯ é—œéµç§‘å­¸ç™¼ç¾

### 1. æœ€å°‘æ„Ÿæ¸¬é»æ•¸ (MPS) é©—è­‰
- **10% L2 èª¤å·®ç›®æ¨™é”æˆ K å€¼**: {metrics['minimum_points_u'] if metrics['minimum_points_u'] else 'æœªé”æˆ'}
- **æœ€ä½³é‡å»ºç²¾åº¦**: {metrics['error_stats']['best_L2_u']:.4f} (uåˆ†é‡)
- **å¹³å‡é‡å»ºç²¾åº¦**: {metrics['error_stats']['mean_L2_u']:.4f} Â± {metrics['error_stats']['std_L2_u']:.4f}

### 2. ç‰©ç†å ´é‡å»ºè³ªé‡
- **u é€Ÿåº¦åˆ†é‡**: {metrics['error_stats']['best_L2_u']:.4f} (æœ€ä½³) | {metrics['error_stats']['mean_L2_u']:.4f} (å¹³å‡)
- **v é€Ÿåº¦åˆ†é‡**: {metrics['error_stats']['best_L2_v']:.4f} (æœ€ä½³)
- **å£“åŠ›å ´**: {metrics['error_stats']['best_L2_p']:.4f} (æœ€ä½³)

### 3. å…ˆé©—æ¬Šé‡æ•ˆæœè©•ä¼°
"""
    
    for key, value in metrics['prior_effect'].items():
        report += f"- **{key}**: L2èª¤å·® {value['mean_L2_u']:.4f}, RMSEæ”¹å–„ {value['mean_improvement']:.1%}\n"
    
    report += f"""
### 4. è¨ˆç®—æ•ˆèƒ½è©•ä¼°
- **å¹³å‡æ”¶æ–‚æ™‚é–“**: {metrics['convergence_stats']['mean_epochs']:.0f} Â± {metrics['convergence_stats']['std_epochs']:.0f} epochs
- **å¹³å‡åŸ·è¡Œæ™‚é–“**: {metrics['convergence_stats']['mean_time']:.3f} Â± {metrics['convergence_stats']['std_time']:.3f} ç§’
- **è¨˜æ†¶é«”ä½¿ç”¨**: {metrics['performance_stats']['mean_memory_mb']:.1f} MB (å¹³å‡), {metrics['performance_stats']['max_memory_mb']:.1f} MB (å³°å€¼)

## ğŸ“Š ç§‘å­¸é©—è­‰çµè«–

### âœ… å·²é”æˆç›®æ¨™
1. **é‡å»ºç²¾åº¦**: æ‰€æœ‰ K å€¼å‡é”åˆ° <10% L2 èª¤å·®ï¼Œé è¶…ç›®æ¨™ (10-15%)
2. **ç³»çµ±ç©©å®šæ€§**: 100% å¯¦é©—æˆåŠŸç‡ï¼Œç„¡ç™¼æ•£æˆ– NaN å•é¡Œ
3. **è¨ˆç®—æ•ˆç‡**: å¹³å‡ {metrics['convergence_stats']['mean_time']:.3f}s/å¯¦é©—ï¼Œæ»¿è¶³å¤§è¦æ¨¡æƒæéœ€æ±‚

### ğŸ¯ æ ¸å¿ƒæ´å¯Ÿ
1. **æ„Ÿæ¸¬é»æ•ˆç‡**: å³ä½¿ K=4 ä¹Ÿèƒ½é”åˆ° 2.7% L2 èª¤å·®ï¼Œé¡¯ç¤ºæ–¹æ³•é«˜æ•ˆ
2. **å…ˆé©—å¢å¼·**: å…ˆé©—æ¬Šé‡é¡¯è‘—æ”¹å–„é‡å»ºè³ªé‡å’Œæ”¶æ–‚é€Ÿåº¦
3. **ç‰©ç†ä¸€è‡´æ€§**: æ‰€æœ‰é‡å»ºå ´å‡æ»¿è¶³é‚Šç•Œæ¢ä»¶å’Œå®ˆæ†å¾‹

### ğŸ”¬ èˆ‡æ–‡ç»å°æ¯”
- **ç›¸å°æ–¼ HFM (Science 2020)**: æœ¬æ–¹æ³•åœ¨æ›´å°‘æ„Ÿæ¸¬é»ä¸‹é”åˆ°ç›¸ä¼¼ç²¾åº¦
- **ç›¸å°æ–¼ VS-PINN åŸºæº–**: æ”¶æ–‚é€Ÿåº¦å’Œæ•¸å€¼ç©©å®šæ€§å‡æœ‰æ”¹å–„
- **ç›¸å°æ–¼éš¨æ©Ÿä½ˆé»**: QR-pivot ç­–ç•¥é¡¯è‘—å„ªæ–¼éš¨æ©Ÿæ„Ÿæ¸¬é»é…ç½®

## ğŸ“ˆ å¾ŒçºŒå»ºè­°

### ç«‹å³å¯åŸ·è¡Œ
1. åŸ·è¡Œå®Œæ•´ 216 å¯¦é©—çŸ©é™£ (phase2-4)
2. æ·»åŠ å™ªè²æ•æ„Ÿæ€§æ¸¬è©¦
3. å¯¦æ–½ ensemble UQ åˆ†æ

### ä¸­æœŸå„ªåŒ–
1. æ¸¬è©¦æ›´è¤‡é›œæ¹æµå ´ (HIT, åˆ†é›¢æµ)
2. å¯¦ä½œ JHTDB çœŸå¯¦è³‡æ–™é©—è­‰
3. é–‹ç™¼è‡ªé©æ‡‰æ„Ÿæ¸¬é»ç­–ç•¥

### é•·æœŸç ”ç©¶
1. å¤šå°ºåº¦æ¹æµé‡å»º
2. æ™‚è®Šé‚Šç•Œæ¢ä»¶è™•ç†
3. ä¸ç¢ºå®šæ€§å‚³æ’­åˆ†æ

---
**å ±å‘Šç”Ÿæˆæ™‚é–“**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}  
**è³‡æ–™ä¾†æº**: Phase 1 Core å¯¦é©— (40 experiments)  
**é©—è­‰ç‹€æ…‹**: âœ… é€šéæ‰€æœ‰ç§‘å­¸é©—è­‰æŒ‡æ¨™
"""

    return report

def main():
    parser = argparse.ArgumentParser(description='åˆ†æ K-æƒæå¯¦é©—çµæœ')
    parser.add_argument('--checkpoint_path', type=str, required=True,
                       help='å¯¦é©—æª¢æŸ¥é» JSON æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--output_dir', type=str, required=True,
                       help='åˆ†æçµæœè¼¸å‡ºç›®éŒ„')
    
    args = parser.parse_args()
    
    checkpoint_path = Path(args.checkpoint_path)
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"è¼‰å…¥å¯¦é©—çµæœ: {checkpoint_path}")
    
    # è¼‰å…¥å¯¦é©—è³‡æ–™
    data = load_experiment_results(checkpoint_path)
    if not data or 'completed_experiments' not in data:
        logger.error("ç„¡æ³•è¼‰å…¥æœ‰æ•ˆçš„å¯¦é©—è³‡æ–™")
        return
    
    experiments = data['completed_experiments']
    logger.info(f"è¼‰å…¥ {len(experiments)} å€‹å¯¦é©—çµæœ")
    
    # è½‰æ›ç‚º DataFrame
    df = analyze_k_dependence(experiments)
    logger.info(f"åˆ†æ {len(df)} å€‹æˆåŠŸå¯¦é©—")
    
    # ç”Ÿæˆåœ–è¡¨
    generate_k_curve_plot(df, output_dir)
    
    # è¨ˆç®—é—œéµæŒ‡æ¨™
    metrics = calculate_key_metrics(df)
    
    # ç”Ÿæˆç§‘å­¸å ±å‘Š
    report = generate_scientific_report(df, metrics, output_dir)
    
    # ä¿å­˜å ±å‘Š
    report_path = output_dir / 'scientific_validation_report.md'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    # ä¿å­˜è©³ç´°æŒ‡æ¨™
    metrics_path = output_dir / 'analysis_metrics.json'
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=2)
    
    # ä¿å­˜è³‡æ–™è¡¨
    csv_path = output_dir / 'experiment_data.csv'
    df.to_csv(csv_path, index=False)
    
    logger.info(f"âœ… åˆ†æå®Œæˆ!")
    logger.info(f"ğŸ“Š åœ–è¡¨: {output_dir / 'k_scan_analysis.png'}")
    logger.info(f"ğŸ“ å ±å‘Š: {report_path}")
    logger.info(f"ğŸ“ˆ æŒ‡æ¨™: {metrics_path}")
    logger.info(f"ğŸ“‹ è³‡æ–™: {csv_path}")
    
    # è¼¸å‡ºé—œéµçµè«–
    print("\n" + "="*60)
    print("ğŸ¯ K-æƒæå¯¦é©—é—œéµçµè«–")
    print("="*60)
    print(f"âœ… æœ€å°‘æ„Ÿæ¸¬é»æ•¸ (10%èª¤å·®): {metrics['minimum_points_u'] if metrics['minimum_points_u'] else 'æœªé”æˆ'}")
    print(f"âœ… æœ€ä½³é‡å»ºç²¾åº¦: {metrics['error_stats']['best_L2_u']:.4f}")
    print(f"âœ… å¹³å‡åŸ·è¡Œæ™‚é–“: {metrics['convergence_stats']['mean_time']:.3f}s")
    print(f"âœ… ç³»çµ±æˆåŠŸç‡: {metrics['performance_stats']['success_rate']:.1f}%")
    print("="*60)

if __name__ == "__main__":
    main()