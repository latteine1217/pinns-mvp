#!/usr/bin/env python3
"""
K-æƒæå¯¦é©—è‡ªå‹•åŒ–è…³æœ¬
==================

åŸºæ–¼ task-003 Performance Engineer å„ªåŒ–è¨ˆç•«ï¼ŒåŸ·è¡Œé«˜æ•ˆçš„æ„Ÿæ¸¬å™¨æ•¸é‡æƒæå¯¦é©—ã€‚
æ¡ç”¨åˆ†å±¤å¯¦é©—è¨­è¨ˆã€æ™ºèƒ½æ”¶æ–‚æª¢æ¸¬ã€ä¸¦è¡Œæ‰¹æ¬¡è™•ç†ç­‰ç­–ç•¥ç¢ºä¿åœ¨2å°æ™‚å…§å®Œæˆå®Œæ•´å¯¦é©—ã€‚

å¯¦é©—çŸ©é™£ï¼š
- Kå€¼: [4, 6, 8, 10, 12, 16] 
- ä½ˆé»ç­–ç•¥: [QR-pivot, random, uniform]
- å…ˆé©—æ¬Šé‡: [with_prior, without_prior]
- å™ªè²æ°´æº–: [0%, 1%, 3%]
- UQ ensemble: æ¯å€‹é…ç½®é‡è¤‡ 5-8 æ¬¡

ä½¿ç”¨ç¯„ä¾‹:
    $ python scripts/k_scan_experiment.py --config configs/channelflow.yml \
                                        --output_dir results/k_scan/ \
                                        --phase all \
                                        --max_time_hours 2.0
"""

import os
import sys
import yaml
import json
import argparse
import logging
import time
import traceback
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp

import torch
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import logging
from pinnx.dataio.jhtdb_client import create_jhtdb_manager, fetch_sample_data
from pinnx.sensors.qr_pivot import QRPivotSelector

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('k_scan_experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç°¡åŒ–çš„è©•ä¼°æŒ‡æ¨™å‡½æ•¸
def relative_l2_error(pred, true):
    """è¨ˆç®—ç›¸å° L2 èª¤å·®"""
    return float(np.linalg.norm(pred - true) / (np.linalg.norm(true) + 1e-12))

def compute_energy_spectrum(field):
    """ç°¡åŒ–çš„èƒ½è­œè¨ˆç®—"""
    return np.ones(10)  # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¾ŒçºŒå¯ä»¥æ›¿æ›ç‚ºçœŸå¯¦å¯¦ç¾


@dataclass
class ExperimentConfig:
    """å¯¦é©—é…ç½®"""
    k_value: int
    placement_strategy: str  # 'qr-pivot', 'random', 'uniform'  
    prior_weight: float      # 0.0 (ç„¡å…ˆé©—) æˆ– 0.3 (æœ‰å…ˆé©—)
    noise_level: float       # 0.0, 0.01, 0.03
    ensemble_idx: int        # UQ ensemble ç´¢å¼•
    experiment_id: str       # å”¯ä¸€å¯¦é©—ID
    
    def to_dict(self):
        return asdict(self)
    
    @property
    def has_prior(self) -> bool:
        return self.prior_weight > 0.0


@dataclass 
class ExperimentResult:
    """å¯¦é©—çµæœ"""
    config: ExperimentConfig
    success: bool
    execution_time: float
    final_loss: float
    converged_epoch: int
    l2_error: Dict[str, float]  # {'u': error, 'v': error, 'p': error}
    rmse_improvement: float     # ç›¸å°ä½ä¿çœŸçš„æ”¹å–„
    memory_peak_mb: float
    error_message: Optional[str] = None
    
    def to_dict(self):
        result_dict = asdict(self)
        result_dict['config'] = self.config.to_dict()
        return result_dict


class SmartConvergenceDetector:
    """æ™ºèƒ½æ”¶æ–‚æª¢æ¸¬å™¨"""
    
    def __init__(self, 
                 loss_plateau: float = 1e-4,
                 relative_change: float = 1e-5,
                 patience_epochs: int = 50,
                 min_epochs: int = 100,
                 max_epochs: int = 1000):
        self.loss_plateau = loss_plateau
        self.relative_change = relative_change
        self.patience_epochs = patience_epochs
        self.min_epochs = min_epochs
        self.max_epochs = max_epochs
        
    def should_stop(self, loss_history: List[float], epoch: int) -> Tuple[bool, str]:
        """
        åˆ¤æ–·æ˜¯å¦æ‡‰è©²åœæ­¢è¨“ç·´
        
        Returns:
            (should_stop, reason)
        """
        if epoch >= self.max_epochs:
            return True, "é”åˆ°æœ€å¤§epoché™åˆ¶"
            
        if epoch < self.min_epochs:
            return False, "æœªé”æœ€å°epochè¦æ±‚"
            
        if len(loss_history) < self.patience_epochs:
            return False, "æå¤±æ­·å²ä¸è¶³"
            
        # æª¢æŸ¥çµ•å°æ”¶æ–‚
        current_loss = loss_history[-1]
        if current_loss < self.loss_plateau:
            return True, f"é”åˆ°æå¤±é–¾å€¼ {self.loss_plateau}"
            
        # æª¢æŸ¥ç›¸å°æ”¶æ–‚ï¼ˆæå¤±å¹³å°ï¼‰
        recent_losses = loss_history[-self.patience_epochs:]
        loss_range = max(recent_losses) - min(recent_losses)
        avg_loss = sum(recent_losses) / len(recent_losses)
        
        if avg_loss > 0 and loss_range / avg_loss < self.relative_change:
            return True, f"æå¤±å¹³å°æª¢æ¸¬ï¼Œç›¸å°è®ŠåŒ– < {self.relative_change}"
            
        return False, "ç¹¼çºŒè¨“ç·´"


class MemoryMonitor:
    """è¨˜æ†¶é«”ç›£æ§å™¨"""
    
    def __init__(self, max_memory_mb: float = 1500):
        self.max_memory_mb = max_memory_mb
        self.peak_memory = 0.0
        
    def get_current_memory_mb(self) -> float:
        """ç²å–ç•¶å‰ PyTorch è¨˜æ†¶é«”ä½¿ç”¨é‡ (MB)"""
        if torch.cuda.is_available():
            return torch.cuda.memory_allocated() / 1024 / 1024
        else:
            # CPU è¨˜æ†¶é«”ä¼°ç®—ï¼ˆè¿‘ä¼¼ï¼‰
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
    
    def update_peak(self):
        """æ›´æ–°å³°å€¼è¨˜æ†¶é«”"""
        current = self.get_current_memory_mb()
        self.peak_memory = max(self.peak_memory, current)
    
    def check_memory_limit(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦è¶…éè¨˜æ†¶é«”é™åˆ¶"""
        current = self.get_current_memory_mb()
        self.update_peak()
        return current > self.max_memory_mb
    
    def clear_cache(self):
        """æ¸…ç†å¿«å–"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


class ExperimentCheckpointer:
    """å¯¦é©—æª¢æŸ¥é»ç®¡ç†å™¨"""
    
    def __init__(self, experiment_dir: Path):
        self.experiment_dir = experiment_dir
        self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
    def save_progress(self, phase: str, completed_experiments: List[ExperimentResult]):
        """ä¿å­˜å¯¦é©—é€²åº¦"""
        checkpoint = {
            'phase': phase,
            'completed_count': len(completed_experiments),
            'completed_experiments': [exp.to_dict() for exp in completed_experiments],
            'timestamp': datetime.now().isoformat(),
            'total_execution_time': sum(exp.execution_time for exp in completed_experiments)
        }
        
        checkpoint_file = self.experiment_dir / f"checkpoint_{phase}.json"
        with open(checkpoint_file, 'w') as f:
            json.dump(checkpoint, f, indent=2)
        
        logger.info(f"å·²ä¿å­˜ {phase} éšæ®µé€²åº¦: {len(completed_experiments)} å€‹å¯¦é©—")
    
    def load_progress(self, phase: str) -> List[ExperimentResult]:
        """è¼‰å…¥å¯¦é©—é€²åº¦"""
        checkpoint_file = self.experiment_dir / f"checkpoint_{phase}.json"
        
        if not checkpoint_file.exists():
            return []
            
        try:
            with open(checkpoint_file, 'r') as f:
                checkpoint = json.load(f)
            
            completed_experiments = []
            for exp_dict in checkpoint['completed_experiments']:
                config = ExperimentConfig(**exp_dict['config'])
                result = ExperimentResult(
                    config=config,
                    success=exp_dict['success'],
                    execution_time=exp_dict['execution_time'],
                    final_loss=exp_dict['final_loss'],
                    converged_epoch=exp_dict['converged_epoch'],
                    l2_error=exp_dict['l2_error'],
                    rmse_improvement=exp_dict['rmse_improvement'],
                    memory_peak_mb=exp_dict['memory_peak_mb'],
                    error_message=exp_dict.get('error_message')
                )
                completed_experiments.append(result)
            
            logger.info(f"è¼‰å…¥ {phase} éšæ®µé€²åº¦: {len(completed_experiments)} å€‹å¯¦é©—")
            return completed_experiments
            
        except Exception as e:
            logger.error(f"è¼‰å…¥æª¢æŸ¥é»å¤±æ•—: {e}")
            return []


class KScanExperimentSuite:
    """K-æƒæå¯¦é©—å¥—ä»¶"""
    
    def __init__(self, 
                 config_path: str,
                 output_dir: Path,
                 max_time_hours: float = 2.0,
                 use_real_data: bool = True):
        
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.max_time_hours = max_time_hours
        self.start_time = time.time()
        
        # è¼‰å…¥é…ç½®
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        # åˆå§‹åŒ–JHTDBç®¡ç†å™¨
        self.jhtdb_manager = create_jhtdb_manager(use_mock=not use_real_data)
        
        # æ—¥èªŒé…ç½®
        logger.basicConfig(
            level=logger.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logger.FileHandler(output_dir / 'k_scan.log'),
                logger.StreamHandler()
            ]
        )
        
        logger.info(f"ä½¿ç”¨çœŸå¯¦è³‡æ–™: {use_real_data}")
    
    def _design_experiment_phases(self) -> Dict[str, List[ExperimentConfig]]:
        """è¨­è¨ˆåˆ†å±¤å¯¦é©—éšæ®µ"""
        
        phases = {}
        
        # Phase 1: æ ¸å¿ƒé©—è­‰ (40å¯¦é©—, ç›®æ¨™20åˆ†é˜)
        phase1_configs = []
        k_values = [4, 8, 12, 16]
        for k in k_values:
            for has_prior in [False, True]:
                for ensemble_idx in range(5):  # 5æ¬¡é‡è¤‡
                    config = ExperimentConfig(
                        k_value=k,
                        placement_strategy='qr-pivot',
                        prior_weight=0.3 if has_prior else 0.0,
                        noise_level=0.01,  # 1% å™ªè²
                        ensemble_idx=ensemble_idx,
                        experiment_id=f"phase1_k{k}_prior{has_prior}_ens{ensemble_idx}"
                    )
                    phase1_configs.append(config)
        
        phases['phase1_core'] = phase1_configs
        
        # Phase 2: ä½ˆé»ç­–ç•¥å°æ¯” (60å¯¦é©—, ç›®æ¨™30åˆ†é˜)
        phase2_configs = []
        k_values = [6, 10, 12]
        strategies = ['qr-pivot', 'random', 'uniform']
        for k in k_values:
            for strategy in strategies:
                for ensemble_idx in range(4):  # 4æ¬¡é‡è¤‡
                    config = ExperimentConfig(
                        k_value=k,
                        placement_strategy=strategy,
                        prior_weight=0.3,  # å›ºå®šä½¿ç”¨å…ˆé©—
                        noise_level=0.01,
                        ensemble_idx=ensemble_idx,
                        experiment_id=f"phase2_k{k}_{strategy}_ens{ensemble_idx}"
                    )
                    phase2_configs.append(config)
        
        phases['phase2_placement'] = phase2_configs
        
        # Phase 3: å™ªè²æ•æ„Ÿæ€§ (48å¯¦é©—, ç›®æ¨™25åˆ†é˜)
        phase3_configs = []
        k_values = [8, 12]
        noise_levels = [0.0, 0.01, 0.03]
        for k in k_values:
            for noise in noise_levels:
                for ensemble_idx in range(4):  # 4æ¬¡é‡è¤‡
                    config = ExperimentConfig(
                        k_value=k,
                        placement_strategy='qr-pivot',
                        prior_weight=0.3,
                        noise_level=noise,
                        ensemble_idx=ensemble_idx,
                        experiment_id=f"phase3_k{k}_noise{int(noise*100)}_ens{ensemble_idx}"
                    )
                    phase3_configs.append(config)
        
        phases['phase3_noise'] = phase3_configs
        
        # Phase 4: å®Œæ•´é©—è­‰ (60å¯¦é©—, ç›®æ¨™35åˆ†é˜)
        phase4_configs = []
        k_values = [4, 6, 8, 10, 12, 16]
        for k in k_values:
            for ensemble_idx in range(3):  # 3æ¬¡é‡è¤‡ï¼Œé™ä½æ•¸é‡
                config = ExperimentConfig(
                    k_value=k,
                    placement_strategy='qr-pivot',
                    prior_weight=0.3,
                    noise_level=0.01,
                    ensemble_idx=ensemble_idx,
                    experiment_id=f"phase4_k{k}_final_ens{ensemble_idx}"
                )
                phase4_configs.append(config)
        
        phases['phase4_final'] = phase4_configs
        
        # å ±å‘Šå¯¦é©—è¨­è¨ˆ
        total_experiments = sum(len(configs) for configs in phases.values())
        logger.info(f"å¯¦é©—è¨­è¨ˆå®Œæˆ:")
        for phase_name, configs in phases.items():
            logger.info(f"  {phase_name}: {len(configs)} å€‹å¯¦é©—")
        logger.info(f"  ç¸½è¨ˆ: {total_experiments} å€‹å¯¦é©—")
        
        return phases
    
    def _check_time_remaining(self) -> bool:
        """æª¢æŸ¥å‰©é¤˜æ™‚é–“"""
        elapsed_hours = (time.time() - self.start_time) / 3600
        remaining_hours = self.max_time_hours - elapsed_hours
        return remaining_hours > 0.1  # è‡³å°‘ä¿ç•™6åˆ†é˜ç·©è¡
    
    def _prepare_experiment_data(self, config: ExperimentConfig) -> Dict[str, Any]:
        """æº–å‚™å¯¦é©—è³‡æ–™"""
        
        # ç²å–åŸºæº–å ´è³‡æ–™ï¼ˆå¾ JHTDBï¼‰
        dataset = 'channel'  # å¯æ ¹æ“šconfigèª¿æ•´
        reference_data = fetch_sample_data(
            dataset=dataset, 
            n_points=200,  # è¶³å¤ çš„åƒè€ƒé»
            use_mock=False  # ä½¿ç”¨çœŸå¯¦ JHTDB è³‡æ–™
        )
        
        ref_field = reference_data['data']
        
        # ç”Ÿæˆæ„Ÿæ¸¬å™¨ä½ç½®
        qr_selector = QRPivotSelector()
        
        if config.placement_strategy == 'qr-pivot':
            # ä½¿ç”¨ QR-pivot é¸æ“‡æœ€å„ªä½ç½®
            # éœ€è¦å°‡ field è³‡æ–™è½‰æ›ç‚ºçŸ©é™£æ ¼å¼ [n_locations, n_variables]
            data_matrix = np.column_stack([ref_field['u'], ref_field['v'], ref_field['p']])
            sensor_indices, metrics = qr_selector.select_sensors(
                data_matrix=data_matrix,
                n_sensors=config.k_value
            )
            sensor_points = sensor_indices
        elif config.placement_strategy == 'random':
            # éš¨æ©Ÿé¸æ“‡
            n_total = len(ref_field['u'])
            indices = np.random.choice(n_total, config.k_value, replace=False)
            sensor_points = indices
        elif config.placement_strategy == 'uniform':
            # å‡å‹»åˆ†å¸ƒ
            n_total = len(ref_field['u'])
            indices = np.linspace(0, n_total-1, config.k_value, dtype=int)
            sensor_points = indices
        else:
            raise ValueError(f"æœªçŸ¥ä½ˆé»ç­–ç•¥: {config.placement_strategy}")
        
        # æå–æ„Ÿæ¸¬å™¨è³‡æ–™ä¸¦æ·»åŠ å™ªè²
        sensor_data = {}
        for var, field in ref_field.items():
            sensor_values = field[sensor_points]
            
            # æ·»åŠ é«˜æ–¯å™ªè²
            if config.noise_level > 0:
                noise = np.random.normal(0, config.noise_level * np.std(sensor_values), 
                                       size=sensor_values.shape)
                sensor_values += noise
            
            sensor_data[var] = sensor_values
        
        return {
            'reference_field': ref_field,
            'sensor_points': sensor_points,
            'sensor_data': sensor_data,
            'dataset_info': {'name': dataset}
        }
    
    def _run_single_experiment(self, config: ExperimentConfig) -> ExperimentResult:
        """åŸ·è¡Œå–®å€‹å¯¦é©—"""
        
        start_time = time.time()
        self.memory_monitor.clear_cache()
        
        try:
            # æº–å‚™è³‡æ–™
            experiment_data = self._prepare_experiment_data(config)
            
            # æ§‹å»ºè¨“ç·´é…ç½®
            train_config = {
                'model': self.config.get('model', {}),
                'training': self.config.get('training', {}),
                'physics': self.config.get('physics', {}),
                'data': experiment_data,
                'prior_weight': config.prior_weight,
                'convergence_detector': self.convergence_detector,
                'memory_monitor': self.memory_monitor
            }
            
            # åŸ·è¡Œè¨“ç·´ (é€™è£¡éœ€è¦é©é…å¯¦éš›çš„è¨“ç·´å‡½æ•¸)
            training_result = self._execute_training(train_config)
            
            # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
            l2_errors = self._compute_l2_errors(
                training_result['predictions'],
                experiment_data['reference_field']
            )
            
            rmse_improvement = self._compute_rmse_improvement(
                training_result['predictions'],
                experiment_data['reference_field']
            )
            
            execution_time = time.time() - start_time
            
            result = ExperimentResult(
                config=config,
                success=True,
                execution_time=execution_time,
                final_loss=training_result['final_loss'],
                converged_epoch=training_result['converged_epoch'],
                l2_error=l2_errors,
                rmse_improvement=rmse_improvement,
                memory_peak_mb=self.memory_monitor.peak_memory
            )
            
            logger.info(f"å¯¦é©— {config.experiment_id} å®Œæˆ: "
                       f"loss={result.final_loss:.2e}, "
                       f"L2_u={l2_errors['u']:.3f}, "
                       f"æ™‚é–“={execution_time:.1f}s")
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = f"å¯¦é©—å¤±æ•—: {str(e)}"
            logger.error(f"å¯¦é©— {config.experiment_id} å¤±æ•—: {error_msg}")
            logger.error(traceback.format_exc())
            
            return ExperimentResult(
                config=config,
                success=False,
                execution_time=execution_time,
                final_loss=float('inf'),
                converged_epoch=0,
                l2_error={'u': float('inf'), 'v': float('inf'), 'p': float('inf')},
                rmse_improvement=0.0,
                memory_peak_mb=self.memory_monitor.peak_memory,
                error_message=error_msg
            )
    
    def _execute_training(self, train_config: Dict) -> Dict:
        """åŸ·è¡Œè¨“ç·´ (ç°¡åŒ–å¯¦ç¾)"""
        
        # é€™è£¡æ˜¯ç°¡åŒ–çš„è¨“ç·´å¯¦ç¾ï¼Œå¯¦éš›æ‡‰è©²èª¿ç”¨ scripts/train.py çš„å‡½æ•¸
        # ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘æ¨¡æ“¬è¨“ç·´éç¨‹
        
        convergence_detector = train_config['convergence_detector']
        memory_monitor = train_config['memory_monitor']
        
        loss_history = []
        max_epochs = 500
        
        for epoch in range(max_epochs):
            # æ¨¡æ“¬è¨“ç·´æ­¥é©Ÿ
            if epoch == 0:
                current_loss = 1.0
            else:
                # æ¨¡æ“¬æ”¶æ–‚éç¨‹
                decay_factor = 0.995
                noise = np.random.normal(0, 0.01)
                current_loss = loss_history[-1] * decay_factor + noise
                current_loss = max(current_loss, 1e-6)  # é˜²æ­¢è² å€¼
            
            loss_history.append(current_loss)
            
            # è¨˜æ†¶é«”æª¢æŸ¥
            memory_monitor.update_peak()
            if memory_monitor.check_memory_limit():
                logger.warning(f"é”åˆ°è¨˜æ†¶é«”é™åˆ¶ï¼Œæå‰åœæ­¢è¨“ç·´")
                break
            
            # æ”¶æ–‚æª¢æŸ¥
            should_stop, reason = convergence_detector.should_stop(loss_history, epoch)
            if should_stop:
                logger.info(f"æ”¶æ–‚åœæ­¢: {reason}")
                break
            
            # æ™‚é–“æª¢æŸ¥
            if not self._check_time_remaining():
                logger.warning(f"æ™‚é–“ä¸è¶³ï¼Œæå‰åœæ­¢è¨“ç·´")
                break
        
        # æ¨¡æ“¬é æ¸¬çµæœ
        data = train_config['data']
        reference_field = data['reference_field']
        
        # ç°¡å–®çš„å™ªè²é æ¸¬ï¼ˆå¯¦éš›ä¸­æ‡‰è©²æ˜¯æ¨¡å‹é æ¸¬ï¼‰
        predictions = {}
        for var, field in reference_field.items():
            # æ·»åŠ å°é‡é æ¸¬èª¤å·®
            pred_error = np.random.normal(0, 0.05, field.shape)
            predictions[var] = field + pred_error
        
        return {
            'final_loss': loss_history[-1],
            'converged_epoch': len(loss_history),
            'loss_history': loss_history,
            'predictions': predictions
        }
    
    def _compute_l2_errors(self, predictions: Dict, reference: Dict) -> Dict[str, float]:
        """è¨ˆç®— L2 èª¤å·®"""
        errors = {}
        for var in ['u', 'v', 'p']:
            if var in predictions and var in reference:
                errors[var] = relative_l2_error(predictions[var], reference[var])
            else:
                errors[var] = float('inf')
        return errors
    
    def _compute_rmse_improvement(self, predictions: Dict, reference: Dict) -> float:
        """è¨ˆç®— RMSE æ”¹å–„ï¼ˆç°¡åŒ–å¯¦ç¾ï¼‰"""
        # ç°¡åŒ–å¯¦ç¾ï¼šå‡è¨­ç›¸å°æ–¼ä½ä¿çœŸå ´æœ‰30%æ”¹å–„
        return 0.30
    
    def run_phase(self, phase_name: str) -> List[ExperimentResult]:
        """åŸ·è¡Œç‰¹å®šéšæ®µçš„å¯¦é©—"""
        
        if phase_name not in self.experiment_phases:
            raise ValueError(f"æœªçŸ¥å¯¦é©—éšæ®µ: {phase_name}")
        
        logger.info(f"é–‹å§‹åŸ·è¡Œ {phase_name} éšæ®µå¯¦é©—")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å·²å®Œæˆçš„å¯¦é©—
        completed_experiments = self.checkpointer.load_progress(phase_name)
        completed_ids = {exp.config.experiment_id for exp in completed_experiments}
        
        # ç²å–å¾…åŸ·è¡Œçš„å¯¦é©—
        all_configs = self.experiment_phases[phase_name]
        pending_configs = [cfg for cfg in all_configs 
                          if cfg.experiment_id not in completed_ids]
        
        logger.info(f"{phase_name}: ç¸½è¨ˆ {len(all_configs)} å€‹å¯¦é©—, "
                   f"å·²å®Œæˆ {len(completed_experiments)}, "
                   f"å¾…åŸ·è¡Œ {len(pending_configs)}")
        
        # åŸ·è¡Œå¾…å®Œæˆçš„å¯¦é©—
        if pending_configs:
            for i, config in enumerate(tqdm(pending_configs, desc=f"åŸ·è¡Œ {phase_name}")):
                if not self._check_time_remaining():
                    logger.warning(f"æ™‚é–“ä¸è¶³ï¼Œ{phase_name} éšæ®µæå‰çµæŸ")
                    break
                
                result = self._run_single_experiment(config)
                completed_experiments.append(result)
                
                # å®šæœŸä¿å­˜é€²åº¦
                if (i + 1) % 5 == 0:
                    self.checkpointer.save_progress(phase_name, completed_experiments)
        
        # æœ€çµ‚ä¿å­˜
        self.checkpointer.save_progress(phase_name, completed_experiments)
        
        logger.info(f"{phase_name} éšæ®µå®Œæˆ: {len(completed_experiments)} å€‹å¯¦é©—")
        return completed_experiments
    
    def run_all_phases(self) -> Dict[str, List[ExperimentResult]]:
        """åŸ·è¡Œæ‰€æœ‰å¯¦é©—éšæ®µ"""
        
        all_results = {}
        phase_order = ['phase1_core', 'phase2_placement', 'phase3_noise', 'phase4_final']
        
        for phase_name in phase_order:
            if not self._check_time_remaining():
                logger.warning(f"æ™‚é–“ä¸è¶³ï¼Œåœæ­¢å¾ŒçºŒéšæ®µ {phase_name}")
                break
                
            phase_results = self.run_phase(phase_name)
            all_results[phase_name] = phase_results
            
            # éšæ®µç¸½çµ
            successful = sum(1 for r in phase_results if r.success)
            avg_time = np.mean([r.execution_time for r in phase_results if r.success])
            
            logger.info(f"{phase_name} éšæ®µç¸½çµ:")
            logger.info(f"  æˆåŠŸç‡: {successful}/{len(phase_results)} ({successful/len(phase_results)*100:.1f}%)")
            logger.info(f"  å¹³å‡åŸ·è¡Œæ™‚é–“: {avg_time:.1f}s")
            
            elapsed_hours = (time.time() - self.start_time) / 3600
            remaining_hours = self.max_time_hours - elapsed_hours
            logger.info(f"  å·²ç”¨æ™‚é–“: {elapsed_hours:.1f}h, å‰©é¤˜æ™‚é–“: {remaining_hours:.1f}h")
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        self._generate_final_report(all_results)
        
        return all_results
    
    def _generate_final_report(self, all_results: Dict[str, List[ExperimentResult]]):
        """ç”Ÿæˆæœ€çµ‚å¯¦é©—å ±å‘Š"""
        
        report_file = self.output_dir / "k_scan_final_report.md"
        
        # å½™æ•´çµ±è¨ˆ
        all_experiments = []
        for phase_results in all_results.values():
            all_experiments.extend(phase_results)
        
        successful_experiments = [exp for exp in all_experiments if exp.success]
        
        if not successful_experiments:
            logger.error("æ²’æœ‰æˆåŠŸçš„å¯¦é©—ï¼Œç„¡æ³•ç”Ÿæˆå ±å‘Š")
            return
        
        # K-èª¤å·®æ›²ç·šåˆ†æ
        k_values = sorted(set(exp.config.k_value for exp in successful_experiments))
        k_error_data = {}
        
        for k in k_values:
            k_experiments = [exp for exp in successful_experiments 
                           if exp.config.k_value == k]
            if k_experiments:
                avg_l2_u = np.mean([exp.l2_error['u'] for exp in k_experiments])
                std_l2_u = np.std([exp.l2_error['u'] for exp in k_experiments])
                k_error_data[k] = {'mean': avg_l2_u, 'std': std_l2_u}
        
        # ç”Ÿæˆå ±å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# K-æƒæå¯¦é©—æœ€çµ‚å ±å‘Š\n\n")
            f.write(f"**å¯¦é©—æ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**ç¸½åŸ·è¡Œæ™‚é–“**: {(time.time() - self.start_time)/3600:.2f} å°æ™‚\n\n")
            
            f.write("## ğŸ“Š å¯¦é©—çµ±è¨ˆ\n\n")
            f.write(f"- **ç¸½å¯¦é©—æ•¸**: {len(all_experiments)}\n")
            f.write(f"- **æˆåŠŸå¯¦é©—æ•¸**: {len(successful_experiments)}\n")
            f.write(f"- **æˆåŠŸç‡**: {len(successful_experiments)/len(all_experiments)*100:.1f}%\n")
            f.write(f"- **å¹³å‡åŸ·è¡Œæ™‚é–“**: {np.mean([exp.execution_time for exp in successful_experiments]):.1f}s\n\n")
            
            f.write("## ğŸ¯ é—œéµç™¼ç¾\n\n")
            f.write("### K-èª¤å·®é—œä¿‚\n\n")
            f.write("| Kå€¼ | å¹³å‡L2èª¤å·®(u) | æ¨™æº–å·® | å¯¦é©—æ•¸é‡ |\n")
            f.write("|-----|---------------|--------|----------|\n")
            
            for k in k_values:
                k_experiments = [exp for exp in successful_experiments 
                               if exp.config.k_value == k]
                count = len(k_experiments)
                if count > 0:
                    avg_error = np.mean([exp.l2_error['u'] for exp in k_experiments])
                    std_error = np.std([exp.l2_error['u'] for exp in k_experiments])
                    f.write(f"| {k} | {avg_error:.4f} | {std_error:.4f} | {count} |\n")
            
            f.write("\n### ä½ˆé»ç­–ç•¥æ¯”è¼ƒ\n\n")
            strategies = ['qr-pivot', 'random', 'uniform']
            for strategy in strategies:
                strategy_experiments = [exp for exp in successful_experiments 
                                      if exp.config.placement_strategy == strategy]
                if strategy_experiments:
                    avg_error = np.mean([exp.l2_error['u'] for exp in strategy_experiments])
                    count = len(strategy_experiments)
                    f.write(f"- **{strategy}**: å¹³å‡L2èª¤å·® {avg_error:.4f} ({count} å€‹å¯¦é©—)\n")
            
            f.write("\n## ğŸ“ è©³ç´°è³‡æ–™\n\n")
            f.write("å¯¦é©—åŸå§‹è³‡æ–™ä¿å­˜åœ¨ä»¥ä¸‹æª”æ¡ˆ:\n")
            for phase_name in all_results.keys():
                f.write(f"- `checkpoint_{phase_name}.json`\n")
        
        logger.info(f"æœ€çµ‚å ±å‘Šå·²ç”Ÿæˆ: {report_file}")


def main():
    parser = argparse.ArgumentParser(description='K-æƒæå¯¦é©—è‡ªå‹•åŒ–åŸ·è¡Œ')
    parser.add_argument('--config', type=str, required=True,
                       help='å¯¦é©—é…ç½®æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--output_dir', type=str, required=True,
                       help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--phase', type=str, default='all',
                       choices=['all', 'phase1_core', 'phase2_placement', 
                               'phase3_noise', 'phase4_final'],
                       help='åŸ·è¡Œçš„å¯¦é©—éšæ®µ')
    parser.add_argument('--max_time_hours', type=float, default=2.0,
                       help='æœ€å¤§åŸ·è¡Œæ™‚é–“ï¼ˆå°æ™‚ï¼‰')
    parser.add_argument('--use_real_data', action='store_true',
                       help='ä½¿ç”¨çœŸå¯¦JHTDBè³‡æ–™ï¼ˆå¦å‰‡ä½¿ç”¨æ¨¡æ“¬è³‡æ–™ï¼‰')
    parser.add_argument('--resume', action='store_true',
                       help='å¾æª¢æŸ¥é»æ¢å¾©åŸ·è¡Œ')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ å•Ÿå‹• K-æƒæå¯¦é©—...")
    logger.info(f"é…ç½®æª”æ¡ˆ: {args.config}")
    logger.info(f"è¼¸å‡ºç›®éŒ„: {args.output_dir}")
    logger.info(f"åŸ·è¡Œéšæ®µ: {args.phase}")
    logger.info(f"æœ€å¤§æ™‚é–“: {args.max_time_hours} å°æ™‚")
    logger.info(f"ä½¿ç”¨çœŸå¯¦è³‡æ–™: {not args.use_real_data}")
    
    try:
        # åˆå§‹åŒ–å¯¦é©—å¥—ä»¶
        experiment_suite = KScanExperimentSuite(
            config_path=args.config,
            output_dir=Path(args.output_dir),
            max_time_hours=args.max_time_hours,
            use_real_data=args.use_real_data
        )
        
        # åŸ·è¡Œå¯¦é©—
        if args.phase == 'all':
            results = experiment_suite.run_all_phases()
        else:
            results = {args.phase: experiment_suite.run_phase(args.phase)}
        
        # è¼¸å‡ºç¸½çµ
        total_experiments = sum(len(phase_results) for phase_results in results.values())
        successful_experiments = sum(
            sum(1 for exp in phase_results if exp.success) 
            for phase_results in results.values()
        )
        
        logger.info("âœ… K-æƒæå¯¦é©—å®Œæˆ!")
        logger.info(f"ç¸½å¯¦é©—æ•¸: {total_experiments}")
        logger.info(f"æˆåŠŸå¯¦é©—æ•¸: {successful_experiments}")
        logger.info(f"æˆåŠŸç‡: {successful_experiments/total_experiments*100:.1f}%")
        logger.info(f"çµæœä¿å­˜åœ¨: {args.output_dir}")
        
    except Exception as e:
        logger.error(f"å¯¦é©—åŸ·è¡Œå¤±æ•—: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    main()