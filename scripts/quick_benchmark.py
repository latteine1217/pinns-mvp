#!/usr/bin/env python3
"""
å¿«é€Ÿæ€§èƒ½åŸºæº–æ¸¬è©¦è…³æœ¬
ç”¨æ–¼é©—è­‰åŸºæœ¬åŠŸèƒ½å’Œæ”¶é›†åˆæ­¥æ€§èƒ½æ•¸æ“š
"""

import os
import sys
import time
import json
import yaml
import platform
from datetime import datetime
from pathlib import Path

import torch
import psutil
import numpy as np

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def quick_hardware_info():
    """å¿«é€Ÿæ”¶é›†ç¡¬é«”è³‡è¨Š"""
    try:
        cpu_freq = psutil.cpu_freq()
        cpu_freq_max = f"{cpu_freq.max:.1f}" if cpu_freq and cpu_freq.max else "Unknown"
        
        return {
            'platform': platform.platform(),
            'cpu_count': psutil.cpu_count(logical=True),
            'cpu_freq_max': cpu_freq_max,
            'memory_total_gb': psutil.virtual_memory().total / (1024**3),
            'torch_version': torch.__version__,
            'cuda_available': torch.cuda.is_available(),
            'device_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU only"
        }
    except Exception as e:
        return {'error': str(e)}

def quick_training_test():
    """å¿«é€Ÿè¨“ç·´æ¸¬è©¦"""
    from pinnx.models.fourier_mlp import PINNNet
    from pinnx.models.wrappers import ScaledPINNWrapper
    
    # è¼‰å…¥é…ç½®
    with open('configs/defaults.yml', 'r') as f:
        config = yaml.safe_load(f)
    
    # è¨­å®šè¨­å‚™
    device = torch.device('cpu')  # å¼·åˆ¶ä½¿ç”¨ CPU ä¾†ç¢ºä¿ä¸€è‡´æ€§
    
    # å‰µå»ºå°å‹æ¨¡å‹é€²è¡Œå¿«é€Ÿæ¸¬è©¦
    model = PINNNet(
        in_dim=3,  # t, x, y
        out_dim=3,  # u, v, p
        width=32,  # å°å¯¬åº¦
        depth=3,   # æ·ºæ·±åº¦
        activation='tanh',
        fourier_m=16,  # å°‘é‡ Fourier features
        fourier_sigma=1.0
    ).to(device)
    
    # åŒ…è£ç‚º ScaledPINNWrapper
    model = ScaledPINNWrapper(model).to(device)
    
    # è¨ˆç®—åƒæ•¸æ•¸é‡
    total_params = sum(p.numel() for p in model.parameters())
    
    # å‰µå»ºå„ªåŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # ç”Ÿæˆå°é‡æ¸¬è©¦è³‡æ–™
    n_points = 100
    x = torch.rand(n_points, 3).to(device)  # [t, x, y]
    
    # å¿«é€Ÿè¨“ç·´å¾ªç’°
    times = []
    losses = []
    
    for epoch in range(10):  # åªè¨“ç·´ 10 æ­¥
        start_time = time.time()
        
        optimizer.zero_grad()
        
        # å‰å‘å‚³æ’­
        x.requires_grad_(True)
        pred = model(x)
        
        # ç°¡å–®æå¤±ï¼ˆé æ¸¬å€¼çš„å¹³æ–¹å’Œï¼‰
        loss = torch.mean(pred**2)
        
        # åå‘å‚³æ’­
        loss.backward()
        optimizer.step()
        
        epoch_time = time.time() - start_time
        times.append(epoch_time)
        losses.append(loss.item())
    
    return {
        'total_params': total_params,
        'avg_epoch_time': np.mean(times),
        'final_loss': losses[-1],
        'all_losses': losses,
        'epoch_times': times
    }

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ åŸ·è¡Œå¿«é€Ÿæ€§èƒ½åŸºæº–æ¸¬è©¦...")
    
    # æ”¶é›†ç¡¬é«”è³‡è¨Š
    hw_info = quick_hardware_info()
    print(f"ç¡¬é«”å¹³å°: {hw_info.get('platform', 'Unknown')}")
    print(f"CPU æ ¸å¿ƒæ•¸: {hw_info.get('cpu_count', 'Unknown')}")
    print(f"è¨˜æ†¶é«”: {hw_info.get('memory_total_gb', 'Unknown'):.1f} GB")
    print(f"PyTorch ç‰ˆæœ¬: {hw_info.get('torch_version', 'Unknown')}")
    print(f"CUDA å¯ç”¨: {hw_info.get('cuda_available', False)}")
    
    # åŸ·è¡Œå¿«é€Ÿè¨“ç·´æ¸¬è©¦
    print("\nâš¡ åŸ·è¡Œå¿«é€Ÿè¨“ç·´æ¸¬è©¦...")
    start_time = time.time()
    try:
        training_result = quick_training_test()
        total_time = time.time() - start_time
        
        print(f"âœ… è¨“ç·´æ¸¬è©¦å®Œæˆï¼")
        print(f"ç¸½æ¸¬è©¦æ™‚é–“: {total_time:.2f} ç§’")
        print(f"æ¨¡å‹åƒæ•¸æ•¸é‡: {training_result['total_params']:,}")
        print(f"å¹³å‡ epoch æ™‚é–“: {training_result['avg_epoch_time']:.4f} ç§’")
        print(f"æœ€çµ‚æå¤±: {training_result['final_loss']:.6f}")
        
        # å„²å­˜çµæœ
        results = {
            'timestamp': datetime.now().isoformat(),
            'hardware_info': hw_info,
            'training_test': training_result,
            'total_test_time': total_time
        }
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_dir = Path('tasks/task-002')
        output_dir.mkdir(exist_ok=True)
        
        # å„²å­˜çµæœ
        with open(output_dir / 'quick_baseline_data.json', 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ“„ çµæœå·²å„²å­˜åˆ°: {output_dir / 'quick_baseline_data.json'}")
        
        # è©•ä¼°æ˜¯å¦ç¬¦åˆåŸºæº–
        meets_standards = True
        if training_result['avg_epoch_time'] > 0.1:
            print(f"âš ï¸  å–® epoch æ™‚é–“ {training_result['avg_epoch_time']:.4f}s è¶…éç›®æ¨™ 0.1s")
            meets_standards = False
        
        if training_result['final_loss'] > 1e-3:
            print(f"âš ï¸  æœ€çµ‚æå¤± {training_result['final_loss']:.6f} è¶…éç›®æ¨™ 1e-3")
            meets_standards = False
        
        if meets_standards:
            print("âœ… æ‰€æœ‰æ€§èƒ½æŒ‡æ¨™ç¬¦åˆåŸºæº–è¦æ±‚ï¼")
        else:
            print("âŒ éƒ¨åˆ†æ€§èƒ½æŒ‡æ¨™éœ€è¦å„ªåŒ–")
            
        return results
        
    except Exception as e:
        print(f"âŒ è¨“ç·´æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()