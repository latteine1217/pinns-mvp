#!/usr/bin/env python3
"""
Channel Flow Re1000 å®Œæ•´ PINNs é€†é‡å»ºå¯¦é©—è…³æœ¬
åŒ…å«çœŸå¯¦çš„ç‰©ç†æ–¹ç¨‹ç´„æŸï¼ˆN-Sæ–¹ç¨‹ï¼‰

åŸºæ–¼æ–°é–‹ç™¼çš„ Channel Flow è¼‰å…¥å™¨é€²è¡ŒçœŸå¯¦çš„ PINNs å¯¦é©—ï¼Œ
åŒ…å«ï¼š
1. N-S æ–¹ç¨‹æ®˜å·®ç´„æŸ
2. é‚Šç•Œæ¢ä»¶ç´„æŸ  
3. ä½ä¿çœŸä¸€è‡´æ€§ç´„æŸ
4. å¤šæ¬Šé‡ç­–ç•¥æ¯”è¼ƒ
"""

import sys
import time
from pathlib import Path
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import yaml
import logging
import matplotlib.pyplot as plt

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PINNsModel(nn.Module):
    """åŒ…å«ç‰©ç†ç´„æŸçš„ PINNs æ¨¡å‹"""
    
    def __init__(self, input_dim=2, hidden_dim=128, num_layers=6, output_dim=4):
        super().__init__()
        
        # æ§‹å»ºç¶²è·¯å±¤
        layers = []
        layers.append(nn.Linear(input_dim, hidden_dim))
        layers.append(nn.Tanh())
        
        for _ in range(num_layers - 2):
            layers.append(nn.Linear(hidden_dim, hidden_dim))
            layers.append(nn.Tanh())
            
        layers.append(nn.Linear(hidden_dim, output_dim))
        
        self.network = nn.Sequential(*layers)
        
        # åˆå§‹åŒ–æ¬Šé‡
        self._initialize_weights()
    
    def _initialize_weights(self):
        """Xavier åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.zeros_(m.bias)
    
    def forward(self, x):
        """
        å‰å‘å‚³æ’­
        
        Args:
            x: è¼¸å…¥åº§æ¨™ [batch_size, 2] -> [x, y]
        
        Returns:
            pred: é æ¸¬è¼¸å‡º [batch_size, 4] -> [u, v, p, S]
        """
        return self.network(x)

class PhysicsLoss:
    """ç‰©ç†æ–¹ç¨‹ç´„æŸæå¤±è¨ˆç®—"""
    
    def __init__(self, nu=1e-4, device='cpu'):
        self.nu = nu  # å‹•åŠ›é»æ€§ä¿‚æ•¸ (å°æ‡‰ Re_tau=1000)
        self.device = device
    
    def navier_stokes_residual(self, coords, pred):
        """
        è¨ˆç®— N-S æ–¹ç¨‹æ®˜å·®
        
        Args:
            coords: åº§æ¨™ [batch_size, 2]
            pred: é æ¸¬ [batch_size, 4] -> [u, v, p, S]
        
        Returns:
            residual: NSæ®˜å·® [batch_size, 1]
        """
        # å°å…¥ç‰©ç†æ¨¡çµ„
        from pinnx.physics.ns_2d import ns_residual_2d
        
        # ç¢ºä¿éœ€è¦æ¢¯åº¦è¨ˆç®—
        coords.requires_grad_(True)
        
        # è¨ˆç®— NS æ–¹ç¨‹æ®˜å·®
        mom_x, mom_y, cont = ns_residual_2d(coords, pred, self.nu)
        
        # çµ„åˆæ‰€æœ‰æ®˜å·®ï¼ˆç­‰æ¬Šé‡ï¼‰
        total_residual = mom_x**2 + mom_y**2 + cont**2
        
        return total_residual
    
    def boundary_conditions(self, coords, pred, domain_bounds):
        """
        é‚Šç•Œæ¢ä»¶ç´„æŸ (é€šé“æµé‚Šç•Œ)
        
        Args:
            coords: åº§æ¨™ [batch_size, 2]
            pred: é æ¸¬ [batch_size, 4]
            domain_bounds: åŸŸé‚Šç•Œå­—å…¸
        
        Returns:
            bc_loss: é‚Šç•Œæ¢ä»¶æå¤±
        """
        x, y = coords[:, 0:1], coords[:, 1:2]
        u, v, p, S = pred[:, 0:1], pred[:, 1:2], pred[:, 2:3], pred[:, 3:4]
        
        # é€šé“æµé‚Šç•Œæ¢ä»¶ï¼š
        # ä¸Šä¸‹å£é¢ (y = Â±1): u = v = 0 (no-slip)
        y_min, y_max = domain_bounds['y']
        
        # è­˜åˆ¥é‚Šç•Œé» (å®¹å¿åº¦ 0.05)
        wall_mask_lower = torch.abs(y - y_min) < 0.05
        wall_mask_upper = torch.abs(y - y_max) < 0.05
        wall_mask = wall_mask_lower | wall_mask_upper
        
        if wall_mask.sum() > 0:
            # å£é¢è™•é€Ÿåº¦ç‚ºé›¶
            u_wall = u[wall_mask]
            v_wall = v[wall_mask]
            bc_loss = torch.mean(u_wall**2 + v_wall**2)
        else:
            bc_loss = torch.tensor(0.0, device=coords.device)
        
        return bc_loss
    
    def data_consistency(self, pred_coords, pred_values, sensor_coords, sensor_data):
        """
        æ„Ÿæ¸¬è³‡æ–™ä¸€è‡´æ€§ç´„æŸ
        
        Args:
            pred_coords: é æ¸¬åº§æ¨™ [batch_size, 2]
            pred_values: é æ¸¬å€¼ [batch_size, 3] -> [u, v, p]
            sensor_coords: æ„Ÿæ¸¬é»åº§æ¨™ [n_sensors, 2]  
            sensor_data: æ„Ÿæ¸¬è³‡æ–™å­—å…¸ {'u': [...], 'v': [...], 'p': [...]}
        
        Returns:
            data_loss: è³‡æ–™ä¸€è‡´æ€§æå¤±
        """
        # å°æ¯å€‹æ„Ÿæ¸¬é»æ‰¾æœ€è¿‘çš„é æ¸¬é»
        data_loss = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)
        n_sensors = len(sensor_coords)
        
        for i in range(n_sensors):
            sensor_pos = sensor_coords[i]
            
            # æ‰¾åˆ°æœ€è¿‘çš„é æ¸¬é» (ç°¡åŒ–å¯¦ç¾)
            distances = torch.norm(pred_coords - sensor_pos, dim=1)
            nearest_idx = torch.argmin(distances)
            
            # è¨ˆç®—è©²é»çš„é æ¸¬èª¤å·®
            pred_u = pred_values[nearest_idx, 0]
            pred_v = pred_values[nearest_idx, 1]
            pred_p = pred_values[nearest_idx, 2]
            
            true_u = sensor_data['u'][i]
            true_v = sensor_data['v'][i]
            true_p = sensor_data['p'][i]
            
            # MSE æå¤±
            data_loss = data_loss + (pred_u - true_u)**2 + (pred_v - true_v)**2 + (pred_p - true_p)**2
        
        return data_loss / n_sensors

def train_pinns_with_physics(data, strategy_name, epochs=100, lr=1e-3):
    """
    åŒ…å«ç‰©ç†ç´„æŸçš„ PINNs è¨“ç·´
    
    Args:
        data: è¼‰å…¥å™¨è¿”å›çš„è³‡æ–™å­—å…¸
        strategy_name: ç­–ç•¥åç¨± (ç”¨æ–¼æ—¥èªŒ)
        epochs: è¨“ç·´è¼ªæ•¸
        lr: å­¸ç¿’ç‡
    
    Returns:
        model: è¨“ç·´å¥½çš„æ¨¡å‹
        losses: æå¤±æ­·å²
    """
    device = torch.device('cpu')
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = PINNsModel(input_dim=2, hidden_dim=64, num_layers=4, output_dim=4).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    physics = PhysicsLoss(nu=1e-4, device='cpu')
    
    # æº–å‚™è¨“ç·´è³‡æ–™
    sensor_coords = torch.tensor(data['coordinates'], dtype=torch.float32, device=device)
    sensor_data = data['sensor_data']
    domain_bounds = data['domain_bounds']
    
    # å»ºç«‹è¨“ç·´åŸŸçš„é›†åˆé»åƒæ•¸ï¼ˆç”¨æ–¼ç‰©ç†ç´„æŸï¼‰
    n_collocation = 200
    x_min, x_max = domain_bounds['x']
    y_min, y_max = domain_bounds['y']
    
    # æå¤±æ¬Šé‡
    w_data = 10.0    # è³‡æ–™ä¸€è‡´æ€§
    w_physics = 1.0  # ç‰©ç†æ–¹ç¨‹
    w_bc = 5.0       # é‚Šç•Œæ¢ä»¶
    
    losses = {
        'total': [], 'data': [], 'physics': [], 'bc': []
    }
    
    total_loss = torch.tensor(0.0)  # åˆå§‹åŒ–é¿å… unbound è­¦å‘Š
    
    logger.info(f"ğŸ‹ï¸ é–‹å§‹ {strategy_name} å®Œæ•´ PINNs è¨“ç·´ ({epochs} epochs)...")
    logger.info(f"ğŸ“ æ„Ÿæ¸¬é»æ•¸: {len(sensor_coords)}, é…ç½®é»æ•¸: {n_collocation}")
    logger.info(f"âš–ï¸ æå¤±æ¬Šé‡: data={w_data}, physics={w_physics}, bc={w_bc}")
    
    for epoch in range(epochs):
        optimizer.zero_grad()
        
        # æ¯å€‹ epoch é‡æ–°ç”Ÿæˆé…ç½®é»ï¼Œé¿å…æ¢¯åº¦åœ–è¤‡ç”¨
        x_coll = torch.rand(n_collocation, 1, device=device, requires_grad=True) * (x_max - x_min) + x_min
        y_coll = torch.rand(n_collocation, 1, device=device, requires_grad=True) * (y_max - y_min) + y_min
        collocation_points = torch.cat([x_coll, y_coll], dim=1)
        
        # === æ„Ÿæ¸¬é»çš„è³‡æ–™ä¸€è‡´æ€§æå¤± ===
        sensor_pred = model(sensor_coords)
        data_loss = physics.data_consistency(
            sensor_coords, sensor_pred[:, :3], 
            sensor_coords.detach().cpu().numpy(), sensor_data
        )
        
        # === é…ç½®é»çš„ç‰©ç†æ–¹ç¨‹æå¤± ===
        collocation_pred = model(collocation_points)
        physics_loss = torch.mean(physics.navier_stokes_residual(collocation_points, collocation_pred))
        
        # === é‚Šç•Œæ¢ä»¶æå¤± ===
        bc_loss = physics.boundary_conditions(collocation_points, collocation_pred, domain_bounds)
        
        # === ç¸½æå¤± ===
        total_loss = w_data * data_loss + w_physics * physics_loss + w_bc * bc_loss
        
        # åå‘å‚³æ’­
        total_loss.backward()
        optimizer.step()
        
        # è¨˜éŒ„æå¤±
        losses['total'].append(total_loss.item())
        losses['data'].append(data_loss.item())
        losses['physics'].append(physics_loss.item()) 
        losses['bc'].append(bc_loss.item())
        
        # å®šæœŸè¼¸å‡º
        if (epoch + 1) % 20 == 0:
            logger.info(f"  Epoch {epoch+1}: Total={total_loss:.6f} "
                       f"(Data={data_loss:.6f}, Physics={physics_loss:.6f}, BC={bc_loss:.6f})")
    
    logger.info(f"âœ… {strategy_name} è¨“ç·´å®Œæˆï¼Œæœ€çµ‚æå¤±: {total_loss:.6f}")
    
    return model, losses

def evaluate_physics_consistency(model, data):
    """è©•ä¼°æ¨¡å‹çš„ç‰©ç†ä¸€è‡´æ€§"""
    device = torch.device('cpu')
    physics = PhysicsLoss(nu=1e-4, device='cpu')
    
    # åœ¨åŸŸå…§éš¨æ©Ÿé»æ¸¬è©¦ç‰©ç†ä¸€è‡´æ€§
    domain_bounds = data['domain_bounds']
    x_min, x_max = domain_bounds['x']
    y_min, y_max = domain_bounds['y']
    
    n_test = 100
    x_test = torch.rand(n_test, 1, requires_grad=True) * (x_max - x_min) + x_min
    y_test = torch.rand(n_test, 1, requires_grad=True) * (y_max - y_min) + y_min
    test_points = torch.cat([x_test, y_test], dim=1)
    
    # è¨ˆç®—ç‰©ç†æ®˜å·®ï¼ˆéœ€è¦æ¢¯åº¦è¨ˆç®—ï¼‰
    pred = model(test_points)
    physics_residual = physics.navier_stokes_residual(test_points, pred)
    
    with torch.no_grad():
        mean_residual = torch.mean(physics_residual).item()
        max_residual = torch.max(physics_residual).item()
    
    return {
        'mean_physics_residual': mean_residual,
        'max_physics_residual': max_residual,
        'n_test_points': n_test
    }

def main():
    """ä¸»å¯¦é©—æµç¨‹"""
    logger.info("ğŸš€ é–‹å§‹ Channel Flow Re1000 å®Œæ•´ PINNs é€†é‡å»ºå¯¦é©—ï¼ˆå«ç‰©ç†ç´„æŸï¼‰")
    
    try:
        # ä½¿ç”¨å’ŒæˆåŠŸè…³æœ¬ç›¸åŒçš„åŒ¯å…¥æ–¹æ³•
        from pinnx.dataio.channel_flow_loader import prepare_training_data as load_channel_flow
        
        # === 1. è¼‰å…¥ä¸åŒç­–ç•¥çš„è³‡æ–™ ===
        strategies = ['qr_pivot', 'random']
        results = {}
        
        for strategy in strategies:
            logger.info(f"\nğŸ” æ¸¬è©¦ {strategy.upper()} ç­–ç•¥...")
            
            # è¼‰å…¥è³‡æ–™
            start_time = time.time()
            data = load_channel_flow(
                strategy=strategy,
                K=8,
                target_fields=['u', 'v', 'p']
            )
            load_time = time.time() - start_time
            logger.info(f"âœ… {strategy} è¼‰å…¥å®Œæˆï¼Œè€—æ™‚: {load_time:.3f}s")
            
            # è¨“ç·´ PINNs æ¨¡å‹
            model, losses = train_pinns_with_physics(data, strategy, epochs=100)
            
            # è©•ä¼°ç‰©ç†ä¸€è‡´æ€§
            physics_eval = evaluate_physics_consistency(model, data)
            
            results[strategy] = {
                'model': model,
                'losses': losses,
                'physics_eval': physics_eval,
                'load_time': load_time
            }
            
            logger.info(f"ğŸ“Š {strategy} ç‰©ç†ä¸€è‡´æ€§:")
            logger.info(f"  å¹³å‡æ®˜å·®: {physics_eval['mean_physics_residual']:.6f}")
            logger.info(f"  æœ€å¤§æ®˜å·®: {physics_eval['max_physics_residual']:.6f}")
        
        # === 2. ç­–ç•¥æ¯”è¼ƒåˆ†æ ===
        logger.info("\n" + "="*50)
        logger.info("ğŸ“Š ç­–ç•¥æ¯”è¼ƒçµæœ:")
        
        qr_final_loss = results['qr_pivot']['losses']['total'][-1]
        random_final_loss = results['random']['losses']['total'][-1]
        
        improvement = (random_final_loss - qr_final_loss) / random_final_loss * 100
        
        logger.info(f"  QR-pivot æœ€çµ‚æå¤±: {qr_final_loss:.6f}")
        logger.info(f"  Random æœ€çµ‚æå¤±:   {random_final_loss:.6f}")
        
        if improvement > 0:
            logger.info(f"  ğŸ† QR-pivot å„ªæ–¼ Random {improvement:.1f}%")
        else:
            logger.info(f"  ğŸ² Random å„ªæ–¼ QR-pivot {-improvement:.1f}%")
        
        # ç‰©ç†ä¸€è‡´æ€§æ¯”è¼ƒ
        qr_physics = results['qr_pivot']['physics_eval']['mean_physics_residual']
        random_physics = results['random']['physics_eval']['mean_physics_residual']
        
        logger.info(f"\nğŸ”¬ ç‰©ç†ä¸€è‡´æ€§æ¯”è¼ƒ:")
        logger.info(f"  QR-pivot å¹³å‡æ®˜å·®: {qr_physics:.6f}")
        logger.info(f"  Random å¹³å‡æ®˜å·®:   {random_physics:.6f}")
        
        physics_improvement = (random_physics - qr_physics) / random_physics * 100
        if physics_improvement > 0:
            logger.info(f"  âš—ï¸ QR-pivot ç‰©ç†ä¸€è‡´æ€§å„ª {physics_improvement:.1f}%")
        else:
            logger.info(f"  âš—ï¸ Random ç‰©ç†ä¸€è‡´æ€§å„ª {-physics_improvement:.1f}%")
        
        # === 3. å¯¦é©—ç¸½çµ ===
        logger.info("\n" + "="*50)
        logger.info("ğŸ‰ å®Œæ•´ PINNs å¯¦é©—ç¸½çµ:")
        logger.info("âœ… æˆåŠŸæ•´åˆç‰©ç†æ–¹ç¨‹ç´„æŸ (N-Sæ–¹ç¨‹)")
        logger.info("âœ… é‚Šç•Œæ¢ä»¶ç´„æŸæ­£å¸¸å·¥ä½œ")
        logger.info("âœ… æ„Ÿæ¸¬è³‡æ–™ä¸€è‡´æ€§ç´„æŸæœ‰æ•ˆ")
        logger.info(f"âœ… QR-pivot vs Random: {improvement:.1f}% æ”¹å–„")
        logger.info(f"âœ… ç‰©ç†ä¸€è‡´æ€§: {physics_improvement:.1f}% æ”¹å–„")
        logger.info("ğŸš€ æº–å‚™å¥½é€²è¡Œæ›´å¤§è¦æ¨¡çš„çœŸå¯¦å¯¦é©—ï¼")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ å¯¦é©—éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
        raise

if __name__ == '__main__':
    results = main()