# ========================================
# PirateNet Google Colab 配置 - 2D 切片版 (修正版 v2)
# ========================================
# 用途：低記憶體 Colab 訓練，修復 NaN loss 問題
# 預期時間：30-60 分鐘（1000 epochs, T4 GPU）
# 目標：L2 誤差 ≤ 20%（2D 切片較寬鬆）
# 記憶體使用：~6 GB（適合 Colab 免費版）
#
# 🔧 v2 修正重點：
#   1. 大幅降低學習率 (1e-3 → 1e-4)
#   2. 啟用梯度裁剪並設為保守值 (0.5)
#   3. 降低 batch size (2048 → 1024)
#   4. 簡化損失權重配置
#   5. 增加 warmup epochs (20 → 50)
#   6. 明確資料歸一化配置

experiment:
  name: "colab_piratenet_2d_fixed_v2"
  version: "v2.0"
  seed: 42
  device: "cuda"
  precision: "float32"
  description: "PirateNet 2D slice - fixed NaN loss issue"

# =============================================================================
# 資料配置（2D 切片）
# =============================================================================
data:
  type: "jhtdb_channel"
  dataset: "channel"
  re_tau: 1000
  
  data_dir: "./data/jhtdb"
  lowfi_dir: "./data/lowfi"
  
  # JHTDB 資料載入
  jhtdb_config:
    enabled: true
    dataset: "channel"
    re_tau: 1000
    time_step: 0.0
    use_cache: true
    
    # ✅ 更新為實際 JHTDB Cutout 網格
    grid_shape: [512, 128, 512]  # (Nx, Ny, Nz)
    
    # Domain configuration (從 integration_test_report.json)
    domain:
      x: [0.0, 25.083654403686523]  # 實際範圍
      y: [-1.0, 0.9998791217803955]  # ✅ 正確的壁面位置
      z: [0.0, 9.406370162963867]    # 實際範圍
    
    # Physical parameters
    Re_tau: 1000.0
    nu: 5.0e-5
    u_tau: 0.04997
    
    # ✅ 新增：HDF5 檔案路徑
    data_dir: "data/jhtdb/channel_flow_re1000/raw"
    velocity_file: "JHU Turbulence Channel_velocity_t1.h5"
    pressure_file: "JHU Turbulence Channel_pressure_t1.h5"
  
  # Top-level domain (for physics module - 從實際 JHTDB 數據)
  domain:
    x_min: 0.0
    x_max: 25.083654403686523
    y_min: -1.0
    y_max: 0.9998791217803955
    z_min: 0.0
    z_max: 9.406370162963867
  
  # 🔧 2D 切片配置
  slice_2d:
    enabled: true
    plane: "xy"  # 主剪切平面（x-y 平面）
    z_position: 4.703  # z 中心位置（域範圍的中點）
    steady_state: true
    time_average_window: [20.0, 26.0]
  
  # 🔧 v2: 降低資料點數以提升穩定性
  num_sensors: 50
  sensor_type: "qr_pivot"
  sensor_noise: 0.01
  
  num_collocation: 2048  # ✅ 降低（原 4096）
  num_boundary: 128      # ✅ 降低（原 256）
  num_initial: 64        # ✅ 降低（原 128）
  
  # 🔧 v2: 明確啟用資料歸一化
  normalization:
    enabled: true
    method: "z_score"  # 標準化到均值 0、標準差 1
    per_variable: true
    
    # ✅ 使用實際 JHTDB Cutout 統計量（從 integration_test_report.json）
    reference_stats:
      u_mean: 0.729   # 從整合測試提取的感測點均值
      u_std: 0.439
      v_mean: -0.002
      v_std: 0.033
      w_mean: 0.001
      w_std: 0.036
      p_mean: -0.002
      p_std: 0.004

# =============================================================================
# 感測點配置
# =============================================================================
sensors:
  K: 50
  selection_method: "qr_pivot"
  spatial_coverage: "optimal"

# =============================================================================
# 模型架構（PirateNet 標準配置 - 保守版）
# =============================================================================
model:
  type: "enhanced_fourier_mlp"
  
  in_dim: 3   # (x, y, z) - 即使是 2D 切片也保留 z 座標
  out_dim: 4  # (u, v, w, p)
  depth: 6    # PirateNet: 2 residual blocks × 3 layers
  width: 512  # 🔧 v2: 降低寬度 (768 → 512) 以提升穩定性
  
  activation: "tanh"  # 🔧 v2: 使用 tanh (更穩定於 swish)
  
  # Fourier Features（PirateNet RFF 配置）
  use_fourier: true
  fourier_m: 64
  fourier_sigma: 1.0  # 🔧 v2: 降低 σ (2.0 → 1.0)
  fourier_multiscale: false
  trainable_fourier: false
  
  # RWF（PirateNet 權重因子化）
  use_rwf: true
  rwf_scale_mean: 1.0
  rwf_scale_std: 0.05  # 🔧 v2: 降低變異性 (0.1 → 0.05)
  
  use_residual: true
  use_layer_norm: true
  dropout: 0.0
  
  # 🔧 v2: 權重初始化配置
  init_method: "xavier_uniform"  # 更穩定的初始化
  init_gain: 0.5  # 保守的增益

# =============================================================================
# 訓練配置（Colab 優化 + 數值穩定性強化）
# =============================================================================
training:
  epochs: 1000
  batch_size: 1024  # 🔧 v2: 降低 (2048 → 1024)
  
  # 優化器
  optimizer:
    type: "adam"
    lr: 1.0e-4  # 🔧 v2: 降低學習率 (1e-3 → 1e-4)
    betas: [0.9, 0.999]
    eps: 1.0e-8
    weight_decay: 0.0
    amsgrad: false  # 保持簡單
  
  # 🔧 v2: 更保守的學習率調度
  scheduler:
    type: "warmup_exponential"
    warmup_epochs: 50  # 🔧 增加 warmup (20 → 50)
    decay_rate: 0.95   # 🔧 更緩慢的衰減 (0.9 → 0.95)
    decay_epochs: 50
    min_lr: 1.0e-7
  
  # 採樣配置
  sampling:
    pde_points: 2048       # 🔧 降低
    boundary_points: 128   # 🔧 降低
    wall_clustering: 0.3
  
  validation_freq: 50
  checkpoint_freq: 100
  log_interval: 10
  
  # 🔧 v2: 關鍵修復 - 強化梯度裁剪
  gradient_clip: 0.5  # 🔧 更保守的裁剪值
  gradient_clip_norm_type: 2.0  # L2 norm
  
  # 🔧 v2: 損失縮放（防止數值下溢）
  loss_scaling: 1.0  # 若仍有問題可調整為 10.0

# =============================================================================
# 損失權重（簡化版 - 避免複雜的自適應機制）
# =============================================================================
losses:
  # 🔧 v2: 簡化權重配置，初期不使用自適應
  data_loss_weight: 100.0  # 🔧 提高資料一致性權重
  pde_loss_weight: 1.0
  wall_loss_weight: 50.0   # 🔧 提高壁面邊界權重
  initial_loss_weight: 100.0
  prior_weight: 0.0  # 🔧 v2: 初期關閉低保真先驗
  
  # 🔧 v2: 階段 1 不使用自適應權重（等穩定後再啟用）
  adaptive_weights:
    enabled: false  # 🔧 先關閉
    method: "gradnorm"
    alpha: 1.5
    update_frequency: 100
  
  # 🔧 v2: 因果權重也先關閉
  causal_weights:
    enabled: false  # 🔧 先關閉
    epsilon: 1.0
    tol: 0.1

# =============================================================================
# 物理配置（2D 切片）
# =============================================================================
physics:
  type: "vs_pinn_channel_flow"
  nu: 5.0e-5
  re_tau: 1000
  u_tau: 0.04997
  
  # 域範圍 (從實際 JHTDB 數據)
  domain:
    x_min: 0.0
    x_max: 25.083654403686523
    y_min: -1.0
    y_max: 0.9998791217803955
    z_min: 0.0
    z_max: 9.406370162963867
  
  # VS-PINN 縮放因子（2D 切片）
  scaling:
    use_scaling: true
    N_x: 2.0   # 流向適度縮放
    N_y: 8.0   # 🔧 v2: 降低 y 方向縮放 (12 → 8)
    N_z: 1.0   # 2D 切片：z 方向不縮放

# =============================================================================
# 輸出配置
# =============================================================================
output:
  checkpoint_dir: "./checkpoints/colab_piratenet_2d_fixed_v2"
  results_dir: "./results/colab_piratenet_2d_fixed_v2"
  visualization_dir: "./results/colab_piratenet_2d_fixed_v2/visualizations"
  save_predictions: true
  save_frequency: 100

# =============================================================================
# 日誌配置
# =============================================================================
logging:
  level: "info"
  log_freq: 10
  tensorboard: true
  wandb: false
  
  metrics:
    - "total_loss"
    - "data_loss"
    - "pde_loss"
    - "wall_loss"
    - "learning_rate"
    - "gradient_norm"  # 🔧 v2: 監控梯度範數

# =============================================================================
# 早停配置
# =============================================================================
early_stopping:
  enabled: true
  patience: 300  # 🔧 v2: 增加耐心 (200 → 300)
  min_delta: 1.0e-6  # 🔧 放寬容忍度
  monitor: "total_loss"

# =============================================================================
# 可重現性配置
# =============================================================================
reproducibility:
  deterministic: true
  benchmark: false

# =============================================================================
# Colab 專用設定
# =============================================================================
colab:
  mount_gdrive: true
  gdrive_checkpoint_dir: "/content/drive/MyDrive/pinns-mvp/checkpoints/colab_piratenet_2d_fixed_v2"
  auto_save_interval: 100
  
  monitor_gpu: true
  monitor_interval: 50
  
  auto_resume: true
  resume_from_gdrive: true

# =============================================================================
# 使用說明
# =============================================================================
usage_notes: |
  🎯 v2 修正版訓練指南：
  
  ✅ 關鍵修正（針對 NaN loss 問題）：
    1. 降低學習率 (1e-3 → 1e-4)
    2. 強化梯度裁剪 (1.0 → 0.5)
    3. 降低 batch size (2048 → 1024)
    4. 降低模型寬度 (768 → 512)
    5. 使用 tanh 激活函數（更穩定）
    6. 簡化損失權重（關閉自適應機制）
    7. 增加 warmup epochs (20 → 50)
    8. 明確啟用資料歸一化
  
  📊 預期結果（1000 epochs）：
    - 訓練時間：40-70 分鐘（T4 GPU）
    - 目標 L2：≤ 20%（2D 切片）
    - 記憶體峰值：~6 GB
    - 損失曲線：穩定下降，無 NaN
  
  🚀 使用命令：
    # Colab 中執行
    !python scripts/train.py --cfg configs/colab_piratenet_2d_slice_fixed_v2.yml
  
  📈 驗證是否修正成功：
    # 檢查前 100 epochs 的損失
    !python scripts/debug/diagnose_piratenet_failure.py \
      --checkpoint checkpoints/colab_piratenet_2d_fixed_v2/epoch_100.pth \
      --config configs/colab_piratenet_2d_slice_fixed_v2.yml
    
    # 關鍵指標：
    # 1. total_loss 穩定下降（無 NaN/Inf）
    # 2. gradient_norm < 10.0（梯度穩定）
    # 3. wall_loss > 0（壁面邊界生效）
  
  ⚠️ 若仍出現 NaN：
    1. 進一步降低學習率 → 5e-5
    2. 減小 Fourier sigma → 0.5
    3. 降低 batch size → 512
    4. 檢查資料是否包含異常值
  
  🔄 階段式訓練策略：
    # 階段 1 (0-200 epochs): 穩定訓練，確保無 NaN
    # 階段 2 (200-500 epochs): 若穩定，可啟用 GradNorm
    # 階段 3 (500-1000 epochs): 精細調整，收斂到目標誤差

# =============================================================================
# 快速啟動命令（複製到 Colab）
# =============================================================================
quick_start_commands: |
  # 1. 掛載 Google Drive
  from google.colab import drive
  drive.mount('/content/drive')
  
  # 2. 克隆專案
  !git clone https://github.com/your-repo/pinns-mvp.git
  %cd pinns-mvp
  
  # 3. 安裝依賴
  !pip install -q torch torchvision torchaudio
  !pip install -q pyJHTDB h5py pyyaml tensorboard
  
  # 4. 下載數據（2D 切片）
  !mkdir -p data/jhtdb/channel_flow_re1000
  !python scripts/fetch_channel_flow.py --K 50 --slice-2d
  
  # 5. 開始訓練（v2 修正版）
  !python scripts/train.py --cfg configs/colab_piratenet_2d_slice_fixed_v2.yml
  
  # 6. 監控訓練（新 Cell）
  %load_ext tensorboard
  %tensorboard --logdir ./checkpoints/colab_piratenet_2d_fixed_v2
  
  # 7. 每 100 epochs 檢查一次（新 Cell，重複執行）
  !tail -30 log/colab_piratenet_2d_fixed_v2/training.log

# =============================================================================
# 診斷檢查清單
# =============================================================================
diagnostic_checklist: |
  訓練前檢查：
  ✅ 1. 資料已正確歸一化（均值~0，標準差~1）
  ✅ 2. 模型權重初始化正常（均值~0，標準差~0.1）
  ✅ 3. 域範圍正確（y ∈ [-1, 1]）
  ✅ 4. 學習率保守（≤ 1e-4）
  ✅ 5. 梯度裁剪啟用（≤ 1.0）
  
  訓練中監控（每 10 epochs）：
  ✅ 1. total_loss 下降且無 NaN
  ✅ 2. gradient_norm < 10.0
  ✅ 3. data_loss 逐步降低
  ✅ 4. wall_loss > 0 且穩定
  ✅ 5. GPU 記憶體使用 < 10 GB
  
  訓練後驗證：
  ✅ 1. 預測場範圍合理（u ∈ [0, 20]）
  ✅ 2. 相對 L2 誤差 < 30%（至少）
  ✅ 3. 統計量均值誤差 < 50%
  ✅ 4. 損失曲線光滑下降
